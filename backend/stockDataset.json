[{"index": 1, "title": "Analysis of market efficiency in main stock markets: using Karman-Filter as an approach", "abstract": "In this study, we utilize the Kalman-Filter analysis to assess market efficiency in major stock markets. The Kalman-Filter operates in two stages, assuming that the data contains a consistent trendline representing the true market value prior to being affected by noise. Unlike traditional methods, it can forecast stock price movements effectively. Our findings reveal significant portfolio returns in emerging markets such as Korea, Vietnam, and Malaysia, as well as positive returns in developed markets like the UK, Europe, Japan, and Hong Kong. This suggests that the Kalman-Filter-based price reversal indicator yields promising results across various market types.", "link": "http://arxiv.org/abs/2404.16449v1"}, {"index": 2, "title": "Natural Capital as a Stock Option", "abstract": "The unfolding climate crisis is a physical manifestation of the damage that market economy, driven by the high intensity consumption of fossil fuels, has inflicted on the Earth System and on the stability conditions that were established by a complex conjugation of natural factors during the Holoecene. The magnitude of the human activities and its predatory nature is such that it is no longer possible to consider the Earth System and the services it provides for the habitability of the planet, the so-called natural capital, as an economical externality. Thus one is left with two main choices in what concerns the sustaintability of the planet's habitability: radical economic degrowth or highly efficient solutions to internalise the maintenance and the restoration of ecosystems and the services of the Earth System. It is proposed that an interesting strategy for the latter is to consider the natural capital as a stock option.", "link": "http://arxiv.org/abs/2404.14041v1"}, {"index": 3, "title": "Stellar population astrophysics (SPA) with the TNG: Measurement of the He I 10830\u00c5 line in the open cluster Stock 2", "abstract": "The precise measurement of stellar abundances plays a pivotal role in providing constraints on the chemical evolution of the Galaxy. However, before spectral lines can be employed as reliable abundance indicators, particularly for challenging elements such as helium, they must undergo thorough scrutiny. Galactic open clusters, representing well-defined single stellar populations, offer an ideal setting for unfolding the information stored in the helium spectral line feature. In this study, we characterize the profile and strength of the helium transition at around 10830{\\AA} (He 10830) in nine giant stars in the Galactic open cluster Stock 2. To remove the influence of weak blending lines near the helium feature, we calibrated their oscillator strengths ($\\log gf$) by employing corresponding abundances obtained from simultaneously observed optical spectra. Our observations reveal that He 10830 in all the targets is observed in absorption, with line strengths categorized into two groups. Three stars exhibit strong absorption, including a discernible secondary component, while the remaining stars exhibit weaker absorption. The lines are in symmetry and align with or around their rest wavelengths, suggesting a stable upper chromosphere without a significant systematic mass motion. We found a correlation between He 10830 strength and Ca II $\\log{R'_\\mathrm{HK}}$ index, with a slope similar to that reported in previous studies on dwarf stars. This correlation underscores the necessity of accounting for stellar chromosphere structure when employing He 10830 as a probe for stellar helium abundance. The procedure of measuring the He 10830 we developed in this study is applicable not only to other Galactic open clusters but also to field stars, with the aim of mapping helium abundance across various types of stars in the future.", "link": "http://arxiv.org/abs/2404.09975v1"}, {"index": 4, "title": "An Iterative Refinement Approach for the Rolling Stock Rotation Problem with Predictive Maintenance", "abstract": "The rolling stock rotation problem with predictive maintenance (RSRP-PdM) involves the assignment of trips to a fleet of vehicles with integrated maintenance scheduling based on the predicted failure probability of the vehicles. These probabilities are determined by the health states of the vehicles, which are considered to be random variables distributed by a parameterized family of probability distribution functions. During the operation of the trips, the corresponding parameters get updated. In this article, we present a dual solution approach for RSRP-PdM and generalize a linear programming based lower bound for this problem to families of probability distribution functions with more than one parameter. For this purpose, we define a rounding function that allows for a consistent underestimation of the parameters and model the problem by a state-expanded event-graph in which the possible states are restricted to a discrete set. This induces a flow problem that is solved by an integer linear program. We show that the iterative refinement of the underlying discretization leads to solutions that converge from below to an optimal solution of the original instance. Thus, the linear relaxation of the considered integer linear program results in a lower bound for RSRP-PdM. Finally, we report on the results of computational experiments conducted on a library of test instances.", "link": "http://arxiv.org/abs/2404.08367v1"}, {"index": 5, "title": "StockGPT: A GenAI Model for Stock Prediction and Trading", "abstract": "This paper introduces StockGPT, an autoregressive ``number'' model trained and tested on 70 million daily U.S. stock returns over nearly 100 years. Treating each return series as a sequence of tokens, StockGPT automatically learns the hidden patterns predictive of future returns via its attention mechanism. On a held-out test sample from 2001 to 2023, a daily rebalanced long-short portfolio formed from StockGPT predictions earns an annual return of 119% with a Sharpe ratio of 6.5. The StockGPT-based portfolio completely spans momentum and long-/short-term reversals, eliminating the need for manually crafted price-based strategies, and also encompasses most leading stock market factors. This highlights the immense promise of generative AI in surpassing human in making complex financial investment decisions.", "link": "http://arxiv.org/abs/2404.05101v2"}, {"index": 6, "title": "Explaining Indian Stock Market through Geometry of Scale free Networks", "abstract": "This paper presents an analysis of the Indian stock market using a method based on embedding the network in a hyperbolic space using Machine learning techniques. We claim novelty on four counts. First, it is demonstrated that the hyperbolic clusters resemble the topological network communities more closely than the Euclidean clusters. Second, we are able to clearly distinguish between periods of market stability and volatility through a statistical analysis of hyperbolic distance and hyperbolic shortest path distance corresponding to the embedded network. Third, we demonstrate that using the modularity of the embedded network significant market changes can be spotted early. Lastly, the coalescent embedding is able to segregate the certain market sectors thereby underscoring its natural clustering ability.", "link": "http://arxiv.org/abs/2404.04710v1"}, {"index": 7, "title": "Train timetabling with rolling stock assignment, short-turning and skip-stop strategy for a bidirectional metro line", "abstract": "Metro train operations is becoming more challenging due to overcrowding and unpredictable irregular passenger demand. To avoid passenger dissatisfaction, metro operators employ various operational strategies to increase the number of train services using limited number of trains. This paper integrates metro timetabling with several operational strategies to improve passenger services with limited number of trains. We propose three optimization models for timetable planning during both peak and off-peak hours: The first model aims to minimize operational costs, the second aims to minimize passenger waiting time, and the third is a multi-objective optimization model that considers both objectives simultaneously. These models integrate operational strategies such as rolling-stock assignment, short-turning, and skip-stop strategies to increase the number of services with limited trains on a bidirectional metro line. The paper also provides detailed calculations for train services, running times, and station dwell times. The proposed models are then implemented on a simplified Santiago metro line 1.", "link": "http://arxiv.org/abs/2404.04233v1"}, {"index": 8, "title": "Quantum computing approach to realistic ESG-friendly stock portfolios", "abstract": "Finding an optimal balance between risk and returns in investment portfolios is a central challenge in quantitative finance, often addressed through Markowitz portfolio theory (MPT). While traditional portfolio optimization is carried out in a continuous fashion, as if stocks could be bought in fractional increments, practical implementations often resort to approximations, as fractional stocks are typically not tradeable. While these approximations are effective for large investment budgets, they deteriorate as budgets decrease. To alleviate this issue, a discrete Markowitz portfolio theory (DMPT) with finite budgets and integer stock weights can be formulated, but results in a non-polynomial (NP)-hard problem. Recent progress in quantum processing units (QPUs), including quantum annealers, makes solving DMPT problems feasible. Our study explores portfolio optimization on quantum annealers, establishing a mapping between continuous and discrete Markowitz portfolio theories. We find that correctly normalized discrete portfolios converge to continuous solutions as budgets increase. Our DMPT implementation provides efficient frontier solutions, outperforming traditional rounding methods, even for moderate budgets. Responding to the demand for environmentally and socially responsible investments, we enhance our discrete portfolio optimization with ESG (environmental, social, governance) ratings for EURO STOXX 50 index stocks. We introduce a utility function incorporating ESG ratings to balance risk, return, and ESG-friendliness, and discuss implications for ESG-aware investors.", "link": "http://dx.doi.org/10.3390/risks12040066"}, {"index": 9, "title": "BERTopic-Driven Stock Market Predictions: Unraveling Sentiment Insights", "abstract": "This paper explores the intersection of Natural Language Processing (NLP) and financial analysis, focusing on the impact of sentiment analysis in stock price prediction. We employ BERTopic, an advanced NLP technique, to analyze the sentiment of topics derived from stock market comments. Our methodology integrates this sentiment analysis with various deep learning models, renowned for their effectiveness in time series and stock prediction tasks. Through comprehensive experiments, we demonstrate that incorporating topic sentiment notably enhances the performance of these models. The results indicate that topics in stock market comments provide implicit, valuable insights into stock market volatility and price trends. This study contributes to the field by showcasing the potential of NLP in enriching financial analysis and opens up avenues for further research into real-time sentiment analysis and the exploration of emotional and contextual aspects of market sentiment. The integration of advanced NLP techniques like BERTopic with traditional financial analysis methods marks a step forward in developing more sophisticated tools for understanding and predicting market behaviors.", "link": "http://arxiv.org/abs/2404.02053v2"}, {"index": 10, "title": "Soil respiration signals in response to sustainable soil management practices enhance soil organic carbon stocks", "abstract": "Development of a spatial-temporal and data-driven model of soil respiration at the global scale based on soil temperature, yearly soil moisture, and soil organic carbon (C) estimates. Prediction of soil respiration on an annual basis (1991-2018) with relatively high accuracy (NSE 0.69, CCC 0.82). Lower soil respiration trends, higher soil respiration magnitudes, and higher soil organic C stocks across areas experiencing the presence of sustainable soil management practices.", "link": "http://arxiv.org/abs/2404.05737v1"}, {"index": 11, "title": "Model Stock: All we need is just a few fine-tuned models", "abstract": "This paper introduces an efficient fine-tuning method for large pre-trained models, offering strong in-distribution (ID) and out-of-distribution (OOD) performance. Breaking away from traditional practices that need a multitude of fine-tuned models for averaging, our approach employs significantly fewer models to achieve final weights yet yield superior accuracy. Drawing from key insights in the weight space of fine-tuned weights, we uncover a strong link between the performance and proximity to the center of weight space. Based on this, we introduce a method that approximates a center-close weight using only two fine-tuned models, applicable during or after training. Our innovative layer-wise weight averaging technique surpasses state-of-the-art model methods such as Model Soup, utilizing only two fine-tuned models. This strategy can be aptly coined Model Stock, highlighting its reliance on selecting a minimal number of models to draw a more optimized-averaged model. We demonstrate the efficacy of Model Stock with fine-tuned models based upon pre-trained CLIP architectures, achieving remarkable performance on both ID and OOD tasks on the standard benchmarks, all while barely bringing extra computational demands. Our code and pre-trained models are available at https://github.com/naver-ai/model-stock.", "link": "http://arxiv.org/abs/2403.19522v1"}, {"index": 12, "title": "Dynamic Correlation of Market Connectivity, Risk Spillover and Abnormal Volatility in Stock Price", "abstract": "The connectivity of stock markets reflects the information efficiency of capital markets and contributes to interior risk contagion and spillover effects. We compare Shanghai Stock Exchange A-shares (SSE A-shares) during tranquil periods, with high leverage periods associated with the 2015 subprime mortgage crisis. We use Pearson correlations of returns, the maximum strongly connected subgraph, and $3\\sigma$ principle to iteratively determine the threshold value for building a dynamic correlation network of SSE A-shares. Analyses are carried out based on the networking structure, intra-sector connectivity, and node status, identifying several contributions. First, compared with tranquil periods, the SSE A-shares network experiences a more significant small-world and connective effect during the subprime mortgage crisis and the high leverage period in 2015. Second, the finance, energy and utilities sectors have a stronger intra-industry connectivity than other sectors. Third, HUB nodes drive the growth of the SSE A-shares market during bull periods, while stocks have a think-tail degree distribution in bear periods and show distinct characteristics in terms of market value and finance. Granger linear and non-linear causality networks are also considered for the comparison purpose. Studies on the evolution of inter-cycle connectivity in the SSE A-share market may help investors improve portfolios and develop more robust risk management policies.", "link": "http://dx.doi.org/10.1016/j.physa.2021.126506"}, {"index": 13, "title": "Stock Recommendations for Individual Investors: A Temporal Graph Network Approach with Diversification-Enhancing Contrastive Learning", "abstract": "In complex financial markets, recommender systems can play a crucial role in empowering individuals to make informed decisions. Existing studies predominantly focus on price prediction, but even the most sophisticated models cannot accurately predict stock prices. Also, many studies show that most individual investors do not follow established investment theories because they have their own preferences. Hence, the tricky point in stock recommendation is that recommendations should give good investment performance but also should not ignore individual preferences. To develop effective stock recommender systems, it is essential to consider three key aspects: 1) individual preferences, 2) portfolio diversification, and 3) temporal aspect of both stock features and individual preferences. In response, we develop the portfolio temporal graph network recommender PfoTGNRec, which can handle time-varying collaborative signals and incorporates diversification-enhancing contrastive learning. As a result, our model demonstrated superior performance compared to various baselines, including cutting-edge dynamic embedding models and existing stock recommendation models, in a sense that our model exhibited good investment performance while maintaining competitive in capturing individual preferences. The source code and data are available at https://anonymous.4open.science/r/IJCAI2024-12F4.", "link": "http://arxiv.org/abs/2404.07223v1"}, {"index": 14, "title": "An End-to-End Structure with Novel Position Mechanism and Improved EMD for Stock Forecasting", "abstract": "As a branch of time series forecasting, stock movement forecasting is one of the challenging problems for investors and researchers. Since Transformer was introduced to analyze financial data, many researchers have dedicated themselves to forecasting stock movement using Transformer or attention mechanisms. However, existing research mostly focuses on individual stock information but ignores stock market information and high noise in stock data. In this paper, we propose a novel method using the attention mechanism in which both stock market information and individual stock information are considered. Meanwhile, we propose a novel EMD-based algorithm for reducing short-term noise in stock data. Two randomly selected exchange-traded funds (ETFs) spanning over ten years from US stock markets are used to demonstrate the superior performance of the proposed attention-based method. The experimental analysis demonstrates that the proposed attention-based method significantly outperforms other state-of-the-art baselines. Code is available at https://github.com/DurandalLee/ACEFormer.", "link": "http://arxiv.org/abs/2404.07969v1"}, {"index": 15, "title": "DiffSTOCK: Probabilistic relational Stock Market Predictions using Diffusion Models", "abstract": "In this work, we propose an approach to generalize denoising diffusion probabilistic models for stock market predictions and portfolio management. Present works have demonstrated the efficacy of modeling interstock relations for market time-series forecasting and utilized Graph-based learning models for value prediction and portfolio management. Though convincing, these deterministic approaches still fall short of handling uncertainties i.e., due to the low signal-to-noise ratio of the financial data, it is quite challenging to learn effective deterministic models. Since the probabilistic methods have shown to effectively emulate higher uncertainties for time-series predictions. To this end, we showcase effective utilisation of Denoising Diffusion Probabilistic Models (DDPM), to develop an architecture for providing better market predictions conditioned on the historical financial indicators and inter-stock relations. Additionally, we also provide a novel deterministic architecture MaTCHS which uses Masked Relational Transformer(MRT) to exploit inter-stock relations along with historical stock features. We demonstrate that our model achieves SOTA performance for movement predication and Portfolio management.", "link": "http://arxiv.org/abs/2403.14063v1"}, {"index": 16, "title": "Modeling stock price dynamics on the Ghana Stock Exchange: A Geometric Brownian Motion approach", "abstract": "Modeling financial data often relies on assumptions that may prove insufficient or unrealistic in practice. The Geometric Brownian Motion (GBM) model is frequently employed to represent stock price processes. This study investigates whether the behavior of weekly and monthly returns of selected equities listed on the Ghana Stock Exchange conforms to the GBM model. Parameters of the GBM model were estimated for five equities, and forecasts were generated for three months. Evaluation of estimation accuracy was conducted using mean square error (MSE). Results indicate that the expected prices from the modeled equities closely align with actual stock prices observed on the Exchange. Furthermore, while some deviations were observed, the actual prices consistently fell within the estimated confidence intervals.", "link": "http://arxiv.org/abs/2403.13192v1"}, {"index": 17, "title": "AlphaFin: Benchmarking Financial Analysis with Retrieval-Augmented Stock-Chain Framework", "abstract": "The task of financial analysis primarily encompasses two key areas: stock trend prediction and the corresponding financial question answering. Currently, machine learning and deep learning algorithms (ML&DL) have been widely applied for stock trend predictions, leading to significant progress. However, these methods fail to provide reasons for predictions, lacking interpretability and reasoning processes. Also, they can not integrate textual information such as financial news or reports. Meanwhile, large language models (LLMs) have remarkable textual understanding and generation ability. But due to the scarcity of financial training datasets and limited integration with real-time knowledge, LLMs still suffer from hallucinations and are unable to keep up with the latest information. To tackle these challenges, we first release AlphaFin datasets, combining traditional research datasets, real-time financial data, and handwritten chain-of-thought (CoT) data. It has a positive impact on training LLMs for completing financial analysis. We then use AlphaFin datasets to benchmark a state-of-the-art method, called Stock-Chain, for effectively tackling the financial analysis task, which integrates retrieval-augmented generation (RAG) techniques. Extensive experiments are conducted to demonstrate the effectiveness of our framework on financial analysis.", "link": "http://arxiv.org/abs/2403.12582v1"}, {"index": 18, "title": "FishNet: Deep Neural Networks for Low-Cost Fish Stock Estimation", "abstract": "Fish stock assessment often involves manual fish counting by taxonomy specialists, which is both time-consuming and costly. We propose an automated computer vision system that performs both taxonomic classification and fish size estimation from images taken with a low-cost digital camera. The system first performs object detection and segmentation using a Mask R-CNN to identify individual fish from images containing multiple fish, possibly consisting of different species. Then each fish species is classified and the predicted length using separate machine learning models. These models are trained on a dataset of 50,000 hand-annotated images containing 163 different fish species, ranging in length from 10cm to 250cm. Evaluated on held-out test data, our system achieves a $92\\%$ intersection over union on the fish segmentation task, a $89\\%$ top-1 classification accuracy on single fish species classification, and a $2.3$~cm mean error on the fish length estimation task.", "link": "http://arxiv.org/abs/2403.10916v1"}, {"index": 19, "title": "MetaSplit: Meta-Split Network for Limited-Stock Product Recommendation", "abstract": "Compared to business-to-consumer (B2C) e-commerce systems, consumer-to-consumer (C2C) e-commerce platforms usually encounter the limited-stock problem, that is, a product can only be sold one time in a C2C system. This poses several unique challenges for click-through rate (CTR) prediction. Due to limited user interactions for each product (i.e. item), the corresponding item embedding in the CTR model may not easily converge. This makes the conventional sequence modeling based approaches cannot effectively utilize user history information since historical user behaviors contain a mixture of items with different volume of stocks. Particularly, the attention mechanism in a sequence model tends to assign higher score to products with more accumulated user interactions, making limited-stock products being ignored and contribute less to the final output. To this end, we propose the Meta-Split Network (MSNet) to split user history sequence regarding to the volume of stock for each product, and adopt differentiated modeling approaches for different sequences. As for the limited-stock products, a meta-learning approach is applied to address the problem of inconvergence, which is achieved by designing meta scaling and shifting networks with ID and side information. In addition, traditional approach can hardly update item embedding once the product is consumed. Thereby, we propose an auxiliary loss that makes the parameters updatable even when the product is no longer in distribution. To the best of our knowledge, this is the first solution addressing the recommendation of limited-stock product. Experimental results on the production dataset and online A/B testing demonstrate the effectiveness of our proposed method.", "link": "http://arxiv.org/abs/2403.06747v5"}, {"index": 20, "title": "The 'Must Stock' Challenge in Academic Publishing: Pricing Implications of Transformative Agreements", "abstract": "The high relevance of top-notch academic journals turns them into 'must stock' products that assign its often commercial owners with extraordinary market power. Intended to tackle this, university consortia around the globe negotiate so-called 'transformative agreements' with many publishing houses. It shall pave the way towards standard open-access publishing. While several contract designs exist, the 'publish-and-read' (PAR) scheme is the one that comes closest to the ideal of an entirely open access environment: Publishers are paid a fixed case-by-case rate for each publication, which includes a fee for their extensive libraries. In turn, all subscription payments are waived. I theoretically derive that this contract design benefits the included publishers regardless of whether the number of publications in these publishers' journals grows or declines. Consequently, widespread PAR contracts are likely to raise entry barriers for new (open-access) competitors even further. Intending to lower costs for the universities, their libraries, and, ultimately, the taxpayers, this PAR fee contract design of transformative agreements might cause the opposite.", "link": "http://arxiv.org/abs/2403.03597v1"}, {"index": 21, "title": "FinReport: Explainable Stock Earnings Forecasting via News Factor Analyzing Model", "abstract": "The task of stock earnings forecasting has received considerable attention due to the demand investors in real-world scenarios. However, compared with financial institutions, it is not easy for ordinary investors to mine factors and analyze news. On the other hand, although large language models in the financial field can serve users in the form of dialogue robots, it still requires users to have financial knowledge to ask reasonable questions. To serve the user experience, we aim to build an automatic system, FinReport, for ordinary investors to collect information, analyze it, and generate reports after summarizing.   Specifically, our FinReport is based on financial news announcements and a multi-factor model to ensure the professionalism of the report. The FinReport consists of three modules: news factorization module, return forecasting module, risk assessment module. The news factorization module involves understanding news information and combining it with stock factors, the return forecasting module aim to analysis the impact of news on market sentiment, and the risk assessment module is adopted to control investment risk. Extensive experiments on real-world datasets have well verified the effectiveness and explainability of our proposed FinReport. Our codes and datasets are available at https://github.com/frinkleko/FinReport.", "link": "http://arxiv.org/abs/2403.02647v1"}, {"index": 22, "title": "RVRAE: A Dynamic Factor Model Based on Variational Recurrent Autoencoder for Stock Returns Prediction", "abstract": "In recent years, the dynamic factor model has emerged as a dominant tool in economics and finance, particularly for investment strategies. This model offers improved handling of complex, nonlinear, and noisy market conditions compared to traditional static factor models. The advancement of machine learning, especially in dealing with nonlinear data, has further enhanced asset pricing methodologies. This paper introduces a groundbreaking dynamic factor model named RVRAE. This model is a probabilistic approach that addresses the temporal dependencies and noise in market data. RVRAE ingeniously combines the principles of dynamic factor modeling with the variational recurrent autoencoder (VRAE) from deep learning. A key feature of RVRAE is its use of a prior-posterior learning method. This method fine-tunes the model's learning process by seeking an optimal posterior factor model informed by future data. Notably, RVRAE is adept at risk modeling in volatile stock markets, estimating variances from latent space distributions while also predicting returns. Our empirical tests with real stock market data underscore RVRAE's superior performance compared to various established baseline methods.", "link": "http://arxiv.org/abs/2403.02500v1"}, {"index": 23, "title": "Optimization decision model of vegetable stock and pricing based on TCN-Attention and genetic algorithm", "abstract": "With the expansion of operational scale of supermarkets in China, the vegetable market has grown considerably. The decision-making related to procurement costs and allocation quantities of vegetables has become a pivotal factor in determining the profitability of supermarkets. This paper analyzes the relationship between pricing and allocation faced by supermarkets in vegetable operations. Optimization algorithms are employed to determine replenishment and pricing strategies. Linear regression is utilized to model the historical data of various products, establishing the relationship between sale prices and sales volumes for 61 products. By integrating historical data on vegetable costs with time information based on the 24 solar terms, a cost prediction model is trained using TCN-Attention. The Topis evaluation model identifies the 32 most market-demanded products. A genetic algorithm is then used to search for the globally optimized vegetable product allocation-pricing decision.", "link": "http://dx.doi.org/10.1145/3644523.3644657"}, {"index": 24, "title": "\"Digitwashing\": The Gap between Words and Deeds in Digital Transformation and Stock Price Crash Risk", "abstract": "The contrast between companies' \"fleshy\" promises and the \"skeletal\" performance in digital transformation may lead to a higher risk of stock price crash. This paper selects a sample of Shanghai and Shenzhen A-share listed companies from 2010 to 2021, empirically analyses the specific impact of the gap between words and deeds in digital transformation (GDT) on the stock price crash risk, and explores the possible causes of GDT. We found that GDT significantly increases the stock price crash risk, and this finding is still valid after a series of robustness tests. In a further study, a deeper examination of the causes of GDT reveals that firms' perceptions of economic policy uncertainty significantly increase GDT, and the effect is more pronounced in the sample of loss-making firms. At the same time, the results of the heterogeneity test suggest that investors are more tolerant of state-owned enterprises when they are in the GDT situation. Taken together, we provide a concrete bridge between the two measures of digital transformation - digital text frequency and digital technology share - and offer new insights to enhance capital market stability.", "link": "http://arxiv.org/abs/2403.01360v1"}, {"index": 25, "title": "MambaStock: Selective state space model for stock prediction", "abstract": "The stock market plays a pivotal role in economic development, yet its intricate volatility poses challenges for investors. Consequently, research and accurate predictions of stock price movements are crucial for mitigating risks. Traditional time series models fall short in capturing nonlinearity, leading to unsatisfactory stock predictions. This limitation has spurred the widespread adoption of neural networks for stock prediction, owing to their robust nonlinear generalization capabilities. Recently, Mamba, a structured state space sequence model with a selection mechanism and scan module (S6), has emerged as a powerful tool in sequence modeling tasks. Leveraging this framework, this paper proposes a novel Mamba-based model for stock price prediction, named MambaStock. The proposed MambaStock model effectively mines historical stock market data to predict future stock prices without handcrafted features or extensive preprocessing procedures. Empirical studies on several stocks indicate that the MambaStock model outperforms previous methods, delivering highly accurate predictions. This enhanced accuracy can assist investors and institutions in making informed decisions, aiming to maximize returns while minimizing risks. This work underscores the value of Mamba in time-series forecasting. Source code is available at https://github.com/zshicode/MambaStock.", "link": "http://arxiv.org/abs/2402.18959v1"}, {"index": 26, "title": "The Random Forest Model for Analyzing and Forecasting the US Stock Market in the Context of Smart Finance", "abstract": "The stock market is a crucial component of the financial market, playing a vital role in wealth accumulation for investors, financing costs for listed companies, and the stable development of the national macroeconomy. Significant fluctuations in the stock market can damage the interests of stock investors and cause an imbalance in the industrial structure, which can interfere with the macro level development of the national economy. The prediction of stock price trends is a popular research topic in academia. Predicting the three trends of stock pricesrising, sideways, and falling can assist investors in making informed decisions about buying, holding, or selling stocks. Establishing an effective forecasting model for predicting these trends is of substantial practical importance. This paper evaluates the predictive performance of random forest models combined with artificial intelligence on a test set of four stocks using optimal parameters. The evaluation considers both predictive accuracy and time efficiency.", "link": "http://arxiv.org/abs/2402.17194v1"}, {"index": 27, "title": "The impact of Facebook-Cambridge Analytica data scandal on the USA tech stock market: An event study based on clustering method", "abstract": "This study delves into the intra-industry effects following a firm-specific scandal, with a particular focus on the Facebook data leakage scandal and its associated events within the U.S. tech industry and two additional relevant groups. We employ various metrics including daily spread, volatility, volume-weighted return, and CAPM-beta for the pre-analysis clustering, and subsequently utilize CAR (Cumulative Abnormal Return) to evaluate the impact on firms grouped within these clusters. From a broader industry viewpoint, significant positive CAARs are observed across U.S. sample firms over the three days post-scandal announcement, indicating no adverse impact on the tech sector overall. Conversely, after Facebook's initial quarterly earnings report, it showed a notable negative effect despite reported positive performance. The clustering principle should aid in identifying directly related companies and thus reducing the influence of randomness. This was indeed achieved for the effect of the key event, namely \"The Effect of Congressional Hearing on Certain Clusters across U.S. Tech Stock Market,\" which was identified as delayed and significantly negative. Therefore, we recommend applying the clustering method when conducting such or similar event studies.", "link": "http://arxiv.org/abs/2402.14206v1"}, {"index": 28, "title": "Ploutos: Towards interpretable stock movement prediction with financial large language model", "abstract": "Recent advancements in large language models (LLMs) have opened new pathways for many domains. However, the full potential of LLMs in financial investments remains largely untapped. There are two main challenges for typical deep learning-based methods for quantitative finance. First, they struggle to fuse textual and numerical information flexibly for stock movement prediction. Second, traditional methods lack clarity and interpretability, which impedes their application in scenarios where the justification for predictions is essential. To solve the above challenges, we propose Ploutos, a novel financial LLM framework that consists of PloutosGen and PloutosGPT. The PloutosGen contains multiple primary experts that can analyze different modal data, such as text and numbers, and provide quantitative strategies from different perspectives. Then PloutosGPT combines their insights and predictions and generates interpretable rationales. To generate accurate and faithful rationales, the training strategy of PloutosGPT leverage rearview-mirror prompting mechanism to guide GPT-4 to generate rationales, and a dynamic token weighting mechanism to finetune LLM by increasing key tokens weight. Extensive experiments show our framework outperforms the state-of-the-art methods on both prediction accuracy and interpretability.", "link": "http://arxiv.org/abs/2403.00782v1"}, {"index": 29, "title": "RAGIC: Risk-Aware Generative Adversarial Model for Stock Interval Construction", "abstract": "Efforts to predict stock market outcomes have yielded limited success due to the inherently stochastic nature of the market, influenced by numerous unpredictable factors. Many existing prediction approaches focus on single-point predictions, lacking the depth needed for effective decision-making and often overlooking market risk. To bridge this gap, we propose a novel model, RAGIC, which introduces sequence generation for stock interval prediction to quantify uncertainty more effectively. Our approach leverages a Generative Adversarial Network (GAN) to produce future price sequences infused with randomness inherent in financial markets. RAGIC's generator includes a risk module, capturing the risk perception of informed investors, and a temporal module, accounting for historical price trends and seasonality. This multi-faceted generator informs the creation of risk-sensitive intervals through statistical inference, incorporating horizon-wise insights. The interval's width is carefully adjusted to reflect market volatility. Importantly, our approach relies solely on publicly available data and incurs only low computational overhead. RAGIC's evaluation across globally recognized broad-based indices demonstrates its balanced performance, offering both accuracy and informativeness. Achieving a consistent 95% coverage, RAGIC maintains a narrow interval width. This promising outcome suggests that our approach effectively addresses the challenges of stock market prediction while incorporating vital risk considerations.", "link": "http://arxiv.org/abs/2402.10760v1"}, {"index": 30, "title": "Prismatic: Interactive Multi-View Cluster Analysis of Concept Stocks", "abstract": "Financial cluster analysis allows investors to discover investment alternatives and avoid undertaking excessive risks. However, this analytical task faces substantial challenges arising from many pairwise comparisons, the dynamic correlations across time spans, and the ambiguity in deriving implications from business relational knowledge. We propose Prismatic, a visual analytics system that integrates quantitative analysis of historical performance and qualitative analysis of business relational knowledge to cluster correlated businesses interactively. Prismatic features three clustering processes: dynamic cluster generation, knowledge-based cluster exploration, and correlation-based cluster validation. Utilizing a multi-view clustering approach, it enriches data-driven clusters with knowledge-driven similarity, providing a nuanced understanding of business correlations. Through well-coordinated visual views, Prismatic facilitates a comprehensive interpretation of intertwined quantitative and qualitative features, demonstrating its usefulness and effectiveness via case studies on formulating concept stocks and extensive interviews with domain experts.", "link": "http://arxiv.org/abs/2402.08978v1"}, {"index": 31, "title": "Do Weibo platform experts perform better at predicting stock market?", "abstract": "Sentiment analysis can be used for stock market prediction. However, existing research has not studied the impact of a user's financial background on sentiment-based forecasting of the stock market using artificial neural networks. In this work, a novel combination of neural networks is used for the assessment of sentiment-based stock market prediction, based on the financial background of the population that generated the sentiment. The state-of-the-art language processing model Bidirectional Encoder Representations from Transformers (BERT) is used to classify the sentiment and a Long-Short Term Memory (LSTM) model is used for time-series based stock market prediction. For evaluation, the Weibo social networking platform is used as a sentiment data collection source. Weibo users (and their comments respectively) are divided into Authorized Financial Advisor (AFA) and Unauthorized Financial Advisor (UFA) groups according to their background information, as collected by Weibo. The Hong Kong Hang Seng index is used to extract historical stock market change data. The results indicate that stock market prediction learned from the AFA group users is 39.67% more precise than that learned from the UFA group users and shows the highest accuracy (87%) when compared to existing approaches.", "link": "http://dx.doi.org/10.1007/978-3-030-80568-5_40"}, {"index": 32, "title": "Existence of an equilibrium with limited stock market participation and power utilities", "abstract": "For constants $\\gamma \\in (0,1)$ and $A\\in (1,\\infty)$, we prove existence and uniqueness of a solution to the singular and path-dependent Riccati-type ODE \\begin{align*} \\begin{cases} h'(y) = \\frac{1+\\gamma}{y}\\big( \\gamma - h(y)\\big)+h(y)\\frac{\\gamma + \\big((A-\\gamma)e^{\\int_y^1 \\frac{1-h(q)}{1-q}dq}-A\\big)h(y)}{1-y},\\quad y\\in(0,1), h(0) = \\gamma, \\quad h(1) = 1. \\end{cases} \\end{align*} As an application, we use the ODE solution to prove existence of a Radner equilibrium with homogenous power-utility investors in the limited participation model from Basak and Cuoco (1998).", "link": "http://arxiv.org/abs/2402.07185v2"}, {"index": 33, "title": "A Study on Stock Forecasting Using Deep Learning and Statistical Models", "abstract": "Predicting a fast and accurate model for stock price forecasting is been a challenging task and this is an active area of research where it is yet to be found which is the best way to forecast the stock price. Machine learning, deep learning and statistical analysis techniques are used here to get the accurate result so the investors can see the future trend and maximize the return of investment in stock trading. This paper will review many deep learning algorithms for stock price forecasting. We use a record of s&p 500 index data for training and testing. The survey motive is to check various deep learning and statistical model techniques for stock price forecasting that are Moving Averages, ARIMA which are statistical techniques and LSTM, RNN, CNN, and FULL CNN which are deep learning models. It will discuss various models, including the Auto regression integration moving average model, the Recurrent neural network model, the long short-term model which is the type of RNN used for long dependency for data, the convolutional neural network model, and the full convolutional neural network model, in terms of error calculation or percentage of accuracy that how much it is accurate which measures by the function like Root mean square error, mean absolute error, mean squared error. The model can be used to predict the stock price by checking the low MAE value as lower the MAE value the difference between the predicting and the actual value will be less and this model will predict the price more accurately than other models.", "link": "http://arxiv.org/abs/2402.06689v1"}, {"index": 34, "title": "Cyber risk and the cross-section of stock returns", "abstract": "We extract firms' cyber risk with a machine learning algorithm measuring the proximity between their disclosures and a dedicated cyber corpus. Our approach outperforms dictionary methods, uses full disclosure and not devoted-only sections, and generates a cyber risk measure uncorrelated with other firms' characteristics. We find that a portfolio of US-listed stocks in the high cyber risk quantile generates an excess return of 18.72% p.a. Moreover, a long-short cyber risk portfolio has a significant and positive risk premium of 6.93% p.a., robust to all factors' benchmarks. Finally, using a Bayesian asset pricing method, we show that our cyber risk factor is the essential feature that allows any multi-factor model to price the cross-section of stock returns.", "link": "http://arxiv.org/abs/2402.04775v2"}, {"index": 35, "title": "Learning to Generate Explainable Stock Predictions using Self-Reflective Large Language Models", "abstract": "Explaining stock predictions is generally a difficult task for traditional non-generative deep learning models, where explanations are limited to visualizing the attention weights on important texts. Today, Large Language Models (LLMs) present a solution to this problem, given their known capabilities to generate human-readable explanations for their decision-making process. However, the task of stock prediction remains challenging for LLMs, as it requires the ability to weigh the varying impacts of chaotic social texts on stock prices. The problem gets progressively harder with the introduction of the explanation component, which requires LLMs to explain verbally why certain factors are more important than the others. On the other hand, to fine-tune LLMs for such a task, one would need expert-annotated samples of explanation for every stock movement in the training set, which is expensive and impractical to scale. To tackle these issues, we propose our Summarize-Explain-Predict (SEP) framework, which utilizes a self-reflective agent and Proximal Policy Optimization (PPO) to let a LLM teach itself how to generate explainable stock predictions in a fully autonomous manner. The reflective agent learns how to explain past stock movements through self-reasoning, while the PPO trainer trains the model to generate the most likely explanations from input texts. The training samples for the PPO trainer are also the responses generated during the reflective process, which eliminates the need for human annotators. Using our SEP framework, we fine-tune a LLM that can outperform both traditional deep-learning and LLM methods in prediction accuracy and Matthews correlation coefficient for the stock classification task. To justify the generalization capability of our framework, we further test it on the portfolio construction task, and demonstrate its effectiveness through various portfolio metrics.", "link": "http://dx.doi.org/10.1145/3589334.3645611"}, {"index": 36, "title": "DiffsFormer: A Diffusion Transformer on Stock Factor Augmentation", "abstract": "Machine learning models have demonstrated remarkable efficacy and efficiency in a wide range of stock forecasting tasks. However, the inherent challenges of data scarcity, including low signal-to-noise ratio (SNR) and data homogeneity, pose significant obstacles to accurate forecasting. To address this issue, we propose a novel approach that utilizes artificial intelligence-generated samples (AIGS) to enhance the training procedures. In our work, we introduce the Diffusion Model to generate stock factors with Transformer architecture (DiffsFormer). DiffsFormer is initially trained on a large-scale source domain, incorporating conditional guidance so as to capture global joint distribution. When presented with a specific downstream task, we employ DiffsFormer to augment the training procedure by editing existing samples. This editing step allows us to control the strength of the editing process, determining the extent to which the generated data deviates from the target domain. To evaluate the effectiveness of DiffsFormer augmented training, we conduct experiments on the CSI300 and CSI800 datasets, employing eight commonly used machine learning models. The proposed method achieves relative improvements of 7.2% and 27.8% in annualized return ratio for the respective datasets. Furthermore, we perform extensive experiments to gain insights into the functionality of DiffsFormer and its constituent components, elucidating how they address the challenges of data scarcity and enhance the overall model performance. Our research demonstrates the efficacy of leveraging AIGS and the DiffsFormer architecture to mitigate data scarcity in stock forecasting tasks.", "link": "http://arxiv.org/abs/2402.06656v1"}, {"index": 37, "title": "Tweet Influence on Market Trends: Analyzing the Impact of Social Media Sentiment on Biotech Stocks", "abstract": "This study investigates the relationship between tweet sentiment across diverse categories: news, company opinions, CEO opinions, competitor opinions, and stock market behavior in the biotechnology sector, with a focus on understanding the impact of social media discourse on investor sentiment and decision-making processes. We analyzed historical stock market data for ten of the largest and most influential pharmaceutical companies alongside Twitter data related to COVID-19, vaccines, the companies, and their respective CEOs. Using VADER sentiment analysis, we examined the sentiment scores of tweets and assessed their relationships with stock market performance. We employed ARIMA (AutoRegressive Integrated Moving Average) and VAR (Vector AutoRegression) models to forecast stock market performance, incorporating sentiment covariates to improve predictions. Our findings revealed a complex interplay between tweet sentiment, news, biotech companies, their CEOs, and stock market performance, emphasizing the importance of considering diverse factors when modeling and predicting stock prices. This study provides valuable insights into the influence of social media on the financial sector and lays a foundation for future research aimed at refining stock price prediction models.", "link": "http://arxiv.org/abs/2402.03353v1"}, {"index": 38, "title": "Transformers with Attentive Federated Aggregation for Time Series Stock Forecasting", "abstract": "Recent innovations in transformers have shown their superior performance in natural language processing (NLP) and computer vision (CV). The ability to capture long-range dependencies and interactions in sequential data has also triggered a great interest in time series modeling, leading to the widespread use of transformers in many time series applications. However, being the most common and crucial application, the adaptation of transformers to time series forecasting has remained limited, with both promising and inconsistent results. In contrast to the challenges in NLP and CV, time series problems not only add the complexity of order or temporal dependence among input sequences but also consider trend, level, and seasonality information that much of this data is valuable for decision making. The conventional training scheme has shown deficiencies regarding model overfitting, data scarcity, and privacy issues when working with transformers for a forecasting task. In this work, we propose attentive federated transformers for time series stock forecasting with better performance while preserving the privacy of participating enterprises. Empirical results on various stock data from the Yahoo! Finance website indicate the superiority of our proposed scheme in dealing with the above challenges and data heterogeneity in federated learning.", "link": "http://dx.doi.org/10.1109/ICOIN56518.2023.10048928"}, {"index": 39, "title": "BioFinBERT: Finetuning Large Language Models (LLMs) to Analyze Sentiment of Press Releases and Financial Text Around Inflection Points of Biotech Stocks", "abstract": "Large language models (LLMs) are deep learning algorithms being used to perform natural language processing tasks in various fields, from social sciences to finance and biomedical sciences. Developing and training a new LLM can be very computationally expensive, so it is becoming a common practice to take existing LLMs and finetune them with carefully curated datasets for desired applications in different fields. Here, we present BioFinBERT, a finetuned LLM to perform financial sentiment analysis of public text associated with stocks of companies in the biotechnology sector. The stocks of biotech companies developing highly innovative and risky therapeutic drugs tend to respond very positively or negatively upon a successful or failed clinical readout or regulatory approval of their drug, respectively. These clinical or regulatory results are disclosed by the biotech companies via press releases, which are followed by a significant stock response in many cases. In our attempt to design a LLM capable of analyzing the sentiment of these press releases,we first finetuned BioBERT, a biomedical language representation model designed for biomedical text mining, using financial textual databases. Our finetuned model, termed BioFinBERT, was then used to perform financial sentiment analysis of various biotech-related press releases and financial text around inflection points that significantly affected the price of biotech stocks.", "link": "http://arxiv.org/abs/2401.11011v1"}, {"index": 40, "title": "MDGNN: Multi-Relational Dynamic Graph Neural Network for Comprehensive and Dynamic Stock Investment Prediction", "abstract": "The stock market is a crucial component of the financial system, but predicting the movement of stock prices is challenging due to the dynamic and intricate relations arising from various aspects such as economic indicators, financial reports, global news, and investor sentiment. Traditional sequential methods and graph-based models have been applied in stock movement prediction, but they have limitations in capturing the multifaceted and temporal influences in stock price movements. To address these challenges, the Multi-relational Dynamic Graph Neural Network (MDGNN) framework is proposed, which utilizes a discrete dynamic graph to comprehensively capture multifaceted relations among stocks and their evolution over time. The representation generated from the graph offers a complete perspective on the interrelationships among stocks and associated entities. Additionally, the power of the Transformer structure is leveraged to encode the temporal evolution of multiplex relations, providing a dynamic and effective approach to predicting stock investment. Further, our proposed MDGNN framework achieves the best performance in public datasets compared with state-of-the-art (SOTA) stock investment methods.", "link": "http://arxiv.org/abs/2402.06633v1"}, {"index": 41, "title": "Binary fraction in Galactic star clusters: FSR 866, NGC 1960, and STOCK 2", "abstract": "The study of binary stars in different astronomical environments offers insights into the dynamical state of the hosting stellar systems. The Binary Fraction in fact plays a crucial role in the dynamical evolution of stellar system, regulating processes like mass segregation and dynamical heating, and in some cases leading to the formation exotic object, like for instance blue straggler stars. We used two methodologies to estimate the binary fraction in three different-age open star clusters: FSR 866, NGC 1960 (M36), and Stock 2. The first, a photometric approach based on colour-magnitude diagram analysis, and the second, a spectroscopic technique which employs radial velocity measurements. We used Gaia DR3 data in tandem with new spectroscopic observations, and employed the DBSCAN clustering algorithm to identify probable cluster members based on proper motion and parallax in 3D space. The new sample of cluster members allows us to provide new estimates of the cluster fundamental parameters. As a by-product, we found two previously undetected, small physical groups of stars in the background of NGC 1960. The resulting binary fractions lie in the range 0.3 - 0.5 and are in good agreement with those expected theoretically for open clusters.", "link": "http://arxiv.org/abs/2401.08797v1"}, {"index": 42, "title": "Detachment Problem -- Application in Prevention of Information Leakage in Stock Markets", "abstract": "In this paper, we introduce the Detachment Problem. It can be seen as a generalized Vaccination Problem. The aim is to optimally cut the individuals' ties to circles that connect them to others, to minimize the overall information transfer in a social network. When an individual is isolated from a particular circle, it leads to the elimination of the connections to all the members of that circle, yet the connections to other circles remain. This approach contrasts with the conventional vaccination problem, in which a subset of vertices is totally eliminated. In our case, the connections of individuals to their circles are selectively, rather than entirely, eliminated. Contextually, this article focuses on private information flows, specifically within networks formed by memberships in circles of insiders in companies. Our quasi-empirical study uses simulated information flows on an observable network, and the statistical properties of the simulated information flows are matched with real-world data. In a broader context, this paper presents the Detachment Problem as a versatile approach for optimal social distancing, applicable across various scenarios. We propose and define a concept of expected proportional outside influence, or EPOI, as measure of how widespread information leak is. We also implement a greedy algorithm for finding a set of detachments to minimize EPOI. For comparison, we devise a simple heuristic based on minimal cut, to separate the most influential circles from each other. We provide evidence that the greedy algorithm is not optimal, and it is sometimes outperformed by the simple heuristic minimum cut algorithm, However, the greedy algorithm outperforms the cut algorithm in most cases. Further avenues of research are discussed.", "link": "http://arxiv.org/abs/2401.07074v1"}, {"index": 43, "title": "Comparison of Markowitz Model and Single-Index Model on Portfolio Selection of Malaysian Stocks", "abstract": "Our article is focused on the application of Markowitz Portfolio Theory and the Single Index Model on 10-year historical monthly return data for 10 stocks included in FTSE Bursa Malaysia KLCI, which is also our market index, as well as a risk-free asset which is the monthly fixed deposit rate. We will calculate the minimum variance portfolio and maximum Sharpe portfolio for both the Markowitz model and Single Index model subject to five different constraints, with the results presented in the form of tables and graphs such that comparisons between the different models and constraints can be made. We hope this article will help provide useful information for future investors who are interested in the Malaysian stock market and would like to construct an efficient investment portfolio. Keywords: Markowitz Portfolio Theory, Single Index Model, FTSE Bursa Malaysia KLCI, Efficient Portfolio", "link": "http://arxiv.org/abs/2401.05264v1"}, {"index": 44, "title": "Hypercomplex neural network in time series forecasting of stock data", "abstract": "The goal of this paper is to test three classes of neural network (NN) architectures based on four-dimensional (4D) hypercomplex algebras for time series prediction. We evaluate different architectures, varying the input layers to include convolutional, Long Short-Term Memory (LSTM), or dense hypercomplex layers for 4D algebras. Four related Stock Market time series are used as input data, with the prediction focused on one of them. Hyperparameter optimization for each architecture class was conducted to compare the best-performing neural networks within each class. The results indicate that, in most cases, architectures with hypercomplex dense layers achieve similar Mean Absolute Error (MAE) accuracy compared to other architectures, but with significantly fewer trainable parameters. Consequently, hypercomplex neural networks demonstrate the ability to learn and process time series data faster than the other tested architectures. Additionally, it was found that the ordering of the input time series have a notable impact on effectiveness.", "link": "http://arxiv.org/abs/2401.04632v2"}, {"index": 45, "title": "Incremental Learning of Stock Trends via Meta-Learning with Dynamic Adaptation", "abstract": "Forecasting the trend of stock prices is an enduring topic at the intersection of finance and computer science. Periodical updates to forecasters have proven effective in handling concept drifts arising from non-stationary markets. However, the existing methods neglect either emerging patterns in recent data or recurring patterns in historical data, both of which are empirically advantageous for future forecasting. To address this issue, we propose meta-learning with dynamic adaptation (MetaDA) for the incremental learning of stock trends, which periodically performs dynamic model adaptation utilizing the emerging and recurring patterns simultaneously. We initially organize the stock trend forecasting into meta-learning tasks and train a forecasting model following meta-learning protocols. During model adaptation, MetaDA efficiently adapts the forecasting model with the latest data and a selected portion of historical data, which is dynamically identified by a task inference module. The task inference module first extracts task-level embeddings from the historical tasks, and then identifies the informative data with a task inference network. MetaDA has been evaluated on real-world stock datasets, achieving state-of-the-art performance with satisfactory efficiency.", "link": "http://arxiv.org/abs/2401.03865v3"}, {"index": 46, "title": "Can Large Language Models Beat Wall Street? Unveiling the Potential of AI in Stock Selection", "abstract": "This paper introduces MarketSenseAI, an innovative framework leveraging GPT-4's advanced reasoning for selecting stocks in financial markets. By integrating Chain of Thought and In-Context Learning, MarketSenseAI analyzes diverse data sources, including market trends, news, fundamentals, and macroeconomic factors, to emulate expert investment decision-making. The development, implementation, and validation of the framework are elaborately discussed, underscoring its capability to generate actionable and interpretable investment signals. A notable feature of this work is employing GPT-4 both as a predictive mechanism and signal evaluator, revealing the significant impact of the AI-generated explanations on signal accuracy, reliability and acceptance. Through empirical testing on the competitive S&P 100 stocks over a 15-month period, MarketSenseAI demonstrated exceptional performance, delivering excess alpha of 10% to 30% and achieving a cumulative return of up to 72% over the period, while maintaining a risk profile comparable to the broader market. Our findings highlight the transformative potential of Large Language Models in financial decision-making, marking a significant leap in integrating generative AI into financial analytics and investment strategies.", "link": "http://arxiv.org/abs/2401.03737v2"}, {"index": 47, "title": "Economic Forces in Stock Returns", "abstract": "When analyzing the components influencing the stock prices, it is commonly believed that economic activities play an important role. More specifically, asset prices are more sensitive to the systematic economic news that impose a pervasive effect on the whole market. Moreover, the investors will not be rewarded for bearing idiosyncratic risks as such risks are diversifiable. In the paper Economic Forces and the Stock Market 1986, the authors introduced an attribution model to identify the specific systematic economic forces influencing the market. They first defined and examined five classic factors from previous research papers: Industrial Production, Unanticipated Inflation, Change in Expected Inflation, Risk Premia, and The Term Structure. By adding in new factors, the Market Indices, Consumptions and Oil Prices, one by one, they examined the significant contribution of each factor to the stock return. The paper concluded that the stock returns are exposed to the systematic economic news, and they are priced with respect to their risk exposure. Also, the significant factors can be identified by simply adopting their model. Driven by such motivation, we conduct an attribution analysis based on the general framework of their model to further prove the importance of the economic factors and identify the specific identity of significant factors.", "link": "http://arxiv.org/abs/2401.04132v1"}, {"index": 48, "title": "CRISIS ALERT:Forecasting Stock Market Crisis Events Using Machine Learning Methods", "abstract": "Historically, the economic recession often came abruptly and disastrously. For instance, during the 2008 financial crisis, the SP 500 fell 46 percent from October 2007 to March 2009. If we could detect the signals of the crisis earlier, we could have taken preventive measures. Therefore, driven by such motivation, we use advanced machine learning techniques, including Random Forest and Extreme Gradient Boosting, to predict any potential market crashes mainly in the US market. Also, we would like to compare the performance of these methods and examine which model is better for forecasting US stock market crashes. We apply our models on the daily financial market data, which tend to be more responsive with higher reporting frequencies. We consider 75 explanatory variables, including general US stock market indexes, SP 500 sector indexes, as well as market indicators that can be used for the purpose of crisis prediction. Finally, we conclude, with selected classification metrics, that the Extreme Gradient Boosting method performs the best in predicting US stock market crisis events.", "link": "http://arxiv.org/abs/2401.06172v1"}, {"index": 49, "title": "Multi-relational Graph Diffusion Neural Network with Parallel Retention for Stock Trends Classification", "abstract": "Stock trend classification remains a fundamental yet challenging task, owing to the intricate time-evolving dynamics between and within stocks. To tackle these two challenges, we propose a graph-based representation learning approach aimed at predicting the future movements of multiple stocks. Initially, we model the complex time-varying relationships between stocks by generating dynamic multi-relational stock graphs. This is achieved through a novel edge generation algorithm that leverages information entropy and signal energy to quantify the intensity and directionality of inter-stock relations on each trading day. Then, we further refine these initial graphs through a stochastic multi-relational diffusion process, adaptively learning task-optimal edges. Subsequently, we implement a decoupled representation learning scheme with parallel retention to obtain the final graph representation. This strategy better captures the unique temporal features within individual stocks while also capturing the overall structure of the stock graph. Comprehensive experiments conducted on real-world datasets from two US markets (NASDAQ and NYSE) and one Chinese market (Shanghai Stock Exchange: SSE) validate the effectiveness of our method. Our approach consistently outperforms state-of-the-art baselines in forecasting next trading day stock trends across three test periods spanning seven years. Datasets and code have been released (https://github.com/pixelhero98/MGDPR).", "link": "http://arxiv.org/abs/2401.05430v1"}, {"index": 50, "title": "A Novel Decision Ensemble Framework: Customized Attention-BiLSTM and XGBoost for Speculative Stock Price Forecasting", "abstract": "Forecasting speculative stock prices is essential for effective investment risk management that drives the need for the development of innovative algorithms. However, the speculative nature, volatility, and complex sequential dependencies within financial markets present inherent challenges which necessitate advanced techniques. This paper proposes a novel framework, CAB-XDE (customized attention BiLSTM-XGB decision ensemble), for predicting the daily closing price of speculative stock Bitcoin-USD (BTC-USD). CAB-XDE framework integrates a customized bi-directional long short-term memory (BiLSTM) with the attention mechanism and the XGBoost algorithm. The customized BiLSTM leverages its learning capabilities to capture the complex sequential dependencies and speculative market trends. Additionally, the new attention mechanism dynamically assigns weights to influential features, thereby enhancing interpretability, and optimizing effective cost measures and volatility forecasting. Moreover, XGBoost handles nonlinear relationships and contributes to the proposed CAB-XDE framework robustness. Additionally, the weight determination theory-error reciprocal method further refines predictions. This refinement is achieved by iteratively adjusting model weights. It is based on discrepancies between theoretical expectations and actual errors in individual customized attention BiLSTM and XGBoost models to enhance performance. Finally, the predictions from both XGBoost and customized attention BiLSTM models are concatenated to achieve diverse prediction space and are provided to the ensemble classifier to enhance the generalization capabilities of CAB-XDE. The proposed CAB-XDE framework is empirically validated on volatile Bitcoin market, sourced from Yahoo Finance and outperforms state-of-the-art models with a MAPE of 0.0037, MAE of 84.40, and RMSE of 106.14.", "link": "http://arxiv.org/abs/2401.11621v1"}, {"index": 51, "title": "DGDNN: Decoupled Graph Diffusion Neural Network for Stock Movement Prediction", "abstract": "Forecasting future stock trends remains challenging for academia and industry due to stochastic inter-stock dynamics and hierarchical intra-stock dynamics influencing stock prices. In recent years, graph neural networks have achieved remarkable performance in this problem by formulating multiple stocks as graph-structured data. However, most of these approaches rely on artificially defined factors to construct static stock graphs, which fail to capture the intrinsic interdependencies between stocks that rapidly evolve. In addition, these methods often ignore the hierarchical features of the stocks and lose distinctive information within. In this work, we propose a novel graph learning approach implemented without expert knowledge to address these issues. First, our approach automatically constructs dynamic stock graphs by entropy-driven edge generation from a signal processing perspective. Then, we further learn task-optimal dependencies between stocks via a generalized graph diffusion process on constructed stock graphs. Last, a decoupled representation learning scheme is adopted to capture distinctive hierarchical intra-stock features. Experimental results demonstrate substantial improvements over state-of-the-art baselines on real-world datasets. Moreover, the ablation study and sensitivity study further illustrate the effectiveness of the proposed method in modeling the time-evolving inter-stock and intra-stock dynamics.", "link": "http://dx.doi.org/10.5220/0012406400003636"}, {"index": 52, "title": "Natural Language Processing and Multimodal Stock Price Prediction", "abstract": "In the realm of financial decision-making, predicting stock prices is pivotal. Artificial intelligence techniques such as long short-term memory networks (LSTMs), support-vector machines (SVMs), and natural language processing (NLP) models are commonly employed to predict said prices. This paper utilizes stock percentage change as training data, in contrast to the traditional use of raw currency values, with a focus on analyzing publicly released news articles. The choice of percentage change aims to provide models with context regarding the significance of price fluctuations and overall price change impact on a given stock. The study employs specialized BERT natural language processing models to predict stock price trends, with a particular emphasis on various data modalities. The results showcase the capabilities of such strategies with a small natural language processing model to accurately predict overall stock trends, and highlight the effectiveness of certain data features and sector-specific data.", "link": "http://arxiv.org/abs/2401.01487v1"}, {"index": 53, "title": "Application of Machine Learning in Stock Market Forecasting: A Case Study of Disney Stock", "abstract": "This document presents a stock market analysis conducted on a dataset consisting of 750 instances and 16 attributes donated in 2014-10-23. The analysis includes an exploratory data analysis (EDA) section, feature engineering, data preparation, model selection, and insights from the analysis. The Fama French 3-factor model is also utilized in the analysis. The results of the analysis are presented, with linear regression being the best-performing model.", "link": "http://arxiv.org/abs/2401.10903v1"}, {"index": 54, "title": "Once Burned, Twice Shy? The Effect of Stock Market Bubbles on Traders that Learn by Experience", "abstract": "We study how experience with asset price bubbles changes the trading strategies of reinforcement learning (RL) traders and ask whether the change in trading strategies helps to prevent future bubbles. We train the RL traders in a multi-agent market simulation platform, ABIDES, and compare the strategies of traders trained with and without bubble experience. We find that RL traders without bubble experience behave like short-term momentum traders, whereas traders with bubble experience behave like value traders. Therefore, RL traders without bubble experience amplify bubbles, whereas RL traders with bubble experience tend to suppress and sometimes prevent them. This finding suggests that learning from experience is a mechanism for a boom and bust cycle where the experience of a collapsing bubble makes future bubbles less likely for a period of time until the memory fades and bubbles become more likely to form again.", "link": "http://arxiv.org/abs/2312.17472v1"}, {"index": 55, "title": "MASTER: Market-Guided Stock Transformer for Stock Price Forecasting", "abstract": "Stock price forecasting has remained an extremely challenging problem for many decades due to the high volatility of the stock market. Recent efforts have been devoted to modeling complex stock correlations toward joint stock price forecasting. Existing works share a common neural architecture that learns temporal patterns from individual stock series and then mixes up temporal representations to establish stock correlations. However, they only consider time-aligned stock correlations stemming from all the input stock features, which suffer from two limitations. First, stock correlations often occur momentarily and in a cross-time manner. Second, the feature effectiveness is dynamic with market variation, which affects both the stock sequential patterns and their correlations. To address the limitations, this paper introduces MASTER, a MArkert-Guided Stock TransformER, which models the momentary and cross-time stock correlation and leverages market information for automatic feature selection. MASTER elegantly tackles the complex stock correlation by alternatively engaging in intra-stock and inter-stock information aggregation. Experiments show the superiority of MASTER compared with previous works and visualize the captured realistic stock correlation to provide valuable insights.", "link": "http://arxiv.org/abs/2312.15235v1"}, {"index": 56, "title": "Some Ideas for Improving Stock Price Prediction Based on Machine Learning", "abstract": "Stock price prediction is a complicated and interesting task. Noisy trends make stock pricing sensitive and complicated while the economical motivation behind, keeps it interesting for researchers and investors. In this paper we are to outline two novel ideas for stock pricing. We also test each of our suggested algorithms for predicting the price of 6 stocks from different sectors. To show the efficiency of our proposed algorithm, we compare the predicted prices with real values and also perform a backtest to verify that the annual returns based on real data and predicted price are almost the same.", "link": "http://arxiv.org/abs/2312.10633v1"}, {"index": 57, "title": "Mapping Housing Stock Characteristics from Drone Images for Climate Resilience in the Caribbean", "abstract": "Comprehensive information on housing stock is crucial for climate adaptation initiatives aiming to reduce the adverse impacts of climate-extreme hazards in high-risk regions like the Caribbean. In this study, we propose a workflow for rapidly generating critical baseline housing stock data using very high-resolution drone images and deep learning techniques. Specifically, our work leverages the Segment Anything Model and convolutional neural networks for the automated generation of building footprints and roof classification maps. By strengthening local capacity within government agencies to leverage AI and Earth Observation-based solutions, this work seeks to improve the climate resilience of the housing sector in small island developing states in the Caribbean.", "link": "http://arxiv.org/abs/2312.10306v1"}, {"index": 58, "title": "A Comparison of Models for Rolling Stock Scheduling", "abstract": "A major step in the planning process of passenger railway operators is the assignment of rolling stock, i.e., train units, to the trips of the timetable. A wide variety of mathematical optimization models have been proposed to support this task, which we discuss and argue to be justified in order to deal with operational differences between railway operators, and hence different planning requirements, in the best possible way. Our investigation focuses on two commonly used models, the Composition model and the Hypergraph model, that were developed for Netherlands Railways (NS) and DB Fernverkehr AG (DB), respectively. We compare these models in a rolling stock scheduling setting similar to that of NS, which we show to be strongly NP-hard, and propose different variants of the Hypergraph model to tune the model to the NS setting. We prove that, in this setting, the linear programming bounds of both models are equally strong as long as a Hypergraph model variant is chosen that is sufficiently expressive. However, through a numerical evaluation on NS instances, we show that the Composition model is generally more compact in practice and can find optimal solutions in the shortest running time.", "link": "http://arxiv.org/abs/2312.09697v1"}, {"index": 59, "title": "A quantitative fusion strategy of stock picking and timing based on Particle Swarm Optimized-Back Propagation Neural Network and Multivariate Gaussian-Hidden Markov Model", "abstract": "In recent years, machine learning (ML) has brought effective approaches and novel techniques to economic decision, investment forecasting, and risk management, etc., coping the variable and intricate nature of economic and financial environments. For the investment in stock market, this research introduces a pioneering quantitative fusion model combining stock timing and picking strategy by leveraging the Multivariate Gaussian-Hidden Markov Model (MGHMM) and Back Propagation Neural Network optimized by Particle Swarm (PSO-BPNN). After the information coefficients (IC) between fifty-two factors that have been winsorized, neutralized and standardized and the return of CSI 300 index are calculated, a given amount of factors that rank ahead are choose to be candidate factors heading for the input of PSO-BPNN after dimension reduction by Principal Component Analysis (PCA), followed by a certain amount of constituent stocks outputted. Subsequently, we conduct the prediction and trading on the basis of the screening stocks and stock market state outputted by MGHMM trained using inputting CSI 300 index data after Box-Cox transformation, bespeaking eximious performance during the period of past four years. Ultimately, some conventional forecast and trading methods are compared with our strategy in Chinese stock market. Our fusion strategy incorporating stock picking and timing presented in this article provide a innovative technique for financial analysis.", "link": "http://arxiv.org/abs/2312.05756v3"}, {"index": 60, "title": "An explanation for the distribution characteristics of stock returns", "abstract": "Observations indicate that the distributions of stock returns in financial markets usually do not conform to normal distributions, but rather exhibit characteristics of high peaks, fat tails and biases. In this work, we assume that the effects of events or information on prices obey normal distribution, while financial markets often overreact or underreact to events or information, resulting in non normal distributions of stock returns. Based on the above assumptions, we propose a reaction function for a financial market reacting to events or information, and a model based on it to describe the distribution of real stock returns. Our analysis of the returns of China Securities Index 300 (CSI 300), the Standard & Poor's 500 Index (SPX or S&P 500) and the Nikkei 225 Index (N225) at different time scales shows that financial markets often underreact to events or information with minor impacts, overreact to events or information with relatively significant impacts, and react slightly stronger to positive events or information than to negative ones. In addition, differences in financial markets and time scales of returns can also affect the shapes of the reaction functions.", "link": "http://arxiv.org/abs/2312.02472v1"}, {"index": 61, "title": "Stock Movement and Volatility Prediction from Tweets, Macroeconomic Factors and Historical Prices", "abstract": "Predicting stock market is vital for investors and policymakers, acting as a barometer of the economic health. We leverage social media data, a potent source of public sentiment, in tandem with macroeconomic indicators as government-compiled statistics, to refine stock market predictions. However, prior research using tweet data for stock market prediction faces three challenges. First, the quality of tweets varies widely. While many are filled with noise and irrelevant details, only a few genuinely mirror the actual market scenario. Second, solely focusing on the historical data of a particular stock without considering its sector can lead to oversight. Stocks within the same industry often exhibit correlated price behaviors. Lastly, simply forecasting the direction of price movement without assessing its magnitude is of limited value, as the extent of the rise or fall truly determines profitability. In this paper, diverging from the conventional methods, we pioneer an ECON. The framework has following advantages: First, ECON has an adept tweets filter that efficiently extracts and decodes the vast array of tweet data. Second, ECON discerns multi-level relationships among stocks, sectors, and macroeconomic factors through a self-aware mechanism in semantic space. Third, ECON offers enhanced accuracy in predicting substantial stock price fluctuations by capitalizing on stock price movement. We showcase the state-of-the-art performance of our proposed model using a dataset, specifically curated by us, for predicting stock market movements and volatility.", "link": "http://arxiv.org/abs/2312.03758v1"}, {"index": 62, "title": "ResNLS: An Improved Model for Stock Price Forecasting", "abstract": "Stock prices forecasting has always been a challenging task. Although many research projects adopt machine learning and deep learning algorithms to address the problem, few of them pay attention to the varying degrees of dependencies between stock prices. In this paper we introduce a hybrid model that improves stock price prediction by emphasizing the dependencies between adjacent stock prices. The proposed model, ResNLS, is mainly composed of two neural architectures, ResNet and LSTM. ResNet serves as a feature extractor to identify dependencies between stock prices across time windows, while LSTM analyses the initial time-series data with the combination of dependencies which considered as residuals. In predicting the SSE Composite Index, our experiment reveals that when the closing price data for the previous 5 consecutive trading days is used as the input, the performance of the model (ResNLS-5) is optimal compared to those with other inputs. Furthermore, ResNLS-5 outperforms vanilla CNN, RNN, LSTM, and BiLSTM models in terms of prediction accuracy. It also demonstrates at least a 20% improvement over the current state-of-the-art baselines. To verify whether ResNLS-5 can help clients effectively avoid risks and earn profits in the stock market, we construct a quantitative trading framework for back testing. The experimental results show that the trading strategy based on predictions from ResNLS-5 can successfully mitigate losses during declining stock prices and generate profits in the periods of rising stock prices.", "link": "http://dx.doi.org/10.1111/coin.12608"}, {"index": 63, "title": "Investigation of Indian stock markets using topological data analysis and geometry-inspired network measures", "abstract": "Geometry-inspired measures (such as discrete Ricci curvatures) and topological data analysis (TDA) based methods (such as persistent homology) have become attractive tools for characterizing the higher-order structure of networks representing the financial systems. In this study, our goal is to perform a comparative analysis of both these approaches, especially by assessing the fragility and systemic risk in the Indian stock markets, which is known for its high volatility and risk. To achieve this goal, we analyze the time series of daily log-returns of stocks comprising the National Stock Exchange (NSE) and the Bombay Stock Exchange (BSE). Specifically, our aim is to monitor the changes in standard network measures, edge-centric discrete Ricci curvatures, and persistent homology based topological measures computed from cross-correlation matrices of stocks. In this study, the edge-centric discrete Ricci curvatures have been employed for the first time in the analysis of the Indian stock markets. The Indian stock markets are known to be less diverse in comparison to the US market, and hence provides us an interesting example. Our results point that, among the persistent homology based topological measures, persistent entropy is simple and more robust than $L^1$-norm and $L^2$-norm of persistence landscape. In a broader comparison between network analysis and TDA, we highlight that the network analysis is sensitive to the way of constructing the networks (threshold or minimum spanning tree), as well as the threshold values used to construct the correlation-based threshold networks. On the other hand, the persistent homology is a more robust approach and is able to capture the higher-order interactions and eliminate noisy data in financial systems, since it does not take into account a single value of threshold but rather a range of values.", "link": "http://arxiv.org/abs/2311.17016v1"}, {"index": 64, "title": "Information Content of Financial Youtube Channel: Case Study of 3PROTV and Korean Stock Market", "abstract": "We investigate the information content of 3PROTV, a south Korean financial youtube channel. In our sample we found evidence for the hypothesis that the channel have information content on stock selection, but only on negative sentiment. Positively mentioned stock had pre-announcement spike followed by steep fall in stock price around announcement period. Negatively mentioned stock started underperforming around the announcement period, with underreaction dynamics in post-announcement period. In the area of market timing, we found that change of sentimental tone of 3PROTV than its historical average predicts the lead value of Korean market portfolio return. Its predictive power cannot be explained by future change in news sentiment, future short term interest rate, and future liquidity risk.", "link": "http://arxiv.org/abs/2311.15247v1"}, {"index": 65, "title": "Real-Time Online Stock Forecasting Utilizing Integrated Quantitative and Qualitative Analysis", "abstract": "The application of Machine learning to finance has become a familiar approach, even more so in stock market forecasting. The stock market is highly volatile, and huge amounts of data are generated every minute globally. The extraction of effective intelligence from this data is of critical importance. However, a collaboration of numerical stock data with qualitative text data can be a challenging task. In this work, we accomplish this by providing an unprecedented, publicly available dataset with technical and fundamental data and sentiment that we gathered from news archives, TV news captions, radio transcripts, tweets, daily financial newspapers, etc. The text data entries used for sentiment extraction total more than 1.4 Million. The dataset consists of daily entries from January 2018 to December 2022 for eight companies representing diverse industrial sectors and the Dow Jones Industrial Average (DJIA) as a whole. Holistic Fundamental and Technical data is provided training ready for Model learning and deployment. Most importantly, the data generated could be used for incremental online learning with real-time data points retrieved daily since no stagnant data was utilized. All the data was retired from APIs or self-designed robust information retrieval technologies with extremely low latency and zero monetary cost. These adaptable technologies facilitate data extraction for any stock. Moreover, the utilization of Spearman's rank correlation over real-time data, linking stock returns with sentiment analysis has produced noteworthy results for the DJIA and the eight other stocks, achieving accuracy levels surpassing 60%. The dataset is made available at https://github.com/batking24/Huge-Stock-Dataset.", "link": "http://arxiv.org/abs/2311.15218v4"}, {"index": 66, "title": "Coevolution of Neural Architectures and Features for Stock Market Forecasting: A Multi-objective Decision Perspective", "abstract": "In a multi objective setting, a portfolio manager's highly consequential decisions can benefit from assessing alternative forecasting models of stock index movement. The present investigation proposes a new approach to identify a set of nondominated neural network models for further selection by the decision maker. A new coevolution approach is proposed to simultaneously select the features and topology of neural networks (collectively referred to as neural architecture), where the features are viewed from a topological perspective as input neurons. Further, the coevolution is posed as a multicriteria problem to evolve sparse and efficacious neural architectures. The well known dominance and decomposition based multiobjective evolutionary algorithms are augmented with a nongeometric crossover operator to diversify and balance the search for neural architectures across conflicting criteria. Moreover, the coevolution is augmented to accommodate the data based implications of distinct market behaviors prior to and during the ongoing COVID 19 pandemic. A detailed comparative evaluation is carried out with the conventional sequential approach of feature selection followed by neural topology design, as well as a scalarized coevolution approach. The results on the NASDAQ index in pre and peri COVID time windows convincingly demonstrate that the proposed coevolution approach can evolve a set of nondominated neural forecasting models with better generalization capabilities.", "link": "http://dx.doi.org/10.1016/j.dss.2023.114015"}, {"index": 67, "title": "Volatility and irregularity Capturing in stock price indices using time series Generative adversarial networks (TimeGAN)", "abstract": "This paper captures irregularities in financial time series data, particularly stock prices, in the presence of COVID-19 shock. We conjectured that jumps and irregularities are embedded in stock data due to the pandemic shock, which brings forth irregular trends in the time series data. We put forward that efficient and robust forecasting methods are needed to predict stock closing prices in the presence of the pandemic shock. This piece of information is helpful to investors as far as confidence risk and return boost are concerned. Generative adversarial networks of a time series nature are used to provide new ways of modeling and learning the proper and suitable distribution for the financial time series data under complex setups. Ideally, these traditional models are liable to producing high forecasting errors, and they need to be more robust to capture dependency structures and other stylized facts like volatility in stock markets. The TimeGAN model is used, effectively dealing with this risk of poor forecasts. Using the DAX stock index from January 2010 to November 2022, we trained the LSTM, GRU, WGAN, and TimeGAN models as benchmarks and forecasting errors were noted, and our TimeGAN outperformed them all as indicated by a small forecasting error.", "link": "http://arxiv.org/abs/2311.12987v1"}, {"index": 68, "title": "Verifying the inverse Laplace transform of total expected stock-outs when demand is Poisson", "abstract": "This note aims to verify a Laplace transform pair, previously published without proof, concerning the expected stock-out that may occur in a production-inventory systems when demand is Poisson, and the time horizon is finite. Stock-out, or \"backlog\", is understood as the non-negative difference between cumulative demand, a stochastic variable, and production over a finite time interval. The hoped for outcome is greater clarity on how the Laplace transform pair of interest might be arrived at, and a possible improvement in terms of accuracy on the original result.", "link": "http://arxiv.org/abs/2311.12629v1"}, {"index": 69, "title": "Reinforcement Learning with Maskable Stock Representation for Portfolio Management in Customizable Stock Pools", "abstract": "Portfolio management (PM) is a fundamental financial trading task, which explores the optimal periodical reallocation of capitals into different stocks to pursue long-term profits. Reinforcement learning (RL) has recently shown its potential to train profitable agents for PM through interacting with financial markets. However, existing work mostly focuses on fixed stock pools, which is inconsistent with investors' practical demand. Specifically, the target stock pool of different investors varies dramatically due to their discrepancy on market states and individual investors may temporally adjust stocks they desire to trade (e.g., adding one popular stocks), which lead to customizable stock pools (CSPs). Existing RL methods require to retrain RL agents even with a tiny change of the stock pool, which leads to high computational cost and unstable performance. To tackle this challenge, we propose EarnMore, a rEinforcement leARNing framework with Maskable stOck REpresentation to handle PM with CSPs through one-shot training in a global stock pool (GSP). Specifically, we first introduce a mechanism to mask out the representation of the stocks outside the target pool. Second, we learn meaningful stock representations through a self-supervised masking and reconstruction process. Third, a re-weighting mechanism is designed to make the portfolio concentrate on favorable stocks and neglect the stocks outside the target pool. Through extensive experiments on 8 subset stock pools of the US stock market, we demonstrate that EarnMore significantly outperforms 14 state-of-the-art baselines in terms of 6 popular financial metrics with over 40% improvement on profit.", "link": "http://arxiv.org/abs/2311.10801v4"}, {"index": 70, "title": "In the Red(dit): Social Media and Stock Prices", "abstract": "Spearheaded by retail traders on the website reddit, the GameStop short squeeze of early 2021 shows that social media embeds information that correlates with market movements. This paper seeks to examine this relationship by using daily frequencies of classified comments and buzzwords as additional factors in a Fama-French three factor model. Comments are classified using an unsupervised clustering method, while past studies have used pretrained models that are not specific to the domains being studied.", "link": "http://arxiv.org/abs/2311.09252v1"}, {"index": 71, "title": "Application Research of Spline Interpolation and ARIMA in the Field of Stock Market Forecasting", "abstract": "The ARIMA (Autoregressive Integrated Moving Average model) has extensive applications in the field of time series forecasting. However, the predictive performance of the ARIMA model is limited when dealing with data gaps or significant noise. Based on previous research, we have found that cubic spline interpolation performs well in capturing the smooth changes of stock price curves, especially when the market trends are relatively stable. Therefore, this paper integrates the two approaches by taking the time series data in stock trading as an example, establishes a time series forecasting model based on cubic spline interpolation and ARIMA. Through validation, the model has demonstrated certain guidance and reference value for short-term time series forecasting.", "link": "http://arxiv.org/abs/2311.10759v1"}, {"index": 72, "title": "Revisiting Stylized Facts for Modern Stock Markets", "abstract": "In 2001, Rama Cont introduced a now-widely used set of 'stylized facts' to synthesize empirical studies of financial time series, resulting in 11 qualitative properties presumed to be universal to all financial markets. Here, we replicate Cont's analyses for a convenience sample of stocks drawn from the U.S. stock market following a fundamental shift in market regulation. Our study relies on the same authoritative data as that used by the U.S. regulator. We find conclusive evidence in the modern market for eight of Cont's original facts, while we find weak support for one additional fact and no support for the remaining two. Our study represents the first test of the original set of 11 stylized facts against the same stocks, therefore providing insight into how Cont's stylized facts should be viewed in the context of modern stock markets.", "link": "http://arxiv.org/abs/2311.07738v1"}, {"index": 73, "title": "Predicting Stock Price of Construction Companies using Weighted Ensemble Learning", "abstract": "Modeling the behavior of stock price data has always been one of the challengeous applications of Artificial Intelligence (AI) and Machine Learning (ML) due to its high complexity and dependence on various conditions. Recent studies show that this will be difficult to do with just one learning model. The problem can be more complex for companies of construction section, due to the dependency of their behavior on more conditions. This study aims to provide a hybrid model for improving the accuracy of prediction for stock price index of companies in construction section. The contribution of this paper can be considered as follows: First, a combination of several prediction models is used to predict stock price, so that learning models can cover each other's error. In this research, an ensemble model based on Artificial Neural Network (ANN), Gaussian Process Regression (GPR) and Classification and Regression Tree (CART) is presented for predicting stock price index. Second, the optimization technique is used to determine the effect of each learning model on the prediction result. For this purpose, first all three mentioned algorithms process the data simultaneously and perform the prediction operation. Then, using the Cuckoo Search (CS) algorithm, the output weight of each algorithm is determined as a coefficient. Finally, using the ensemble technique, these results are combined and the final output is generated through weighted averaging on optimal coefficients. The results showed that using CS optimization in the proposed ensemble system is highly effective in reducing prediction error. Comparing the evaluation results of the proposed system with similar algorithms, indicates that our model is more accurate and can be useful for predicting stock price index in real-world scenarios.", "link": "http://arxiv.org/abs/2311.06397v2"}, {"index": 74, "title": "How Embeddedness Affects the Evolution of Collaboration: The Role of Knowledge Stock and Social Interactions", "abstract": "Science and technology are becoming increasingly collaborative. This paper aims to explore the factors and mechanisms that impact the dynamic changes of collaborative innovation networks. We consider both collaborative interactions of organizations and their knowledge element exchanges to reveal how social and knowledge network embeddedness affects the collaboration dynamics. Knowledge elements are extracted to present the core concepts of scientific and technical information, overcoming the limitations of using predefined categorizations such as IPC when representing the content. Based on multiple collaboration and knowledge networks, we then conduct a longitudinal analysis and apply a stochastic actor-oriented model (SAOM) to model network dynamics over different periods. The influence of network features and structures, individual node characteristics, and various dimensions of proximity on collaboration dynamics is tested and analyzed.", "link": "http://arxiv.org/abs/2311.05909v1"}, {"index": 75, "title": "A Model-Based Synthetic Stock Price Time Series Generation Framework", "abstract": "The Ornstein-Uhlenbeck (OU) process, a mean-reverting stochastic process, has been widely applied as a time series model in various domains. This paper describes the design and implementation of a model-based synthetic time series model based on a multivariate OU process and the Arbitrage Pricing Theory (APT) for generating synthetic pricing data for a complex market of interacting stocks. The objective is to create a group of synthetic stock price time series that reflects the correlation between individual stocks and clusters of stocks in how a real market behaves. We demonstrate the method using the Standard and Poor's (S&P) 500 universe of stocks as an example.", "link": "http://arxiv.org/abs/2311.02209v1"}, {"index": 76, "title": "ALERTA-Net: A Temporal Distance-Aware Recurrent Networks for Stock Movement and Volatility Prediction", "abstract": "For both investors and policymakers, forecasting the stock market is essential as it serves as an indicator of economic well-being. To this end, we harness the power of social media data, a rich source of public sentiment, to enhance the accuracy of stock market predictions. Diverging from conventional methods, we pioneer an approach that integrates sentiment analysis, macroeconomic indicators, search engine data, and historical prices within a multi-attention deep learning model, masterfully decoding the complex patterns inherent in the data. We showcase the state-of-the-art performance of our proposed model using a dataset, specifically curated by us, for predicting stock market movements and volatility.", "link": "http://dx.doi.org/10.1145/3625007.3627488"}, {"index": 77, "title": "Boosting Stock Price Prediction with Anticipated Macro Policy Changes", "abstract": "Prediction of stock prices plays a significant role in aiding the decision-making of investors. Considering its importance, a growing literature has emerged trying to forecast stock prices with improved accuracy. In this study, we introduce an innovative approach for forecasting stock prices with greater accuracy. We incorporate external economic environment-related information along with stock prices. In our novel approach, we improve the performance of stock price prediction by taking into account variations due to future expected macroeconomic policy changes as investors adjust their current behavior ahead of time based on expected future macroeconomic policy changes. Furthermore, we incorporate macroeconomic variables along with historical stock prices to make predictions. Results from this strongly support the inclusion of future economic policy changes along with current macroeconomic information. We confirm the supremacy of our method over the conventional approach using several tree-based machine-learning algorithms. Results are strongly conclusive across various machine learning models. Our preferred model outperforms the conventional approach with an RMSE value of 1.61 compared to an RMSE value of 1.75 from the conventional approach.", "link": "http://dx.doi.org/10.32996/jmss"}, {"index": 78, "title": "Stock Market Directional Bias Prediction Using ML Algorithms", "abstract": "The stock market has been established since the 13th century, but in the current epoch of time, it is substantially more practicable to anticipate the stock market than it was at any other point in time due to the tools and data that are available for both traditional and algorithmic trading. There are many different machine learning models that can do time-series forecasting in the context of machine learning. These models can be used to anticipate the future prices of assets and/or the directional bias of assets. In this study, we examine and contrast the effectiveness of three different machine learning algorithms, namely, logistic regression, decision tree, and random forest to forecast the movement of the assets traded on the Japanese stock market. In addition, the models are compared to a feed forward deep neural network, and it is found that all of the models consistently reach above 50% in directional bias forecasting for the stock market. The results of our study contribute to a better understanding of the complexity involved in stock market forecasting and give insight on the possible role that machine learning could play in this context.", "link": "http://arxiv.org/abs/2310.16855v1"}, {"index": 79, "title": "A Comparative Study of Portfolio Optimization Methods for the Indian Stock Market", "abstract": "This chapter presents a comparative study of the three portfolio optimization methods, MVP, HRP, and HERC, on the Indian stock market, particularly focusing on the stocks chosen from 15 sectors listed on the National Stock Exchange of India. The top stocks of each cluster are identified based on their free-float market capitalization from the report of the NSE published on July 1, 2022 (NSE Website). For each sector, three portfolios are designed on stock prices from July 1, 2019, to June 30, 2022, following three portfolio optimization approaches. The portfolios are tested over the period from July 1, 2022, to June 30, 2023. For the evaluation of the performances of the portfolios, three metrics are used. These three metrics are cumulative returns, annual volatilities, and Sharpe ratios. For each sector, the portfolios that yield the highest cumulative return, the lowest volatility, and the maximum Sharpe Ratio over the training and the test periods are identified.", "link": "http://arxiv.org/abs/2310.14748v1"}, {"index": 80, "title": "Feature selection and regression methods for stock price prediction using technical indicators", "abstract": "Due to the influence of many factors, including technical indicators on stock price prediction, feature selection is important to choose the best indicators. This study uses technical indicators and features selection and regression methods to solve the problem of closing the stock market price. The aim of this research is to predict the stock market price with the least error. By the proposed method, the data created by the 3-day time window were converted to the appropriate input for regression methods. In this paper, 10 regressor and 123 technical indicators have been examined on data of the last 13 years of Apple Company. The results have been investigated by 5 error-based evaluation criteria. Based on results of the proposed method, MLPSF has 56/47% better performance than MLP. Also, SVRSF has 67/42% improved compared to SVR. LRSF was 76.7 % improved compared to LR. The RISF method also improved 72.82 % of Ridge regression. The DTRSB method had 24.23 % improvement over DTR. KNNSB had 15.52 % improvement over KNN regression. RFSB had a 6 % improvement over RF. GBRSF also improved at 7% over GBR. Finally, ADASF and ADASB also had a 4% improvement over the ADA regression. Also, Ridge and LinearRegression had the best results for stock price prediction. Based on results, the best indicators to predict stock price are: the Squeeze_pro, Percentage Price Oscillator, Thermo, Decay, Archer On-Balance Volume, Bollinger Bands, Squeeze and Ichimoku indicator. According to the results, the use of suitable combination of suggested indicators along with regression methods has resulted in high accuracy in predicting the closing price.", "link": "http://arxiv.org/abs/2310.09903v4"}, {"index": 81, "title": "A Portfolio Rebalancing Approach for the Indian Stock Market", "abstract": "This chapter presents a calendar rebalancing approach to portfolios of stocks in the Indian stock market. Ten important sectors of the Indian economy are first selected. For each of these sectors, the top ten stocks are identified based on their free-float market capitalization values. Using the ten stocks in each sector, a sector-specific portfolio is designed. In this study, the historical stock prices are used from January 4, 2021, to September 20, 2023 (NSE Website). The portfolios are designed based on the training data from January 4, 2021 to June 30, 2022. The performances of the portfolios are tested over the period from July 1, 2022, to September 20, 2023. The calendar rebalancing approach presented in the chapter is based on a yearly rebalancing method. However, the method presented is perfectly flexible and can be adapted for weekly or monthly rebalancing. The rebalanced portfolios for the ten sectors are analyzed in detail for their performances. The performance results are not only indicative of the relative performances of the sectors over the training (i.e., in-sample) data and test (out-of-sample) data, but they also reflect the overall effectiveness of the proposed portfolio rebalancing approach.", "link": "http://arxiv.org/abs/2310.09770v1"}, {"index": 82, "title": "Potential of ChatGPT in predicting stock market trends based on Twitter Sentiment Analysis", "abstract": "The rise of ChatGPT has brought a notable shift to the AI sector, with its exceptional conversational skills and deep grasp of language. Recognizing its value across different areas, our study investigates ChatGPT's capacity to predict stock market movements using only social media tweets and sentiment analysis. We aim to see if ChatGPT can tap into the vast sentiment data on platforms like Twitter to offer insightful predictions about stock trends. We focus on determining if a tweet has a positive, negative, or neutral effect on two big tech giants Microsoft and Google's stock value. Our findings highlight a positive link between ChatGPT's evaluations and the following days stock results for both tech companies. This research enriches our view on ChatGPT's adaptability and emphasizes the growing importance of AI in shaping financial market forecasts.", "link": "http://arxiv.org/abs/2311.06273v1"}, {"index": 83, "title": "Quantum-Enhanced Forecasting: Leveraging Quantum Gramian Angular Field and CNNs for Stock Return Predictions", "abstract": "We propose a time series forecasting method named Quantum Gramian Angular Field (QGAF). This approach merges the advantages of quantum computing technology with deep learning, aiming to enhance the precision of time series classification and forecasting. We successfully transformed stock return time series data into two-dimensional images suitable for Convolutional Neural Network (CNN) training by designing specific quantum circuits. Distinct from the classical Gramian Angular Field (GAF) approach, QGAF's uniqueness lies in eliminating the need for data normalization and inverse cosine calculations, simplifying the transformation process from time series data to two-dimensional images. To validate the effectiveness of this method, we conducted experiments on datasets from three major stock markets: the China A-share market, the Hong Kong stock market, and the US stock market. Experimental results revealed that compared to the classical GAF method, the QGAF approach significantly improved time series prediction accuracy, reducing prediction errors by an average of 25% for Mean Absolute Error (MAE) and 48% for Mean Squared Error (MSE). This research confirms the potential and promising prospects of integrating quantum computing with deep learning techniques in financial time series forecasting.", "link": "http://arxiv.org/abs/2310.07427v3"}, {"index": 84, "title": "Valuation Duration of the Stock Market", "abstract": "At the peak of the tech bubble, only 0.57% of market valuation comes from dividends in the next year. Taking the ratio of total market value to the value of one-year dividends, we obtain a valuation-based duration of 175 years. In contrast, at the height of the global financial crisis, more than 2.2% of market value is from dividends in the next year, implying a duration of 46 years. What drives valuation duration? We find that market participants have limited information about cash flow beyond one year. Therefore, an increase in valuation duration is due to a decrease in the discount rate rather than good news about long-term growth. Accordingly, valuation duration negatively predicts annual market return with an out-of-sample R2 of 15%, robustly outperforming other predictors in the literature. While the price-dividend ratio reflects the overall valuation level, our valuation-based measure of duration captures the slope of the valuation term structure. We show that valuation duration, as a discount rate proxy, is a critical state variable that augments the price-dividend ratio in spanning the (latent) state space for stock-market dynamics.", "link": "http://arxiv.org/abs/2310.07110v1"}, {"index": 85, "title": "Dual-Class Stocks: Can They Serve as Effective Predictors?", "abstract": "Kardemir Karabuk Iron Steel Industry Trade & Co. Inc., ranked as the 24th largest industrial company in Turkey, offers three distinct stocks listed on the Borsa Istanbul: KRDMA, KRDMB, and KRDMD. These stocks, sharing the sole difference in voting power, have exhibited significant price divergence over an extended period. This paper conducts an in-depth analysis of the divergence patterns observed in these three stock prices from January 2001 to July 2023. Additionally, it introduces an innovative training set selection rule tailored for LSTM models, incorporating a rolling training set, and demonstrates its significant predictive superiority over the conventional use of LSTM models with large training sets. Despite their strong correlation, the study found no compelling evidence supporting the efficiency of dual-class stocks as predictors of each other's performance.", "link": "http://arxiv.org/abs/2310.16845v1"}, {"index": 86, "title": "Construction of stock molecular system and popularization of Density Functional Theory in stock market", "abstract": "Over the past two decades, some scholars have noticed the correlation between quantum mechanics and finance/economy, making some novel attempts to introduce the theoretical framework of quantum mechanics into financial and economic research, subsequently a new research domain called quantum finance or quantum economy was set up. In particular, some studies have made their endeavour in the stock market, utilizing the quantum mechanical paradigm to describe the movement of stock price. Nevertheless, the majority of researches have paid attention to describing the motion of a single stock, and drawn an analogy between the motion of a single stock and a one-dimensional infinite well, or one-dimensional harmonic oscillator model, whose modality looks alike to the one-electron Schr\\\"odinger equation, in which the information is solved analytically in most cases. Hitherto, the whole stock market system composed of all stocks and stock indexes have not been discussed. In this paper, the concept of stock molecular system is first proposed with pioneer. The modality of stock molecular system resembles the multi-electrons Schr\\\"odinger equation with Born-Oppenheimer approximation. Similar to the interaction among all nuclei and electrons in a molecule, the interaction exist among all stock indexes and stocks. This paper also establish the stock-index Coulomb potential, stock-index Coulomb potential, stock-stock Coulomb potential and stock coulomb correlation terms by statistical theory. At length, the conceive and feasibility of drawing upon density functional theory (DFT) to solve the Schr\\\"odinger equation of stock molecular system are put forward together with proof, ending up with experiments executed in CSI 300 index system.", "link": "http://arxiv.org/abs/2310.05677v3"}, {"index": 87, "title": "Integrating Stock Features and Global Information via Large Language Models for Enhanced Stock Return Prediction", "abstract": "The remarkable achievements and rapid advancements of Large Language Models (LLMs) such as ChatGPT and GPT-4 have showcased their immense potential in quantitative investment. Traders can effectively leverage these LLMs to analyze financial news and predict stock returns accurately. However, integrating LLMs into existing quantitative models presents two primary challenges: the insufficient utilization of semantic information embedded within LLMs and the difficulties in aligning the latent information within LLMs with pre-existing quantitative stock features. We propose a novel framework consisting of two components to surmount these challenges. The first component, the Local-Global (LG) model, introduces three distinct strategies for modeling global information. These approaches are grounded respectively on stock features, the capabilities of LLMs, and a hybrid method combining the two paradigms. The second component, Self-Correlated Reinforcement Learning (SCRL), focuses on aligning the embeddings of financial news generated by LLMs with stock features within the same semantic space. By implementing our framework, we have demonstrated superior performance in Rank Information Coefficient and returns, particularly compared to models relying only on stock features in the China A-share market.", "link": "http://arxiv.org/abs/2310.05627v1"}, {"index": 88, "title": "An Information Theory Approach to the Stock and Cryptocurrency Market: A Statistical Equilibrium Perspective", "abstract": "We study the stochastic structure of cryptocurrency rates of returns as compared to stock returns by focusing on the associated cross-sectional distributions. We build two datasets. The first comprises forty-six major cryptocurrencies, and the second includes all the companies listed in the S&P 500. We collect individual data from January 2017 until December 2022. We then apply the Quantal Response Statistical Equilibrium (QRSE) model to recover the cross-sectional frequency distribution of the daily returns of cryptocurrencies and S&P 500 companies. We study the stochastic structure of these two markets and the properties of investors' behavior over bear and bull trends. Finally, we compare the degree of informational efficiency of these two markets.", "link": "http://arxiv.org/abs/2310.04907v1"}, {"index": 89, "title": "Hidden Markov Models for Stock Market Prediction", "abstract": "The stock market presents a challenging environment for accurately predicting future stock prices due to its intricate and ever-changing nature. However, the utilization of advanced methodologies can significantly enhance the precision of stock price predictions. One such method is Hidden Markov Models (HMMs). HMMs are statistical models that can be used to model the behavior of a partially observable system, making them suitable for modeling stock prices based on historical data. Accurate stock price predictions can help traders make better investment decisions, leading to increased profits.   In this article, we trained and tested a Hidden Markov Model for the purpose of predicting a stock closing price based on its opening price and the preceding day's prices. The model's performance has been evaluated using two indicators: Mean Average Prediction Error (MAPE), which specifies the average accuracy of our model, and Directional Prediction Accuracy (DPA), a newly introduced indicator that accounts for the number of fractional change predictions that are correct in sign.", "link": "http://arxiv.org/abs/2310.03775v1"}, {"index": 90, "title": "Linkages among the Foreign Exchange, Stock, and Bond Markets in Japan and the United States", "abstract": "While economic theory explains the linkages among the financial markets of different countries, empirical studies mainly verify the linkages through Granger causality, without considering latent variables or instantaneous effects. Their findings are inconsistent regarding the existence of causal linkages among financial markets, which might be attributed to differences in the focused markets, data periods, and methods applied. Our study adopts causal discovery methods including VAR-LiNGAM and LPCMCI with domain knowledge to explore the linkages among financial markets in Japan and the United States (US) for the post Covid-19 pandemic period under divergent monetary policy directions. The VAR-LiNGAM results reveal that the previous day's US market influences the following day's Japanese market for both stocks and bonds, and the bond markets of the previous day impact the following day's foreign exchange (FX) market directly and the following day's Japanese stock market indirectly. The LPCMCI results indicate the existence of potential latent confounders. Our results demonstrate that VAR-LiNGAM uniquely identifies the directed acyclic graph (DAG), and thus provides informative insight into the causal relationship when the assumptions are considered valid. Our study contributes to a better understanding of the linkages among financial markets in the analyzed data period by supporting the existence of linkages between Japan and the US for the same financial markets and among FX, stock, and bond markets, thus highlighting the importance of leveraging causal discovery methods in the financial domain.", "link": "http://arxiv.org/abs/2310.16841v1"}, {"index": 91, "title": "1D-CapsNet-LSTM: A Deep Learning-Based Model for Multi-Step Stock Index Forecasting", "abstract": "Multi-step stock index forecasting is vital in finance for informed decision-making. Current forecasting methods on this task frequently produce unsatisfactory results due to the inherent data randomness and instability, thereby underscoring the demand for advanced forecasting models. Given the superiority of capsule network (CapsNet) over CNN in various forecasting and classification tasks, this study investigates the potential of integrating a 1D CapsNet with an LSTM network for multi-step stock index forecasting. To this end, a hybrid 1D-CapsNet-LSTM model is introduced, which utilizes a 1D CapsNet to generate high-level capsules from sequential data and a LSTM network to capture temporal dependencies. To maintain stochastic dependencies over different forecasting horizons, a multi-input multi-output (MIMO) strategy is employed. The model's performance is evaluated on real-world stock market indices, including S&P 500, DJIA, IXIC, and NYSE, and compared to baseline models, including LSTM, RNN, and CNN-LSTM, using metrics such as RMSE, MAE, MAPE, and TIC. The proposed 1D-CapsNet-LSTM model consistently outperforms baseline models in two key aspects. It exhibits significant reductions in forecasting errors compared to baseline models. Furthermore, it displays a slower rate of error increase with lengthening forecast horizons, indicating increased robustness for multi-step forecasting tasks.", "link": "http://dx.doi.org/10.1016/j.jksuci.2024.101959"}, {"index": 92, "title": "Study of Stylized Facts in Stock Market Data", "abstract": "A property of data which is common across a wide range of instruments, markets and time periods is known as stylized empirical fact in the financial statistics literature. This paper first presents a wide range of stylized facts studied in literature which include some univariate distributional properties, multivariate properties and time series related properties of the financial time series data. In the next part of the paper, price data from several stocks listed on 10 stock exchanges spread across different continents has been analysed and data analysis has been presented.", "link": "http://arxiv.org/abs/2310.00753v1"}, {"index": 93, "title": "NoxTrader: LSTM-Based Stock Return Momentum Prediction for Quantitative Trading", "abstract": "We introduce NoxTrader, a sophisticated system designed for portfolio construction and trading execution with the primary objective of achieving profitable outcomes in the stock market, specifically aiming to generate moderate to long-term profits. The underlying learning process of NoxTrader is rooted in the assimilation of valuable insights derived from historical trading data, particularly focusing on time-series analysis due to the nature of the dataset employed. In our approach, we utilize price and volume data of US stock market for feature engineering to generate effective features, including Return Momentum, Week Price Momentum, and Month Price Momentum. We choose the Long Short-Term Memory (LSTM)model to capture continuous price trends and implement dynamic model updates during the trading execution process, enabling the model to continuously adapt to the current market trends. Notably, we have developed a comprehensive trading backtesting system - NoxTrader, which allows us to manage portfolios based on predictive scores and utilize custom evaluation metrics to conduct a thorough assessment of our trading performance. Our rigorous feature engineering and careful selection of prediction targets enable us to generate prediction data with an impressive correlation range between 0.65 and 0.75. Finally, we monitor the dispersion of our prediction data and perform a comparative analysis against actual market data. Through the use of filtering techniques, we improved the initial -60% investment return to 325%.", "link": "http://arxiv.org/abs/2310.00747v2"}, {"index": 94, "title": "Assessing Look-Ahead Bias in Stock Return Predictions Generated By GPT Sentiment Analysis", "abstract": "Large language models (LLMs), including ChatGPT, can extract profitable trading signals from the sentiment in news text. However, backtesting such strategies poses a challenge because LLMs are trained on many years of data, and backtesting produces biased results if the training and backtesting periods overlap. This bias can take two forms: a look-ahead bias, in which the LLM may have specific knowledge of the stock returns that followed a news article, and a distraction effect, in which general knowledge of the companies named interferes with the measurement of a text's sentiment. We investigate these sources of bias through trading strategies driven by the sentiment of financial news headlines. We compare trading performance based on the original headlines with de-biased strategies in which we remove the relevant company's identifiers from the text. In-sample (within the LLM training window), we find, surprisingly, that the anonymized headlines outperform, indicating that the distraction effect has a greater impact than look-ahead bias. This tendency is particularly strong for larger companies--companies about which we expect an LLM to have greater general knowledge. Out-of-sample, look-ahead bias is not a concern but distraction remains possible. Our proposed anonymization procedure is therefore potentially useful in out-of-sample implementation, as well as for de-biased backtesting.", "link": "http://arxiv.org/abs/2309.17322v1"}, {"index": 95, "title": "Stock Volatility Prediction Based on Transformer Model Using Mixed-Frequency Data", "abstract": "With the increasing volume of high-frequency data in the information age, both challenges and opportunities arise in the prediction of stock volatility. On one hand, the outcome of prediction using tradition method combining stock technical and macroeconomic indicators still leaves room for improvement; on the other hand, macroeconomic indicators and peoples' search record on those search engines affecting their interested topics will intuitively have an impact on the stock volatility. For the convenience of assessment of the influence of these indicators, macroeconomic indicators and stock technical indicators are then grouped into objective factors, while Baidu search indices implying people's interested topics are defined as subjective factors. To align different frequency data, we introduce GARCH-MIDAS model. After mixing all the above data, we then feed them into Transformer model as part of the training data. Our experiments show that this model outperforms the baselines in terms of mean square error. The adaption of both types of data under Transformer model significantly reduces the mean square error from 1.00 to 0.86.", "link": "http://arxiv.org/abs/2309.16196v1"}, {"index": 96, "title": "Sluggish news reactions: A combinatorial approach for synchronizing stock jumps", "abstract": "Stock prices often react sluggishly to news, producing gradual jumps and jump delays. Econometricians typically treat these sluggish reactions as microstructure effects and settle for a coarse sampling grid to guard against them. Synchronizing mistimed stock returns on a fine sampling grid allows us to automatically detect noisy jumps and better approximate the true common jumps in related stock prices.", "link": "http://arxiv.org/abs/2309.15705v1"}, {"index": 97, "title": "Stock network inference: A framework for market analysis from topology perspective", "abstract": "From a complex network perspective, investigating the stock market holds paramount significance as it enables the systematic revelation of topological features inherent in the market. This approach is crucial in exploring market interconnectivity, systemic risks, portfolio management, and structural evolution. However, prevailing methodologies for constructing networks based on stock data rely on threshold filtering, often needing help to uncover intricate underlying associations among stocks. To address this, we introduce the Stock Network Inference Framework (SNIF), which leverages a self-encoding mechanism. Specifically, the Stock Network Inference Encoder (SNIE) facilitates network construction, while the Movement Prediction Decoder (MPD) enhances movement forecasting. This integrated process culminates in the inference of a stock network, exhibiting remarkable performance across applications such as market structure analysis, stock movement prediction, portfolio construction, and community evolution analysis. Our approach streamlines the automatic construction of stock networks, liberating the process from threshold dependencies and eliminating the need for additional financial indicators. Incorporating Graph Convolutional Network (GCN) and Long Short-Term Memory (LSTM) models within the SNIF framework, we effectively unearth deep-seated associations among stocks, augmenting the toolset available for comprehensive financial market research. This integration empowers our methodology to automatically construct stock networks without threshold dependencies or reliance on additional economic indicators.", "link": "http://arxiv.org/abs/2309.15437v1"}, {"index": 98, "title": "Performance Evaluation of Equal-Weight Portfolio and Optimum Risk Portfolio on Indian Stocks", "abstract": "Designing an optimum portfolio for allocating suitable weights to its constituent assets so that the return and risk associated with the portfolio are optimized is a computationally hard problem. The seminal work of Markowitz that attempted to solve the problem by estimating the future returns of the stocks is found to perform sub-optimally on real-world stock market data. This is because the estimation task becomes extremely challenging due to the stochastic and volatile nature of stock prices. This work illustrates three approaches to portfolio design minimizing the risk, optimizing the risk, and assigning equal weights to the stocks of a portfolio. Thirteen critical sectors listed on the National Stock Exchange (NSE) of India are first chosen. Three portfolios are designed following the above approaches choosing the top ten stocks from each sector based on their free-float market capitalization. The portfolios are designed using the historical prices of the stocks from Jan 1, 2017, to Dec 31, 2022. The portfolios are evaluated on the stock price data from Jan 1, 2022, to Dec 31, 2022. The performances of the portfolios are compared, and the portfolio yielding the higher return for each sector is identified.", "link": "http://arxiv.org/abs/2309.13696v1"}, {"index": 99, "title": "Stock Market Sentiment Classification and Backtesting via Fine-tuned BERT", "abstract": "With the rapid development of big data and computing devices, low-latency automatic trading platforms based on real-time information acquisition have become the main components of the stock trading market, so the topic of quantitative trading has received widespread attention. And for non-strongly efficient trading markets, human emotions and expectations always dominate market trends and trading decisions. Therefore, this paper starts from the theory of emotion, taking East Money as an example, crawling user comment titles data from its corresponding stock bar and performing data cleaning. Subsequently, a natural language processing model BERT was constructed, and the BERT model was fine-tuned using existing annotated data sets. The experimental results show that the fine-tuned model has different degrees of performance improvement compared to the original model and the baseline model. Subsequently, based on the above model, the user comment data crawled is labeled with emotional polarity, and the obtained label information is combined with the Alpha191 model to participate in regression, and significant regression results are obtained. Subsequently, the regression model is used to predict the average price change for the next five days, and use it as a signal to guide automatic trading. The experimental results show that the incorporation of emotional factors increased the return rate by 73.8\\% compared to the baseline during the trading period, and by 32.41\\% compared to the original alpha191 model. Finally, we discuss the advantages and disadvantages of incorporating emotional factors into quantitative trading, and give possible directions for further research in the future.", "link": "http://arxiv.org/abs/2309.11979v1"}, {"index": 100, "title": "Comparing effects of price limit and circuit breaker in stock exchanges by an agent-based model", "abstract": "The prevention of rapidly and steeply falling market prices is vital to avoid financial crisis. To this end, some stock exchanges implement a price limit or a circuit breaker, and there has been intensive investigation into which regulation best prevents rapid and large variations in price. In this study, we examine this question using an artificial market model that is an agent-based model for a financial market. Our findings show that the price limit and the circuit breaker basically have the same effect when the parameters, limit price range and limit time range, are the same. However, the price limit is less effective when limit the time range is smaller than the cancel time range. With the price limit, many sell orders are accumulated around the lower limit price, and when the lower limit price is changed before the accumulated sell orders are cancelled, it leads to the accumulation of sell orders of various prices. These accumulated sell orders essentially act as a wall against buy orders, thereby preventing price from rising. Caution should be taken in the sense that these results pertain to a limited situation. Specifically, our finding that the circuit breaker is better than the price limit should be adapted only in cases where the reason for falling prices is erroneous orders and when individual stocks are regulated.", "link": "http://arxiv.org/abs/2309.10220v1"}, {"index": 101, "title": "Incorporating Pre-trained Model Prompting in Multimodal Stock Volume Movement Prediction", "abstract": "Multimodal stock trading volume movement prediction with stock-related news is one of the fundamental problems in the financial area. Existing multimodal works that train models from scratch face the problem of lacking universal knowledge when modeling financial news. In addition, the models ability may be limited by the lack of domain-related knowledge due to insufficient data in the datasets. To handle this issue, we propose the Prompt-based MUltimodal Stock volumE prediction model (ProMUSE) to process text and time series modalities. We use pre-trained language models for better comprehension of financial news and adopt prompt learning methods to leverage their capability in universal knowledge to model textual information. Besides, simply fusing two modalities can cause harm to the unimodal representations. Thus, we propose a novel cross-modality contrastive alignment while reserving the unimodal heads beside the fusion head to mitigate this problem. Extensive experiments demonstrate that our proposed ProMUSE outperforms existing baselines. Comprehensive analyses further validate the effectiveness of our architecture compared to potential variants and learning mechanisms.", "link": "http://arxiv.org/abs/2309.05608v1"}, {"index": 102, "title": "Media Moments and Corporate Connections: A Deep Learning Approach to Stock Movement Classification", "abstract": "The financial industry poses great challenges with risk modeling and profit generation. These entities are intricately tied to the sophisticated prediction of stock movements. A stock forecaster must untangle the randomness and ever-changing behaviors of the stock market. Stock movements are influenced by a myriad of factors, including company history, performance, and economic-industry connections. However, there are other factors that aren't traditionally included, such as social media and correlations between stocks. Social platforms such as Reddit, Facebook, and X (Twitter) create opportunities for niche communities to share their sentiment on financial assets. By aggregating these opinions from social media in various mediums such as posts, interviews, and news updates, we propose a more holistic approach to include these \"media moments\" within stock market movement prediction. We introduce a method that combines financial data, social media, and correlated stock relationships via a graph neural network in a hierarchical temporal fashion. Through numerous trials on current S&P 500 index data, with results showing an improvement in cumulative returns by 28%, we provide empirical evidence of our tool's applicability for use in investment decisions.", "link": "http://arxiv.org/abs/2309.06559v1"}, {"index": 103, "title": "CSPRD: A Financial Policy Retrieval Dataset for Chinese Stock Market", "abstract": "In recent years, great advances in pre-trained language models (PLMs) have sparked considerable research focus and achieved promising performance on the approach of dense passage retrieval, which aims at retrieving relative passages from massive corpus with given questions. However, most of existing datasets mainly benchmark the models with factoid queries of general commonsense, while specialised fields such as finance and economics remain unexplored due to the deficiency of large-scale and high-quality datasets with expert annotations. In this work, we propose a new task, policy retrieval, by introducing the Chinese Stock Policy Retrieval Dataset (CSPRD), which provides 700+ prospectus passages labeled by experienced experts with relevant articles from 10k+ entries in our collected Chinese policy corpus. Experiments on lexical, embedding and fine-tuned bi-encoder models show the effectiveness of our proposed CSPRD yet also suggests ample potential for improvement. Our best performing baseline achieves 56.1% MRR@10, 28.5% NDCG@10, 37.5% Recall@10 and 80.6% Precision@10 on dev set.", "link": "http://arxiv.org/abs/2309.04389v2"}, {"index": 104, "title": "GPT-InvestAR: Enhancing Stock Investment Strategies through Annual Report Analysis with Large Language Models", "abstract": "Annual Reports of publicly listed companies contain vital information about their financial health which can help assess the potential impact on Stock price of the firm. These reports are comprehensive in nature, going up to, and sometimes exceeding, 100 pages. Analysing these reports is cumbersome even for a single firm, let alone the whole universe of firms that exist. Over the years, financial experts have become proficient in extracting valuable information from these documents relatively quickly. However, this requires years of practice and experience. This paper aims to simplify the process of assessing Annual Reports of all the firms by leveraging the capabilities of Large Language Models (LLMs). The insights generated by the LLM are compiled in a Quant styled dataset and augmented by historical stock price data. A Machine Learning model is then trained with LLM outputs as features. The walkforward test results show promising outperformance wrt S&P500 returns. This paper intends to provide a framework for future work in this direction. To facilitate this, the code has been released as open source.", "link": "http://arxiv.org/abs/2309.03079v1"}, {"index": 105, "title": "Linking microblogging sentiments to stock price movement: An application of GPT-4", "abstract": "This paper investigates the potential improvement of the GPT-4 Language Learning Model (LLM) in comparison to BERT for modeling same-day daily stock price movements of Apple and Tesla in 2017, based on sentiment analysis of microblogging messages. We recorded daily adjusted closing prices and translated them into up-down movements. Sentiment for each day was extracted from messages on the Stocktwits platform using both LLMs. We develop a novel method to engineer a comprehensive prompt for contextual sentiment analysis which unlocks the true capabilities of modern LLM. This enables us to carefully retrieve sentiments, perceived advantages or disadvantages, and the relevance towards the analyzed company. Logistic regression is used to evaluate whether the extracted message contents reflect stock price movements. As a result, GPT-4 exhibited substantial accuracy, outperforming BERT in five out of six months and substantially exceeding a naive buy-and-hold strategy, reaching a peak accuracy of 71.47 % in May. The study also highlights the importance of prompt engineering in obtaining desired outputs from GPT-4's contextual abilities. However, the costs of deploying GPT-4 and the need for fine-tuning prompts highlight some practical considerations for its use.", "link": "http://arxiv.org/abs/2308.16771v1"}, {"index": 106, "title": "New general dependence measures: construction, estimation and application to high-frequency stock returns", "abstract": "We propose a set of dependence measures that are non-linear, local, invariant to a wide range of transformations on the marginals, can show tail and risk asymmetries, are always well-defined, are easy to estimate and can be used on any dataset. We propose a nonparametric estimator and prove its consistency and asymptotic normality. Thereby we significantly improve on existing (extreme) dependence measures used in asset pricing and statistics. To show practical utility, we use these measures on high-frequency stock return data around market distress events such as the 2010 Flash Crash and during the GFC. Contrary to ubiquitously used correlations we find that our measures clearly show tail asymmetry, non-linearity, lack of diversification and endogenous buildup of risks present during these distress events. Additionally, our measures anticipate large (joint) losses during the Flash Crash while also anticipating the bounce back and flagging the subsequent market fragility. Our findings have implications for risk management, portfolio construction and hedging at any frequency.", "link": "http://arxiv.org/abs/2309.00025v1"}, {"index": 107, "title": "Estimating Changepoints in Extremal Dependence, Applied to Aviation Stock Prices During COVID-19 Pandemic", "abstract": "The dependence in the tails of the joint distribution of two random variables is measured using chi-measure. This work is motivated by the structural changes in chi-measure between the daily return rates of the two largest Indian airlines in 2019, IndiGo and SpiceJet, during the COVID-19 pandemic. We model the daily maximum return rate vectors (potentially transformed) using the bivariate Husler-Reiss (BHR) distribution, which is the only possible non-degenerate limiting distribution of a renormalized element-wise block maxima of a sequence of bivariate Gaussian random vectors. To estimate the changepoint in the chi-measure of the BHR distribution, we explore the changepoint detection procedures based on Likelihood Ratio Test (LRT) and Modified Information Criterion (MIC). We obtain critical values and power curves of the LRT and MIC test statistics for low through high values of chi-measure. We also explore the consistency of the estimators of the changepoint based on LRT and MIC numerically. In our data application, the most prominent changepoint detected by LRT and MIC coincides with the announcement of the first phase of lockdown declared by the Government of India, which is realistic; thus, our study would be beneficial for portfolio optimization in the case of future pandemic situations.", "link": "http://arxiv.org/abs/2308.13895v1"}, {"index": 108, "title": "The Potential of Quantum Techniques for Stock Price Prediction", "abstract": "We explored the potential applications of various Quantum Algorithms for stock price prediction by conducting a series of experimental simulations using both Classical as well as Quantum Hardware. Firstly, we extracted various stock price indicators, such as Moving Averages (MA), Average True Range (ATR), and Aroon, to gain insights into market trends and stock price movements. Next, we employed Quantum Annealing (QA) for feature selection and Principal Component Analysis (PCA) for dimensionality reduction. Further, we transformed the stock price prediction task essentially into a classification problem. We trained the Quantum Support Vector Machine (QSVM) to predict price movements (whether up or down) contrasted their performance with classical models and analyzed their accuracy on a dataset formulated using Quantum Annealing and PCA individually. We focused on the stock price prediction and binary classification of stock prices for four different companies, namely Apple, Visa, Johnson and Jonson, and Honeywell. We primarily used the real-time stock data of the raw stock prices of these companies. We compared various Quantum Computing techniques with their classical counterparts in terms of accuracy and F-score of the prediction model. Through these experimental simulations, we shed light on the potential advantages and limitations of Quantum Algorithms in stock price prediction and contribute to the growing body of knowledge at the intersection of Quantum Computing and Finance.", "link": "http://arxiv.org/abs/2308.13642v1"}, {"index": 109, "title": "Automatic Historical Stock Price Dataset Generation Using Python", "abstract": "With the dynamic political and economic environments, the ever-changing stock markets generate large amounts of data daily. Acquiring up-to-date data is crucial to enhancing predictive precision in stock price behavior studies. However, preparing the dataset manually can be challenging and time-demanding. The stock market analysis usually revolves around specific indices such as S&P500, Nasdaq, Dow Jones, the New York Stock Exchange (NYSE), etc. It is necessary to analyze all the companies of any particular index. While raw data are accessible from diverse financial websites, these resources are tailored for individual company data retrieval and there is a big gap between what is available and what is needed to generate large datasets. Python emerges as a valuable tool for comprehensively collecting all constituent stocks within a given index. While certain online sources offer code snippets for limited dataset generation, a comprehensive and unified script is yet to be developed and publicly available. Therefore, we present a comprehensive and consolidated code resource that facilitates the extraction of updated datasets for any particular time period and for any specific stock market index and closes the gap. The code is available at https://github.com/amp1590/automatic_stock_data_collection.", "link": "http://arxiv.org/abs/2308.13414v1"}, {"index": 110, "title": "The Impact of Stocks on Correlations of Crop Yields and Prices and on Revenue Insurance Premiums using Semiparametric Quantile Regression", "abstract": "Crop yields and harvest prices are often considered to be negatively correlated, thus acting as a natural risk management hedge through stabilizing revenues. Storage theory gives reason to believe that the correlation is an increasing function of stocks carried over from previous years. Stock-conditioned second moments have implications for price movements during shortages and for hedging needs, while spatially varying yield-price correlation structures have implications for who benefits from commodity support policies. In this paper, we propose to use semi-parametric quantile regression (SQR) with penalized B-splines to estimate a stock-conditioned joint distribution of yield and price. The proposed method, validated through a comprehensive simulation study, enables sampling from the true joint distribution using SQR. Then it is applied to approximate stock-conditioned correlation and revenue insurance premium for both corn and soybeans in the United States. For both crops, Cornbelt core regions have more negative correlations than do peripheral regions. We find strong evidence that correlation becomes less negative as stocks increase. We also show that conditioning on stocks is important when calculating actuarially fair revenue insurance premiums. In particular, revenue insurance premiums in the Cornbelt core will be biased upward if the model for calculating premiums does not allow correlation to vary with stocks available. The stock-dependent correlation can be viewed as a form of tail dependence that, if unacknowledged, leads to mispricing of revenue insurance products.", "link": "http://arxiv.org/abs/2308.11805v1"}, {"index": 111, "title": "Modelling Structural Breaks In Stock Price Time Series Using Stochastic Differential Equations", "abstract": "This paper studies the effect of quarterly earnings reports on the stock price. The profitability of the stock is modelled by geometric Brownian diffusion and the Constant Elasticity of Variance model. We fit several variations of stochastic differential equations to the pre-and after-report period using the Maximum Likelihood Estimation and Grid Search of parameters method. By examining the change in the model parameters after reports' publication, the study reveals that the reports have enough evidence to be a structural breakpoint, meaning that all the forecast models exploited are not applicable for forecasting and should be refitted shortly.", "link": "http://arxiv.org/abs/2308.11548v1"}, {"index": 112, "title": "Meta-Stock: Task-Difficulty-Adaptive Meta-learning for Sub-new Stock Price Prediction", "abstract": "Sub-new stock price prediction, forecasting the price trends of stocks listed less than one year, is crucial for effective quantitative trading. While deep learning methods have demonstrated effectiveness in predicting old stock prices, they require large training datasets unavailable for sub-new stocks. In this paper, we propose Meta-Stock: a task-difficulty-adaptive meta-learning approach for sub-new stock price prediction. Leveraging prediction tasks formulated by old stocks, our meta-learning method aims to acquire the fast generalization ability that can be further adapted to sub-new stock price prediction tasks, thereby solving the data scarcity of sub-new stocks. Moreover, we enhance the meta-learning process by incorporating an adaptive learning strategy sensitive to varying task difficulties. Through wavelet transform, we extract high-frequency coefficients to manifest stock price volatility. This allows the meta-learning model to assign gradient weights based on volatility-quantified task difficulty. Extensive experiments on datasets collected from three stock markets spanning twenty-two years prove that our Meta-Stock significantly outperforms previous methods and manifests strong applicability in real-world stock trading. Besides, we evaluate the reasonability of the task difficulty quantification and the effectiveness of the adaptive learning strategy.", "link": "http://arxiv.org/abs/2308.11117v1"}, {"index": 113, "title": "D-TIPO: Deep time-inconsistent portfolio optimization with stocks and options", "abstract": "In this paper, we propose a machine learning algorithm for time-inconsistent portfolio optimization. The proposed algorithm builds upon neural network based trading schemes, in which the asset allocation at each time point is determined by a a neural network. The loss function is given by an empirical version of the objective function of the portfolio optimization problem. Moreover, various trading constraints are naturally fulfilled by choosing appropriate activation functions in the output layers of the neural networks. Besides this, our main contribution is to add options to the portfolio of risky assets and a risk-free bond and using additional neural networks to determine the amount allocated into the options as well as their strike prices.   We consider objective functions more in line with the rational preference of an investor than the classical mean-variance, apply realistic trading constraints and model the assets with a correlated jump-diffusion SDE. With an incomplete market and a more involved objective function, we show that it is beneficial to add options to the portfolio. Moreover, it is shown that adding options leads to a more constant stock allocation with less demand for drastic re-allocations.", "link": "http://arxiv.org/abs/2308.10556v2"}, {"index": 114, "title": "Do We Price Happiness? Evidence from Korean Stock Market", "abstract": "This study explores the potential of internet search volume data, specifically Google Trends, as an indicator for cross-sectional stock returns. Unlike previous studies, our research specifically investigates the search volume of the topic 'happiness' and its impact on stock returns in the aspect of risk pricing rather than as sentiment measurement. Empirical results indicate that this 'happiness' search exposure (HSE) can explain future returns, particularly for big and value firms. This suggests that HSE might be a reflection of a firm's ability to produce goods or services that meet societal utility needs. Our findings have significant implications for institutional investors seeking to leverage HSE-based strategies for outperformance. Additionally, our research suggests that, when selected judiciously, some search topics on Google Trends can be related to risks that impact stock prices.", "link": "http://arxiv.org/abs/2308.10039v1"}, {"index": 115, "title": "Student't mixture models for stock indices. A comparative study", "abstract": "We perform a comparative study for multiple equity indices of different countries using different models to determine the best fit using the Kolmogorov-Smirnov statistic, the Anderson-Darling statistic, the Akaike information criterion and the Bayesian information criteria as goodness-of-fit measures. We fit models both to daily and to hourly log-returns. The main result is the excellent performance of a mixture of three Student's $t$ distributions with the numbers of degrees of freedom fixed a priori (3St). In addition, we find that the different components of the 3St mixture with small/moderate/high degree of freedom parameter describe the extreme/moderate/small log-returns of the studied equity indices.", "link": "http://dx.doi.org/10.1016/j.physa.2021.126143"}, {"index": 116, "title": "Diffusion Variational Autoencoder for Tackling Stochasticity in Multi-Step Regression Stock Price Prediction", "abstract": "Multi-step stock price prediction over a long-term horizon is crucial for forecasting its volatility, allowing financial institutions to price and hedge derivatives, and banks to quantify the risk in their trading books. Additionally, most financial regulators also require a liquidity horizon of several days for institutional investors to exit their risky assets, in order to not materially affect market prices. However, the task of multi-step stock price prediction is challenging, given the highly stochastic nature of stock data. Current solutions to tackle this problem are mostly designed for single-step, classification-based predictions, and are limited to low representation expressiveness. The problem also gets progressively harder with the introduction of the target price sequence, which also contains stochastic noise and reduces generalizability at test-time. To tackle these issues, we combine a deep hierarchical variational-autoencoder (VAE) and diffusion probabilistic techniques to do seq2seq stock prediction through a stochastic generative process. The hierarchical VAE allows us to learn the complex and low-level latent variables for stock prediction, while the diffusion probabilistic model trains the predictor to handle stock price stochasticity by progressively adding random noise to the stock data. Our Diffusion-VAE (D-Va) model is shown to outperform state-of-the-art solutions in terms of its prediction accuracy and variance. More importantly, the multi-step outputs can also allow us to form a stock portfolio over the prediction length. We demonstrate the effectiveness of our model outputs in the portfolio investment task through the Sharpe ratio metric and highlight the importance of dealing with different types of prediction uncertainties.", "link": "http://dx.doi.org/10.1145/3583780.3614844"}, {"index": 117, "title": "Microstructure-Empowered Stock Factor Extraction and Utilization", "abstract": "High-frequency quantitative investment is a crucial aspect of stock investment. Notably, order flow data plays a critical role as it provides the most detailed level of information among high-frequency trading data, including comprehensive data from the order book and transaction records at the tick level. The order flow data is extremely valuable for market analysis as it equips traders with essential insights for making informed decisions. However, extracting and effectively utilizing order flow data present challenges due to the large volume of data involved and the limitations of traditional factor mining techniques, which are primarily designed for coarser-level stock data. To address these challenges, we propose a novel framework that aims to effectively extract essential factors from order flow data for diverse downstream tasks across different granularities and scenarios. Our method consists of a Context Encoder and an Factor Extractor. The Context Encoder learns an embedding for the current order flow data segment's context by considering both the expected and actual market state. In addition, the Factor Extractor uses unsupervised learning methods to select such important signals that are most distinct from the majority within the given context. The extracted factors are then utilized for downstream tasks. In empirical studies, our proposed framework efficiently handles an entire year of stock order flow data across diverse scenarios, offering a broader range of applications compared to existing tick-level approaches that are limited to only a few days of stock data. We demonstrate that our method extracts superior factors from order flow data, enabling significant improvement for stock trend prediction and order execution tasks at the second and minute level.", "link": "http://arxiv.org/abs/2308.08135v1"}, {"index": 118, "title": "Methods for Acquiring and Incorporating Knowledge into Stock Price Prediction: A Survey", "abstract": "Predicting stock prices presents a challenging research problem due to the inherent volatility and non-linear nature of the stock market. In recent years, knowledge-enhanced stock price prediction methods have shown groundbreaking results by utilizing external knowledge to understand the stock market. Despite the importance of these methods, there is a scarcity of scholarly works that systematically synthesize previous studies from the perspective of external knowledge types. Specifically, the external knowledge can be modeled in different data structures, which we group into non-graph-based formats and graph-based formats: 1) non-graph-based knowledge captures contextual information and multimedia descriptions specifically associated with an individual stock; 2) graph-based knowledge captures interconnected and interdependent information in the stock market. This survey paper aims to provide a systematic and comprehensive description of methods for acquiring external knowledge from various unstructured data sources and then incorporating it into stock price prediction models. We also explore fusion methods for combining external knowledge with historical price features. Moreover, this paper includes a compilation of relevant datasets and delves into potential future research directions in this domain.", "link": "http://arxiv.org/abs/2308.04947v1"}, {"index": 119, "title": "Stock Market Price Prediction: A Hybrid LSTM and Sequential Self-Attention based Approach", "abstract": "One of the most enticing research areas is the stock market, and projecting stock prices may help investors profit by making the best decisions at the correct time. Deep learning strategies have emerged as a critical technique in the field of the financial market. The stock market is impacted due to two aspects, one is the geo-political, social and global events on the bases of which the price trends could be affected. Meanwhile, the second aspect purely focuses on historical price trends and seasonality, allowing us to forecast stock prices. In this paper, our aim is to focus on the second aspect and build a model that predicts future prices with minimal errors. In order to provide better prediction results of stock price, we propose a new model named Long Short-Term Memory (LSTM) with Sequential Self-Attention Mechanism (LSTM-SSAM). Finally, we conduct extensive experiments on the three stock datasets: SBIN, HDFCBANK, and BANKBARODA. The experimental results prove the effectiveness and feasibility of the proposed model compared to existing models. The experimental findings demonstrate that the root-mean-squared error (RMSE), and R-square (R2) evaluation indicators are giving the best results.", "link": "http://arxiv.org/abs/2308.04419v1"}, {"index": 120, "title": "A Branch-and-Cut-and-Price Algorithm for Cutting Stock and Related Problems", "abstract": "We present a branch-and-cut-and-price framework to solve Cutting Stock Problems with strong relaxations using Set Covering (Partition) Formulations, which are solved by column generation. We propose an extended Ryan-Foster branching scheme for non-binary models, a pricing algorithm that converges in a few iterations, and a variable selection algorithm based on branching history. These strategies are combined with subset-row cuts and custom primal heuristics to create a framework that overcomes the current state-of-the-art for the following problems: Cutting Stock, Skiving Stock, Ordered Open-End Bin Packing, Class-Constrained Bin Packing, and Identical Parallel Machines Scheduling with Minimum Makespan. Additionally, a new challenging benchmark for Cutting Stock is introduced.", "link": "http://arxiv.org/abs/2308.03595v1"}, {"index": 121, "title": "Towards Machine Learning-based Fish Stock Assessment", "abstract": "The accurate assessment of fish stocks is crucial for sustainable fisheries management. However, existing statistical stock assessment models can have low forecast performance of relevant stock parameters like recruitment or spawning stock biomass, especially in ecosystems that are changing due to global warming and other anthropogenic stressors. In this paper, we investigate the use of machine learning models to improve the estimation and forecast of such stock parameters. We propose a hybrid model that combines classical statistical stock assessment models with supervised ML, specifically gradient boosted trees. Our hybrid model leverages the initial estimate provided by the classical model and uses the ML model to make a post-hoc correction to improve accuracy. We experiment with five different stocks and find that the forecast accuracy of recruitment and spawning stock biomass improves considerably in most cases.", "link": "http://arxiv.org/abs/2308.03403v1"}, {"index": 122, "title": "Quantitative statistical analysis of order-splitting behaviour of individual trading accounts in the Japanese stock market over nine years", "abstract": "In this research, we focus on the order-splitting behavior. The order splitting is a trading strategy to execute their large potential metaorder into small pieces to reduce transaction cost. This strategic behavior is believed to be important because it is a promising candidate for the microscopic origin of the long-range correlation (LRC) in the persistent order flow. Indeed, in 2005, Lillo, Mike, and Farmer (LMF) introduced a microscopic model of the order-splitting traders to predict the asymptotic behavior of the LRC from the microscopic dynamics, even quantitatively. The plausibility of this scenario has been qualitatively investigated by Toth et al. 2015. However, no solid support has been presented yet on the quantitative prediction by the LMF model in the lack of large microscopic datasets. In this report, we have provided the first quantitative statistical analysis of the order-splitting behavior at the level of each trading account. We analyse a large dataset of the Tokyo stock exchange (TSE) market over nine years, including the account data of traders (called virtual servers). The virtual server is a unit of trading accounts in the TSE market, and we can effectively define the trader IDs by an appropriate preprocessing. We apply a strategy clustering to individual traders to identify the order-splitting traders and the random traders. For most of the stocks, we find that the metaorder length distribution obeys power laws with exponent $\\alpha$, such that $P(L)\\propto L^{-\\alpha-1}$ with the metaorder length $L$. By analysing the sign correlation $C(\\tau)\\propto \\tau^{-\\gamma}$, we directly confirmed the LMF prediction $\\gamma \\approx \\alpha-1$. Furthermore, we discuss how to estimate the total number of the splitting traders only from public data via the ACF prefactor formula in the LMF model. Our work provides the first quantitative evidence of the LMF model.", "link": "http://dx.doi.org/10.1103/PhysRevResearch.5.043131"}, {"index": 123, "title": "Effects of Daily News Sentiment on Stock Price Forecasting", "abstract": "Predicting future prices of a stock is an arduous task to perform. However, incorporating additional elements can significantly improve our predictions, rather than relying solely on a stock's historical price data to forecast its future price. Studies have demonstrated that investor sentiment, which is impacted by daily news about the company, can have a significant impact on stock price swings. There are numerous sources from which we can get this information, but they are cluttered with a lot of noise, making it difficult to accurately extract the sentiments from them. Hence the focus of our research is to design an efficient system to capture the sentiments from the news about the NITY50 stocks and investigate how much the financial news sentiment of these stocks are affecting their prices over a period of time. This paper presents a robust data collection and preprocessing framework to create a news database for a timeline of around 3.7 years, consisting of almost half a million news articles. We also capture the stock price information for this timeline and create multiple time series data, that include the sentiment scores from various sections of the article, calculated using different sentiment libraries. Based on this, we fit several LSTM models to forecast the stock prices, with and without using the sentiment scores as features and compare their performances.", "link": "http://arxiv.org/abs/2308.08549v1"}, {"index": 124, "title": "VolTS: A Volatility-based Trading System to forecast Stock Markets Trend using Statistics and Machine Learning", "abstract": "Volatility-based trading strategies have attracted a lot of attention in financial markets due to their ability to capture opportunities for profit from market dynamics. In this article, we propose a new volatility-based trading strategy that combines statistical analysis with machine learning techniques to forecast stock markets trend.   The method consists of several steps including, data exploration, correlation and autocorrelation analysis, technical indicator use, application of hypothesis tests and statistical models, and use of variable selection algorithms. In particular, we use the k-means++ clustering algorithm to group the mean volatility of the nine largest stocks in the NYSE and NasdaqGS markets. The resulting clusters are the basis for identifying relationships between stocks based on their volatility behaviour. Next, we use the Granger Causality Test on the clustered dataset with mid-volatility to determine the predictive power of a stock over another stock. By identifying stocks with strong predictive relationships, we establish a trading strategy in which the stock acting as a reliable predictor becomes a trend indicator to determine the buy, sell, and hold of target stock trades.   Through extensive backtesting and performance evaluation, we find the reliability and robustness of our volatility-based trading strategy. The results suggest that our approach effectively captures profitable trading opportunities by leveraging the predictive power of volatility clusters, and Granger causality relationships between stocks.   The proposed strategy offers valuable insights and practical implications to investors and market participants who seek to improve their trading decisions and capitalize on market trends. It provides valuable insights and practical implications for market participants looking to.", "link": "http://arxiv.org/abs/2307.13422v2"}, {"index": 125, "title": "The Effect of COVID-19 on Cryptocurrencies and the Stock Market Volatility -- A Two-Stage DCC-EGARCH Model Analysis", "abstract": "This research examines the correlations between the return volatility of cryptocurrencies, global stock market indices, and the spillover effects of the COVID-19 pandemic. For this purpose, we employed a two-stage multivariate volatility exponential GARCH (EGARCH) model with an integrated dynamic conditional correlation (DCC) approach to measure the impact on the financial portfolio returns from 2019 to 2020. Moreover, we used value-at-risk (VaR) and value-at-risk measurements based on the Cornish-Fisher expansion (CFVaR). The empirical results show significant long- and short-term spillover effects. The two-stage multivariate EGARCH model's results show that the conditional volatilities of both asset portfolios surge more after positive news and respond well to previous shocks. As a result, financial assets have low unconditional volatility and the lowest risk when there are no external interruptions. Despite the financial assets' sensitivity to shocks, they exhibit some resistance to fluctuations in market confidence. The VaR performance comparison results with the assets portfolios differ. During the COVID-19 outbreak, the Dow (DJI) index reports VaR's highest loss, followed by the S&P500. Conversely, the CFVaR reports negative risk results for the entire cryptocurrency portfolio during the pandemic, except for the Ethereum (ETH).", "link": "http://dx.doi.org/10.3390/jrfm16010025"}, {"index": 126, "title": "Contrasting the efficiency of stock price prediction models using various types of LSTM models aided with sentiment analysis", "abstract": "Our research aims to find the best model that uses companies projections and sector performances and how the given company fares accordingly to correctly predict equity share prices for both short and long term goals.", "link": "http://arxiv.org/abs/2307.07868v1"}, {"index": 127, "title": "Real-time Trading System based on Selections of Potentially Profitable, Uncorrelated, and Balanced Stocks by NP-hard Combinatorial Optimization", "abstract": "Financial portfolio construction problems are often formulated as quadratic and discrete (combinatorial) optimization that belong to the nondeterministic polynomial time (NP)-hard class in computational complexity theory. Ising machines are hardware devices that work in quantum-mechanical/quantum-inspired principles for quickly solving NP-hard optimization problems, which potentially enable making trading decisions based on NP-hard optimization in the time constraints for high-speed trading strategies. Here we report a real-time stock trading system that determines long(buying)/short(selling) positions through NP-hard portfolio optimization for improving the Sharpe ratio using an embedded Ising machine based on a quantum-inspired algorithm called simulated bifurcation. The Ising machine selects a balanced (delta-neutral) group of stocks from an $N$-stock universe according to an objective function involving maximizing instantaneous expected returns defined as deviations from volume-weighted average prices and minimizing the summation of statistical correlation factors (for diversification). It has been demonstrated in the Tokyo Stock Exchange that the trading strategy based on NP-hard portfolio optimization for $N$=128 is executable with the FPGA (field-programmable gate array)-based trading system with a response latency of 164 $\\mu$s.", "link": "http://dx.doi.org/10.1109/ACCESS.2023.3326816"}, {"index": 128, "title": "Bayesian Forecasting of Stock Returns on the JSE using Simultaneous Graphical Dynamic Linear Models", "abstract": "Cross-series dependencies are crucial in obtaining accurate forecasts when forecasting a multivariate time series. Simultaneous Graphical Dynamic Linear Models (SGDLMs) are Bayesian models that elegantly capture cross-series dependencies. This study forecasts returns of a 40-dimensional time series of stock data from the Johannesburg Stock Exchange (JSE) using SGDLMs. The SGDLM approach involves constructing a customised dynamic linear model (DLM) for each univariate time series. At each time point, the DLMs are recoupled using importance sampling and decoupled using mean-field variational Bayes. Our results suggest that SGDLMs forecast stock data on the JSE accurately and respond to market gyrations effectively.", "link": "http://arxiv.org/abs/2307.08665v1"}, {"index": 129, "title": "Are there Dragon Kings in the Stock Market?", "abstract": "We undertake a systematic study of historic market volatility spanning roughly five preceding decades. We focus specifically on the time series of realized volatility (RV) of the S&P500 index and its distribution function. As expected, the largest values of RV coincide with the largest economic upheavals of the period: Savings and Loan Crisis, Tech Bubble, Financial Crisis and Covid Pandemic. We address the question of whether these values belong to one of the three categories: Black Swans (BS), that is they lie on scale-free, power-law tails of the distribution; Dragon Kings (DK), defined as statistically significant upward deviations from BS; or Negative Dragons Kings (nDK), defined as statistically significant downward deviations from BS. In analyzing the tails of the distribution with RV > 40, we observe the appearance of \"potential\" DK which eventually terminate in an abrupt plunge to nDK. This phenomenon becomes more pronounced with the increase of the number of days over which the average RV is calculated -- here from daily, n=1, to \"monthly,\" n=21. We fit the entire distribution with a modified Generalized Beta (mGB) distribution function, which terminates at a finite value of the variable but exhibits a long power-law stretch prior to that, as well as Generalized Beta Prime (GB2) distribution function, which has a power-law tail. We also fit the tails directly with a straight line on a log-log scale. In order to ascertain BS, DK or nDK behavior, all fits include their confidence intervals and p-values are evaluated for the data points to check if they can come from the respective distributions.", "link": "http://dx.doi.org/10.3390/foundations4010008"}, {"index": 130, "title": "LOB-Based Deep Learning Models for Stock Price Trend Prediction: A Benchmark Study", "abstract": "The recent advancements in Deep Learning (DL) research have notably influenced the finance sector. We examine the robustness and generalizability of fifteen state-of-the-art DL models focusing on Stock Price Trend Prediction (SPTP) based on Limit Order Book (LOB) data. To carry out this study, we developed LOBCAST, an open-source framework that incorporates data preprocessing, DL model training, evaluation and profit analysis. Our extensive experiments reveal that all models exhibit a significant performance drop when exposed to new data, thereby raising questions about their real-world market applicability. Our work serves as a benchmark, illuminating the potential and the limitations of current approaches and providing insight for innovative solutions.", "link": "http://arxiv.org/abs/2308.01915v2"}, {"index": 131, "title": "The Predictability of Stock Price: Empirical Study onTick Data in Chinese Stock Market", "abstract": "Whether or not stocks are predictable has been a topic of concern for decades.The efficient market hypothesis (EMH) says that it is difficult for investors to make extra profits by predicting stock prices, but this may not be true, especially for the Chinese stock market. Therefore, we explore the predictability of the Chinese stock market based on tick data, a widely studied high-frequency data. We obtain the predictability of 3, 834 Chinese stocks by adopting the concept of true entropy, which is calculated by Limpel-Ziv data compression method. The Markov chain model and the diffusion kernel model are used to compare the upper bounds on predictability, and it is concluded that there is still a significant performance gap between the forecasting models used and the theoretical upper bounds.Our work shows that more than 73% of stocks have prediction accuracy greater than 70% and RMSE less than 2 CNY under different quantification intervals with different models. We further take Spearman's correlation to reveal that the average stock price and price volatility may have a negative impact on prediction accuracy, which may be helpful for stock investors.", "link": "http://arxiv.org/abs/2307.02099v2"}, {"index": 132, "title": "Principal Component Analysis and Hidden Markov Model for Forecasting Stock Returns", "abstract": "This paper presents a method for predicting stock returns using principal component analysis (PCA) and the hidden Markov model (HMM) and tests the results of trading stocks based on this approach. Principal component analysis is applied to the covariance matrix of stock returns for companies listed in the S&P 500 index, and interpreting principal components as factor returns, we apply the HMM model on them. Then we use the transition probability matrix and state conditional means to forecast the factors returns. Reverting the factor returns forecasts to stock returns using eigenvectors, we obtain forecasts for the stock returns. We find that, with the right hyperparameters, our model yields a strategy that outperforms the buy-and-hold strategy in terms of the annualized Sharpe ratio.", "link": "http://arxiv.org/abs/2307.00459v1"}, {"index": 133, "title": "Which Algorithm Best Propagates the Meyer-Miller-Stock-Thoss Mapping Hamiltonian for Non-Adiabatic Dynamics?", "abstract": "A common strategy to simulate mixed quantum-classical dynamics is by propagating classical trajectories with mapping variables, often using the Meyer-Miller-Stock-Thoss (MMST) Hamiltonian or the related spin-mapping approach. When mapping the quantum subsystem, the coupled dynamics reduce to a set of equations of motion to integrate. Several numerical algorithms have been proposed, but a thorough performance comparison appears to be lacking. Here, we compare three time-propagation algorithms for the MMST Hamiltonian: the Momentum Integral (MInt) (arXiv:1709.07474), the Split-Liouvillian (SL) (arXiv:1609.00644), and the algorithm in arXiv:1201.1042 that we refer to as the Degenerate Eigenvalue (DE) algorithm due to the approximation required during derivation. We analyse the accuracy of individual trajectories, correlation functions, energy conservation, symplecticity, Liouville's theorem and the computational cost. We find that the MInt algorithm is the only rigorously symplectic algorithm. However, comparable accuracy at a lower computational cost can be obtained with the SL algorithm. The approximation implicitly made within the DE algorithm conserves energy poorly, even for small timesteps, and thus leads to slightly different results. These results should guide future mapping-variable simulations.", "link": "http://dx.doi.org/10.1021/acs.jctc.3c00709"}, {"index": 134, "title": "Higher-order Graph Attention Network for Stock Selection with Joint Analysis", "abstract": "Stock selection is important for investors to construct profitable portfolios. Graph neural networks (GNNs) are increasingly attracting researchers for stock prediction due to their strong ability of relation modelling and generalisation. However, the existing GNN methods only focus on simple pairwise stock relation and do not capture complex higher-order structures modelling relations more than two nodes. In addition, they only consider factors of technical analysis and overlook factors of fundamental analysis that can affect the stock trend significantly. Motivated by them, we propose higher-order graph attention network with joint analysis (H-GAT). H-GAT is able to capture higher-order structures and jointly incorporate factors of fundamental analysis with factors of technical analysis. Specifically, the sequential layer of H-GAT take both types of factors as the input of a long-short term memory model. The relation embedding layer of H-GAT constructs a higher-order graph and learn node embedding with GAT. We then predict the ranks of stock return. Extensive experiments demonstrate the superiority of our H-GAT method on the profitability test and Sharp ratio over both NSDAQ and NYSE datasets", "link": "http://arxiv.org/abs/2306.15526v1"}, {"index": 135, "title": "Unveiling the Potential of Sentiment: Can Large Language Models Predict Chinese Stock Price Movements?", "abstract": "The rapid advancement of Large Language Models (LLMs) has led to extensive discourse regarding their potential to boost the return of quantitative stock trading strategies. This discourse primarily revolves around harnessing the remarkable comprehension capabilities of LLMs to extract sentiment factors which facilitate informed and high-frequency investment portfolio adjustments. To ensure successful implementations of these LLMs into the analysis of Chinese financial texts and the subsequent trading strategy development within the Chinese stock market, we provide a rigorous and encompassing benchmark as well as a standardized back-testing framework aiming at objectively assessing the efficacy of various types of LLMs in the specialized domain of sentiment factor extraction from Chinese news text data. To illustrate how our benchmark works, we reference three distinctive models: 1) the generative LLM (ChatGPT), 2) the Chinese language-specific pre-trained LLM (Erlangshen-RoBERTa), and 3) the financial domain-specific fine-tuned LLM classifier(Chinese FinBERT). We apply them directly to the task of sentiment factor extraction from large volumes of Chinese news summary texts. We then proceed to building quantitative trading strategies and running back-tests under realistic trading scenarios based on the derived sentiment factors and evaluate their performances with our benchmark. By constructing such a comparative analysis, we invoke the question of what constitutes the most important element for improving a LLM's performance on extracting sentiment factors. And by ensuring that the LLMs are evaluated on the same benchmark, following the same standardized experimental procedures that are designed with sufficient expertise in quantitative trading, we make the first stride toward answering such a question.", "link": "http://arxiv.org/abs/2306.14222v1"}, {"index": 136, "title": "Comparative Study of Predicting Stock Index Using Deep Learning Models", "abstract": "Time series forecasting has seen many methods attempted over the past few decades, including traditional technical analysis, algorithmic statistical models, and more recent machine learning and artificial intelligence approaches. Recently, neural networks have been incorporated into the forecasting scenario, such as the LSTM and conventional RNN approaches, which utilize short-term and long-term dependencies. This study evaluates traditional forecasting methods, such as ARIMA, SARIMA, and SARIMAX, and newer neural network approaches, such as DF-RNN, DSSM, and Deep AR, built using RNNs. The standard NIFTY-50 dataset from Kaggle is used to assess these models using metrics such as MSE, RMSE, MAPE, POCID, and Theil's U. Results show that Deep AR outperformed all other conventional deep learning and traditional approaches, with the lowest MAPE of 0.01 and RMSE of 189. Additionally, the performance of Deep AR and GRU did not degrade when the amount of training data was reduced, suggesting that these models may not require a large amount of data to achieve consistent and reliable performance. The study demonstrates that incorporating deep learning approaches in a forecasting scenario significantly outperforms conventional approaches and can handle complex datasets, with potential applications in various domains, such as weather predictions and other time series applications in a real-world scenario.", "link": "http://arxiv.org/abs/2306.13931v1"}, {"index": 137, "title": "The Impact of Customer Online Satisfaction on Stock Returns: Evidence from the E-commerce Reviews in China", "abstract": "This paper investigates the significance of consumer opinions in relation to value in China's A-share market. By analyzing a large dataset comprising over 18 million product reviews by customers on JD.com, we demonstrate that sentiments expressed in consumer reviews can influence stock returns, indicating that consumer opinions contain valuable information that can impact the stock market. Our findings show that Customer Negative Sentiment Tendency (CNST) and One-Star Tendency (OST) have a negative effect on expected stock returns, even after controlling for firm characteristics such as market risk, illiquidity, idiosyncratic volatility, and asset growth. Further analysis reveals that the predictive power of CNST is stronger in firms with high sentiment conditions, growth companies, and firms with lower accounting transparency. We also find that CNST negatively predicts revenue surprises, earnings surprises, and cash flow shocks. These results suggest that online satisfaction derived from big data analysis of customer reviews contains novel information about firms' fundamentals.", "link": "http://arxiv.org/abs/2306.12119v1"}, {"index": 138, "title": "Stock Price Prediction using Dynamic Neural Networks", "abstract": "This paper will analyze and implement a time series dynamic neural network to predict daily closing stock prices. Neural networks possess unsurpassed abilities in identifying underlying patterns in chaotic, non-linear, and seemingly random data, thus providing a mechanism to predict stock price movements much more precisely than many current techniques. Contemporary methods for stock analysis, including fundamental, technical, and regression techniques, are conversed and paralleled with the performance of neural networks. Also, the Efficient Market Hypothesis (EMH) is presented and contrasted with Chaos theory using neural networks. This paper will refute the EMH and support Chaos theory. Finally, recommendations for using neural networks in stock price prediction will be presented.", "link": "http://arxiv.org/abs/2306.12969v1"}, {"index": 139, "title": "DoubleAdapt: A Meta-learning Approach to Incremental Learning for Stock Trend Forecasting", "abstract": "Stock trend forecasting is a fundamental task of quantitative investment where precise predictions of price trends are indispensable. As an online service, stock data continuously arrive over time. It is practical and efficient to incrementally update the forecast model with the latest data which may reveal some new patterns recurring in the future stock market. However, incremental learning for stock trend forecasting still remains under-explored due to the challenge of distribution shifts (a.k.a. concept drifts). With the stock market dynamically evolving, the distribution of future data can slightly or significantly differ from incremental data, hindering the effectiveness of incremental updates. To address this challenge, we propose DoubleAdapt, an end-to-end framework with two adapters, which can effectively adapt the data and the model to mitigate the effects of distribution shifts. Our key insight is to automatically learn how to adapt stock data into a locally stationary distribution in favor of profitable updates. Complemented by data adaptation, we can confidently adapt the model parameters under mitigated distribution shifts. We cast each incremental learning task as a meta-learning task and automatically optimize the adapters for desirable data adaptation and parameter initialization. Experiments on real-world stock datasets demonstrate that DoubleAdapt achieves state-of-the-art predictive performance and shows considerable efficiency.", "link": "http://arxiv.org/abs/2306.09862v3"}, {"index": 140, "title": "Mean-Variance Efficient Collaborative Filtering for Stock Recommendation", "abstract": "The rise of FinTech has transformed financial services onto online platforms, yet stock investment recommender systems have received limited attention compared to other industries. Personalized stock recommendations can significantly impact customer engagement and satisfaction within the industry. However, traditional investment recommendations focus on high-return stocks or highly diversified portfolios based on the modern portfolio theory, often neglecting user preferences. On the other hand, collaborative filtering (CF) methods also may not be directly applicable to stock recommendations, because it is inappropriate to just recommend stocks that users like. The key is to optimally blend users preference with the portfolio theory. However, research on stock recommendations within the recommender system domain remains comparatively limited, and no existing model considers both the preference of users and the risk-return characteristics of stocks. In this regard, we propose a mean-variance efficient collaborative filtering (MVECF) model for stock recommendations that consider both aspects. Our model is specifically designed to improve the pareto optimality (mean-variance efficiency) in a trade-off between the risk (variance of return) and return (mean return) by systemically handling uncertainties in stock prices. Such improvements are incorporated into the MVECF model using regularization, and the model is restructured to fit into the ordinary matrix factorization scheme to boost computational efficiency. Experiments on real-world fund holdings data show that our model can increase the mean-variance efficiency of suggested portfolios while sacrificing just a small amount of mean average precision and recall. Finally, we further show MVECF is easily applicable to the state-of-the-art graph-based ranking models.", "link": "http://arxiv.org/abs/2306.06590v1"}, {"index": 141, "title": "Interbank Decisions and Margins of Stability: an Agent-Based Stock-Flow Consistent Approach", "abstract": "This study investigates the functioning of modern payment systems through the lens of banks' maturity mismatch practices, and it examines the effects of banks' refusal to roll over short-term interbank liabilities on financial stability. Within an agent-based stock-flow consistent framework, banks can engage in two segments of the interbank market that differ in maturity, overnight and term. We compare two interbank matching scenarios to assess how bank-specific maturity targets, dependent on the dictates of the Net Stable Funding Ratio, impact the dynamics of the interbank market and the effectiveness of conventional monetary policies. The findings reveal that maturity misalignment between deficit and surplus banks compromises the interbank market's efficiency and increases reliance on the central bank's standing facilities. Monetary policy interest-rate steering practices also become less effective. The study also uncovers a dual stability-based configuration in the banking sector, resembling the segmented European interbank structure. This paper suggests that heterogeneous maturity mismatches between surplus and deficit banks may result in asymmetric funding frictions that might precede credit- and sovereign-risk explanations of interbank tensions. Also, a combined examination of macroprudential tools and rollover-based interbank dynamics can enhance our understanding of how regulatory changes impact the stability of heterogeneous banking sectors.", "link": "http://arxiv.org/abs/2306.05860v1"}, {"index": 142, "title": "Agent Performing Autonomous Stock Trading under Good and Bad Situations", "abstract": "Stock trading is one of the popular ways for financial management. However, the market and the environment of economy is unstable and usually not predictable. Furthermore, engaging in stock trading requires time and effort to analyze, create strategies, and make decisions. It would be convenient and effective if an agent could assist or even do the task of analyzing and modeling the past data and then generate a strategy for autonomous trading. Recently, reinforcement learning has been shown to be robust in various tasks that involve achieving a goal with a decision making strategy based on time-series data. In this project, we have developed a pipeline that simulates the stock trading environment and have trained an agent to automate the stock trading process with deep reinforcement learning methods, including deep Q-learning, deep SARSA, and the policy gradient method. We evaluate our platform during relatively good (before 2021) and bad (2021 - 2022) situations. The stocks we've evaluated on including Google, Apple, Tesla, Meta, Microsoft, and IBM. These stocks are among the popular ones, and the changes in trends are representative in terms of having good and bad situations. We showed that before 2021, the three reinforcement methods we have tried always provide promising profit returns with total annual rates around $70\\%$ to $90\\%$, while maintain a positive profit return after 2021 with total annual rates around 2% to 7%.", "link": "http://arxiv.org/abs/2306.03985v1"}, {"index": 143, "title": "Forecasting the Performance of US Stock Market Indices During COVID-19: RF vs LSTM", "abstract": "The US stock market experienced instability following the recession (2007-2009). COVID-19 poses a significant challenge to US stock traders and investors. Traders and investors should keep up with the stock market. This is to mitigate risks and improve profits by using forecasting models that account for the effects of the pandemic. With consideration of the COVID-19 pandemic after the recession, two machine learning models, including Random Forest and LSTM are used to forecast two major US stock market indices. Data on historical prices after the big recession is used for developing machine learning models and forecasting index returns. To evaluate the model performance during training, cross-validation is used. Additionally, hyperparameter optimizing, regularization, such as dropouts and weight decays, and preprocessing improve the performances of Machine Learning techniques. Using high-accuracy machine learning techniques, traders and investors can forecast stock market behavior, stay ahead of their competition, and improve profitability. Keywords: COVID-19, LSTM, S&P500, Random Forest, Russell 2000, Forecasting, Machine Learning, Time Series JEL Code: C6, C8, G4.", "link": "http://arxiv.org/abs/2306.03620v1"}, {"index": 144, "title": "Optimal Market Making in the Chinese Stock Market: A Stochastic Control and Scenario Analysis", "abstract": "Market making plays a crucial role in providing liquidity and maintaining stability in financial markets, making it an essential component of well-functioning capital markets. Despite its importance, there is limited research on market making in the Chinese stock market, which is one of the largest and most rapidly growing markets globally. To address this gap, we employ an optimal market making framework with an exponential CARA-type (Constant Absolute Risk Aversion) utility function that accounts for various market conditions, such as price drift, volatility, and stamp duty, and is capable of describing 3 major risks (i.e., inventory, execution and adverse selection risks) in market making practice, and provide an in-depth quantitative and scenario analysis of market making in the Chinese stock market. Our numerical experiments explore the impact of volatility on the market maker's inventory. Furthermore, we find that the stamp duty rate is a critical factor in market making, with a negative impact on both the profit of the market maker and the liquidity of the market. Additionally, our analysis emphasizes the significance of accurately estimating stock drift for managing inventory and adverse selection risks effectively and enhancing profit for the market maker. These findings offer valuable insights for both market makers and policymakers in the Chinese stock market and provide directions for further research in designing effective market making strategies and policies.", "link": "http://arxiv.org/abs/2306.02764v1"}, {"index": 145, "title": "Financial sentiment analysis using FinBERT with application in predicting stock movement", "abstract": "We apply sentiment analysis in financial context using FinBERT, and build a deep neural network model based on LSTM to predict the movement of financial market movement. We apply this model on stock news dataset, and compare its effectiveness to BERT, LSTM and classical ARIMA model. We find that sentiment is an effective factor in predicting market movement. We also propose several method to improve the model.", "link": "http://arxiv.org/abs/2306.02136v1"}, {"index": 146, "title": "ChatGPT Informed Graph Neural Network for Stock Movement Prediction", "abstract": "ChatGPT has demonstrated remarkable capabilities across various natural language processing (NLP) tasks. However, its potential for inferring dynamic network structures from temporal textual data, specifically financial news, remains an unexplored frontier. In this research, we introduce a novel framework that leverages ChatGPT's graph inference capabilities to enhance Graph Neural Networks (GNN). Our framework adeptly extracts evolving network structures from textual data, and incorporates these networks into graph neural networks for subsequent predictive tasks. The experimental results from stock movement forecasting indicate our model has consistently outperformed the state-of-the-art Deep Learning-based benchmarks. Furthermore, the portfolios constructed based on our model's outputs demonstrate higher annualized cumulative returns, alongside reduced volatility and maximum drawdown. This superior performance highlights the potential of ChatGPT for text-based network inferences and underscores its promising implications for the financial sector.", "link": "http://dx.doi.org/10.2139/ssrn.4464002"}, {"index": 147, "title": "A Comparative Analysis of Portfolio Optimization Using Mean-Variance, Hierarchical Risk Parity, and Reinforcement Learning Approaches on the Indian Stock Market", "abstract": "This paper presents a comparative analysis of the performances of three portfolio optimization approaches. Three approaches of portfolio optimization that are considered in this work are the mean-variance portfolio (MVP), hierarchical risk parity (HRP) portfolio, and reinforcement learning-based portfolio. The portfolios are trained and tested over several stock data and their performances are compared on their annual returns, annual risks, and Sharpe ratios. In the reinforcement learning-based portfolio design approach, the deep Q learning technique has been utilized. Due to the large number of possible states, the construction of the Q-table is done using a deep neural network. The historical prices of the 50 premier stocks from the Indian stock market, known as the NIFTY50 stocks, and several stocks from 10 important sectors of the Indian stock market are used to create the environment for training the agent.", "link": "http://arxiv.org/abs/2305.17523v1"}, {"index": 148, "title": "The Ensemble Approach of Column Generation for Solving Cutting Stock Problems", "abstract": "This paper investigates the column generation (CG) for solving cutting stock problems (CSP). Traditional CG method, which repeatedly solves a restricted master problem (RMP), often suffers from two critical issues in practice -- the loss of solution quality introduced by linear relaxation of both feasible domain and objective and the high time cost of last iterations close to convergence. We empirically find that the first issue is common in ordinary CSPs with linear cutting constraints, while the second issue is especially severe in CSPs with nonlinear cutting constraints that are often generated by approximating chance constraints. We propose an alternative approach, ensembles of multiple column generation processes. In particular, we present two methods -- \\mc (multi-column) which return multiple feasible columns in each RMP iteration, and \\mt (multi-path) which restarts the RMP iterations from different initialized column sets once the iteration time exceeds a given time limit. The ideas behind are same: leverage the multiple column generation pathes to compensate the loss induced by relaxation, and add earlier sub-optimal columns to accelerate convergence of RMP iterations. Besides, we give theoretical analysis on performance improvement guarantees. Experiments on cutting stock problems demonstrate that compared to traditional CG, our method achieves significant run-time reduction on CSPs with nonlinear constraints, and dramatically improves the ratio of solve-to-optimal on CSPs with linear constraints.", "link": "http://arxiv.org/abs/2305.14055v1"}, {"index": 149, "title": "Stock and market index prediction using Informer network", "abstract": "Applications of deep learning in financial market prediction has attracted huge attention from investors and researchers. In particular, intra-day prediction at the minute scale, the dramatically fluctuating volume and stock prices within short time periods have posed a great challenge for the convergence of networks result. Informer is a more novel network, improved on Transformer with smaller computational complexity, longer prediction length and global time stamp features. We have designed three experiments to compare Informer with the commonly used networks LSTM, Transformer and BERT on 1-minute and 5-minute frequencies for four different stocks/ market indices. The prediction results are measured by three evaluation criteria: MAE, RMSE and MAPE. Informer has obtained best performance among all the networks on every dataset. Network without the global time stamp mechanism has significantly lower prediction effect compared to the complete Informer; it is evident that this mechanism grants the time series to the characteristics and substantially improves the prediction accuracy of the networks. Finally, transfer learning capability experiment is conducted, Informer also achieves a good performance. Informer has good robustness and improved performance in market prediction, which can be exactly adapted to real trading.", "link": "http://arxiv.org/abs/2305.14382v1"}, {"index": 150, "title": "Predicting Stock Market Time-Series Data using CNN-LSTM Neural Network Model", "abstract": "Stock market is often important as it represents the ownership claims on businesses. Without sufficient stocks, a company cannot perform well in finance. Predicting a stock market performance of a company is nearly hard because every time the prices of a company stock keeps changing and not constant. So, its complex to determine the stock data. But if the previous performance of a company in stock market is known, then we can track the data and provide predictions to stockholders in order to wisely take decisions on handling the stocks to a company. To handle this, many machine learning models have been invented but they didn't succeed due to many reasons like absence of advanced libraries, inaccuracy of model when made to train with real time data and much more. So, to track the patterns and the features of data, a CNN-LSTM Neural Network can be made. Recently, CNN is now used in Natural Language Processing (NLP) based applications, so by identifying the features from stock data and converting them into tensors, we can obtain the features and then send it to LSTM neural network to find the patterns and thereby predicting the stock market for given period of time. The accuracy of the CNN-LSTM NN model is found to be high even when allowed to train on real-time stock market data. This paper describes about the features of the custom CNN-LSTM model, experiments we made with the model (like training with stock market datasets, performance comparison with other models) and the end product we obtained at final stage.", "link": "http://arxiv.org/abs/2305.14378v1"}, {"index": 151, "title": "Support for Stock Trend Prediction Using Transformers and Sentiment Analysis", "abstract": "Stock trend analysis has been an influential time-series prediction topic due to its lucrative and inherently chaotic nature. Many models looking to accurately predict the trend of stocks have been based on Recurrent Neural Networks (RNNs). However, due to the limitations of RNNs, such as gradient vanish and long-term dependencies being lost as sequence length increases, in this paper we develop a Transformer based model that uses technical stock data and sentiment analysis to conduct accurate stock trend prediction over long time windows. This paper also introduces a novel dataset containing daily technical stock data and top news headline data spanning almost three years. Stock prediction based solely on technical data can suffer from lag caused by the inability of stock indicators to effectively factor in breaking market news. The use of sentiment analysis on top headlines can help account for unforeseen shifts in market conditions caused by news coverage. We measure the performance of our model against RNNs over sequence lengths spanning 5 business days to 30 business days to mimic different length trading strategies. This reveals an improvement in directional accuracy over RNNs as sequence length is increased, with the largest improvement being close to 18.63% at 30 business days.", "link": "http://arxiv.org/abs/2305.14368v1"}, {"index": 152, "title": "Short-Term Stock Price Forecasting using exogenous variables and Machine Learning Algorithms", "abstract": "Creating accurate predictions in the stock market has always been a significant challenge in finance. With the rise of machine learning as the next level in the forecasting area, this research paper compares four machine learning models and their accuracy in forecasting three well-known stocks traded in the NYSE in the short term from March 2020 to May 2022. We deploy, develop, and tune XGBoost, Random Forest, Multi-layer Perceptron, and Support Vector Regression models. We report the models that produce the highest accuracies from our evaluation metrics: RMSE, MAPE, MTT, and MPE. Using a training data set of 240 trading days, we find that XGBoost gives the highest accuracy despite running longer (up to 10 seconds). Results from this study may improve by further tuning the individual parameters or introducing more exogenous variables.", "link": "http://arxiv.org/abs/2309.00618v1"}, {"index": 153, "title": "A spectral approach to stock market performance", "abstract": "We pose the estimation and predictability of stock market performance. Three cases are taken: US, Japan, Germany, the monthly index of the value of realized investment in stocks, prices plus the value of dividend payments (OECD data). Once deflated and trend removed, harmonic analysis is applied. The series are taken with and without the periods with evidence of exogenous shocks. The series are erratic and the random walk hypothesis is reasonably falsified. The estimation reveals relevant hidden periodicities, which approximate stock value movements. From July 2008 onwards, it is successfully analyzed whether the subsequent fall in share value would have been predictable. Again, the data are irregular and scattered, but the sum of the first five harmonics in relevance anticipates the fall in stock market values that followed.", "link": "http://arxiv.org/abs/2305.05762v1"}, {"index": 154, "title": "Monetary Policy & Stock Market", "abstract": "This paper assesses the link between central bank's policy rate, inflation rate and output gap through Taylor rule equation in both United States and United Kingdom from 1990 to 2020. Also, it analyses the relationship between monetary policy and asset price volatility using an augmented Taylor rule. According to the literature, there has been a discussion about the utility of using asset prices to evaluate central bank monetary policy decisions. First, I derive the equation coefficients and examine the stability of the relationship over the shocking period. Test the model with actual data to see its robustness. I add asset price to the equation in the next step, and then test the relationship by Normality, Newey-West, and GMM estimator tests. Lastly, I conduct comparison between USA and UK results to find out which country's policy decisions can be explained better through Taylor rule.", "link": "http://arxiv.org/abs/2305.13930v1"}, {"index": 155, "title": "Spatiotemporal Transformer for Stock Movement Prediction", "abstract": "Financial markets are an intriguing place that offer investors the potential to gain large profits if timed correctly. Unfortunately, the dynamic, non-linear nature of financial markets makes it extremely hard to predict future price movements. Within the US stock exchange, there are a countless number of factors that play a role in the price of a company's stock, including but not limited to financial statements, social and news sentiment, overall market sentiment, political happenings and trading psychology. Correlating these factors is virtually impossible for a human. Therefore, we propose STST, a novel approach using a Spatiotemporal Transformer-LSTM model for stock movement prediction. Our model obtains accuracies of 63.707 and 56.879 percent against the ACL18 and KDD17 datasets, respectively. In addition, our model was used in simulation to determine its real-life applicability. It obtained a minimum of 10.41% higher profit than the S&P500 stock index, with a minimum annualized return of 31.24%.", "link": "http://arxiv.org/abs/2305.03835v1"}, {"index": 156, "title": "Macroeconomic factors and Stock exchange return: A Statistical Analysis", "abstract": "The purpose of this research is to examine the relationship between the Dhaka Stock exchange index return and macroeconomic variables such as exchange rate, inflation, money supply etc. The long-term relationship between macroeconomic variables and stock market returns has been analyzed by using the Johnson Cointegration test, Augmented Dicky Fuller (ADF) and Phillip Perron (PP) tests. The results revealed the existence of cointegrating relationship between stock prices and the macroeconomic variables in the Dhaka stock exchange. The consumer price index, money supply, and exchange rates proved to be strongly associated with stock returns, while market capitalization was found to be negatively associated with stock returns. The findings suggest that in the long run, the Dhaka stock exchange is reactive to macroeconomic indicators.", "link": "http://arxiv.org/abs/2305.02229v1"}, {"index": 157, "title": "Hierarchical and Upstream-Downstream Composition of Stock and Flow Models", "abstract": "The growing complexity of decision-making in public health and health care has motivated an increasing use of mathematical modeling. An important line of health modeling is based on stock & flow diagrams. Such modeling elevates transparency across the interdisciplinary teams responsible for most impactful models, but existing tools suffer from a number of shortcomings when used at scale. Recent research has sought to address such limitations by establishing a categorical foundation for stock & flow modeling, including the capacity to compose a pair of models through identification of common stocks and sum variables. This work supplements such efforts by contributing two new forms of composition for stock & flow diagrams. We first describe a hierarchical means of diagram composition, in which a single existing stock is replaced by a diagram featuring compatible flow structure. Our composition method offers extra flexibility by allowing a single flow in the stock being replaced to split into several flows totalling to the same overall flow rate. Secondly, to address the common need of docking a stock & flow diagram with another \"upstream\" diagram depicting antecedent factors, we contribute a composition approach that allows a flow out of an upstream stock in one diagram to be connected to a downstream stock in another diagram. Both of these approaches are enabled by performing colimit decomposition of stock & flow diagrams into single-stock corollas and unit flows.", "link": "http://arxiv.org/abs/2305.02136v1"}, {"index": 158, "title": "Using a Deep Learning Model to Simulate Human Stock Trader's Methods of Chart Analysis", "abstract": "Despite the efficient market hypothesis, many studies suggest the existence of inefficiencies in the stock market leading to the development of techniques to gain above-market returns. Systematic trading has undergone significant advances in recent decades with deep learning schemes emerging as a powerful tool for analyzing and predicting market behavior. In this paper, a method is proposed that is inspired by how professional technical analysts trade. This scheme looks at stock prices of the previous 600 days and predicts whether the stock price will rise or fall 10% or 20% within the next D days. The proposed method uses the Resnet's (a deep learning model) skip connections and logits to increase the probability of the prediction. The model was trained and tested using historical data from both the Korea and US stock markets. The backtest is done using the data from 2020 to 2022. Using the proposed method for the Korea market it gave return of 75.36% having Sharpe ratio of 1.57, which far exceeds the market return by 36% and 0.61, respectively. On the US market it gives total return of 27.17% with Sharpe ratio of 0.61, which outperforms other benchmarks such as NASDAQ, S&P500, DOW JONES index by 17.69% and 0.27, respectively.", "link": "http://arxiv.org/abs/2304.14870v3"}, {"index": 159, "title": "Selecting Sustainable Optimal Stock by Using Multi-Criteria Fuzzy Decision-Making Approaches Based on the Development of the Gordon Model: A case study of the Toronto Stock Exchange", "abstract": "Choosing the right stock portfolio with the highest efficiencies has always concerned accurate and legal investors. Investors have always been concerned about the accuracy and legitimacy of choosing the right stock portfolio with high efficiency. Therefore, this paper aims to determine the criteria for selecting an optimal stock portfolio with a high-efficiency ratio in the Toronto Stock Exchange using the integrated evaluation and decision-making trial laboratory (DEMATEL) model and Multi-Criteria Fuzzy decision-making approaches regarding the development of the Gordon model. In the current study, results obtained using combined multi-criteria fuzzy decision-making approaches, the practical factors, the relative weight of dividends, discount rate, and dividend growth rate have been comprehensively illustrated using combined multi-criteria fuzzy decision-making approaches. A group of 10 experts with at least a ten-year of experience in the stock exchange field was formed to review the different and new aspects of the subject (portfolio selection) to decide the interaction between the group members and the exchange of attitudes and ideas regarding the criteria. The sequence of influence and effectiveness of the main criteria with DEMATEL has shown that the profitability criterion interacts most with other criteria. The criteria of managing methods and operations (MPO), market, risk, and growth criteria are ranked next in terms of interaction with other criteria. This study concludes that regarding the model's appropriate and reliable validity in choosing the optimal stock portfolio, it is recommended that portfolio managers in companies, investment funds, and capital owners use the model to select stocks in the Toronto Stock Exchange optimally.", "link": "http://arxiv.org/abs/2304.13818v1"}, {"index": 160, "title": "The cross-sectional stock return predictions via quantum neural network and tensor network", "abstract": "In this paper, we investigate the application of quantum and quantum-inspired machine learning algorithms to stock return predictions. Specifically, we evaluate the performance of quantum neural network, an algorithm suited for noisy intermediate-scale quantum computers, and tensor network, a quantum-inspired machine learning algorithm, against classical models such as linear regression and neural networks. To evaluate their abilities, we construct portfolios based on their predictions and measure investment performances. The empirical study on the Japanese stock market shows the tensor network model achieves superior performance compared to classical benchmark models, including linear and neural network models. Though the quantum neural network model attains a lowered risk-adjusted excess return than the classical neural network models over the whole period, both the quantum neural network and tensor network models have superior performances in the latest market environment, which suggests the capability of the model's capturing non-linearity between input features.", "link": "http://dx.doi.org/10.1007/s42484-023-00136-x"}, {"index": 161, "title": "Construct sparse portfolio with mutual fund's favourite stocks in China A share market", "abstract": "Unlike developed market, some emerging markets are dominated by retail and unprofessional trading. China A share market is a good and fitting example in last 20 years. Meanwhile, lots of research show professional investor in China A share market continuously generate excess return compare with total market index. Specifically, this excess return mostly come from stock selectivity ability instead of market timing. However for some reason such as fund capacity limit, fund manager change or market regional switch, it is very hard to find a fund could continuously beat market. Therefore, in order to get excess return from mutual fund industry, we use quantitative way to build the sparse portfolio that take advantage of favorite stocks by mutual fund in China A market. Firstly we do the analysis about favourite stocks by mutual fund and compare the different method to construct our portfolio. Then we build a sparse stock portfolio with constraint on both individual stock and industry exposure using portfolio optimizer to closely track the partial equity funds index 930950.CSI with median 0.985 correlation. This problem is much more difficult than tracking full information index or traditional ETF as higher turnover of mutual fund, just first 10 holding of mutual fund available and fund report updated quarterly with 15 days delay. Finally we build another low risk and balanced sparse portfolio that consistently outperform benchmark 930950.CSI.", "link": "http://arxiv.org/abs/2305.01642v1"}, {"index": 162, "title": "Can Perturbations Help Reduce Investment Risks? Risk-Aware Stock Recommendation via Split Variational Adversarial Training", "abstract": "In the stock market, a successful investment requires a good balance between profits and risks. Based on the learning to rank paradigm, stock recommendation has been widely studied in quantitative finance to recommend stocks with higher return ratios for investors. Despite the efforts to make profits, many existing recommendation approaches still have some limitations in risk control, which may lead to intolerable paper losses in practical stock investing. To effectively reduce risks, we draw inspiration from adversarial learning and propose a novel Split Variational Adversarial Training (SVAT) method for risk-aware stock recommendation. Essentially, SVAT encourages the stock model to be sensitive to adversarial perturbations of risky stock examples and enhances the model's risk awareness by learning from perturbations. To generate representative adversarial examples as risk indicators, we devise a variational perturbation generator to model diverse risk factors. Particularly, the variational architecture enables our method to provide a rough risk quantification for investors, showing an additional advantage of interpretability. Experiments on several real-world stock market datasets demonstrate the superiority of our SVAT method. By lowering the volatility of the stock recommendation model, SVAT effectively reduces investment risks and outperforms state-of-the-art baselines by more than 30% in terms of risk-adjusted profits. All the experimental data and source code are available at https://drive.google.com/drive/folders/14AdM7WENEvIp5x5bV3zV_i4Aev21C9g6?usp=sharing.", "link": "http://dx.doi.org/10.1145/3643131"}, {"index": 163, "title": "Can ChatGPT Forecast Stock Price Movements? Return Predictability and Large Language Models", "abstract": "We examine the potential of ChatGPT and other large language models in predicting stock market returns using news headlines. We use ChatGPT to assess whether each headline is good, bad, or neutral for firms' stock prices. We document a significantly positive correlation between ChatGPT scores and subsequent daily stock returns. We find that ChatGPT outperforms traditional sentiment analysis methods. More basic models such as GPT-1, GPT-2, and BERT cannot accurately forecast returns, indicating return predictability is an emerging capacity of complex language models. Long-short strategies based on ChatGPT-4 deliver the highest Sharpe ratio. Furthermore, we find predictability in both small and large stocks, suggesting market underreaction to company news. Predictability is stronger among smaller stocks and stocks with bad news, consistent with limits-to-arbitrage also playing an important role. Finally, we propose a new method to evaluate and understand the models' reasoning capabilities. Overall, our results suggest that incorporating advanced language models into the investment decision-making process can yield more accurate predictions and enhance the performance of quantitative trading strategies.", "link": "http://arxiv.org/abs/2304.07619v4"}, {"index": 164, "title": "The Wall Street Neophyte: A Zero-Shot Analysis of ChatGPT Over MultiModal Stock Movement Prediction Challenges", "abstract": "Recently, large language models (LLMs) like ChatGPT have demonstrated remarkable performance across a variety of natural language processing tasks. However, their effectiveness in the financial domain, specifically in predicting stock market movements, remains to be explored. In this paper, we conduct an extensive zero-shot analysis of ChatGPT's capabilities in multimodal stock movement prediction, on three tweets and historical stock price datasets. Our findings indicate that ChatGPT is a \"Wall Street Neophyte\" with limited success in predicting stock movements, as it underperforms not only state-of-the-art methods but also traditional methods like linear regression using price features. Despite the potential of Chain-of-Thought prompting strategies and the inclusion of tweets, ChatGPT's performance remains subpar. Furthermore, we observe limitations in its explainability and stability, suggesting the need for more specialized training or fine-tuning. This research provides insights into ChatGPT's capabilities and serves as a foundation for future work aimed at improving financial market analysis and prediction by leveraging social media sentiment and historical stock data.", "link": "http://arxiv.org/abs/2304.05351v2"}, {"index": 165, "title": "Stock Price Predictability and the Business Cycle via Machine Learning", "abstract": "We study the impacts of business cycles on machine learning (ML) predictions. Using the S&P 500 index, we find that ML models perform worse during most recessions, and the inclusion of recession history or the risk-free rate does not necessarily improve their performance. Investigating recessions where models perform well, we find that they exhibit lower market volatility than other recessions. This implies that the improved performance is not due to the merit of ML methods but rather factors such as effective monetary policies that stabilized the market. We recommend that ML practitioners evaluate their models during both recessions and expansions.", "link": "http://arxiv.org/abs/2304.09937v1"}, {"index": 166, "title": "Mapping historical forest biomass for stock-change assessments at parcel to landscape scales", "abstract": "Understanding historical forest dynamics, specifically changes in forest biomass and carbon stocks, has become critical for assessing current forest climate benefits and projecting future benefits under various policy, regulatory, and stewardship scenarios. Carbon accounting frameworks based exclusively on national forest inventories are limited to broad-scale estimates, but model-based approaches that combine these inventories with remotely sensed data can yield contiguous fine-resolution maps of forest biomass and carbon stocks across landscapes over time. Here we describe a fundamental step in building a map-based stock-change framework: mapping historical forest biomass at fine temporal and spatial resolution (annual, 30m) across all of New York State (USA) from 1990 to 2019, using freely available data and open-source tools.   Using Landsat imagery, US Forest Service Forest Inventory and Analysis (FIA) data, and off-the-shelf LiDAR collections we developed three modeling approaches for mapping historical forest aboveground biomass (AGB): training on FIA plot-level AGB estimates (direct), training on LiDAR-derived AGB maps (indirect), and an ensemble averaging predictions from the direct and indirect models. Model prediction surfaces (maps) were tested against FIA estimates at multiple scales. All three approaches produced viable outputs, yet tradeoffs were evident in terms of model complexity, map accuracy, saturation, and fine-scale pattern representation. The resulting map products can help identify where, when, and how forest carbon stocks are changing as a result of both anthropogenic and natural drivers alike. These products can thus serve as inputs to a wide range of applications including stock-change assessments, monitoring reporting and verification frameworks, and prioritizing parcels for protection or enrollment in improved management programs.", "link": "http://dx.doi.org/10.1016/j.foreco.2023.121348"}, {"index": 167, "title": "Words that Matter: The Impact of Negative Words on News Sentiment and Stock Market Index", "abstract": "This study investigates the impact of negative words on sentiment analysis and its effect on the South Korean stock market index, KOSPI200. The research analyzes a dataset of 45,723 South Korean daily economic news articles using Word2Vec, cosine similarity, and an expanded lexicon. The findings suggest that incorporating negative words significantly increases sentiment scores' negativity in news titles, which can affect the stock market index. The study reveals that an augmented sentiment lexicon (Sent1000), including the top 1,000 negative words with high cosine similarity to 'Crisis,' more effectively captures the impact of news sentiment on the stock market index than the original sentiment lexicon (Sent0). The results underscore the importance of considering negative nuances and context when analyzing news content and its potential impact on market dynamics and public opinion.", "link": "http://arxiv.org/abs/2304.00468v2"}, {"index": 168, "title": "Taureau: A Stock Market Movement Inference Framework Based on Twitter Sentiment Analysis", "abstract": "With the advent of fast-paced information dissemination and retrieval, it has become inherently important to resort to automated means of predicting stock market prices. In this paper, we propose Taureau, a framework that leverages Twitter sentiment analysis for predicting stock market movement. The aim of our research is to determine whether Twitter, which is assumed to be representative of the general public, can give insight into the public perception of a particular company and has any correlation to that company's stock price movement. We intend to utilize this correlation to predict stock price movement. We first utilize Tweepy and getOldTweets to obtain historical tweets indicating public opinions for a set of top companies during periods of major events. We filter and label the tweets using standard programming libraries. We then vectorize and generate word embedding from the obtained tweets. Afterward, we leverage TextBlob, a state-of-the-art sentiment analytics engine, to assess and quantify the users' moods based on the tweets. Next, we correlate the temporal dimensions of the obtained sentiment scores with monthly stock price movement data. Finally, we design and evaluate a predictive model to forecast stock price movement from lagged sentiment scores. We evaluate our framework using actual stock price movement data to assess its ability to predict movement direction.", "link": "http://arxiv.org/abs/2303.17667v1"}, {"index": 169, "title": "A Case Study on AI Engineering Practices: Developing an Autonomous Stock Trading System", "abstract": "Today, many systems use artificial intelligence (AI) to solve complex problems. While this often increases system effectiveness, developing a production-ready AI-based system is a difficult task. Thus, solid AI engineering practices are required to ensure the quality of the resulting system and to improve the development process. While several practices have already been proposed for the development of AI-based systems, detailed practical experiences of applying these practices are rare.   In this paper, we aim to address this gap by collecting such experiences during a case study, namely the development of an autonomous stock trading system that uses machine learning functionality to invest in stocks. We selected 10 AI engineering practices from the literature and systematically applied them during development, with the goal to collect evidence about their applicability and effectiveness. Using structured field notes, we documented our experiences. Furthermore, we also used field notes to document challenges that occurred during the development, and the solutions we applied to overcome them. Afterwards, we analyzed the collected field notes, and evaluated how each practice improved the development. Lastly, we compared our evidence with existing literature.   Most applied practices improved our system, albeit to varying extent, and we were able to overcome all major challenges. The qualitative results provide detailed accounts about 10 AI engineering practices, as well as challenges and solutions associated with such a project. Our experiences therefore enrich the emerging body of evidence in this field, which may be especially helpful for practitioner teams new to AI engineering.", "link": "http://arxiv.org/abs/2303.13216v1"}, {"index": 170, "title": "Network log-ARCH models for forecasting stock market volatility", "abstract": "This paper presents a novel dynamic network autoregressive conditional heteroscedasticity (ARCH) model based on spatiotemporal ARCH models to forecast volatility in the US stock market. To improve the forecasting accuracy, the model integrates temporally lagged volatility information and information from adjacent nodes, which may instantaneously spill across the entire network. The model is also suitable for high-dimensional cases where multivariate ARCH models are typically no longer applicable. We adopt the theoretical foundations from spatiotemporal statistics and transfer the dynamic ARCH model for processes to networks. This new approach is compared with independent univariate log-ARCH models. We could quantify the improvements due to the instantaneous network ARCH effects, which are studied for the first time in this paper. The edges are determined based on various distance and correlation measures between the time series. The performances of the alternative networks' definitions are compared in terms of out-of-sample accuracy. Furthermore, we consider ensemble forecasts based on different network definitions.", "link": "http://arxiv.org/abs/2303.11064v1"}, {"index": 171, "title": "On Using Proportional Representation Methods as Alternatives to Pro-Rata Based Order Matching Algorithms in Stock Exchanges", "abstract": "The first observation of the paper is that methods for determining proportional representation in electoral systems may be suitable as alternatives to the pro-rata order matching algorithm used in stock exchanges. The main part of our work is to comprehensively consider various well known proportional representation methods and analyse in details their suitability for replacing the pro-rata algorithm. Our analysis consists of a theoretical study as well as simulation studies based on data sampled from a distribution which has been suggested in the literature as models of limit orders. Based on our analysis, we put forward the suggestion that the well known Hamilton's method is a superior alternative to the pro-rata algorithm for order matching applications.", "link": "http://arxiv.org/abs/2303.09652v4"}, {"index": 172, "title": "Portfolio Volatility Estimation Relative to Stock Market Cross-Sectional Intrinsic Entropy", "abstract": "Selecting stock portfolios and assessing their relative volatility risk compared to the market as a whole, market indices, or other portfolios is of great importance to professional fund managers and individual investors alike. Our research uses the cross-sectional intrinsic entropy (CSIE) model to estimate the cross-sectional volatility of the stock groups that can be considered together as portfolio constituents. In our study, we benchmark portfolio volatility risks against the volatility of the entire market provided by the CSIE and the volatility of market indices computed using longitudinal data. This article introduces CSIE-based betas to characterise the relative volatility risk of the portfolio against market indices and the market as a whole. We empirically prove that, through CSIE-based betas, multiple sets of symbols that outperform the market indices in terms of rate of return while maintaining the same level of risk or even lower than the one exhibited by the market index can be discovered, for any given time interval. These sets of symbols can be used as constituent stock portfolios and, in connection with the perspective provided by the CSIE volatility estimates, to hierarchically assess their relative volatility risk within the broader context of the overall volatility of the stock market.", "link": "http://dx.doi.org/10.3390/jrfm16020114"}, {"index": 173, "title": "Improving CNN-base Stock Trading By Considering Data Heterogeneity and Burst", "abstract": "In recent years, there have been quite a few attempts to apply intelligent techniques to financial trading, i.e., constructing automatic and intelligent trading framework based on historical stock price. Due to the unpredictable, uncertainty and volatile nature of financial market, researchers have also resorted to deep learning to construct the intelligent trading framework. In this paper, we propose to use CNN as the core functionality of such framework, because it is able to learn the spatial dependency (i.e., between rows and columns) of the input data. However, different with existing deep learning-based trading frameworks, we develop novel normalization process to prepare the stock data. In particular, we first empirically observe that the stock data is intrinsically heterogeneous and bursty, and then validate the heterogeneity and burst nature of stock data from a statistical perspective. Next, we design the data normalization method in a way such that the data heterogeneity is preserved and bursty events are suppressed. We verify out developed CNN-based trading framework plus our new normalization method on 29 stocks. Experiment results show that our approach can outperform other comparing approaches.", "link": "http://dx.doi.org/10.5121/ijci.2023.120201"}, {"index": 174, "title": "TM-vector: A Novel Forecasting Approach for Market stock movement with a Rich Representation of Twitter and Market data", "abstract": "Stock market forecasting has been a challenging part for many analysts and researchers. Trend analysis, statistical techniques, and movement indicators have traditionally been used to predict stock price movements, but text extraction has emerged as a promising method in recent years. The use of neural networks, especially recurrent neural networks, is abundant in the literature. In most studies, the impact of different users was considered equal or ignored, whereas users can have other effects. In the current study, we will introduce TM-vector and then use this vector to train an IndRNN and ultimately model the market users' behaviour. In the proposed model, TM-vector is simultaneously trained with both the extracted Twitter features and market information. Various factors have been used for the effectiveness of the proposed forecasting approach, including the characteristics of each individual user, their impact on each other, and their impact on the market, to predict market direction more accurately. Dow Jones 30 index has been used in current work. The accuracy obtained for predicting daily stock changes of Apple is based on various models, closed to over 95\\% and for the other stocks is significant. Our results indicate the effectiveness of TM-vector in predicting stock market direction.", "link": "http://arxiv.org/abs/2304.02094v1"}, {"index": 175, "title": "The Stock Price Relationship between Holding Companies and Subsidiaries: A Case study of Indonesia Multiholding Companies", "abstract": "This study aimed to examine the correlation between the stock prices of two major Indonesian holding companies, MNC Group and Elang Mahkota Teknologi (Emtek) Group, and their respective subsidiaries as case studies. The data for the analysis were collected from 2013 to 2022, and Spearman correlation was used to determine the strength and direction of the relationship between the stock prices of the holding companies and their subsidiaries. The results of the analysis revealed that there were varying degrees of correlation between the stock prices of the holding companies and their subsidiaries. The strongest positive correlation was observed between BHIT and BMTR, while the weakest correlations were found between BHIT and IPTV, and BHIT and MSIN. The correlations were also found to have changed over time, possibly due to market conditions, company-specific events, or changes in industry sectors.In the case of Emtek Group, the analysis suggested that EMTK's stock price movements had a significant impact on the stock prices of its subsidiaries, with varying strengths of relationships. The negative correlation between EMTK and SCMA over the entire period suggested an inverse relationship, while positive correlations with BUKA, AMOR, BBHI, and RSGK indicated a tendency to move in the same direction as EMTK's stock price. The correlations were found to have increased over time, possibly due to market conditions and EMTK's ownership stake in these companies. Overall, the findings of this study suggest that there is a complex interplay between the stock prices of parent companies and their subsidiaries, and that there are a variety of factors that can influence these relationships over time. These findings may be useful for investors in making informed decisions about their investment portfolios, as changes in the correlations could impact their portfolio's performance.", "link": "http://arxiv.org/abs/2303.07244v1"}, {"index": 176, "title": "Stock Trend Prediction: A Semantic Segmentation Approach", "abstract": "Market financial forecasting is a trending area in deep learning. Deep learning models are capable of tackling the classic challenges in stock market data, such as its extremely complicated dynamics as well as long-term temporal correlation. To capture the temporal relationship among these time series, recurrent neural networks are employed. However, it is difficult for recurrent models to learn to keep track of long-term information. Convolutional Neural Networks have been utilized to better capture the dynamics and extract features for both short- and long-term forecasting. However, semantic segmentation and its well-designed fully convolutional networks have never been studied for time-series dense classification. We present a novel approach to predict long-term daily stock price change trends with fully 2D-convolutional encoder-decoders. We generate input frames with daily prices for a time-frame of T days. The aim is to predict future trends by pixel-wise classification of the current price frame. We propose a hierarchical CNN structure to encode multiple price frames to multiscale latent representation in parallel using Atrous Spatial Pyramid Pooling blocks and take that temporal coarse feature stacks into account in the decoding stages. Our hierarchical structure of CNNs makes it capable of capturing both long and short-term temporal relationships effectively. The effect of increasing the input time horizon via incrementing parallel encoders has been studied with interesting and substantial changes in the output segmentation masks. We achieve overall accuracy and AUC of %78.18 and 0.88 for joint trend prediction over the next 20 days, surpassing other semantic segmentation approaches. We compared our proposed model with several deep models specifically designed for technical analysis and found that for different output horizons, our proposed models outperformed other models.", "link": "http://arxiv.org/abs/2303.09323v1"}, {"index": 177, "title": "Stock Price Prediction Using Temporal Graph Model with Value Chain Data", "abstract": "Stock price prediction is a crucial element in financial trading as it allows traders to make informed decisions about buying, selling, and holding stocks. Accurate predictions of future stock prices can help traders optimize their trading strategies and maximize their profits. In this paper, we introduce a neural network-based stock return prediction method, the Long Short-Term Memory Graph Convolutional Neural Network (LSTM-GCN) model, which combines the Graph Convolutional Network (GCN) and Long Short-Term Memory (LSTM) Cells. Specifically, the GCN is used to capture complex topological structures and spatial dependence from value chain data, while the LSTM captures temporal dependence and dynamic changes in stock returns data. We evaluated the LSTM-GCN model on two datasets consisting of constituents of Eurostoxx 600 and S&P 500. Our experiments demonstrate that the LSTM-GCN model can capture additional information from value chain data that are not fully reflected in price data, and the predictions outperform baseline models on both datasets.", "link": "http://arxiv.org/abs/2303.09406v1"}, {"index": 178, "title": "Predicting Stock Price Movement as an Image Classification Problem", "abstract": "The paper studies intraday price movement of stocks that is considered as an image classification problem. Using a CNN-based model we make a compelling case for the high-level relationship between the first hour of trading and the close. The algorithm managed to adequately separate between the two opposing classes and investing according to the algorithm's predictions outperformed all alternative constructs but the theoretical maximum. To support the thesis, we ran several additional tests. The findings in the paper highlight the suitability of computer vision techniques for studying financial markets and in particular prediction of stock price movements.", "link": "http://arxiv.org/abs/2303.01111v1"}, {"index": 179, "title": "Stock Broad-Index Trend Patterns Learning via Domain Knowledge Informed Generative Network", "abstract": "Predicting the Stock movement attracts much attention from both industry and academia. Despite such significant efforts, the results remain unsatisfactory due to the inherently complicated nature of the stock market driven by factors including supply and demand, the state of the economy, the political climate, and even irrational human behavior. Recently, Generative Adversarial Networks (GAN) have been extended for time series data; however, robust methods are primarily for synthetic series generation, which fall short for appropriate stock prediction. This is because existing GANs for stock applications suffer from mode collapse and only consider one-step prediction, thus underutilizing the potential of GAN. Furthermore, merging news and market volatility are neglected in current GANs. To address these issues, we exploit expert domain knowledge in finance and, for the first time, attempt to formulate stock movement prediction into a Wasserstein GAN framework for multi-step prediction. We propose IndexGAN, which includes deliberate designs for the inherent characteristics of the stock market, leverages news context learning to thoroughly investigate textual information and develop an attentive seq2seq learning network that captures the temporal dependency among stock prices, news, and market sentiment. We also utilize the critic to approximate the Wasserstein distance between actual and predicted sequences and develop a rolling strategy for deployment that mitigates noise from the financial market. Extensive experiments are conducted on real-world broad-based indices, demonstrating the superior performance of our architecture over other state-of-the-art baselines, also validating all its contributing components.", "link": "http://arxiv.org/abs/2302.14164v1"}, {"index": 180, "title": "Physical Momentum in the Indian Stock Market", "abstract": "Our study focuses on determining the presence of abnormal returns for physical momentum portfolios in the context of the Indian market. The physical momentum portfolios, comprising stocks from the NSE 500, are constructed for the daily, weekly, monthly, and yearly timescales. In the aforementioned timescales, we empirically evaluate the historical returns and varied risk profiles of these portfolios for the years 2014-2021. It has been observed that the best-performing physical momentum portfolios from each of the four timescales achieved higher returns and better risk measures when compared to the benchmark NIFTY 50 portfolio. We further find that the high-frequency daily time scale exhibits the strongest reversal in the physical momentum effect, wherein the portfolio yielded a 16-fold profit over the initial investment.", "link": "http://arxiv.org/abs/2302.13245v1"}, {"index": 181, "title": "Stock data analysis using sympbolic data analysis", "abstract": "In this paper we present a model of the stock exchange domain using symbolic dataanalysis and we use the SODAS software to analyze this domain. After a short presentationof the software, we present the analysis in three steps: choice of the symbolic objects, theirdefinition and their analysis with SODAS. We give details for each of these steps and thereimportance is underlined. Two examples of results are described to show the analysis interestand pertinence. The conclusion describes perspectives after the improvement of SODAS forits application in the stock exchange domain.", "link": "http://arxiv.org/abs/2302.12070v1"}, {"index": 182, "title": "Factor Exposure Heterogeneity in Green and Brown Stocks", "abstract": "Using the peer-exposure ratio, we explore the factor exposure heterogeneity in green and brown stocks. By looking at peer groups of S&P 500 index firms over 2014-2020 based on their greenhouse gas emission levels, we find that, on average, green stocks exhibit less factor exposure heterogeneity than brown stocks for most of the traditional equity factors but the value factor. Hence, investment managers shifting their investments from brown stocks to green stocks have less room to differentiate themselves regarding their factor exposures. Finally, we find that factor exposure heterogeneity has increased for green stocks compared to earlier periods.", "link": "http://dx.doi.org/10.1016/j.frl.2023.103900"}, {"index": 183, "title": "Optimal investment with a noisy signal of future stock prices", "abstract": "We consider an investor who is dynamically informed about the future evolution of one of the independent Brownian motions driving a stock's price fluctuations. With linear temporary price impact the resulting optimal investment problem with exponential utility turns out to be not only well posed, but it even allows for a closed-form solution. We describe this solution and the resulting problem value for this stochastic control problem with partial observation by solving its convex-analytic dual problem.", "link": "http://arxiv.org/abs/2302.10485v2"}, {"index": 184, "title": "A Comparative Predicting Stock Prices using Heston and Geometric Brownian Motion Models", "abstract": "This paper presents a novel approach to predicting stock prices using technical analysis. By utilizing Ito's lemma and Euler-Maruyama methods, the researchers develop Heston and Geometric Brownian Motion models that take into account volatility, interest rate, and historical stock prices to generate predictions. The results of the study demonstrate that these models are effective in accurately predicting stock prices and outperform commonly used statistical indicators. The authors conclude that this technical analysis-based method offers a promising solution for stock market prediction.", "link": "http://arxiv.org/abs/2302.07796v1"}, {"index": 185, "title": "The Impact of Twitter Sentiments on Stock Market Trends", "abstract": "The Web is a vast virtual space where people can share their opinions, impacting all aspects of life and having implications for marketing and communication. The most up-to-date and comprehensive information can be found on social media because of how widespread and straightforward it is to post a message. Proportionately, they are regarded as a valuable resource for making precise market predictions. In particular, Twitter has developed into a potent tool for understanding user sentiment. This article examines how well tweets can influence stock symbol trends. We analyze the volume, sentiment, and mentions of the top five stock symbols in the S&P 500 index on Twitter over three months. Long Short-Term Memory, Bernoulli Na\\\"ive Bayes, and Random Forest were the three algorithms implemented in this process. Our study revealed a significant correlation between stock prices and Twitter sentiment.", "link": "http://arxiv.org/abs/2302.07244v1"}, {"index": 186, "title": "Control of Emerging-Market Target, Abnormal Stock Return: Evidence in Vietnam", "abstract": "Joining with the upward trend of Global Foreign direct investment and FDI in emerging economies and emerging Asian economies, FDI to Vietnam, especially M&As have increased significantly in both numbers and value of deals from 1995 to 2015...", "link": "http://arxiv.org/abs/2302.07117v2"}, {"index": 187, "title": "Modelling Illiquid Stocks Using Quantum Stochastic Calculus: Asymptotic Methods", "abstract": "This article investigates the Fokker-Planck equations that arise from the application of quantum stochastic calculus to the modelling of illiquid financial markets, using asymptotic methods. We present a power series solution for quantum stochastic processes with a non-zero conservation process. Whilst the series in question are in general divergent, we show they can be used to approximate solutions for longer time frames, and provide estimates for the relative error on the higher order terms.", "link": "http://arxiv.org/abs/2302.05256v1"}, {"index": 188, "title": "Modelling Illiquid Stocks Using Quantum Stochastic Calculus", "abstract": "Quantum Stochastic Calculus can be used as a means by which randomness can be introduced to observables acting on a Hilbert space. In this article we show how the mechanisms of Quantum Stochastic Calculus can be used to extend the classical Black-Scholes framework by incorporating a breakdown in the liquidity of a traded asset. This is captured via the widening of the bid offer spread, and the impact on the nature of the resulting probability distribution is modelled in this work.", "link": "http://arxiv.org/abs/2302.05243v1"}, {"index": 189, "title": "Order book regulatory impact on stock market quality: a multi-agent reinforcement learning perspective", "abstract": "Recent technological developments have changed the fundamental ways stock markets function, bringing regulatory instances to assess the benefits of these developments. In parallel, the ongoing machine learning revolution and its multiple applications to trading can now be used to design a next generation of financial models, and thereby explore the systemic complexity of financial stock markets in new ways. We here follow on a previous groundwork, where we designed and calibrated a novel agent-based model stock market simulator, where each agent autonomously learns to trade by reinforcement learning. In this Paper, we now study the predictions of this model from a regulator's perspective. In particular, we focus on how the market quality is impacted by smaller order book tick sizes, increasingly larger metaorders, and higher trading frequencies, respectively. Under our model assumptions, we find that the market quality benefits from the latter, but not from the other two trends.", "link": "http://arxiv.org/abs/2302.04184v1"}, {"index": 190, "title": "Market-Based Probability of Stock Returns", "abstract": "Markets possess all available information on stock returns. The randomness of market trade determines the statistics of stock returns. This paper describes the dependence of the first four market-based statistical moments of stock returns on statistical moments and correlations of current and past trade values. The mean return of trades during the averaging period coincides with Markowitz's definition of portfolio value weighted return. We derive the market-based volatility of return and return-value correlations. We present approximations of the characteristic functions and probability measures of stock return by a finite number of market-based statistical moments. To forecast market-based average return or volatility of return, one should predict the statistical moments and correlations of current and past market trade values at the same time horizon.", "link": "http://arxiv.org/abs/2302.07935v3"}, {"index": 191, "title": "Empirical analysis in limit order book modeling for Nikkei 225 Stocks with Cox-type intensities", "abstract": "In this paper, we build on the analysis of Muni Toke and Yoshida (2020) and conduct several empirical studies using high-frequency financial data. Muni Toke and Yoshida (2020) showed the consistency and asymptotic behavior of the Cox-type model estimators for relative intensities of orders in the limit order book, and then by using high-frequency trading data for 36 stocks traded on the Paris Stock Exchange, they carry out model selection and trading sign prediction. In this study, we add new covariates and carry out model selection and trading sign prediction using high-frequency trading data for 222 stocks traded on the Tokyo Stock Exchange. We not only show that the Cox-type model performs well in the Japanese market as well as in the Euronext Paris market, but also present the key factors for more accurate estimation. We also suggest how often the covariates should be calibrated.", "link": "http://arxiv.org/abs/2302.01668v2"}, {"index": 192, "title": "Detecting Pump&Dump Stock Market Manipulation from Online Forums", "abstract": "The intersection of social media, low-cost trading platforms, and naive investors has created an ideal situation for information-based market manipulations, especially pump&dumps. Manipulators accumulate small-cap stocks, disseminate false information on social media to inflate their price, and sell at the peak. We collect a dataset of stocks whose price and volume profiles have the characteristic shape of a pump&dump, and social media posts for those same stocks that match the timing of the initial price rises. From these we build predictive models for pump&dump events based on the language used in the social media posts.   There are multiple difficulties: not every post will cause the intended market reaction, some pump&dump events may be triggered by posts in other forums, and there may be accidental confluences of post timing and market movements. Nevertheless, our best model achieves a prediction accuracy of 85% and an F1-score of 62%. Such a tool can provide early warning to investors and regulators that a pump&dump may be underway.", "link": "http://arxiv.org/abs/2301.11403v1"}, {"index": 193, "title": "DSE Stock Price Prediction using Hidden Markov Model", "abstract": "Stock market forecasting is a classic problem that has been thoroughly investigated using machine learning and artificial neural network based tools and techniques. Interesting aspects of this problem include its time reliance as well as its volatility and other complex relationships. To combine them, hidden markov models (HMMs) have been utilized to anticipate the price of stocks. We demonstrated the Maximum A Posteriori (MAP) HMM method for predicting stock prices for the next day based on previous data. An HMM is trained by analyzing the fractional change in the stock price as well as the intraday high and low values. It is then utilized to produce a MAP estimate across all possible stock prices for the next day. The approach demonstrated in our work is quite generalized and can be used to predict the stock price for any company, given that the HMM is trained on the dataset of that company's stocks dataset. We evaluated the accuracy of our models using some extensively used accuracy metrics for regression problems and came up with a satisfactory outcome.", "link": "http://arxiv.org/abs/2302.08911v1"}, {"index": 194, "title": "Improved Stock Price Movement Classification Using News Articles Based on Embeddings and Label Smoothing", "abstract": "Stock price movement prediction is a challenging and essential problem in finance. While it is well established in modern behavioral finance that the share prices of related stocks often move after the release of news via reactions and overreactions of investors, how to capture the relationships between price movements and news articles via quantitative models is an active area research; existing models have achieved success with variable degrees. In this paper, we propose to improve stock price movement classification using news articles by incorporating regularization and optimization techniques from deep learning. More specifically, we capture the dependencies between news articles and stocks through embeddings and bidirectional recurrent neural networks as in recent models. We further incorporate weight decay, batch normalization, dropout, and label smoothing to improve the generalization of the trained models. To handle high fluctuations of validation accuracy of batch normalization, we propose dual-phase training to realize the improvements reliably. Our experimental results on a commonly used dataset show significant improvements, achieving average accuracy of 80.7% on the test set, which is more than 10.0% absolute improvement over existing models. Our ablation studies show batch normalization and label smoothing are most effective, leading to 6.0% and 3.4% absolute improvement, respectively on average.", "link": "http://arxiv.org/abs/2301.10458v1"}, {"index": 195, "title": "An Optimal Control Strategy for Execution of Large Stock Orders Using LSTMs", "abstract": "In this paper, we simulate the execution of a large stock order with real data and general power law in the Almgren and Chriss model. The example that we consider is the liquidation of a large position executed over the course of a single trading day in a limit order book. Transaction costs are incurred because large orders walk the order book, that is, they consume order book liquidity beyond the best bid/ask. We model the order book with a power law that is proportional to trading volume, and thus transaction costs are inversely proportional to a power of trading volume. We obtain a policy approximation by training a long short term memory (LSTM) neural network to minimize transaction costs accumulated when execution is carried out as a sequence of smaller suborders. Using historical S&P100 price and volume data, we evaluate our LSTM strategy relative to strategies based on time-weighted average price (TWAP) and volume-weighted average price (VWAP). For execution of a single stock, the input to the LSTM is the cross section of data on all 100 stocks, including prices, volumes, TWAPs and VWAPs. By using this data cross section, the LSTM should be able to exploit inter-stock co-dependence in volume and price movements, thereby reducing transaction costs for the day. Our tests on S&P100 data demonstrate that in fact this is so, as our LSTM strategy consistently outperforms TWAP and VWAP-based strategies.", "link": "http://arxiv.org/abs/2301.09705v4"}, {"index": 196, "title": "Sequential Graph Attention Learning for Predicting Dynamic Stock Trends (Student Abstract)", "abstract": "The stock market is characterized by a complex relationship between companies and the market. This study combines a sequential graph structure with attention mechanisms to learn global and local information within temporal time. Specifically, our proposed \"GAT-AGNN\" module compares model performance across multiple industries as well as within single industries. The results show that the proposed framework outperforms the state-of-the-art methods in predicting stock trends across multiple industries on Taiwan Stock datasets.", "link": "http://arxiv.org/abs/2301.10153v1"}, {"index": 197, "title": "Utilizing Technical Data to Discover Similar Companies in Dhaka Stock Exchange", "abstract": "Stock market investment have been an ideal form of investment for many years. Investing capitals smartly in stock market yields high profit returns. But there are many companies available in a market. Currently there are more than $345$ active companies who have stocks in Dhaka Stock Exchange (DSE). Analyzing all these companies is quite impossible. However, many companies tend to move together. This study aims at finding which companies in DSE have a close connection and move alongside each other. By analyzing this relation, the investors and traders will be able to analyze a lot of companies' statistics from a calculating just a handful number of companies. The conducted experiment yielded promising results. It was found that though the system was not given anything other than technical data, it was able to identify companies that show domain specific outcomes. In other words, a relation between technical data and fundamental data was discovered from the conducted experiment.", "link": "http://arxiv.org/abs/2301.04455v1"}, {"index": 198, "title": "Stock market forecasting using DRAGAN and feature matching", "abstract": "Applying machine learning methods to forecast stock prices has been one of the research topics of interest in recent years. Almost few studies have been reported based on generative adversarial networks (GANs) in this area, but their results are promising. GANs are powerful generative models successfully applied in different areas but suffer from inherent challenges such as training instability and mode collapse. Also, a primary concern is capturing correlations in stock prices. Therefore, our challenges fall into two main categories: capturing correlations and inherent problems of GANs. In this paper, we have introduced a novel framework based on DRAGAN and feature matching for stock price forecasting, which improves training stability and alleviates mode collapse. We have employed windowing to acquire temporal correlations by the generator. Also, we have exploited conditioning on discriminator inputs to capture temporal correlations and correlations between prices and features. Experimental results on data from several stocks indicate that our proposed method outperformed long short-term memory (LSTM) as a baseline method, also basic GANs and WGAN-GP as two different variants of GANs.", "link": "http://arxiv.org/abs/2301.05693v1"}, {"index": 199, "title": "Nowcasting Stock Implied Volatility with Twitter", "abstract": "In this study, we predict next-day movements of stock end-of-day implied volatility using random forests. Through an ablation study, we examine the usefulness of different sources of predictors and expose the value of attention and sentiment features extracted from Twitter. We study the approach on a stock universe comprised of the 165 most liquid US stocks diversified across the 11 traditional market sectors using a sizeable out-of-sample period spanning over six years. In doing so, we uncover that stocks in certain sectors, such as Consumer Discretionary, Technology, Real Estate, and Utilities are easier to predict than others. Further analysis shows that possible reasons for these discrepancies might be caused by either excess social media attention or low option liquidity. Lastly, we explore how our proposed approach fares throughout time by identifying four underlying market regimes in implied volatility using hidden Markov models. We find that most added value is achieved in regimes associated with lower implied volatility, but optimal regimes vary per market sector.", "link": "http://arxiv.org/abs/2301.00248v1"}, {"index": 200, "title": "Stock Market Prediction via Deep Learning Techniques: A Survey", "abstract": "Existing surveys on stock market prediction often focus on traditional machine learning methods instead of deep learning methods. This motivates us to provide a structured and comprehensive overview of the research on stock market prediction. We present four elaborated subtasks of stock market prediction and propose a novel taxonomy to summarize the state-of-the-art models based on deep neural networks. In addition, we also provide detailed statistics on the datasets and evaluation metrics commonly used in the stock market. Finally, we point out several future directions by sharing some new perspectives on stock market prediction.", "link": "http://arxiv.org/abs/2212.12717v2"}, {"index": 201, "title": "Emergent invariance and scaling properties in the collective return dynamics of a stock market", "abstract": "Several works have observed heavy-tailed behavior in the distributions of returns in different markets, which are observable indicators of underlying complex dynamics. Such prior works study return distributions that are marginalized across the individual stocks in the market, and do not track statistics about the joint distributions of returns conditioned on different stocks, which would be useful for optimizing inter-stock asset allocation strategies. As a step towards this goal, we study emergent phenomena in the distributions of returns as captured by their pairwise correlations. In particular, we consider the pairwise (between stocks $i,j$) partial correlations of returns with respect to the market mode, $c_{i,j}(\\tau)$, (thus, correcting for the baseline return behavior of the market), over different time horizons ($\\tau$), and discover two novel emergent phenomena: (i) the standardized distributions of the $c_{i,j}(\\tau)$'s are observed to be invariant of $\\tau$ ranging from from $1000 \\textrm{min}$ (2.5 days) to $30000 \\textrm{min}$ (2.5 months); (ii) the scaling of the standard deviation of $c_{i,j}(\\tau)$'s with $\\tau$ admits \\iffalse within this regime is empirically observed to \\fi good fits to simple model classes such as a power-law $\\tau^{-\\lambda}$ or stretched exponential function $e^{-\\tau^\\beta}$ ($\\lambda,\\beta > 0$). Moreover, the parameters governing these fits provide a summary view of market health: for instance, in years marked by unprecedented financial crises -- for example $2008$ and $2020$ -- values of $\\lambda$ (scaling exponent) are substantially lower. Finally, we demonstrate that the observed emergent behavior cannot be adequately supported by existing generative frameworks such as single- and multi-factor models. We introduce a promising agent-based Vicsek model that closes this gap.", "link": "http://arxiv.org/abs/2212.12703v4"}, {"index": 202, "title": "Multi-step-ahead Stock Price Prediction Using Recurrent Fuzzy Neural Network and Variational Mode Decomposition", "abstract": "Financial time series prediction, a growing research topic, has attracted considerable interest from scholars, and several approaches have been developed. Among them, decomposition-based methods have achieved promising results. Most decomposition-based methods approximate a single function, which is insufficient for obtaining accurate results. Moreover, most existing researches have concentrated on one-step-ahead forecasting that prevents stock market investors from arriving at the best decisions for the future. This study proposes two novel methods for multi-step-ahead stock price prediction based on the issues outlined. DCT-MFRFNN, a method based on discrete cosine transform (DCT) and multi-functional recurrent fuzzy neural network (MFRFNN), uses DCT to reduce fluctuations in the time series and simplify its structure and MFRFNN to predict the stock price. VMD-MFRFNN, an approach based on variational mode decomposition (VMD) and MFRFNN, brings together their advantages. VMD-MFRFNN consists of two phases. The input signal is decomposed to several IMFs using VMD in the decomposition phase. In the prediction and reconstruction phase, each of the IMFs is given to a separate MFRFNN for prediction, and predicted signals are summed to reconstruct the output. Three financial time series, including Hang Seng Index (HSI), Shanghai Stock Exchange (SSE), and Standard & Poor's 500 Index (SPX), are used for the evaluation of the proposed methods. Experimental results indicate that VMD-MFRFNN surpasses other state-of-the-art methods. VMD-MFRFNN, on average, shows 35.93%, 24.88%, and 34.59% decreases in RMSE from the second-best model for HSI, SSE, and SPX, respectively. Also, DCT-MFRFNN outperforms MFRFNN in all experiments.", "link": "http://arxiv.org/abs/2212.14687v1"}, {"index": 203, "title": "Cross-Domain Shopping and Stock Trend Analysis", "abstract": "This paper presents a cross-domain trend analysis that aims to identify and analyze the relationships between stock prices, stock news on Twitter, and users' behaviors on e-commerce websites. The analysis is based on three datasets: a US stock dataset, a stock tweets dataset, and an e-commerce behavior dataset. The analysis is performed using Hadoop, Hive, and Tableau, allowing for efficient and scalable processing and visualizing large datasets.   The analysis includes trend analysis of Twitter sentiment (positive and negative tweets) and correlation analysis, including the correlation between tweet sentiment and stocks, the correlation between stock trends and shopping behavior, and the understanding of data based on different slices of time. By comparing different features from the datasets over time, we hope to gain insight into the factors that drive user behavior as well as the market in different categories. The results of this analysis can provide valuable insights for businesses and investors to inform decision-making.   We believe that our analysis can serve as a valuable starting point for further research and investigation into these topics.", "link": "http://arxiv.org/abs/2212.14689v1"}, {"index": 204, "title": "Does Peer-Reviewed Research Help Predict Stock Returns?", "abstract": "Mining 29,000 accounting ratios for t-statistics over 2.0 leads to cross-sectional predictability similar to the peer review process. For both methods, about 50% of predictability remains after the original sample periods. Data mining generates other features of peer review including the rise in returns as original sample periods end, the speed of post-sample decay, and themes like investment, issuance, and accruals. Predictors supported by peer-reviewed risk explanations underperform data mining. Similarly, the relationship between modeling rigor and post-sample returns is negative. Our results suggest peer review systematically mislabels mispricing as risk, though only 18% of predictors are attributed to risk.", "link": "http://arxiv.org/abs/2212.10317v4"}, {"index": 205, "title": "Correlation matrix of equi-correlated normal population: fluctuation of the largest eigenvalue, scaling of the bulk eigenvalues, and stock market", "abstract": "Given an $N$-dimensional sample of size $T$ and form a sample correlation matrix $\\mathbf{C}$. Suppose that $N$ and $T$ tend to infinity with $T/N $ converging to a fixed finite constant $Q>0$. If the population is a factor model, then the eigenvalue distribution of $\\mathbf{C}$ almost surely converges weakly to Mar\\v{c}enko-Pastur distribution such that the index is $Q$ and the scale parameter is the limiting ratio of the specific variance to the $i$-th variable $(i\\to\\infty)$. For an $N$-dimensional normal population with equi-correlation coefficient $\\rho$, which is a one-factor model, for the largest eigenvalue $\\lambda$ of $\\mathbf{C}$, we prove that $\\lambda/N$ converges to the equi-correlation coefficient $\\rho$ almost surely. These results suggest an important role of an equi-correlated normal population and a factor model in (Laloux et al. Random matrix theory and financial correlations, Int. J. Theor. Appl. Finance, 2000): the histogram of the eigenvalue of sample correlation matrix of the returns of stock prices fits the density of Mar\\v{c}enko-Pastur distribution of index $T/N $ and scale parameter $1-\\lambda/N$. Moreover, we provide the limiting distribution of the largest eigenvalue of a sample covariance matrix of an equi-correlated normal population. We discuss the phase transition as to the decay rate of the equi-correlation coefficient in $N$.", "link": "http://arxiv.org/abs/2212.05504v3"}, {"index": 206, "title": "Time Series Analysis in American Stock Market Recovering in Post COVID-19 Pandemic Period", "abstract": "Every financial crisis has caused a dual shock to the global economy. The shortage of market liquidity, such as default in debt and bonds, has led to the spread of bankruptcies, such as Lehman Brothers in 2008. Using the data for the ETFs of the S&P 500, Nasdaq 100, and Dow Jones Industrial Average collected from Yahoo Finance, this study implemented Deep Learning, Neuro Network, and Time-series to analyze the trend of the American Stock Market in the post-COVID-19 period. LSTM model in Neuro Network to predict the future trend, which suggests the US stock market keeps falling for the post-COVID-19 period. This study reveals a reasonable allocation method of Long Short-Term Memory for which there is strong evidence.", "link": "http://arxiv.org/abs/2212.05369v1"}, {"index": 207, "title": "Understanding stock market instability via graph auto-encoders", "abstract": "Understanding stock market instability is a key question in financial management as practitioners seek to forecast breakdowns in asset co-movements which expose portfolios to rapid and devastating collapses in value. The structure of these co-movements can be described as a graph where companies are represented by nodes and edges capture correlations between their price movements. Learning a timely indicator of co-movement breakdowns (manifested as modifications in the graph structure) is central in understanding both financial stability and volatility forecasting. We propose to use the edge reconstruction accuracy of a graph auto-encoder (GAE) as an indicator for how spatially homogeneous connections between assets are, which, based on financial network literature, we use as a proxy to infer market volatility. Our experiments on the S&P 500 over the 2015-2022 period show that higher GAE reconstruction error values are correlated with higher volatility. We also show that out-of-sample autoregressive modeling of volatility is improved by the addition of the proposed measure. Our paper contributes to the literature of machine learning in finance particularly in the context of understanding stock market instability.", "link": "http://arxiv.org/abs/2212.04974v1"}, {"index": 208, "title": "Monetary Uncertainty as a Determinant of the Response of Stock Market to Macroeconomic News", "abstract": "This paper examines the effect of macroeconomic news announcements (MNA) on the stock market. Stocks exhibit a strong positive response to major MNA: 1 standard deviation of MNA surprise causes 11-25 bps higher returns. This response is highly time-varying and is weaker during periods of high monetary uncertainty. I decompose this response into cash flow and risk-free rate channels. 1 standard deviation of good MNA surprise leads to plus 30 bps returns from the cash flow channel and minus 23 bps per 1\\% of monetary uncertainty from the risk-free rate channel. Risk-free rate channel is time-varying and is stronger when monetary uncertainty is high. High levels of monetary uncertainty mask the strong positive response of stocks to MNA, which explains why past research failed to detect this relation.", "link": "http://arxiv.org/abs/2212.04525v1"}, {"index": 209, "title": "MTMD: Multi-Scale Temporal Memory Learning and Efficient Debiasing Framework for Stock Trend Forecasting", "abstract": "Recently, machine learning methods have shown the prospects of stock trend forecasting. However, the volatile and dynamic nature of the stock market makes it difficult to directly apply machine learning techniques. Previous methods usually use the temporal information of historical stock price patterns to predict future stock trends, but the multi-scale temporal dependence of financial data and stable trading opportunities are still difficult to capture. The main problem can be ascribed to the challenge of recognizing the patterns of real profit signals from noisy information. In this paper, we propose a framework called Multiscale Temporal Memory Learning and Efficient Debiasing (MTMD). Specifically, through self-similarity, we design a learnable embedding with external attention as memory block, in order to reduce the noise issues and enhance the temporal consistency of the model. This framework not only aggregates comprehensive local information in each timestamp, but also concentrates the global important historical patterns in the whole time stream. Meanwhile, we also design the graph network based on global and local information to adaptively fuse the heterogeneous multi-scale information. Extensive ablation studies and experiments demonstrate that MTMD outperforms the state-of-the-art approaches by a significant margin on the benchmark datasets. The source code of our proposed method is available at https://github.com/MingjieWang0606/MDMT-Public.", "link": "http://arxiv.org/abs/2212.08656v1"}, {"index": 210, "title": "A Novel Deep Reinforcement Learning Based Automated Stock Trading System Using Cascaded LSTM Networks", "abstract": "More and more stock trading strategies are constructed using deep reinforcement learning (DRL) algorithms, but DRL methods originally widely used in the gaming community are not directly adaptable to financial data with low signal-to-noise ratios and unevenness, and thus suffer from performance shortcomings. In this paper, to capture the hidden information, we propose a DRL based stock trading system using cascaded LSTM, which first uses LSTM to extract the time-series features from stock daily data, and then the features extracted are fed to the agent for training, while the strategy functions in reinforcement learning also use another LSTM for training. Experiments in DJI in the US market and SSE50 in the Chinese stock market show that our model outperforms previous baseline models in terms of cumulative returns and Sharp ratio, and this advantage is more significant in the Chinese stock market, a merging market. It indicates that our proposed method is a promising way to build a automated stock trading system.", "link": "http://arxiv.org/abs/2212.02721v2"}, {"index": 211, "title": "Novel Modelling Strategies for High-frequency Stock Trading Data", "abstract": "Full electronic automation in stock exchanges has recently become popular, generating high-frequency intraday data and motivating the development of near real-time price forecasting methods. Machine learning algorithms are widely applied to mid-price stock predictions. Processing raw data as inputs for prediction models (e.g., data thinning and feature engineering) can primarily affect the performance of the prediction methods. However, researchers rarely discuss this topic. This motivated us to propose three novel modelling strategies for processing raw data. We illustrate how our novel modelling strategies improve forecasting performance by analyzing high-frequency data of the Dow Jones 30 component stocks. In these experiments, our strategies often lead to statistically significant improvement in predictions. The three strategies improve the F1 scores of the SVM models by 0.056, 0.087, and 0.016, respectively.", "link": "http://dx.doi.org/10.1186/s40854-022-00431-9"}, {"index": 212, "title": "Text Representation Enrichment Utilizing Graph based Approaches: Stock Market Technical Analysis Case Study", "abstract": "Graph neural networks (GNNs) have been utilized for various natural language processing (NLP) tasks lately. The ability to encode corpus-wide features in graph representation made GNN models popular in various tasks such as document classification. One major shortcoming of such models is that they mainly work on homogeneous graphs, while representing text datasets as graphs requires several node types which leads to a heterogeneous schema. In this paper, we propose a transductive hybrid approach composed of an unsupervised node representation learning model followed by a node classification/edge prediction model. The proposed model is capable of processing heterogeneous graphs to produce unified node embeddings which are then utilized for node classification or link prediction as the downstream task. The proposed model is developed to classify stock market technical analysis reports, which to our knowledge is the first work in this domain. Experiments, which are carried away using a constructed dataset, demonstrate the ability of the model in embedding extraction and the downstream tasks.", "link": "http://arxiv.org/abs/2211.16103v1"}, {"index": 213, "title": "Optimizing Stock Option Forecasting with the Assembly of Machine Learning Models and Improved Trading Strategies", "abstract": "This paper introduced key aspects of applying Machine Learning (ML) models, improved trading strategies, and the Quasi-Reversibility Method (QRM) to optimize stock option forecasting and trading results. It presented the findings of the follow-up project of the research \"Application of Convolutional Neural Networks with Quasi-Reversibility Method Results for Option Forecasting\". First, the project included an application of Recurrent Neural Networks (RNN) and Long Short-Term Memory (LSTM) networks to provide a novel way of predicting stock option trends. Additionally, it examined the dependence of the ML models by evaluating the experimental method of combining multiple ML models to improve prediction results and decision-making. Lastly, two improved trading strategies and simulated investing results were presented. The Binomial Asset Pricing Model with discrete time stochastic process analysis and portfolio hedging was applied and suggested an optimized investment expectation. These results can be utilized in real-life trading strategies to optimize stock option investment results based on historical data.", "link": "http://arxiv.org/abs/2211.15912v1"}, {"index": 214, "title": "Option pricing under path-dependent stock models", "abstract": "This paper studies how to price and hedge options under stock models given as a path-dependent SDE solution. When the path-dependent SDE coefficients have Fr\\'{e}chet derivatives, an option price is differentiable with respect to time and the path, and is given as a solution to the path-dependent PDE. This can be regarded as a path-dependent version of the Feynman-Kac formula. As a byproduct, we obtain the differentiability of path-dependent SDE solutions and the SDE representation of their derivatives. In addition, we provide formulas for Greeks with path-dependent coefficient perturbations. A stock model having coefficients with time integration forms of paths is covered as an example.", "link": "http://arxiv.org/abs/2211.10953v2"}, {"index": 215, "title": "An investigation of open clusters Berkeley 68 and Stock 20 using CCD UBV and Gaia DR3 data", "abstract": "We performed detailed photometric and astrometric analyses of the open star clusters Berkeley 68 and Stock 20. This was based on ground-based CCD UBV photometric data complemented by space-based Gaia Data Release 3 photometry and astrometry. 198 stars were identified as likely cluster members for Berkeley 68 and 51 for Stock 20. Two-color diagrams were used to derive the reddening and photometric metallicity for each cluster. The reddening for Berkeley 68 is $E(B-V)=0.520 \\pm 0.032$ and $0.400 \\pm 0.048$ mag for Stock 20. Photometric metallicity [Fe/H] is $-0.13 \\pm 0.08$ dex for Berkeley 68, and $-0.01 \\pm 0.06$ dex for Stock 20. Keeping as constant reddening and metallicity, we determined the distance moduli and ages of the clusters through fitting isochrones to the UBV and Gaia based color-magnitude diagrams. Photometric distances are $d=3003 \\pm 165$ pc for Berkeley 69 and $2911 \\pm 216$ pc for Stock 20. The cluster ages are $2.4 \\pm 0.2$ Gyr and $50 \\pm 10$ Myr for Berkeley 68 and Stock 20, respectively. Present-day mass function slopes were found to be $\\Gamma = 1.38 \\pm 0.71$ and $\\Gamma = 1.53 \\pm 0.39$ for Berkeley 68 and Stock 20, respectively. These values are compatible with the value of Salpeter (1955). The relaxation times were estimated as 32.55 Myr and 23.17 Myr for Berkeley 68 and Stock 20, respectively. These times are less than the estimated cluster ages, indicating that both clusters are dynamically relaxed. Orbit integration was carried out only for Berkeley 68 since radial velocity data was not available for Stock 20. Analysis indicated that Berkeley 68 was born outside the solar circle and belongs to the thin-disc component of the Milky Way.", "link": "http://dx.doi.org/10.3847/1538-3881/aca6f0"}, {"index": 216, "title": "Designing Efficient Pair-Trading Strategies Using Cointegration for the Indian Stock Market", "abstract": "A pair-trading strategy is an approach that utilizes the fluctuations between prices of a pair of stocks in a short-term time frame, while in the long-term the pair may exhibit a strong association and co-movement pattern. When the prices of the stocks exhibit significant divergence, the shares of the stock that gains in price are sold (a short strategy) while the shares of the other stock whose price falls are bought (a long strategy). This paper presents a cointegration-based approach that identifies stocks listed in the five sectors of the National Stock Exchange (NSE) of India for designing efficient pair-trading portfolios. Based on the stock prices from Jan 1, 2018, to Dec 31, 2020, the cointegrated stocks are identified and the pairs are formed. The pair-trading portfolios are evaluated on their annual returns for the year 2021. The results show that the pairs of stocks from the auto and the realty sectors, in general, yielded the highest returns among the five sectors studied in the work. However, two among the five pairs from the information technology (IT) sector are found to have yielded negative returns.", "link": "http://dx.doi.org/10.1063/1.1395242"}, {"index": 217, "title": "FinBERT-LSTM: Deep Learning based stock price prediction using News Sentiment Analysis", "abstract": "Economy is severely dependent on the stock market. An uptrend usually corresponds to prosperity while a downtrend correlates to recession. Predicting the stock market has thus been a centre of research and experiment for a long time. Being able to predict short term movements in the market enables investors to reap greater returns on their investments. Stock prices are extremely volatile and sensitive to financial market. In this paper we use Deep Learning networks to predict stock prices, assimilating financial, business and technology news articles which present information about the market. First, we create a simple Multilayer Perceptron (MLP) network and then expand into more complex Recurrent Neural Network (RNN) like Long Short Term Memory (LSTM), and finally propose FinBERT-LSTM model, which integrates news article sentiments to predict stock price with greater accuracy by analysing short-term market information. We then train the model on NASDAQ-100 index stock data and New York Times news articles to evaluate the performance of MLP, LSTM, FinBERT-LSTM models using mean absolute error (MAE), mean absolute percentage error (MAPE) and accuracy metrics.", "link": "http://arxiv.org/abs/2211.07392v1"}, {"index": 218, "title": "A Bayesian approach for the modelling of material stocks and flows with incomplete data", "abstract": "Material Flow Analysis (MFA) is used to quantify and understand the life cycles of materials from production to end of use, which enables environmental, social and economic impacts and interventions. MFA is challenging as available data is often limited and uncertain, giving rise to an underdetermined system with an infinite number of solutions when attempting to calculate the values of all stocks and flows in the system. Bayesian statistics is an effective way to address these challenges as it rigorously quantifies uncertainty in the data and propagates it in a system flow model to provide the probabilities associated with model solutions. Furthermore, the Bayesian approach provides a natural way to incorporate useful domain knowledge about the system through the elicitation of the prior distribution.   This paper presents a novel Bayesian approach to MFA. We propose a mass based framework that directly models the flow and change in stock variables in the system, including systems with simultaneous presence of stocks and disaggregation of processes. The proposed approach is demonstrated on a global aluminium cycle, under a scenario where there is a shortage of data, coupled with weakly informative priors that only require basic information on flows and change in stocks. Bayesian model checking helps to identify inconsistencies in the data, and the posterior distribution is used to identify the variables in the system with the most uncertainty, which can aid data collection. We numerically investigate the properties of our method in simulations, and show that in limited data settings, the elicitation of an informative prior can greatly improve the performance of Bayesian methods, including for both estimation accuracy and uncertainty quantification.", "link": "http://arxiv.org/abs/2211.06178v1"}, {"index": 219, "title": "Efficient Integration of Multi-Order Dynamics and Internal Dynamics in Stock Movement Prediction", "abstract": "Advances in deep neural network (DNN) architectures have enabled new prediction techniques for stock market data. Unlike other multivariate time-series data, stock markets show two unique characteristics: (i) \\emph{multi-order dynamics}, as stock prices are affected by strong non-pairwise correlations (e.g., within the same industry); and (ii) \\emph{internal dynamics}, as each individual stock shows some particular behaviour. Recent DNN-based methods capture multi-order dynamics using hypergraphs, but rely on the Fourier basis in the convolution, which is both inefficient and ineffective. In addition, they largely ignore internal dynamics by adopting the same model for each stock, which implies a severe information loss.   In this paper, we propose a framework for stock movement prediction to overcome the above issues. Specifically, the framework includes temporal generative filters that implement a memory-based mechanism onto an LSTM network in an attempt to learn individual patterns per stock. Moreover, we employ hypergraph attentions to capture the non-pairwise correlations. Here, using the wavelet basis instead of the Fourier basis, enables us to simplify the message passing and focus on the localized convolution. Experiments with US market data over six years show that our framework outperforms state-of-the-art methods in terms of profit and stability. Our source code and data are available at \\url{https://github.com/thanhtrunghuynh93/estimate}.", "link": "http://arxiv.org/abs/2211.07400v2"}, {"index": 220, "title": "Variance of entropy for testing time-varying regimes with an application to meme stocks", "abstract": "Shannon entropy is the most common metric to measure the degree of randomness of time series in many fields, ranging from physics and finance to medicine and biology. Real-world systems may be in general non stationary, with an entropy value that is not constant in time. The goal of this paper is to propose a hypothesis testing procedure to test the null hypothesis of constant Shannon entropy for time series, against the alternative of a significant variation of the entropy between two subsequent periods. To this end, we find an unbiased approximation of the variance of the Shannon entropy's estimator, up to the order O(n^(-4)) with n the sample size. In order to characterize the variance of the estimator, we first obtain the explicit formulas of the central moments for both the binomial and the multinomial distributions, which describe the distribution of the Shannon entropy. Second, we find the optimal length of the rolling window used for estimating the time-varying Shannon entropy by optimizing a novel self-consistent criterion based on the counting of significant variations of entropy within a time window. We corroborate our findings by using the novel methodology to test for time-varying regimes of entropy for stock price dynamics, in particular considering the case of meme stocks in 2020 and 2021. We empirically show the existence of periods of market inefficiency for meme stocks. In particular, sharp increases of prices and trading volumes correspond to statistically significant drops of Shannon entropy.", "link": "http://arxiv.org/abs/2211.05415v3"}, {"index": 221, "title": "Liquidity Costs, Idiosyncratic Volatility and Expected Stock Returns", "abstract": "This paper considers liquidity as an explanation for the positive association between expected idiosyncratic volatility (IV) and expected stock returns. Liquidity costs may affect the stock returns, through bid-ask bounce and other microstructure-induced noise, which will affect the estimation of IV. We use a novel method (developed by Weaver, 1991) to eliminate microstructure influences from stock closing price-based returns and then estimate IV. We show that there is a premium for IV in value-weighted portfolios, but this premium is less strong after correcting returns for microstructure bias. We further show that this premium is driven by liquidity in the prior month after correcting returns for microstructure noise. The pricing results from equally-weighted portfolios indicate that IV does not predict returns either before or after controlling for liquidity costs. These findings are robust after controlling for common risk factors as well as analysing double-sorted portfolios based on IV and liquidity.", "link": "http://dx.doi.org/10.1016/j.irfa.2015.09.005"}, {"index": 222, "title": "A Categorical Framework for Modeling with Stock and Flow Diagrams", "abstract": "Stock and flow diagrams are already an important tool in epidemiology, but category theory lets us go further and treat these diagrams as mathematical entities in their own right. In this chapter we use communicable disease models created with our software, StockFlow.jl, to explain the benefits of the categorical approach. We first explain the category of stock-flow diagrams and note the clear separation between the syntax of these diagrams and their semantics, demonstrating three examples of semantics already implemented in the software: ODEs, causal loop diagrams, and system structure diagrams. We then turn to two methods for building large stock-flow diagrams from smaller ones in a modular fashion: composition and stratification. Finally, we introduce the open-source ModelCollab software for diagram-based collaborative modeling. The graphical user interface of this web-based software lets modelers take advantage of the ideas discussed here without any knowledge of their categorical foundations.", "link": "http://arxiv.org/abs/2211.01290v3"}, {"index": 223, "title": "Evaluating Impact of Social Media Posts by Executives on Stock Prices", "abstract": "Predicting stock market movements has always been of great interest to investors and an active area of research. Research has proven that popularity of products is highly influenced by what people talk about. Social media like Twitter, Reddit have become hotspots of such influences. This paper investigates the impact of social media posts on close price prediction of stocks using Twitter and Reddit posts. Our objective is to integrate sentiment of social media data with historical stock data and study its effect on closing prices using time series models. We carried out rigorous experiments and deep analysis using multiple deep learning based models on different datasets to study the influence of posts by executives and general people on the close price. Experimental results on multiple stocks (Apple and Tesla) and decentralised currencies (Bitcoin and Ethereum) consistently show improvements in prediction on including social media data and greater improvements on including executive posts.", "link": "http://dx.doi.org/10.1145/3574318.3574339"}, {"index": 224, "title": "Uncertainty Aware Trader-Company Method: Interpretable Stock Price Prediction Capturing Uncertainty", "abstract": "Machine learning is an increasingly popular tool with some success in predicting stock prices. One promising method is the Trader-Company~(TC) method, which takes into account the dynamism of the stock market and has both high predictive power and interpretability. Machine learning-based stock prediction methods including the TC method have been concentrating on point prediction. However, point prediction in the absence of uncertainty estimates lacks credibility quantification and raises concerns about safety. The challenge in this paper is to make an investment strategy that combines high predictive power and the ability to quantify uncertainty. We propose a novel approach called Uncertainty Aware Trader-Company Method~(UTC) method. The core idea of this approach is to combine the strengths of both frameworks by merging the TC method with the probabilistic modeling, which provides probabilistic predictions and uncertainty estimations. We expect this to retain the predictive power and interpretability of the TC method while capturing the uncertainty. We theoretically prove that the proposed method estimates the posterior variance and does not introduce additional biases from the original TC method. We conduct a comprehensive evaluation of our approach based on the synthetic and real market datasets. We confirm with synthetic data that the UTC method can detect situations where the uncertainty increases and the prediction is difficult. We also confirmed that the UTC method can detect abrupt changes in data generating distributions. We demonstrate with real market data that the UTC method can achieve higher returns and lower risks than baselines.", "link": "http://arxiv.org/abs/2210.17030v2"}, {"index": 225, "title": "Stock price reaction to power outages following extreme weather events: Evidence from Texas power outage", "abstract": "In this study, we evaluate the effects of natural disasters on the stock (market) values of firms located in the affected counties. We are able to measure the change in stock prices of the firms affected by the 2021 Texas winter storm. To measure the abnormal return due to the storm, we use four different benchmark models: (1) the market-adjusted model, (2) the market model, (3) the Fama-French three-factor model, and (4) the Fama French plus momentum model. These statistical models in finance characterize the normal risk-return trade-off.", "link": "http://arxiv.org/abs/2210.16905v1"}, {"index": 226, "title": "Monitoring the Dynamic Networks of Stock Returns", "abstract": "In this paper, we study the connection between the companies in the Swedish capital market. We consider 28 companies included in the determination of the market index OMX30. The network structure of the market is constructed using different methods to determine the distance between the companies. We use hierarchical clustering methods to find the relation among the companies in each window. Next, we obtain one-dimensional time series of the distances between the clustering trees that reflect the changes in the relationship between the companies in the market over time. The method of statistical process control, namely the Shewhart control chart, is applied to those time series to detect abnormal changes in the financial market.", "link": "http://arxiv.org/abs/2210.16679v1"}, {"index": 227, "title": "Intelligence and Global Bias in the Stock Market", "abstract": "Trade is one of the essential feature of human intelligence. The securities market is the ultimate expression of it. The fundamental indicators of stocks include information as well as the effects of noise and bias on the stock prices; however, identifying the effects of noise and bias is generally difficult. In this article, I present the true fundamentals hypothesis based on rational expectations and detect the global bias components from the actual fundamental indicators by using a log-normal distribution model based on the true fundamentals hypothesis. The analysis results show that biases generally exhibit the same characteristics, strongly supporting the true fundamentals hypothesis. Notably, the positive price-to-cash flows from the investing activities ratio is a proxy for the true fundamentals. Where do these biases come from? The answer is extremely simple: ``Cash is a fact, profit is an opinion.'' Namely, opinions of management and accounting are added to true fundamentals. As a result, Kesten process is realized and the Pareto distribution is to be obtained. This means that the market knows it and represents as a stable global bias in the stock market.", "link": "http://dx.doi.org/10.3934/DSFE.2023011"}, {"index": 228, "title": "Incorporating Interactive Facts for Stock Selection via Neural Recursive ODEs", "abstract": "Stock selection attempts to rank a list of stocks for optimizing investment decision making, aiming at minimizing investment risks while maximizing profit returns. Recently, researchers have developed various (recurrent) neural network-based methods to tackle this problem. Without exceptions, they primarily leverage historical market volatility to enhance the selection performance. However, these approaches greatly rely on discrete sampled market observations, which either fail to consider the uncertainty of stock fluctuations or predict continuous stock dynamics in the future. Besides, some studies have considered the explicit stock interdependence derived from multiple domains (e.g., industry and shareholder). Nevertheless, the implicit cross-dependencies among different domains are under-explored. To address such limitations, we present a novel stock selection solution -- StockODE, a latent variable model with Gaussian prior. Specifically, we devise a Movement Trend Correlation module to expose the time-varying relationships regarding stock movements. We design Neural Recursive Ordinary Differential Equation Networks (NRODEs) to capture the temporal evolution of stock volatility in a continuous dynamic manner. Moreover, we build a hierarchical hypergraph to incorporate the domain-aware dependencies among the stocks. Experiments conducted on two real-world stock market datasets demonstrate that StockODE significantly outperforms several baselines, such as up to 18.57% average improvement regarding Sharpe Ratio.", "link": "http://arxiv.org/abs/2210.15925v1"}, {"index": 229, "title": "Housing Forecasts via Stock Market Indicators", "abstract": "Through the reinterpretation of housing data as candlesticks, we extend Nature Scientific Reports' article by Liang and Unwin [LU22] on stock market indicators for COVID-19 data, and utilize some of the most prominent technical indicators from the stock market to estimate future changes in the housing market, comparing the findings to those one would obtain from studying real estate ETF's. By providing an analysis of MACD, RSI, and Candlestick indicators (Bullish Engulfing, Bearish Engulfing, Hanging Man, and Hammer), we exhibit their statistical significance in making predictions for USA data sets (using Zillow Housing data) and also consider their applications within three different scenarios: a stable housing market, a volatile housing market, and a saturated market. In particular, we show that bearish indicators have a much higher statistical significance then bullish indicators, and we further illustrate how in less stable or more populated countries, bearish trends are only slightly more statistically present compared to bullish trends.", "link": "http://arxiv.org/abs/2210.10146v1"}, {"index": 230, "title": "Sector-wise analysis of Indian stock market: Long and short-term risk and stability analysis", "abstract": "This paper, for the first time, focuses on the sector-wise analysis of a stock market through multifractal analysis. We have considered Bombay Stock Exchange, India, and identified two time scales, short ($<200$ days) and long time-scale ($>200$ days) for investment. We infer that long-term investment will be more profitable. For long time scale, sectors can be separated into two categories based on the Hurst exponent values; one corresponds to stable sectors with small fluctuations, and the other with dominance of large fluctuations leading to possible downturns in those sectors.", "link": "http://arxiv.org/abs/2210.09619v1"}, {"index": 231, "title": "Chemically Peculiar Stars in the Open Cluster Stock 2", "abstract": "The recently re-discovered open cluster Stock 2, located roughly 375 pc away and about 400 Myr old, has the potential to be an exciting new testbed for our understanding of stellar evolution. We present results from a spectroscopic campaign to characterize stars near the cluster's main-sequence turnoff; our goal is to identify candidate chemically peculiar stars among the cluster's A stars. We obtained echelle spectra for 64 cluster members with ESPaDOnS on the 3.6-m Canada-France-Hawaii Telescope, Mauna Kea Observatory, USA, and for six stars with SOPHIE on the 1.93-m telescope at the Observatoire de Haute-Provence, France. We complemented these new observations with those of 13 high-mass cluster members from the HARPS-N archive; our overall sample is of 71 stars. We derived the fundamental parameters (Teff, log g, [M/H]) as well as vsini for our sample using the Sliced Inverse Regression (SIR) technique, and then used iSpec to derive individual abundances of 12 chemical species. With these abundance determinations, we identified nine A stars with anomalous levels of Sc, Ca, and other metallic lines. Follow-up observations of these Am candidates with a known age can transform them into benchmarks for evolutionary models that include atomic diffusion and help build a better understanding of the complex interactions between macroscopic and microscopic processes in stellar interiors.", "link": "http://dx.doi.org/10.3847/1538-3881/ac9c56"}, {"index": 232, "title": "Stock Trading Volume Prediction with Dual-Process Meta-Learning", "abstract": "Volume prediction is one of the fundamental objectives in the Fintech area, which is helpful for many downstream tasks, e.g., algorithmic trading. Previous methods mostly learn a universal model for different stocks. However, this kind of practice omits the specific characteristics of individual stocks by applying the same set of parameters for different stocks. On the other hand, learning different models for each stock would face data sparsity or cold start problems for many stocks with small capitalization. To take advantage of the data scale and the various characteristics of individual stocks, we propose a dual-process meta-learning method that treats the prediction of each stock as one task under the meta-learning framework. Our method can model the common pattern behind different stocks with a meta-learner, while modeling the specific pattern for each stock across time spans with stock-dependent parameters. Furthermore, we propose to mine the pattern of each stock in the form of a latent variable which is then used for learning the parameters for the prediction module. This makes the prediction procedure aware of the data pattern. Extensive experiments on volume predictions show that our method can improve the performance of various baseline models. Further analyses testify the effectiveness of our proposed meta-learning framework.", "link": "http://arxiv.org/abs/2211.01762v1"}, {"index": 233, "title": "Design and Analysis of Optimized Portfolios for Selected Sectors of the Indian Stock Market", "abstract": "Portfolio optimization is a challenging problem that has attracted considerable attention and effort from researchers. The optimization of stock portfolios is a particularly hard problem since the stock prices are volatile and estimation of their future volatilities and values, in most cases, is very difficult, if not impossible. This work uses three ratios, the Sharpe ratio, the Sortino ratio, and the Calmar ratio, for designing the mean-variance optimized portfolios for six important sectors listed in the National Stock Exchange (NSE) of India. Three portfolios are designed for each sector maximizing the ratios based on the historical prices of the ten most important stocks of each sector from Jan 1, 2017, to Dec 31, 2020. The evaluation of the portfolios is done based on their cumulative returns over the test period from Jan 1, 2021, to Dec 31, 2021. The ratio that yields the maximum cumulative returns for both the training and the test periods for the majority of the sectors is identified. The sectors that exhibit the maximum cumulative returns for the same ratio are also identified. The results provide useful insights for investors in the stock market in making their investment decisions based on the current return and risks associated with the six sectors and their stocks.", "link": "http://dx.doi.org/10.1109/DASA54658.2022.9765289"}, {"index": 234, "title": "Stock Volatility Prediction using Time Series and Deep Learning Approach", "abstract": "Volatility clustering is a crucial property that has a substantial impact on stock market patterns. Nonetheless, developing robust models for accurately predicting future stock price volatility is a difficult research topic. For predicting the volatility of three equities listed on India's national stock market (NSE), we propose multiple volatility models depending on the generalized autoregressive conditional heteroscedasticity (GARCH), Glosten-Jagannathan-GARCH (GJR-GARCH), Exponential general autoregressive conditional heteroskedastic (EGARCH), and LSTM framework. Sector-wise stocks have been chosen in our study. The sectors which have been considered are banking, information technology (IT), and pharma. yahoo finance has been used to obtain stock price data from Jan 2017 to Dec 2021. Among the pulled-out records, the data from Jan 2017 to Dec 2020 have been taken for training, and data from 2021 have been chosen for testing our models. The performance of predicting the volatility of stocks of three sectors has been evaluated by implementing three different types of GARCH models as well as by the LSTM model are compared. It has been observed the LSTM performed better in predicting volatility in pharma over banking and IT sectors. In tandem, it was also observed that E-GARCH performed better in the case of the banking sector and for IT and pharma, GJR-GARCH performed better.", "link": "http://arxiv.org/abs/2210.02126v1"}, {"index": 235, "title": "A Comparative Study of Hierarchical Risk Parity Portfolio and Eigen Portfolio on the NIFTY 50 Stocks", "abstract": "Portfolio optimization has been an area of research that has attracted a lot of attention from researchers and financial analysts. Designing an optimum portfolio is a complex task since it not only involves accurate forecasting of future stock returns and risks but also needs to optimize them. This paper presents a systematic approach to portfolio optimization using two approaches, the hierarchical risk parity algorithm and the Eigen portfolio on seven sectors of the Indian stock market. The portfolios are built following the two approaches to historical stock prices from Jan 1, 2016, to Dec 31, 2020. The portfolio performances are evaluated on the test data from Jan 1, 2021, to Nov 1, 2021. The backtesting results of the portfolios indicate that the performance of the HRP portfolio is superior to that of its Eigen counterpart on both training and test data for the majority of the sectors studied.", "link": "http://dx.doi.org/10.1007/978-981-19-3391-2_34"}, {"index": 236, "title": "Sentiment Analysis of ESG disclosures on Stock Market", "abstract": "In this paper, we look at the impact of Environment, Social and Governance related news articles and social media data on the stock market performance. We pick four stocks of companies which are widely known in their domain to understand the complete effect of ESG as the newly opted investment style remains restricted to only the stocks with widespread information. We summarise live data of both twitter tweets and newspaper articles and create a sentiment index using a dictionary technique based on online information for the month of July, 2022. We look at the stock price data for all the four companies and calculate the percentage change in each of them. We also compare the overall sentiment of the company to its percentage change over a specific historical period.", "link": "http://arxiv.org/abs/2210.00731v1"}, {"index": 237, "title": "Decoupled algorithms for non-linearly coupled reaction-diffusion competition model with harvesting and Stocking", "abstract": "We propose, analyze and test two novel fully discrete decoupled linearized algorithms for a nonlinearly coupled reaction-diffusion $N$-species competition model with harvesting or stocking effort. The time-stepping algorithms are first and second order accurate in time and optimally accurate in space. Stability and optimal convergence theorems of the decoupled schemes are proven rigorously. We verify the predicted convergence rates of our analysis and efficacy of the algorithms using numerical experiments and synthetic data for analytical test problems. We also study the effect of harvesting or stocking and diffusion parameters on the evolution of species population density numerically, and observe the co-existence scenario subject to optimal harvesting or stocking.", "link": "http://arxiv.org/abs/2209.14144v1"}, {"index": 238, "title": "Multiclass Sentiment Prediction for Stock Trading", "abstract": "Python was used to download and format NewsAPI article data relating to 400 publicly traded, low cap. Biotech companies. Crowd-sourcing was used to label a subset of this data to then train and evaluate a variety of models to classify the public sentiment of each company. The best performing models were then used to show that trading entirely off public sentiment could provide market beating returns.", "link": "http://arxiv.org/abs/2210.00870v1"}, {"index": 239, "title": "Precision measurement of the return distribution property of the Chinese stock market index", "abstract": "This paper systematically conducts an analysis of the composite index 1-min datasets over the 17-year period (2005-2021) for both the Shanghai and Shenzhen stock exchanges. To reveal the difference between the Chinese and the mature stock markets, here we precisely measure the property of return distribution of composite index over the time scale $\\Delta t$ ranging from 1 min up to almost 4,000 min. The main findings are as follows. (1) Return distribution presents a leptokurtic, fat-tailed, and almost symmetrical shape, which is similar to that of mature markets. (2) The central part of return distribution is well described by the symmetrical L\\'{e}vy $\\alpha$-stable process with a stability parameter comparable with the value of about 1.4 extracted in the U.S. stock market. (3) Return distribution can be well described by the student's t-distribution within a wider return range than the L\\'{e}vy $\\alpha$-stable distribution. (4) Distinctively, the stability parameter shows a potential change when $\\Delta t$ increases, and thus a crossover region at 15 $< \\Delta t <$ 60 min is observed. This is different from the finding in the U.S. stock market where a single value of about 1.4 holds over 1 $\\le \\Delta t \\le$ 1,000 min. (5) The tail distribution of returns at small $\\Delta t$ decays as an asymptotic power-law with an exponent of about 3, which is a value widely existing in mature markets. However, it decays exponentially when $\\Delta t \\ge$ 240 min, which is not observed in mature markets. (6) Return distributions gradually converge to Gaussian as $\\Delta t$ increases. This observation is different from the finding of a critical $\\Delta t =$ 4 days in the U.S. stock market.", "link": "http://dx.doi.org/10.3390/e25010036"}, {"index": 240, "title": "Estimation of Average Derivatives of Latent Regressors: With an Application to Inference on Buffer-Stock Saving", "abstract": "This paper proposes a density-weighted average derivative estimator based on two noisy measures of a latent regressor. Both measures have classical errors with possibly asymmetric distributions. We show that the proposed estimator achieves the root-n rate of convergence, and derive its asymptotic normal distribution for statistical inference. Simulation studies demonstrate excellent small-sample performance supporting the root-n asymptotic normality. Based on the proposed estimator, we construct a formal test on the sub-unity of the marginal propensity to consume out of permanent income (MPCP) under a nonparametric consumption model and a permanent-transitory model of income dynamics with nonparametric distribution. Applying the test to four recent waves of U.S. Panel Study of Income Dynamics (PSID), we reject the null hypothesis of the unit MPCP in favor of a sub-unit MPCP, supporting the buffer-stock model of saving.", "link": "http://arxiv.org/abs/2209.05914v1"}, {"index": 241, "title": "A semi-Markovian approach to model the tick-by-tick dynamics of stock price", "abstract": "We model the stock price dynamics through a semi-Markov process obtained using a Poisson random measure. We establish the existence and uniqueness of the classical solution of a non-homogeneous terminal value problem and we show that the expected value of stock price at horizon can be obtained as a classical solution of a linear partial differential equation that is a special case of the terminal value problem studied in this paper. We further analyze the market making problem using the point of view of an agent who posts the limit orders at the best price available. We use the dynamic programming principle to obtain a HJB equation. In no-risk aversion case, we obtain the value function as a classical solution of a linear pde and derive the expressions for optimal controls by solving the HJB equation.", "link": "http://arxiv.org/abs/2209.04620v1"}, {"index": 242, "title": "Solving the Stock Option Forecast problem by a numerical method for the Black-Scholes Equation with Machine Learning Classification Model", "abstract": "We proposed classification models that utilize the result from the Quasi-Reversibility Method, which solves the Black-Scholes equation to forecast the option prices one day in advance. Combining the minimizer from QRM with our machine learning classifications, we can classify the option as an increase or decrease in value. Based on the different classifications of the options, we can apply various trading strategies which we aim to figure out ways to improve the results from QRM's extrapolations. To further test the viability of our model, we collected 23548 options data from the real-world market for our model, and we will then feed in the data along with the minimizer from QRM to form decision trees and random forests, which we will later test for accuracy, precision, and recall.", "link": "http://arxiv.org/abs/2209.03512v2"}, {"index": 243, "title": "Predict stock prices with ARIMA and LSTM", "abstract": "MAE, MSE and RMSE performance indicators are used to analyze the performance of different stocks predicted by LSTM and ARIMA models in this paper. 50 listed company stocks from finance.yahoo.com are selected as the research object in the experiments. The dataset used in this work consists of the highest price on transaction days, corresponding to the period from 01 January 2010 to 31 December 2018. For LSTM model, the data from 01 January 2010 to 31 December 2015 are selected as the training set, the data from 01 January 2016 to 31 December 2017 as the validation set and the data from 01 January 2018 to 31 December 2018 as the test set. In term of ARIMA model, the data from 01 January 2016 to 31 December 2017 are selected as the training set, and the data from 01 January 2018 to 31 December 2018 as the test set. For both models, 60 days of data are used to predict the next day. After analysis, it is suggested that both ARIMA and LSTM models can predict stock prices, and the prediction results are generally consistent with the actual results;and LSTM has better performance in predicting stock prices(especially in expressing stock price changes), while the application of ARIMA is more convenient.", "link": "http://arxiv.org/abs/2209.02407v1"}, {"index": 244, "title": "Stock Market Prediction using Natural Language Processing -- A Survey", "abstract": "The stock market is a network which provides a platform for almost all major economic transactions. While investing in the stock market is a good idea, investing in individual stocks may not be, especially for the casual investor. Smart stock-picking requires in-depth research and plenty of dedication. Predicting this stock value offers enormous arbitrage profit opportunities. This attractiveness of finding a solution has prompted researchers to find a way past problems like volatility, seasonality, and dependence on time. This paper surveys recent literature in the domain of natural language processing and machine learning techniques used to predict stock market movements. The main contributions of this paper include the sophisticated categorizations of many recent articles and the illustration of the recent trends of research in stock market prediction and its related areas.", "link": "http://arxiv.org/abs/2208.13564v1"}, {"index": 245, "title": "Pricing Stocks with Trading Volumes", "abstract": "The present paper proposes a new framework for describing the stock price dynamics. In the traditional geometric Brownian motion model and its variants, volatility plays a vital role. The modern studies of asset pricing expand around volatility, trying to improve the understanding of it and remove the gap between the theory and market data. Unlike this, we propose to replace volatility with trading volume in stock pricing models. This pricing strategy is based on two hypotheses: a price-volume relation with an idea borrowed from fluid flows and a white-noise hypothesis for the price rate of change (ROC) that is verified via statistic testing on actual market data. The new framework can be easily adopted to local volume and stochastic volume models for the option pricing problem, which will point out a new possible direction for this central problem in quantitative finance.", "link": "http://arxiv.org/abs/2208.12067v2"}, {"index": 246, "title": "Explainable Reinforcement Learning on Financial Stock Trading using SHAP", "abstract": "Explainable Artificial Intelligence (XAI) research gained prominence in recent years in response to the demand for greater transparency and trust in AI from the user communities. This is especially critical because AI is adopted in sensitive fields such as finance, medicine etc., where implications for society, ethics, and safety are immense. Following thorough systematic evaluations, work in XAI has primarily focused on Machine Learning (ML) for categorization, decision, or action. To the best of our knowledge, no work is reported that offers an Explainable Reinforcement Learning (XRL) method for trading financial stocks. In this paper, we proposed to employ SHapley Additive exPlanation (SHAP) on a popular deep reinforcement learning architecture viz., deep Q network (DQN) to explain an action of an agent at a given instance in financial stock trading. To demonstrate the effectiveness of our method, we tested it on two popular datasets namely, SENSEX and DJIA, and reported the results.", "link": "http://arxiv.org/abs/2208.08790v1"}, {"index": 247, "title": "Stock Prices as Janardan Galton Watson Process", "abstract": "Janardan (1980) introduces a class of offspring distributions that sandwich between Bernoulli and Poisson. This paper extends the Janardan Galton Watson (JGW) branching process as a model of stock prices. In this article, the return value over time t depends on the initial close price, which shows the number of offspring, has a role in the expectation of return and probability of extinction after the passage at time t. Suppose the number of offspring in t th generation is zero, (i.e., called extinction of model at time t) is equivalent with negative return values over time [0, t]. We also introduce the Algorithm that detecting the trend of stock markets.", "link": "http://arxiv.org/abs/2208.08496v1"}, {"index": 248, "title": "Transformer-Based Deep Learning Model for Stock Price Prediction: A Case Study on Bangladesh Stock Market", "abstract": "In modern capital market the price of a stock is often considered to be highly volatile and unpredictable because of various social, financial, political and other dynamic factors. With calculated and thoughtful investment, stock market can ensure a handsome profit with minimal capital investment, while incorrect prediction can easily bring catastrophic financial loss to the investors. This paper introduces the application of a recently introduced machine learning model - the Transformer model, to predict the future price of stocks of Dhaka Stock Exchange (DSE), the leading stock exchange in Bangladesh. The transformer model has been widely leveraged for natural language processing and computer vision tasks, but, to the best of our knowledge, has never been used for stock price prediction task at DSE. Recently the introduction of time2vec encoding to represent the time series features has made it possible to employ the transformer model for the stock price prediction. This paper concentrates on the application of transformer-based model to predict the price movement of eight specific stocks listed in DSE based on their historical daily and weekly data. Our experiments demonstrate promising results and acceptable root mean squared error on most of the stocks.", "link": "http://dx.doi.org/10.1142/S146902682350013X"}, {"index": 249, "title": "New drugs and stock market: how to predict pharma market reaction to clinical trial announcements", "abstract": "Pharmaceutical companies operate in a strictly regulated and highly risky environment in which a single slip can lead to serious financial implications. Accordingly, the announcements of clinical trial results tend to determine the future course of events, hence being closely monitored by the public. In this work, we provide statistical evidence for the result promulgation influence on the public pharma market value. Whereas most works focus on retrospective impact analysis, the present research aims to predict the numerical values of announcement-induced changes in stock prices. For this purpose, we develop a pipeline that includes a BERT-based model for extracting sentiment polarity of announcements, a Temporal Fusion Transformer for forecasting the expected return, a graph convolution network for capturing event relationships, and gradient boosting for predicting the price change. The challenge of the problem lies in inherently different patterns of responses to positive and negative announcements, reflected in a stronger and more pronounced reaction to the negative news. Moreover, such phenomenon as the drop in stocks after the positive announcements affirms the counterintuitiveness of the price behavior. Importantly, we discover two crucial factors that should be considered while working within a predictive framework. The first factor is the drug portfolio size of the company, indicating the greater susceptibility to an announcement in the case of small drug diversification. The second one is the network effect of the events related to the same company or nosology. All findings and insights are gained on the basis of one of the biggest FDA (the Food and Drug Administration) announcement datasets, consisting of 5436 clinical trial announcements from 681 companies over the last five years.", "link": "http://arxiv.org/abs/2208.07248v2"}, {"index": 250, "title": "Recurrence measures and transitions in stock market dynamics", "abstract": "The financial markets are understood as complex dynamical systems whose dynamics is analysed mostly using nonstationary and brief data sets that usually come from stock markets. For such data sets, a reliable method of analysis is based on recurrence plots and recurrence networks, constructed from the data sets over the period of study. In this study, we do a comprehensive analysis of the complexity of the underlying dynamics of 26 markets around the globe using recurrence based measures. We also examine trends in the nature of transitions as revealed from these measures by the sliding window analysis along the time series during the global financial crisis of 2008 and compare that with changes during the most recent pandemic related lock down. We show that the measures derived from recurrence patterns can be used to capture the nature of transitions in stock market dynamics. Our study reveals that the changes around 2008 indicate stochasticity driven transition, which is different from the transition during the pandemic.", "link": "http://dx.doi.org/10.1016/j.physa.2022.128240"}, {"index": 251, "title": "A data-driven approach for modeling the behavior of stock prices", "abstract": "In this paper, we describe two approaches to model the behavior of stock prices. The first approach considers the underlying probability distribution of day-to-day price differences. The second approach models the movement of the price as a stochastic birth-death process. We demonstrated the two approaches using historical opening prices of Apple inc. and compared the simulated prices from the two approaches to the actual ones using information theory metrics.", "link": "http://arxiv.org/abs/2208.02949v1"}, {"index": 252, "title": "Distributional Correlation--Aware Knowledge Distillation for Stock Trading Volume Prediction", "abstract": "Traditional knowledge distillation in classification problems transfers the knowledge via class correlations in the soft label produced by teacher models, which are not available in regression problems like stock trading volume prediction. To remedy this, we present a novel distillation framework for training a light-weight student model to perform trading volume prediction given historical transaction data. Specifically, we turn the regression model into a probabilistic forecasting model, by training models to predict a Gaussian distribution to which the trading volume belongs. The student model can thus learn from the teacher at a more informative distributional level, by matching its predicted distributions to that of the teacher. Two correlational distillation objectives are further introduced to encourage the student to produce consistent pair-wise relationships with the teacher model. We evaluate the framework on a real-world stock volume dataset with two different time window settings. Experiments demonstrate that our framework is superior to strong baseline models, compressing the model size by $5\\times$ while maintaining $99.6\\%$ prediction accuracy. The extensive analysis further reveals that our framework is more effective than vanilla distillation methods under low-resource scenarios.", "link": "http://arxiv.org/abs/2208.07232v1"}, {"index": 253, "title": "Advantages in Using a Stock Spring Selection Tool that Manages the Uncertainty of the Designer Requirements", "abstract": "This paper analyses the advantages of using a stock spring selection tool that manages the uncertainty of designer requirements. Firstly, the manual search and its main drawbacks are described. Then a computer assisted stock spring selection tool is presented which performs all necessary calculations to extract the most suitable spring from within a database. The algorithm analyses data set with interval values using both multi-criteria analysis and fuzzy logic. Two examples, comparing manual and assisted search, are presented. They show not only that the results are significantly better using the assisted search but it helps designers to detail easily and precisely their specifications and thus increase design process flexibility.", "link": "http://dx.doi.org/10.1007/978-1-4471-0519-0_6"}, {"index": 254, "title": "The Impact of Retail Investors Sentiment on Conditional Volatility of Stocks and Bonds", "abstract": "We measure bond and stock conditional return volatility as a function of changes in sentiment, proxied by six indicators from the Tel Aviv Stock Exchange. We find that changes in sentiment affect conditional volatilities at different magnitudes and often in an opposite manner in the two markets, subject to market states. We are the first to measure bonds conditional volatility of retail investors sentiment thanks to a unique dataset of corporate bond returns from a limit-order-book with highly active retail traders. This market structure differs from the prevalent OTC platforms, where institutional investors are active yet less prone to sentiment.", "link": "http://arxiv.org/abs/2208.01538v1"}, {"index": 255, "title": "A penalized two-pass regression to predict stock returns with time-varying risk premia", "abstract": "We develop a penalized two-pass regression with time-varying factor loadings. The penalization in the first pass enforces sparsity for the time-variation drivers while also maintaining compatibility with the no-arbitrage restrictions by regularizing appropriate groups of coefficients. The second pass delivers risk premia estimates to predict equity excess returns. Our Monte Carlo results and our empirical results on a large cross-sectional data set of US individual stocks show that penalization without grouping can yield to nearly all estimated time-varying models violating the no-arbitrage restrictions. Moreover, our results demonstrate that the proposed method reduces the prediction errors compared to a penalized approach without appropriate grouping or a time-invariant factor model.", "link": "http://arxiv.org/abs/2208.00972v1"}, {"index": 256, "title": "Change point detection in dynamic Gaussian graphical models: the impact of COVID-19 pandemic on the US stock market", "abstract": "Reliable estimates of volatility and correlation are fundamental in economics and finance for understanding the impact of macroeconomics events on the market and guiding future investments and policies. Dependence across financial returns is likely to be subject to sudden structural changes, especially in correspondence with major global events, such as the COVID-19 pandemic. In this work, we are interested in capturing abrupt changes over time in the dependence across US industry stock portfolios, over a time horizon that covers the COVID-19 pandemic. The selected stocks give a comprehensive picture of the US stock market. To this end, we develop a Bayesian multivariate stochastic volatility model based on a time-varying sequence of graphs capturing the evolution of the dependence structure. The model builds on the Gaussian graphical models and the random change points literature. In particular, we treat the number, the position of change points, and the graphs as object of posterior inference, allowing for sparsity in graph recovery and change point detection. The high dimension of the parameter space poses complex computational challenges. However, the model admits a hidden Markov model formulation. This leads to the development of an efficient computational strategy, based on a combination of sequential Monte-Carlo and Markov chain Monte-Carlo techniques. Model and computational development are widely applicable, beyond the scope of the application of interest in this work.", "link": "http://arxiv.org/abs/2208.00952v3"}, {"index": 257, "title": "How Covid mobility restrictions modified the population of investors in Italian stock markets", "abstract": "This paper investigates how Covid mobility restrictions impacted the population of investors of the Italian stock market. The analysis tracks the trading activity of individual investors in Italian stocks in the period January 2019-September 2021, investigating how their composition and the trading activity changed around the Covid-19 lockdown period (March 9 - May 19, 2020) and more generally in the period of the pandemic. The results pinpoint that the lockdown restriction was accompanied by a surge in interest toward stock market, as testified by the trading volume by households. Given the generically falling prices during the lockdown, the households, which are typically contrarian, were net buyers, even if less than expected from their trading activity in 2019. This can be explained by the arrival, during the lockdown, of a group of about 185k new investors (i.e. which had never traded since January 2019) which were on average ten year younger and with a larger fraction of males than the pre-lockdown investors. By looking at the gross P&L, there is clear evidence that these new investors were more skilled in trading. There are thus indications that the lockdown, and more generally the Covid pandemic, created a sort of regime change in the population of financial investors.", "link": "http://arxiv.org/abs/2208.00181v1"}, {"index": 258, "title": "Augmented Bilinear Network for Incremental Multi-Stock Time-Series Classification", "abstract": "Deep Learning models have become dominant in tackling financial time-series analysis problems, overturning conventional machine learning and statistical methods. Most often, a model trained for one market or security cannot be directly applied to another market or security due to differences inherent in the market conditions. In addition, as the market evolves through time, it is necessary to update the existing models or train new ones when new data is made available. This scenario, which is inherent in most financial forecasting applications, naturally raises the following research question: How to efficiently adapt a pre-trained model to a new set of data while retaining performance on the old data, especially when the old data is not accessible? In this paper, we propose a method to efficiently retain the knowledge available in a neural network pre-trained on a set of securities and adapt it to achieve high performance in new ones. In our method, the prior knowledge encoded in a pre-trained neural network is maintained by keeping existing connections fixed, and this knowledge is adjusted for the new securities by a set of augmented connections, which are optimized using the new data. The auxiliary connections are constrained to be of low rank. This not only allows us to rapidly optimize for the new task but also reduces the storage and run-time complexity during the deployment phase. The efficiency of our approach is empirically validated in the stock mid-price movement prediction problem using a large-scale limit order book dataset. Experimental results show that our approach enhances prediction performance as well as reduces the overall number of network parameters.", "link": "http://arxiv.org/abs/2207.11577v1"}, {"index": 259, "title": "A Study on Impact of Downsizing on Profitability of Construction Industries listed in Bombay Stock Exchange (BSE) India", "abstract": "The study investigates the impact of downsizing layoffs on the profitability of construction industries listed in BSE India. In India, construction industries have adopted downsizing long back in the organization to improve the firms performance. For the purpose of the study, Secondary data of 15 Construction companies listed in BSE India have been considered for a period of 10 years from FY.2010 to FY2019. Data has been taken from the companys official website. The variable considered for the analysis is Other Expenses, Returns on Net Worth, Employee Expenses, Number of Employees, and Profit Per Employee. The study has used the Co-integration test to see co-integration between the variables, Ordinary Least Square (OLS) and Vector Auto Regression (VAR) the model used for estimating the impact of downsizing on the profitability of construction companies. OLS and VAR model has been used to draw a conclusion based on the P values and R square. From the result, it can be concluded that, Expect Profit Per Employees are the downsizing variable that has no significant impact on the profitability of the firms performance. Whereas the other Downsizing variables Employee Expenses and the Number of Employee has a significant impact on the profitability of the firms performance", "link": "http://arxiv.org/abs/2207.11546v1"}, {"index": 260, "title": "Efficiency of the Moscow Stock Exchange before 2022", "abstract": "This paper investigates the degree of efficiency for the Moscow Stock Exchange. A market is called efficient if prices of its assets fully reflect all available information. We show that the degree of market efficiency is significantly low for most of the months from 2012 to 2021. We calculate the degree of market efficiency by (i) filtering out regularities in financial data and (ii) computing the Shannon entropy of the filtered return time series. We have developed a simple method for estimating volatility and price staleness in empirical data, in order to filter out such regularity patterns from return time series. The resulting financial time series of stocks' returns are then clustered into different groups according to some entropy measures. In particular, we use the Kullback-Leibler distance and a novel entropy metric capturing the co-movements between pairs of stocks. By using Monte Carlo simulations, we are then able to identify the time periods of market inefficiency for a group of 18 stocks. The inefficiency of the Moscow Stock Exchange that we have detected is a signal of the possibility of devising profitable strategies, net of transaction costs. The deviation from the efficient behavior for a stock strongly depends on the industrial sector it belongs.", "link": "http://dx.doi.org/10.3390/e24091184"}, {"index": 261, "title": "Using the Newton-Raphson Method with Automatic Differentiation to Numerically Solve Implied Volatility of Stock Option through Binomial Model", "abstract": "In the paper written by Klibanov et al, it proposes a novel method to calculate implied volatility of a European stock options as a solution to ill-posed inverse problem for the Black-Scholes equation. In addition, it proposes a trading strategy based on the difference between implied volatility of the option and the volatility of the underlying stock. In addition to the Black-Scholes equation, Binomial model is another method used to price European options. And, the implied volatility can be also calculated through this model. In this paper, we apply the Newton-Raphson method together with Automatic Differention to numerically approximate the implied volatility of an arbitrary stock option through this model. We provide an explanation of the mathematical model and methods, the methodology, and the results from our test using the stimulated data from the Geometric Brownian Motion Model and the Binomial Model itself, and the data from the US market data from 2018 to 2021.", "link": "http://arxiv.org/abs/2207.09033v2"}, {"index": 262, "title": "Learning Embedded Representation of the Stock Correlation Matrix using Graph Machine Learning", "abstract": "Understanding non-linear relationships among financial instruments has various applications in investment processes ranging from risk management, portfolio construction and trading strategies. Here, we focus on interconnectedness among stocks based on their correlation matrix which we represent as a network with the nodes representing individual stocks and the weighted links between pairs of nodes representing the corresponding pair-wise correlation coefficients. The traditional network science techniques, which are extensively utilized in financial literature, require handcrafted features such as centrality measures to understand such correlation networks. However, manually enlisting all such handcrafted features may quickly turn out to be a daunting task. Instead, we propose a new approach for studying nuances and relationships within the correlation network in an algorithmic way using a graph machine learning algorithm called Node2Vec. In particular, the algorithm compresses the network into a lower dimensional continuous space, called an embedding, where pairs of nodes that are identified as similar by the algorithm are placed closer to each other. By using log returns of S&P 500 stock data, we show that our proposed algorithm can learn such an embedding from its correlation network. We define various domain specific quantitative (and objective) and qualitative metrics that are inspired by metrics used in the field of Natural Language Processing (NLP) to evaluate the embeddings in order to identify the optimal one. Further, we discuss various applications of the embeddings in investment management.", "link": "http://arxiv.org/abs/2207.07183v1"}, {"index": 263, "title": "Effect of Demonetisation of on Indian High Denomination Currencies on Indian Stock Market and its Relationship with Foreign Exchange Rate", "abstract": "This study examines the impact of the foreign exchange rate, i.e., US Dollar to Indian Rupee (USD/INR) on the Indian Stock Market Index (Nifty 50) during the demonetization of high denomination Indian currencies. A daily rate of return of Foreign exchange rate (USD/INR) and the Indian Stock Market Index (Nifty 50) were considered for the study. The Dummy variable was used to measure the effect of demonetization during Nov/Dec 2016. The period of study was restricted to 243 days from 1st April 2016 to 31st March 2017. The study reveals that there was an upward trend observed in the Indian Stock Market and the Indian currency was strengthened with the decrease in the Foreign exchange rate (USD/INR).", "link": "http://dx.doi.org/10.36478/ibm.2018.205.211"}, {"index": 264, "title": "StockBot: Using LSTMs to Predict Stock Prices", "abstract": "The evaluation of the financial markets to predict their behaviour have been attempted using a number of approaches, to make smart and profitable investment decisions. Owing to the highly non-linear trends and inter-dependencies, it is often difficult to develop a statistical approach that elucidates the market behaviour entirely. To this end, we present a long-short term memory (LSTM) based model that leverages the sequential structure of the time-series data to provide an accurate market forecast. We then develop a decision making StockBot that buys/sells stocks at the end of the day with the goal of maximizing profits. We successfully demonstrate an accurate prediction model, as a result of which our StockBot can outpace the market and can strategize for gains that are ~15 times higher than the most aggressive ETFs in the market.", "link": "http://arxiv.org/abs/2207.06605v2"}, {"index": 265, "title": "Variations on two-parameter families of forecasting functions: seasonal/nonseasonal Models, comparison to the exponential smoothing and ARIMA models, and applications to stock market data", "abstract": "We introduce twenty four two-parameter families of advanced time series forecasting functions using a new and nonparametric approach. We also introduce the concept of powering and derive nonseasonal and seasonal models with examples in education, sales, finance and economy. We compare the performance of our twenty four models to both Holt--Winters and ARIMA models for both nonseasonal and seasonal times series. We show in particular that our models not only do not require a decomposition of a seasonal time series into trend, seasonal and random components, but leads also to substantially lower sum of absolute error and a higher number of closer forecasts than both Holt--Winters and ARIMA models. Finally, we apply and compare the performance of our twenty four models using five-year stock market data of 467 companies of the S&P500.", "link": "http://arxiv.org/abs/2207.04882v2"}, {"index": 266, "title": "Deep Reinforcement Learning Approach for Trading Automation in The Stock Market", "abstract": "Deep Reinforcement Learning (DRL) algorithms can scale to previously intractable problems. The automation of profit generation in the stock market is possible using DRL, by combining the financial assets price \"prediction\" step and the \"allocation\" step of the portfolio in one unified process to produce fully autonomous systems capable of interacting with their environment to make optimal decisions through trial and error. This work represents a DRL model to generate profitable trades in the stock market, effectively overcoming the limitations of supervised learning approaches. We formulate the trading problem as a Partially Observed Markov Decision Process (POMDP) model, considering the constraints imposed by the stock market, such as liquidity and transaction costs. We then solve the formulated POMDP problem using the Twin Delayed Deep Deterministic Policy Gradient (TD3) algorithm reporting a 2.68 Sharpe Ratio on unseen data set (test data). From the point of view of stock market forecasting and the intelligent decision-making mechanism, this paper demonstrates the superiority of DRL in financial markets over other types of machine learning and proves its credibility and advantages of strategic decision-making.", "link": "http://dx.doi.org/10.1109/ACCESS.2022.3203697"}, {"index": 267, "title": "A Study on the Impact of Human Resource Accounting on Firms Value with Respect to Companies Listed in National Stock Exchange", "abstract": "The study focuses on the Impact of Employment Benefit Cots on the Profitability of Companies listed in the National Stock Exchange. The study has considered the Amount spent on Employment Benefit Cots as an Independent variable and Profit after tax, Total Assets, Return on Equity, and Return on Asset and Debt equity Ration as the Dependent variable. The present study is to analyses the relationship between Employment Benefit Cots and Profit after tax, Total Assets, Return on Equity, Return on Asset, and Debt equity Ration. The data is collected from 20 companies listed on the National Stock Exchange for 10 years from the Annual reports of companies. The data collected were analyzed using Panel data Regression in E-Views. Results revealed that there is a significant Relationship between Employment Benefit Cots and Profit after tax, Total Assets, Return on Equity, Return on Asset, and Debt equity Ration. The study shows that Employment Benefit Cots impact positively on Firms profitability.", "link": "http://dx.doi.org/10.37896/BMJ21.09/2962"}, {"index": 268, "title": "A Study on Impact of Capital Structure on Profitability of Companies Listed in Indian Stock Exchange with respect to Automobile Industry", "abstract": "Current research helps in understanding both positive and negative impacts of capital structure on profits of Indian automobile companies by using variables like Return on Capital Employed, Return on Long Term Funds, Return on Net Worth, Gross Profit Margin, and Operating Profit, and Return on Asset. The study hypothesized that RoCE, RoLT, and RoNW have a positive effect and GP, OP and ROA have a negative impact on debt-equity and interest coverage ratios i.e capital structure of the companies. Also, the study proves that the relationship between profitability and capital structure variables is strongly significant. The hypothesis was tested by using fixed effect and random effect models by considering 10 years of data (from 2010-2019) from 17 automobile companies. The result of the study recommends that the firms can improve their performance by using an optimal capital structure. Also, a fair mix of debt and equity should be established to ensure that the firm maintains capital adequacy. Firms can thus be able to meet their financial compulsions and investments that can promise attractive returns.", "link": "http://arxiv.org/abs/2207.00720v1"}, {"index": 269, "title": "A Study on Impact of Environmental Accounting on Profitability of Companies listed in Bombay Stock Exchange", "abstract": "The study focuses on the Impact of Environmental Accounting on the Profitability of Companies listed on the Bombay Stock Exchange. The study has considered the Amount spent on Environmental protection as an Independent variable and Return on Capital Employed, Return on Assets, Return on Net worth/equity, Net Profit Margin, and Dividend per Share as the Dependent variable. The present study is to analyses the relationship between Amounts spent on Environmental protection costs and Return on Capital Employed, Return on Assets, Return on Net worth/equity, Net Profit Margin, and Dividend per Share. The data is collected from 18 companies listed on the Bombay Stock Exchange for 10 years from the Annual reports of companies. The data collected were analysed using Panel data Regression in E-Views. Results revealed that there is a significant Relationship between Environmental protection Cost and Return on Capital Employed, Return on Assets, Return on Net worth/equity, Net Profit Margin, and Dividend per Share. The study shows that Environmental accounting impact positively on Firms profitability.", "link": "http://dx.doi.org/10.37896/BMJ21.08/2905"}, {"index": 270, "title": "Stock Performance Evaluation for Portfolio Design from Different Sectors of the Indian Stock Market", "abstract": "The stock market offers a platform where people buy and sell shares of publicly listed companies. Generally, stock prices are quite volatile; hence predicting them is a daunting task. There is still much research going to develop more accuracy in stock price prediction. Portfolio construction refers to the allocation of different sector stocks optimally to achieve a maximum return by taking a minimum risk. A good portfolio can help investors earn maximum profit by taking a minimum risk. Beginning with Dow Jones Theory a lot of advancement has happened in the area of building efficient portfolios. In this project, we have tried to predict the future value of a few stocks from six important sectors of the Indian economy and also built a portfolio. As part of the project, our team has conducted a study of the performance of various Time series, machine learning, and deep learning models in stock price prediction on selected stocks from the chosen six important sectors of the economy. As part of building an efficient portfolio, we have studied multiple portfolio optimization theories beginning with the Modern Portfolio theory. We have built a minimum variance portfolio and optimal risk portfolio for all the six chosen sectors by using the daily stock prices over the past five years as training data and have also conducted back testing to check the performance of the portfolio. We look forward to continuing our study in the area of stock price prediction and asset allocation and consider this project as the first stepping stone.", "link": "http://arxiv.org/abs/2208.07166v1"}, {"index": 271, "title": "Deep Multiple Instance Learning For Forecasting Stock Trends Using Financial News", "abstract": "A major source of information can be taken from financial news articles, which have some correlations about the fluctuation of stock trends. In this paper, we investigate the influences of financial news on the stock trends, from a multi-instance view. The intuition behind this is based on the news uncertainty of varying intervals of news occurrences and the lack of annotation in every single financial news. Under the scenario of Multiple Instance Learning (MIL) where training instances are arranged in bags, and a label is assigned for the entire bag instead of instances, we develop a flexible and adaptive multi-instance learning model and evaluate its ability in directional movement forecast of Standard & Poors 500 index on financial news dataset. Specifically, we treat each trading day as one bag, with certain amounts of news happening on each trading day as instances in each bag. Experiment results demonstrate that our proposed multi-instance-based framework gains outstanding results in terms of the accuracy of trend prediction, compared with other state-of-art approaches and baselines.", "link": "http://arxiv.org/abs/2206.14452v1"}, {"index": 272, "title": "The Lepto-Variance of Stock Returns", "abstract": "The Regression Tree (RT) sorts the samples using a specific feature and finds the split point that produces the maximum variance reduction from a node to its children. Our key observation is that the best factor to use (in terms of MSE drop) is always the target itself, as this most clearly separates the target. Thus using the target as the splitting factor provides an upper bound on MSE drop (or lower bound on the residual children MSE). Based on this observation, we define the k-bit lepto-variance ${\\lambda}k^2$ of a target variable (or equivalently the lepto-variance at a specific depth k) as the variance that cannot be removed by any regression tree of a depth equal to k. As the upper bound performance for any feature, we believe ${\\lambda}k^2$ to be an interesting statistical concept related to the underlying structure of the sample as it quantifies the resolving power of the RT for the sample. The max variance that may be explained using RTs of depth up to k is called the sample k-bit macro-variance. At any depth, total sample variance is thus decomposed into lepto-variance ${\\lambda}^2$ and macro-variance ${\\mu}^2$. We demonstrate the concept, by performing 1- and 2-bit RT based lepto-structure analysis for daily IBM stock returns.", "link": "http://arxiv.org/abs/2207.04867v2"}, {"index": 273, "title": "Detection and Forecasting of Extreme event in Stock Price Triggered by Fundamental, Technical, and External Factors", "abstract": "The sporadic large fluctuations are seen in the stock market due to changes in fundamental parameters, technical setups, and external factors. These large fluctuations are termed as Extreme Events (EE). The EEs may be positive or negative depending on the impact of these factors. During such events, the stock price time series is found to be nonstationary. Hence, the Hilbert-Huang transformation (HHT) is used to identify EEs based on their high instantaneous energy ($IE$) concentration. The analysis shows that the $IE$ concentration in the stock price is very high during both positive and negative EE with $IE>E_{\\mu}+4\\sigma,$ where $E_{\\mu}$ and $\\sigma$ are the mean energy and standard deviation of energy, respectively. Further, support vector regression is used to predict the stock price during an EE, with the close price being the most helpful input than the open-high-low-close (OHLC) inputs. The maximum prediction accuracy for one step using close price and OHLC prices are 95.98\\% and 95.64\\% respectively. Whereas, for the two steps prediction, the accuracies are 94.09\\% and 93.58\\% respectively. The EEs found from the predicted time series shows similar statistical characteristics that were obtained from the original data. The analysis emphasizes the importance of monitoring factors that lead to EEs for a compelling entry or exit strategy as investors can gain or lose significant amounts of capital due to these events.", "link": "http://dx.doi.org/10.1016/j.chaos.2023.113716"}, {"index": 274, "title": "Predicting Stock Price Movement after Disclosure of Corporate Annual Reports: A Case Study of 2021 China CSI 300 Stocks", "abstract": "In the current stock market, computer science and technology are more and more widely used to analyse stocks. Not same as most related machine learning stock price prediction work, this work study the predicting the tendency of the stock price on the second day right after the disclosure of the companies' annual reports. We use a variety of different models, including decision tree, logistic regression, random forest, neural network, prototypical networks. We use two sets of financial indicators (key and expanded) to conduct experiments, these financial indicators are obtained from the EastMoney website disclosed by companies, and finally we find that these models are not well behaved to predict the tendency. In addition, we also filter stocks with ROE greater than 0.15 and net cash ratio greater than 0.9. We conclude that according to the financial indicators based on the just-released annual report of the company, the predictability of the stock price movement on the second day after disclosure is weak, with maximum accuracy about 59.6% and maximum precision about 0.56 on our test set by the random forest classifier, and the stock filtering does not improve the performance. And random forests perform best in general among all these models which conforms to some work's findings.", "link": "http://arxiv.org/abs/2206.12528v2"}, {"index": 275, "title": "Parameter Estimation Methods of Required Rate of Return on Stock", "abstract": "In this study, we introduce new estimation methods for the required rate of return of the stochastic dividend discount model (DDM) and the private company valuation model, which will appear below. To estimate the required rate of return, we use the maximum likelihood method, the Bayesian method, and the Kalman filtering. We apply the model to a set of firms from the S\\&P 500 index using historical dividend and price data over a 32--year period. Overall, suggested methods can be used to estimate the required rate of return.", "link": "http://arxiv.org/abs/2206.09657v2"}, {"index": 276, "title": "A comparative study of the MACD-base trading strategies: evidence from the US stock market", "abstract": "In recent years, more and more investors use technical analysis methods in their own trading. Evaluating the effectiveness of technical analysis has become more feasible due to increasing computing capability and blooming public data, which indie investors can perform stock analysis and backtest their own trading strategy conveniently. The Moving Average Convergence Divergence (MACD) indicator is one of the popular technical indicators that are widely used in different strategies. In order to verify the MACD effectiveness, in this thesis, I use the MACD indicator with traditional parameters (12, 26, 9) to build various trading strategies. Then, I apply these strategies to stocks listed on three indices in the US stock market (i.e., Dow-Jones, Nasdaq, and S&P 500) and evaluate its performance in terms of win rate, profitability, Sharpe ratio, number of trades and maximum drawdown. The backtesting is programmed using Python, covering the period between 01/01/2015 and 28-08-2021. The result shows that the win-rate of the strategy with only the MACD indicator is less than 50%. However, the win-rate is improved for the trading strategies that combine the MACD indicator with other momentum indicators like the Money Flow Index (MFI) and the Relative Strength Index (RSI). Based on this result, I redesign the MACD mathematical formula by taking the trading volume and daily price volatility into consideration to derive a new indicator called VPVMA. The results show that the win-rate and risk-adjust performance of this new trading strategy have been improved significantly. In general, the findings suggest that while all the MACD trading strategies mentioned above can generate positive returns, the performance is not good without using other momentum indicators. Hence, the VPVMA indicator performs better.", "link": "http://arxiv.org/abs/2206.12282v1"}, {"index": 277, "title": "Development of a hybrid method for stock trading based on TOPSIS, EMD and ELM", "abstract": "Deciding when to buy or sell a stock is not an easy task because the market is hard to predict, being influenced by political and economic factors. Thus, methodologies based on computational intelligence have been applied to this challenging problem. In this work, every day the stocks are ranked by technique for order preference by similarity to ideal solution (TOPSIS) using technical analysis criteria, and the most suitable stock is selected for purchase. Even so, it may occur that the market is not favorable to purchase on certain days, or even, the TOPSIS make an incorrect selection. To improve the selection, another method should be used. So, a hybrid model composed of empirical mode decomposition (EMD) and extreme learning machine (ELM) is proposed. The EMD decomposes the series into several sub-series, and thus the main omponent (trend) is extracted. This component is processed by the ELM, which performs the prediction of the next element of component. If the value predicted by the ELM is greater than the last value, then the purchase of the stock is confirmed. The method was applied in a universe of 50 stocks in the Brazilian market. The selection made by TOPSIS showed promising results when compared to the random selection and the return generated by the Bovespa index. Confirmation with the EMD-ELM hybrid model was able to increase the percentage of profit tradings.", "link": "http://arxiv.org/abs/2206.06723v1"}, {"index": 278, "title": "Astock: A New Dataset and Automated Stock Trading based on Stock-specific News Analyzing Model", "abstract": "Natural Language Processing(NLP) demonstrates a great potential to support financial decision-making by analyzing the text from social media or news outlets. In this work, we build a platform to study the NLP-aided stock auto-trading algorithms systematically. In contrast to the previous work, our platform is characterized by three features: (1) We provide financial news for each specific stock. (2) We provide various stock factors for each stock. (3) We evaluate performance from more financial-relevant metrics. Such a design allows us to develop and evaluate NLP-aided stock auto-trading algorithms in a more realistic setting. In addition to designing an evaluation platform and dataset collection, we also made a technical contribution by proposing a system to automatically learn a good feature representation from various input information. The key to our algorithm is a method called semantic role labeling Pooling (SRLP), which leverages Semantic Role Labeling (SRL) to create a compact representation of each news paragraph. Based on SRLP, we further incorporate other stock factors to make the final prediction. In addition, we propose a self-supervised learning strategy based on SRLP to enhance the out-of-distribution generalization performance of our system. Through our experimental study, we show that the proposed method achieves better performance and outperforms all the baselines' annualized rate of return as well as the maximum drawdown of the CSI300 index and XIN9 index on real trading. Our Astock dataset and code are available at https://github.com/JinanZou/Astock.", "link": "http://arxiv.org/abs/2206.06606v1"}, {"index": 279, "title": "Safe-FinRL: A Low Bias and Variance Deep Reinforcement Learning Implementation for High-Freq Stock Trading", "abstract": "In recent years, many practitioners in quantitative finance have attempted to use Deep Reinforcement Learning (DRL) to build better quantitative trading (QT) strategies. Nevertheless, many existing studies fail to address several serious challenges, such as the non-stationary financial environment and the bias and variance trade-off when applying DRL in the real financial market. In this work, we proposed Safe-FinRL, a novel DRL-based high-freq stock trading strategy enhanced by the near-stationary financial environment and low bias and variance estimation. Our main contributions are twofold: firstly, we separate the long financial time series into the near-stationary short environment; secondly, we implement Trace-SAC in the near-stationary financial environment by incorporating the general retrace operator into the Soft Actor-Critic. Extensive experiments on the cryptocurrency market have demonstrated that Safe-FinRL has provided a stable value estimation and a steady policy improvement and reduced bias and variance significantly in the near-stationary financial environment.", "link": "http://arxiv.org/abs/2206.05910v1"}, {"index": 280, "title": "Quantitative Stock Investment by Routing Uncertainty-Aware Trading Experts: A Multi-Task Learning Approach", "abstract": "Quantitative investment is a fundamental financial task that highly relies on accurate stock prediction and profitable investment decision making. Despite recent advances in deep learning (DL) have shown stellar performance on capturing trading opportunities in the stochastic stock market, we observe that the performance of existing DL methods is sensitive to random seeds and network initialization. To design more profitable DL methods, we analyze this phenomenon and find two major limitations of existing works. First, there is a noticeable gap between accurate financial predictions and profitable investment strategies. Second, investment decisions are made based on only one individual predictor without consideration of model uncertainty, which is inconsistent with the workflow in real-world trading firms. To tackle these two limitations, we first reformulate quantitative investment as a multi-task learning problem. Later on, we propose AlphaMix, a novel two-stage mixture-of-experts (MoE) framework for quantitative investment to mimic the efficient bottom-up trading strategy design workflow of successful trading firms. In Stage one, multiple independent trading experts are jointly optimized with an individual uncertainty-aware loss function. In Stage two, we train neural routers (corresponding to the role of a portfolio manager) to dynamically deploy these experts on an as-needed basis. AlphaMix is also a universal framework that is applicable to various backbone network architectures with consistent performance gains. Through extensive experiments on long-term real-world data spanning over five years on two of the most influential financial markets (US and China), we demonstrate that AlphaMix significantly outperforms many state-of-the-art baselines in terms of four financial criteria.", "link": "http://arxiv.org/abs/2207.07578v1"}, {"index": 281, "title": "12 Years of Self-tracking for Promoting Physical Activity from a User Diversity Perspective: Taking Stock and Thinking Ahead", "abstract": "Despite the indisputable personal and societal benefits of regular physical activity, a large portion of the population does not follow the recommended guidelines, harming their health and wellness. The World Health Organization has called upon governments, practitioners, and researchers to accelerate action to address the global prevalence of physical inactivity. To this end, an emerging wave of research in ubiquitous computing has been exploring the potential of interactive self-tracking technology in encouraging positive health behavior change. Numerous findings indicate the benefits of personalization and inclusive design regarding increasing the motivational appeal and overall effectiveness of behavior change systems, with the ultimate goal of empowering and facilitating people to achieve their goals. However, most interventions still adopt a \"one-size-fits-all\" approach to their design, assuming equal effectiveness for all system features in spite of individual and collective user differences. To this end, we analyze a corpus of 12 years of research in self-tracking technology for health behavior change, focusing on physical activity, to identify those design elements that have proven most effective in inciting desirable behavior across diverse population segments. We then provide actionable recommendations for designing and evaluating behavior change self-tracking technology based on age, gender, occupation, fitness, and health condition. Finally, we engage in a critical commentary on the diversity of the domain and discuss ethical concerns surrounding tailored interventions and directions for moving forward.", "link": "http://dx.doi.org/10.1145/3511047.3538029"}, {"index": 282, "title": "Predicting Day-Ahead Stock Returns using Search Engine Query Volumes: An Application of Gradient Boosted Decision Trees to the S&P 100", "abstract": "The internet has changed the way we live, work and take decisions. As it is the major modern resource for research, detailed data on internet usage exhibits vast amounts of behavioral information. This paper aims to answer the question whether this information can be facilitated to predict future returns of stocks on financial capital markets. In an empirical analysis it implements gradient boosted decision trees to learn relationships between abnormal returns of stocks within the S&P 100 index and lagged predictors derived from historical financial data, as well as search term query volumes on the internet search engine Google. Models predict the occurrence of day-ahead stock returns in excess of the index median. On a time frame from 2005 to 2017, all disparate datasets exhibit valuable information. Evaluated models have average areas under the receiver operating characteristic between 54.2% and 56.7%, clearly indicating a classification better than random guessing. Implementing a simple statistical arbitrage strategy, models are used to create daily trading portfolios of ten stocks and result in annual performances of more than 57% before transaction costs. With ensembles of different data sets topping up the performance ranking, the results further question the weak form and semi-strong form efficiency of modern financial capital markets. Even though transaction costs are not included, the approach adds to the existing literature. It gives guidance on how to use and transform data on internet usage behavior for financial and economic modeling and forecasting.", "link": "http://arxiv.org/abs/2205.15853v2"}, {"index": 283, "title": "Asymptotic dependence modelling of the BRICS stock markets", "abstract": "With the use of empirical data, this paper focuses on solving financial and investment issues involving extremal dependence of ten pairwise combinations of the five BRICS (Brazil, Russia, India, China, and South Africa) stock markets. Daily closing equity indices from 5 January 2010 to 6 August 2018 are used in the study. Unlike previous literature, we use bivariate point process and conditional multivariate extreme value models to investigate the extremal dependence of the stock market returns. However, it is observed that the point process was able to model many more extreme observations or exceedances that contribute to the likelihood estimation. It gives more information than the threshold excess method of the CMEV model. This study shows varying levels of low extremal dependence structure whose outcomes are highly beneficial to investors, portfolio managers and other market participants interested in maximising investment returns and financial gains.", "link": "http://arxiv.org/abs/2205.15169v1"}, {"index": 284, "title": "Stock Trading Optimization through Model-based Reinforcement Learning with Resistance Support Relative Strength", "abstract": "Reinforcement learning (RL) is gaining attention by more and more researchers in quantitative finance as the agent-environment interaction framework is aligned with decision making process in many business problems. Most of the current financial applications using RL algorithms are based on model-free method, which still faces stability and adaptivity challenges. As lots of cutting-edge model-based reinforcement learning (MBRL) algorithms mature in applications such as video games or robotics, we design a new approach that leverages resistance and support (RS) level as regularization terms for action in MBRL, to improve the algorithm's efficiency and stability. From the experiment results, we can see RS level, as a market timing technique, enhances the performance of pure MBRL models in terms of various measurements and obtains better profit gain with less riskiness. Besides, our proposed method even resists big drop (less maximum drawdown) during COVID-19 pandemic period when the financial market got unpredictable crisis. Explanations on why control of resistance and support level can boost MBRL is also investigated through numerical experiments, such as loss of actor-critic network and prediction error of the transition dynamical model. It shows that RS indicators indeed help the MBRL algorithms to converge faster at early stage and obtain smaller critic loss as training episodes increase.", "link": "http://arxiv.org/abs/2205.15056v1"}, {"index": 285, "title": "A time-varying study of Chinese investor sentiment, stock market liquidity and volatility: Based on deep learning BERT model and TVP-VAR model", "abstract": "Based on the commentary data of the Shenzhen Stock Index bar on the EastMoney website from January 1, 2018 to December 31, 2019. This paper extracts the embedded investor sentiment by using a deep learning BERT model and investigates the time-varying linkage between investment sentiment, stock market liquidity and volatility using a TVP-VAR model. The results show that the impact of investor sentiment on stock market liquidity and volatility is stronger. Although the inverse effect is relatively small, it is more pronounced with the state of the stock market. In all cases, the response is more pronounced in the short term than in the medium to long term, and the impact is asymmetric, with shocks stronger when the market is in a downward spiral.", "link": "http://arxiv.org/abs/2205.05719v2"}, {"index": 286, "title": "Cryptocurrency Bubble Detection: A New Stock Market Dataset, Financial Task & Hyperbolic Models", "abstract": "The rapid spread of information over social media influences quantitative trading and investments. The growing popularity of speculative trading of highly volatile assets such as cryptocurrencies and meme stocks presents a fresh challenge in the financial realm. Investigating such \"bubbles\" - periods of sudden anomalous behavior of markets are critical in better understanding investor behavior and market dynamics. However, high volatility coupled with massive volumes of chaotic social media texts, especially for underexplored assets like cryptocoins pose a challenge to existing methods. Taking the first step towards NLP for cryptocoins, we present and publicly release CryptoBubbles, a novel multi-span identification task for bubble detection, and a dataset of more than 400 cryptocoins from 9 exchanges over five years spanning over two million tweets. Further, we develop a set of sequence-to-sequence hyperbolic models suited to this multi-span identification task based on the power-law dynamics of cryptocurrencies and user behavior on social media. We further test the effectiveness of our models under zero-shot settings on a test set of Reddit posts pertaining to 29 \"meme stocks\", which see an increase in trade volume due to social media hype. Through quantitative, qualitative, and zero-shot analyses on Reddit and Twitter spanning cryptocoins and meme-stocks, we show the practical applicability of CryptoBubbles and hyperbolic models.", "link": "http://arxiv.org/abs/2206.06320v1"}, {"index": 287, "title": "Deep learning based Chinese text sentiment mining and stock market correlation research", "abstract": "We explore how to crawl financial forum data such as stock bars and combine them with deep learning models for sentiment analysis. In this paper, we will use the BERT model to train against the financial corpus and predict the SZSE Component Index, and find that applying the BERT model to the financial corpus through the maximum information coefficient comparison study. The obtained sentiment features will be able to reflect the fluctuations in the stock market and help to improve the prediction accuracy effectively. Meanwhile, this paper combines deep learning with financial text, in further exploring the mechanism of investor sentiment on stock market through deep learning method, which will be beneficial for national regulators and policy departments to develop more reasonable policy guidelines for maintaining the stability of stock market.", "link": "http://arxiv.org/abs/2205.04743v1"}, {"index": 288, "title": "Collective behavior of stock prices in the time of crisis as a response to the external stimulus", "abstract": "We analyze the interaction between stock prices of big companies in the USA and Germany using Granger Causality. We claim that the increase in pair-wise Granger causality interaction between prices in the times of crisis is the consequence of simultaneous response of the markets to the outside events or external stimulus that is considered as a common driver to all the stocks, not a result of real causal predictability between the prices themselves. An alternative approach through recurrence analysis in single stock price series supports this claim. The observed patterns in the price of stocks are modelled by adding a multiplicative exogenous term as the representative for external factors to the geometric Brownian motion model for stock prices. Altogether, we can detect and model the effects of the Great Recession as a consequence of the mortgage crisis in 2007/2008 as well as the impacts of the Covid out-break in early 2020", "link": "http://arxiv.org/abs/2205.06677v1"}, {"index": 289, "title": "Research on the correlation between text emotion mining and stock market based on deep learning", "abstract": "This paper discusses how to crawl the data of financial forums such as stock bar, and conduct emotional analysis combined with the in-depth learning model. This paper will use the Bert model to train the financial corpus and predict the Shenzhen stock index. Through the comparative study of the maximal information coefficient (MIC), it is found that the emotional characteristics obtained by applying the BERT model to the financial corpus can be reflected in the fluctuation of the stock market, which is conducive to effectively improve the prediction accuracy. At the same time, this paper combines in-depth learning with financial texts to further explore the impact mechanism of investor sentiment on the stock market through in-depth learning, which will help the national regulatory authorities and policy departments to formulate more reasonable policies and guidelines for maintaining the stability of the stock market.", "link": "http://arxiv.org/abs/2205.06675v1"}, {"index": 290, "title": "Compositional Modeling with Stock and Flow Diagrams", "abstract": "Stock and flow diagrams are widely used in epidemiology to model the dynamics of populations. Although tools already exist for building these diagrams and simulating the systems they describe, we have created a new package called StockFlow, part of the AlgebraicJulia ecosystem, which uses ideas from category theory to overcome notable limitations of existing software. Compositionality is provided by the theory of decorated cospans: stock and flow diagrams can be composed to form larger ones in an intuitive way formalized by the operad of undirected wiring diagrams. Our approach also cleanly separates the syntax of stock and flow diagrams from the semantics they can be assigned. We consider semantics in ordinary differential equations, although others are possible. As an example, we explain code in StockFlow that implements a simplified version of a COVID-19 model used in Canada.", "link": "http://dx.doi.org/10.4204/EPTCS.380.5"}, {"index": 291, "title": "Randomized geometric tools for anomaly detection in stock markets", "abstract": "We propose novel randomized geometric tools to detect low-volatility anomalies in stock markets; a principal problem in financial economics. Our modeling of the (detection) problem results in sampling and estimating the (relative) volume of geodesically non-convex and non-connected spherical patches that arise by intersecting a non-standard simplex with a sphere. To sample, we introduce two novel Markov Chain Monte Carlo (MCMC) algorithms that exploit the geometry of the problem and employ state-of-the-art continuous geometric random walks (such as Billiard walk and Hit-and-Run) adapted on spherical patches. To our knowledge, this is the first geometric formulation and MCMC-based analysis of the volatility puzzle in stock markets. We have implemented our algorithms in C++ (along with an R interface) and we illustrate the power of our approach by performing extensive experiments on real data. Our analyses provide accurate detection and new insights into the distribution of portfolios' performance characteristics. Moreover, we use our tools to show that classical methods for low-volatility anomaly detection in finance form bad proxies that could lead to misleading or inaccurate results.", "link": "http://arxiv.org/abs/2205.03852v2"}, {"index": 292, "title": "Univariate and Multivariate LSTM Model for Short-Term Stock Market Prediction", "abstract": "Designing robust and accurate prediction models has been a viable research area since a long time. While proponents of a well-functioning market predictors believe that it is difficult to accurately predict market prices but many scholars disagree. Robust and accurate prediction systems will not only be helpful to the businesses but also to the individuals in making their financial investments. This paper presents an LSTM model with two different input approaches for predicting the short-term stock prices of two Indian companies, Reliance Industries and Infosys Ltd. Ten years of historic data (2012-2021) is taken from the yahoo finance website to carry out analysis of proposed approaches. In the first approach, closing prices of two selected companies are directly applied on univariate LSTM model. For the approach second, technical indicators values are calculated from the closing prices and then collectively applied on Multivariate LSTM model. Short term market behaviour for upcoming days is evaluated. Experimental outcomes revel that approach one is useful to determine the future trend but multivariate LSTM model with technical indicators found to be useful in accurately predicting the future price behaviours.", "link": "http://arxiv.org/abs/2205.06673v1"}, {"index": 293, "title": "The probability flow in the Stock market and Spontaneous symmetry breaking in Quantum Finance", "abstract": "The Spontaneous Symmetry breaking in Quantum Finance considers the martingale condition in the stock market as a vacuum state if we express the financial equations in the Hamiltonian form. The original analysis for this phenomena ignores completely the kinetic terms in the neighborhood of the minimal of the potential terms. This is correct in most of the cases. However, when we deal with the Martingale condition, it comes out that the kinetic terms can also behave as potential terms and then reproduce a shift on the effective location of the vacuum (Martingale). In this paper we analyze the effective symmetry breaking patterns and the connected vacuum degeneracy for these special circumstances. Within the same scenario, we analyze the connection between the flow of information and the multiplicity of martingale states, providing in this way powerful tools for analyzing the dynamic of the stock market.", "link": "http://dx.doi.org/10.3390/math9212777"}, {"index": 294, "title": "A Volatility Estimator of Stock Market Indices Based on the Intrinsic Entropy Model", "abstract": "Grasping the historical volatility of stock market indices and accurately estimating are two of the major focuses of those involved in the financial securities industry and derivative instruments pricing. This paper presents the results of employing the intrinsic entropy model as a substitute for estimating the volatility of stock market indices. Diverging from the widely used volatility models that take into account only the elements related to the traded prices, namely the open, high, low, and close prices of a trading day (OHLC), the intrinsic entropy model takes into account the traded volumes during the considered time frame as well. We adjust the intraday intrinsic entropy model that we introduced earlier for exchange-traded securities in order to connect daily OHLC prices with the ratio of the corresponding daily volume to the overall volume traded in the considered period. The intrinsic entropy model conceptualizes this ratio as entropic probability or market credence assigned to the corresponding price level. The intrinsic entropy is computed using historical daily data for traded market indices (S&P 500, Dow 30, NYSE Composite, NASDAQ Composite, Nikkei 225, and Hang Seng Index). We compare the results produced by the intrinsic entropy model with the volatility estimates obtained for the same data sets using widely employed industry volatility estimators. The intrinsic entropy model proves to consistently deliver reliable estimates for various time frames while showing peculiarly high values for the coefficient of variation, with the estimates falling in a significantly lower interval range compared with those provided by the other advanced volatility estimators.", "link": "http://dx.doi.org/10.3390/e23040484"}, {"index": 295, "title": "A Word is Worth A Thousand Dollars: Adversarial Attack on Tweets Fools Stock Predictions", "abstract": "More and more investors and machine learning models rely on social media (e.g., Twitter and Reddit) to gather real-time information and sentiment to predict stock price movements. Although text-based models are known to be vulnerable to adversarial attacks, whether stock prediction models have similar vulnerability is underexplored. In this paper, we experiment with a variety of adversarial attack configurations to fool three stock prediction victim models. We address the task of adversarial generation by solving combinatorial optimization problems with semantics and budget constraints. Our results show that the proposed attack method can achieve consistent success rates and cause significant monetary loss in trading simulation by simply concatenating a perturbed but semantically similar tweet.", "link": "http://arxiv.org/abs/2205.01094v3"}, {"index": 296, "title": "The Cross-Sectional Intrinsic Entropy. A Comprehensive Stock Market Volatility Estimator", "abstract": "To take into account the temporal dimension of uncertainty in stock markets, this paper introduces a cross-sectional estimation of stock market volatility based on the intrinsic entropy model. The proposed cross-sectional intrinsic entropy (CSIE) is defined and computed as a daily volatility estimate for the entire market, grounded on the daily traded prices: open, high, low, and close prices (OHLC), along with the daily traded volume for all symbols listed on The New York Stock Exchange (NYSE) and The National Association of Securities Dealers Automated Quotations (NASDAQ). We perform a comparative analysis between the time series obtained from the CSIE and the historical volatility as provided by the estimators: close-to-close, Parkinson, Garman-Klass, Rogers-Satchell, Yang-Zhang, and intrinsic entropy (IE), defined and computed from historical OHLC daily prices of the Standard & Poor's 500 index (S&P500), Dow Jones Industrial Average (DJIA), and the NASDAQ Composite index, respectively, for various time intervals. Our study uses approximately 6000 day reference points, starting on 1 Jan. 2001, until 23 Jan. 2022, for both the NYSE and the NASDAQ. We found that the CSIE market volatility estimator is consistently at least 10 times more sensitive to market changes, compared to the volatility estimate captured through the market indices. Furthermore, beta values confirm a consistently lower volatility risk for market indices overall, between 50% and 90% lower, compared to the volatility risk of the entire market in various time intervals and rolling windows.", "link": "http://dx.doi.org/10.3390/e24050623"}, {"index": 297, "title": "Autoencoder based Hybrid Multi-Task Predictor Network for Daily Open-High-Low-Close Prices Prediction of Indian Stocks", "abstract": "Stock prices are highly volatile and sudden changes in trends are often very problematic for traditional forecasting models to handle. The standard Long Short Term Memory (LSTM) networks are regarded as the state-of-the-art models for such predictions. But, these models fail to handle sudden and drastic changes in the price trend. Moreover, there are some inherent constraints with the open, high, low and close (OHLC) prices of the stocks. Literature lacks the study on the inherent property of OHLC prices. We argue that predicting the OHLC prices for the next day is much more informative than predicting the trends of the stocks as the trend is mostly calculated using these OHLC prices only. The problem mainly is focused on Buy-Today Sell-Tomorrow (BTST) trading. In this regard, AEs when pre-trained with the stock prices, may be beneficial. A novel framework is proposed where a pre-trained encoder is cascaded in front of the multi-task predictor network. This hybrid network can leverage the power of a combination of networks and can both handle the OHLC constraints as well as capture any sudden drastic changes in the prices. It is seen that such a network is much more efficient at predicting stock prices. The experiments have been extended to recommend the most profitable and most overbought stocks on the next day. The model has been tested for multiple Indian companies and it is found that the recommendations from the proposed model have not resulted in a single loss for a test period of 300 days.", "link": "http://arxiv.org/abs/2204.13422v1"}, {"index": 298, "title": "Fuzzy Expert System for Stock Portfolio Selection: An Application to Bombay Stock Exchange", "abstract": "Selection of proper stocks, before allocating investment ratios, is always a crucial task for the investors. Presence of many influencing factors in stock performance have motivated researchers to adopt various Artificial Intelligence (AI) techniques to make this challenging task easier. In this paper a novel fuzzy expert system model is proposed to evaluate and rank the stocks under Bombay Stock Exchange (BSE). Dempster-Shafer (DS) evidence theory is used for the first time to automatically generate the consequents of the fuzzy rule base to reduce the effort in knowledge base development of the expert system. Later a portfolio optimization model is constructed where the objective function is considered as the ratio of the difference of fuzzy portfolio return and the risk free return to the weighted mean semi-variance of the assets that has been used. The model is solved by applying Ant Colony Optimization (ACO) algorithm by giving preference to the top ranked stocks. The performance of the model proved to be satisfactory for short-term investment period when compared with the recent performance of the stocks.", "link": "http://arxiv.org/abs/2204.13385v2"}, {"index": 299, "title": "Policy Gradient Stock GAN for Realistic Discrete Order Data Generation in Financial Markets", "abstract": "This study proposes a new generative adversarial network (GAN) for generating realistic orders in financial markets. In some previous works, GANs for financial markets generated fake orders in continuous spaces because of GAN architectures' learning limitations. However, in reality, the orders are discrete, such as order prices, which has minimum order price unit, or order types. Thus, we change the generation method to place the generated fake orders into discrete spaces in this study. Because this change disabled the ordinary GAN learning algorithm, this study employed a policy gradient, frequently used in reinforcement learning, for the learning algorithm. Through our experiments, we show that our proposed model outperforms previous models in generated order distribution. As an additional benefit of introducing the policy gradient, the entropy of the generated policy can be used to check GAN's learning status. In the future, higher performance GANs, better evaluation methods, or the applications of our GANs can be addressed.", "link": "http://arxiv.org/abs/2204.13338v1"}, {"index": 300, "title": "Stability of China's Stock Market: Measure and Forecast by Ricci Curvature on Network", "abstract": "The systemic stability of a stock market is one of the core issues in the financial field. The market can be regarded as a complex network whose nodes are stocks connected by edges that signify their correlation strength. Since the market is a strongly nonlinear system, it is difficult to measure the macroscopic stability and depict market fluctuations in time. In this paper, we use a geometric measure derived from discrete Ricci curvature to capture the higher-order nonlinear architecture of financial networks. In order to confirm the effectiveness of our method, we use it to analyze the CSI 300 constituents of China's stock market from 2005--2020 and the systemic stability of the market is quantified through the network's Ricci type curvatures. Furthermore, we use a hybrid model to analyze the curvature time series and predict the future trends of the market accurately. As far as we know, this is the first paper to apply Ricci curvature to forecast the systemic stability of domestic stock market, and our results show that Ricci curvature has good explanatory power for the market stability and can be a good indicator to judge the future risk and volatility of the domestic market.", "link": "http://arxiv.org/abs/2204.06692v1"}, {"index": 301, "title": "Stock Price Prediction using Sentiment Analysis and Deep Learning for Indian Markets", "abstract": "Stock market prediction has been an active area of research for a considerable period. Arrival of computing, followed by Machine Learning has upgraded the speed of research as well as opened new avenues. As part of this research study, we aimed to predict the future stock movement of shares using the historical prices aided with availability of sentiment data. Two models were used as part of the exercise, LSTM was the first model with historical prices as the independent variable. Sentiment Analysis captured using Intensity Analyzer was used as the major parameter for Random Forest Model used for the second part, some macro parameters like Gold, Oil prices, USD exchange rate and Indian Govt. Securities yields were also added to the model for improved accuracy of the model. As the end product, prices of 4 stocks viz. Reliance, HDFC Bank, TCS and SBI were predicted using the aforementioned two models. The results were evaluated using RMSE metric.", "link": "http://arxiv.org/abs/2204.05783v1"}, {"index": 302, "title": "Attention-based CNN-LSTM and XGBoost hybrid model for stock prediction", "abstract": "Stock market plays an important role in the economic development. Due to the complex volatility of the stock market, the research and prediction on the change of the stock price, can avoid the risk for the investors. The traditional time series model ARIMA can not describe the nonlinearity, and can not achieve satisfactory results in the stock prediction. As neural networks are with strong nonlinear generalization ability, this paper proposes an attention-based CNN-LSTM and XGBoost hybrid model to predict the stock price. The model constructed in this paper integrates the time series model, the Convolutional Neural Networks with Attention mechanism, the Long Short-Term Memory network, and XGBoost regressor in a non-linear relationship, and improves the prediction accuracy. The model can fully mine the historical information of the stock market in multiple periods. The stock data is first preprocessed through ARIMA. Then, the deep learning architecture formed in pretraining-finetuning framework is adopted. The pre-training model is the Attention-based CNN-LSTM model based on sequence-to-sequence framework. The model first uses convolution to extract the deep features of the original stock data, and then uses the Long Short-Term Memory networks to mine the long-term time series features. Finally, the XGBoost model is adopted for fine-tuning. The results show that the hybrid model is more effective and the prediction accuracy is relatively high, which can help investors or institutions to make decisions and achieve the purpose of expanding return and avoiding risk. Source code is available at https://github.com/zshicode/Attention-CLX-stock-prediction.", "link": "http://arxiv.org/abs/2204.02623v2"}, {"index": 303, "title": "The echo chamber effect resounds on financial markets: a social media alert system for meme stocks", "abstract": "The short squeeze of Gamestop (GME) has revealed to the world how retail investors pooling through social media can severely impact financial markets. In this paper, we devise an early warning signal to detect suspicious users' social network activity, which might affect the financial market stability. We apply our approach to the subreddit r/WallStreetBets, selecting two meme stocks (GME and AMC) and two non-meme stocks (AAPL and MSFT) as case studies. The alert system is structured in two stpng; the first one is based on extraordinary activity on the social network, while the second aims at identifying whether the movement seeks to coordinate the users to a bulk action. We run an event study analysis to see the reaction of the financial markets when the alert system catches social network turmoil. A regression analysis witnesses the discrepancy between the meme and non-meme stocks in how the social networks might affect the trend on the financial market.", "link": "http://arxiv.org/abs/2203.13790v1"}, {"index": 304, "title": "Turning Stocks into Memes: A Dataset for Understanding How Social Communities Can Drive Wall Street", "abstract": "Who actually expresses an intent to buy GameStop shares on Reddit? What convinces people to buy stocks? Are people convinced to support a coordinated plan to adversely impact Wall Street investors? Existing literature on understanding intent has mainly relied on surveys and self reporting; however there are limitations to these methodologies. Hence, in this paper, we develop an annotated dataset of communications centered on the GameStop phenomenon to analyze the subscriber intentions behaviors within the r/WallStreetBets community to buy (or not buy) stocks. Likewise, we curate a dataset to better understand how intent interacts with a user's general support towards the coordinated actions of the community for GameStop. Overall, our dataset can provide insight to social scientists on the persuasive power to buy into social movements online by adopting common language and narrative. WARNING: This paper contains offensive language that commonly appears on Reddit's r/WallStreetBets subreddit.", "link": "http://arxiv.org/abs/2203.08694v1"}, {"index": 305, "title": "Dynamic and Context-Dependent Stock Price Prediction Using Attention Modules and News Sentiment", "abstract": "The growth of machine-readable data in finance, such as alternative data, requires new modeling techniques that can handle non-stationary and non-parametric data. Due to the underlying causal dependence and the size and complexity of the data, we propose a new modeling approach for financial time series data, the $\\alpha_{t}$-RIM (recurrent independent mechanism). This architecture makes use of key-value attention to integrate top-down and bottom-up information in a context-dependent and dynamic way. To model the data in such a dynamic manner, the $\\alpha_{t}$-RIM utilizes an exponentially smoothed recurrent neural network, which can model non-stationary times series data, combined with a modular and independent recurrent structure. We apply our approach to the closing prices of three selected stocks of the S\\&P 500 universe as well as their news sentiment score. The results suggest that the $\\alpha_{t}$-RIM is capable of reflecting the causal structure between stock prices and news sentiment, as well as the seasonality and trends. Consequently, this modeling approach markedly improves the generalization performance, that is, the prediction of unseen data, and outperforms state-of-the-art networks such as long short-term memory models.", "link": "http://arxiv.org/abs/2205.01639v1"}, {"index": 306, "title": "HiSA-SMFM: Historical and Sentiment Analysis based Stock Market Forecasting Model", "abstract": "One of the pillars to build a country's economy is the stock market. Over the years, people are investing in stock markets to earn as much profit as possible from the amount of money that they possess. Hence, it is vital to have a prediction model which can accurately predict future stock prices. With the help of machine learning, it is not an impossible task as the various machine learning techniques if modeled properly may be able to provide the best prediction values. This would enable the investors to decide whether to buy, sell or hold the share. The aim of this paper is to predict the future of the financial stocks of a company with improved accuracy. In this paper, we have proposed the use of historical as well as sentiment data to efficiently predict stock prices by applying LSTM. It has been found by analyzing the existing research in the area of sentiment analysis that there is a strong correlation between the movement of stock prices and the publication of news articles. Therefore, in this paper, we have integrated these factors to predict the stock prices more accurately.", "link": "http://arxiv.org/abs/2203.08143v1"}, {"index": 307, "title": "Solar Term Anomaly in China Stock Market: Evidence from Shanghai Index", "abstract": "This paper investigates the solar term effect in China stock market as a supplementary to the existing literature of calender effect. Based on a regression framework, this paper verifies the existence of solar term effect in Shanghai Index in multiple dimensions: inter-solar-term analysis, full sample analysis at mean level and risk level as well as the turn of solar term effect. Several solar terms have been found to cause significant positive and negative value to the return such as solar term 1,3 and 4. and bring high volatility such as solar term 8, 11 and 14. The result is reliable and robust under the Extreme Bound Analysis and various assumptions of errors distribution in IGARCH model. These findings give readers a new perspective to view calender effect under the influence of traditional Chinese culture that solar terms affect the market through affecting investors mood, expectation, enthusiasm, etc. which is a good evidence to the Culture bonus hypothesis proposed by Chen and Chien and the possible influence by the Chinese culture in other Asian markets.", "link": "http://arxiv.org/abs/2203.12603v2"}, {"index": 308, "title": "Precise Stock Price Prediction for Optimized Portfolio Design Using an LSTM Model", "abstract": "Accurate prediction of future prices of stocks is a difficult task to perform. Even more challenging is to design an optimized portfolio of stocks with the identification of proper weights of allocation to achieve the optimized values of return and risk. We present optimized portfolios based on the seven sectors of the Indian economy. The past prices of the stocks are extracted from the web from January 1, 2016, to December 31, 2020. Optimum portfolios are designed on the selected seven sectors. An LSTM regression model is also designed for predicting future stock prices. Five months after the construction of the portfolios, i.e., on June 1, 2021, the actual and predicted returns and risks of each portfolio are computed. The predicted and the actual returns indicate the very high accuracy of the LSTM model.", "link": "http://dx.doi.org/10.1109/OCIT53463.2021.00050"}, {"index": 309, "title": "Robust Portfolio Design and Stock Price Prediction Using an Optimized LSTM Model", "abstract": "Accurate prediction of future prices of stocks is a difficult task to perform. Even more challenging is to design an optimized portfolio with weights allocated to the stocks in a way that optimizes its return and the risk. This paper presents a systematic approach towards building two types of portfolios, optimum risk, and eigen, for four critical economic sectors of India. The prices of the stocks are extracted from the web from Jan 1, 2016, to Dec 31, 2020. Sector-wise portfolios are built based on their ten most significant stocks. An LSTM model is also designed for predicting future stock prices. Six months after the construction of the portfolios, i.e., on Jul 1, 2021, the actual returns and the LSTM-predicted returns for the portfolios are computed. A comparison of the predicted and the actual returns indicate a high accuracy level of the LSTM model.", "link": "http://dx.doi.org/10.1109/INDICON52576.2021.9691583"}, {"index": 310, "title": "GCNET: graph-based prediction of stock price movement using graph convolutional network", "abstract": "The importance of considering related stocks data for the prediction of stock price movement has been shown in many studies, however, advanced graphical techniques for modeling, embedding and analyzing the behavior of interrelated stocks have not been widely exploited for the prediction of stocks price movements yet. The main challenges in this domain are to find a way for modeling the existing relations among an arbitrary set of stocks and to exploit such a model for improving the prediction performance for those stocks. The most of existing methods in this domain rely on basic graph-analysis techniques, with limited prediction power, and suffer from a lack of generality and flexibility. In this paper, we introduce a novel framework, called GCNET that models the relations among an arbitrary set of stocks as a graph structure called influence network and uses a set of history-based prediction models to infer plausible initial labels for a subset of the stock nodes in the graph. Finally, GCNET uses the Graph Convolutional Network algorithm to analyze this partially labeled graph and predicts the next price direction of movement for each stock in the graph. GCNET is a general prediction framework that can be applied for the prediction of the price fluctuations of interacting stocks based on their historical data. Our experiments and evaluations on a set of stocks from the NASDAQ index demonstrate that GCNET significantly improves the performance of SOTA in terms of accuracy and MCC measures.", "link": "http://arxiv.org/abs/2203.11091v2"}, {"index": 311, "title": "Forecasting Stock Options Prices via the Solution of an Ill-Posed Problem for the Black-Scholes Equation", "abstract": "In the previous paper (Inverse Problems, 32, 015010, 2016), a new heuristic mathematical model was proposed for accurate forecasting of prices of stock options for 1-2 trading days ahead of the present one. This new technique uses the Black-Scholes equation supplied by new intervals for the underlying stock and new initial and boundary conditions for option prices. The Black-Scholes equation was solved in the positive direction of the time variable, This ill-posed initial boundary value problem was solved by the so-called Quasi-Reversibility Method (QRM). This approach with an added trading strategy was tested on the market data for 368 stock options and good forecasting results were demonstrated. In the current paper, we use the geometric Brownian motion to provide an explanation of that effectivity using computationally simulated data for European call options. We also provide a convergence analysis for QRM. The key tool of that analysis is a Carleman estimate.", "link": "http://dx.doi.org/10.1088/1361-6420/ac91ec"}, {"index": 312, "title": "Stock Embeddings: Learning Distributed Representations for Financial Assets", "abstract": "Identifying meaningful relationships between the price movements of financial assets is a challenging but important problem in a variety of financial applications. However with recent research, particularly those using machine learning and deep learning techniques, focused mostly on price forecasting, the literature investigating the modelling of asset correlations has lagged somewhat. To address this, inspired by recent successes in natural language processing, we propose a neural model for training stock embeddings, which harnesses the dynamics of historical returns data in order to learn the nuanced relationships that exist between financial assets. We describe our approach in detail and discuss a number of ways that it can be used in the financial domain. Furthermore, we present the evaluation results to demonstrate the utility of this approach, compared to several important benchmarks, in two real-world financial analytics tasks.", "link": "http://arxiv.org/abs/2202.08968v1"}, {"index": 313, "title": "A Large Confirmatory Dynamic Factor Model for Stock Market Returns in Different Time Zones", "abstract": "We propose a confirmatory dynamic factor model for a large number of daily returns across multiple time zones. The model has a global factor and three continental factors. We propose two estimators of the model: a quasi-maximum likelihood estimator (QML-just-identified), and an improved estimator (QML-all-res). Our estimators are consistent and asymptotically normal. In particular, the asymptotic distributions of QML-all-res are the same as those of the infeasible OLS estimators that treat factors as known and utilize all the restrictions of the parameters of the model. We apply the model to MSCI equity indices of 42 developed and emerging markets, and find that the market is more integrated when the US VIX is high.", "link": "http://arxiv.org/abs/2202.03638v6"}, {"index": 314, "title": "Machine Learning Models in Stock Market Prediction", "abstract": "The paper focuses on predicting the Nifty 50 Index by using 8 Supervised Machine Learning Models. The techniques used for empirical study are Adaptive Boost (AdaBoost), k-Nearest Neighbors (kNN), Linear Regression (LR), Artificial Neural Network (ANN), Random Forest (RF), Stochastic Gradient Descent (SGD), Support Vector Machine (SVM) and Decision Trees (DT). Experiments are based on historical data of Nifty 50 Index of Indian Stock Market from 22nd April, 1996 to 16th April, 2021, which is time series data of around 25 years. During the period there were 6220 trading days excluding all the non trading days. The entire trading dataset was divided into 4 subsets of different size-25% of entire data, 50% of entire data, 75% of entire data and entire data. Each subset was further divided into 2 parts-training data and testing data. After applying 3 tests- Test on Training Data, Test on Testing Data and Cross Validation Test on each subset, the prediction performance of the used models were compared and after comparison, very interesting results were found. The evaluation results indicate that Adaptive Boost, k- Nearest Neighbors, Random Forest and Decision Trees under performed with increase in the size of data set. Linear Regression and Artificial Neural Network shown almost similar prediction results among all the models but Artificial Neural Network took more time in training and validating the model. Thereafter Support Vector Machine performed better among rest of the models but with increase in the size of data set, Stochastic Gradient Descent performed better than Support Vector Machine.", "link": "http://dx.doi.org/10.35940/ijitee.C9733.0111322"}, {"index": 315, "title": "Hierarchical Risk Parity and Minimum Variance Portfolio Design on NIFTY 50 Stocks", "abstract": "Portfolio design and optimization have been always an area of research that has attracted a lot of attention from researchers from the finance domain. Designing an optimum portfolio is a complex task since it involves accurate forecasting of future stock returns and risks and making a suitable tradeoff between them. This paper proposes a systematic approach to designing portfolios using two algorithms, the critical line algorithm, and the hierarchical risk parity algorithm on eight sectors of the Indian stock market. While the portfolios are designed using the stock price data from Jan 1, 2016, to Dec 31, 2020, they are tested on the data from Jan 1, 2021, to Aug 26, 2021. The backtesting results of the portfolios indicate while the performance of the CLA algorithm is superior on the training data, the HRP algorithm has outperformed the CLA algorithm on the test data.", "link": "http://dx.doi.org/10.1109/DASA53625.2021.9681925"}, {"index": 316, "title": "Portfolio Optimization on NIFTY Thematic Sector Stocks Using an LSTM Model", "abstract": "Portfolio optimization has been a broad and intense area of interest for quantitative and statistical finance researchers and financial analysts. It is a challenging task to design a portfolio of stocks to arrive at the optimized values of the return and risk. This paper presents an algorithmic approach for designing optimum risk and eigen portfolios for five thematic sectors of the NSE of India. The prices of the stocks are extracted from the web from Jan 1, 2016, to Dec 31, 2020. Optimum risk and eigen portfolios for each sector are designed based on ten critical stocks from the sector. An LSTM model is designed for predicting future stock prices. Seven months after the portfolios were formed, on Aug 3, 2021, the actual returns of the portfolios are compared with the LSTM-predicted returns. The predicted and the actual returns indicate a very high-level accuracy of the LSTM model.", "link": "http://dx.doi.org/10.1109/ICDABI53623.2021.9655886"}, {"index": 317, "title": "On Robust Optimal Linear Feedback Stock Trading", "abstract": "The take-off point for this paper is the Simultaneous Long-Short (SLS) control class, which is known to guarantee the so-called robust positive expectation (RPE) property. That is, the expected cumulative trading gain-loss function is guaranteed to be positive for a broad class of stock price processes. This fact attracts many new extensions and ramifications to the SLS theory. However, it is arguable that \"systematic\" way to select an optimal decision variable that is robust in the RPE sense is still unresolved. To this end, we propose a modified SLS control structure, which we call the {double linear feedback control scheme}, that allows us to solve the issue above for stock price processes involving independent returns. In this paper, we go beyond the existing literature by not only deriving explicit expressions for the expected value and variance of cumulative gain-loss function but also proving various theoretical results regarding {robust positive expected growth} and {monotonicity}. Subsequently, we propose a new {robust optimal gain selection problem} that seeks a solution maximizing the expected trading gain-loss subject to the prespecified standard deviation {and} RPE constraints. Under some mild conditions, we show that the optimal solution exists and is unique. Moreover, a simple graphical approach that allows one to systematically determine the optimal solution is also proposed. Finally, some numerical and empirical studies using historical price data are also provided to support our theory.", "link": "http://arxiv.org/abs/2202.02300v1"}, {"index": 318, "title": "StonkBERT: Can Language Models Predict Medium-Run Stock Price Movements?", "abstract": "To answer this question, we fine-tune transformer-based language models, including BERT, on different sources of company-related text data for a classification task to predict the one-year stock price performance. We use three different types of text data: News articles, blogs, and annual reports. This allows us to analyze to what extent the performance of language models is dependent on the type of the underlying document. StonkBERT, our transformer-based stock performance classifier, shows substantial improvement in predictive accuracy compared to traditional language models. The highest performance was achieved with news articles as text source. Performance simulations indicate that these improvements in classification accuracy also translate into above-average stock market returns.", "link": "http://arxiv.org/abs/2202.02268v1"}, {"index": 319, "title": "Implementation of a Type-2 Fuzzy Logic Based Prediction System for the Nigerian Stock Exchange", "abstract": "Stock Market can be easily seen as one of the most attractive places for investors, but it is also very complex in terms of making trading decisions. Predicting the market is a risky venture because of the uncertainties and nonlinear nature of the market. Deciding on the right time to trade is key to every successful trader as it can lead to either a huge gain of money or totally a loss in investment that will be recorded as a careless trade. The aim of this research is to develop a prediction system for stock market using Fuzzy Logic Type2 which will handle these uncertainties and complexities of human behaviour in general when it comes to buy, hold or sell decision making in stock trading. The proposed system was developed using VB.NET programming language as frontend and Microsoft SQL Server as backend. A total of four different technical indicators were selected for this research. The selected indicators are the Relative Strength Index, William Average, Moving Average Convergence and Divergence, and Stochastic Oscillator. These indicators serve as input variable to the Fuzzy System. The MACD and SO are deployed as primary indicators, while the RSI and WA are used as secondary indicators. Fibonacci retracement ratio was adopted for the secondary indicators to determine their support and resistance level in terms of making trading decisions. The input variables to the Fuzzy System is fuzzified to Low, Medium, and High using the Triangular and Gaussian Membership Function. The Mamdani Type Fuzzy Inference rules were used for combining the trading rules for each input variable to the fuzzy system. The developed system was tested using sample data collected from ten different companies listed on the Nigerian Stock Exchange for a total of fifty two periods. The dataset collected are Opening, High, Low, and Closing prices of each security.", "link": "http://arxiv.org/abs/2202.02107v1"}, {"index": 320, "title": "An Exploratory Study of Stock Price Movements from Earnings Calls", "abstract": "Financial market analysis has focused primarily on extracting signals from accounting, stock price, and other numerical hard data reported in P&L statements or earnings per share reports. Yet, it is well-known that the decision-makers routinely use soft text-based documents that interpret the hard data they narrate. Recent advances in computational methods for analyzing unstructured and soft text-based data at scale offer possibilities for understanding financial market behavior that could improve investments and market equity. A critical and ubiquitous form of soft data are earnings calls. Earnings calls are periodic (often quarterly) statements usually by CEOs who attempt to influence investors' expectations of a company's past and future performance. Here, we study the statistical relationship between earnings calls, company sales, stock performance, and analysts' recommendations. Our study covers a decade of observations with approximately 100,000 transcripts of earnings calls from 6,300 public companies from January 2010 to December 2019. In this study, we report three novel findings. First, the buy, sell and hold recommendations from professional analysts made prior to the earnings have low correlation with stock price movements after the earnings call. Second, using our graph neural network based method that processes the semantic features of earnings calls, we reliably and accurately predict stock price movements in five major areas of the economy. Third, the semantic features of transcripts are more predictive of stock price movements than sales and earnings per share, i.e., traditional hard data in most of the cases.", "link": "http://arxiv.org/abs/2203.12460v1"}, {"index": 321, "title": "Comparative Study of Machine Learning Models for Stock Price Prediction", "abstract": "In this work, we apply machine learning techniques to historical stock prices to forecast future prices. To achieve this, we use recursive approaches that are appropriate for handling time series data. In particular, we apply a linear Kalman filter and different varieties of long short-term memory (LSTM) architectures to historical stock prices over a 10-year range (1/1/2011 - 1/1/2021). We quantify the results of these models by computing the error of the predicted values versus the historical values of each stock. We find that of the algorithms we investigated, a simple linear Kalman filter can predict the next-day value of stocks with low-volatility (e.g., Microsoft) surprisingly well. However, in the case of high-volatility stocks (e.g., Tesla) the more complex LSTM algorithms significantly outperform the Kalman filter. Our results show that we can classify different types of stocks and then train an LSTM for each stock type. This method could be used to automate portfolio generation for a target return rate.", "link": "http://arxiv.org/abs/2202.03156v1"}, {"index": 322, "title": "Impact of Gold Prices on Stock Exchange: An Empirical Case Study of Nepal", "abstract": "The purpose of this study is to examine the long-run relationship between gold prices and Nepal Stock Exchange (NEPSE).", "link": "http://arxiv.org/abs/2202.00007v1"}, {"index": 323, "title": "ReforesTree: A Dataset for Estimating Tropical Forest Carbon Stock with Deep Learning and Aerial Imagery", "abstract": "Forest biomass is a key influence for future climate, and the world urgently needs highly scalable financing schemes, such as carbon offsetting certifications, to protect and restore forests. Current manual forest carbon stock inventory methods of measuring single trees by hand are time, labour, and cost-intensive and have been shown to be subjective. They can lead to substantial overestimation of the carbon stock and ultimately distrust in forest financing. The potential for impact and scale of leveraging advancements in machine learning and remote sensing technologies is promising but needs to be of high quality in order to replace the current forest stock protocols for certifications.   In this paper, we present ReforesTree, a benchmark dataset of forest carbon stock in six agro-forestry carbon offsetting sites in Ecuador. Furthermore, we show that a deep learning-based end-to-end model using individual tree detection from low cost RGB-only drone imagery is accurately estimating forest carbon stock within official carbon offsetting certification standards. Additionally, our baseline CNN model outperforms state-of-the-art satellite-based forest biomass and carbon stock estimates for this type of small-scale, tropical agro-forestry sites. We present this dataset to encourage machine learning research in this area to increase accountability and transparency of monitoring, verification and reporting (MVR) in carbon offsetting projects, as well as scaling global reforestation financing through accurate remote sensing.", "link": "http://arxiv.org/abs/2201.11192v1"}, {"index": 324, "title": "Machine Learning for Stock Prediction Based on Fundamental Analysis", "abstract": "Application of machine learning for stock prediction is attracting a lot of attention in recent years. A large amount of research has been conducted in this area and multiple existing results have shown that machine learning methods could be successfully used toward stock predicting using stocks historical data. Most of these existing approaches have focused on short term prediction using stocks historical price and technical indicators. In this paper, we prepared 22 years worth of stock quarterly financial data and investigated three machine learning algorithms: Feed-forward Neural Network (FNN), Random Forest (RF) and Adaptive Neural Fuzzy Inference System (ANFIS) for stock prediction based on fundamental analysis. In addition, we applied RF based feature selection and bootstrap aggregation in order to improve model performance and aggregate predictions from different models. Our results show that RF model achieves the best prediction results, and feature selection is able to improve test performance of FNN and ANFIS. Moreover, the aggregated model outperforms all baseline models as well as the benchmark DJIA index by an acceptable margin for the test period. Our findings demonstrate that machine learning models could be used to aid fundamental analysts with decision-making regarding stock investment.", "link": "http://dx.doi.org/10.1109/SSCI50451.2021.9660134"}, {"index": 325, "title": "Modeling bid and ask price dynamics with an extended Hawkes process and its empirical applications for high-frequency stock market data", "abstract": "This study proposes a versatile model for the dynamics of the best bid and ask prices using an extended Hawkes process. The model incorporates the zero intensities of the spread-narrowing processes at the minimum bid-ask spread, spread-dependent intensities, possible negative excitement, and nonnegative intensities. We apply the model to high-frequency best bid and ask price data from US stock markets. The empirical findings demonstrate a spread-narrowing tendency, excitations of the intensities caused by previous events, the impact of flash crashes, characteristic trends in fast trading over time, and the different features of market participants in the various exchanges.", "link": "http://dx.doi.org/10.1093/jjfinec/nbab029"}, {"index": 326, "title": "Predicting The Stock Trend Using News Sentiment Analysis and Technical Indicators in Spark", "abstract": "Predicting the stock market trend has always been challenging since its movement is affected by many factors. Here, we approach the future trend prediction problem as a machine learning classification problem by creating tomorrow_trend feature as our label to be predicted. Different features are given to help the machine learning model predict the label of a given day; whether it is an uptrend or downtrend, those features are technical indicators generated from the stock's price history. In addition, as financial news plays a vital role in changing the investor's behavior, the overall sentiment score on a given day is created from all news released on that day and added to the model as another feature. Three different machine learning models are tested in Spark (big-data computing platform), Logistic Regression, Random Forest, and Gradient Boosting Machine. Random Forest was the best performing model with a 63.58% test accuracy.", "link": "http://arxiv.org/abs/2201.12283v1"}, {"index": 327, "title": "A Stock Trading System for a Medium Volatile Asset using Multi Layer Perceptron", "abstract": "Stock market forecasting is a lucrative field of interest with promising profits but not without its difficulties and for some people could be even causes of failure. Financial markets by their nature are complex, non-linear and chaotic, which implies that accurately predicting the prices of assets that are part of it becomes very complicated. In this paper we propose a stock trading system having as main core the feed-forward deep neural networks (DNN) to predict the price for the next 30 days of open market, of the shares issued by Abercrombie & Fitch Co. (ANF) in the stock market of the New York Stock Exchange (NYSE).   The system we have elaborated calculates the most effective technical indicator, applying it to the predictions computed by the DNNs, for generating trades. The results showed an increase in values such as Expectancy Ratio of 2.112% of profitable trades with Sharpe, Sortino, and Calmar Ratios of 2.194, 3.340, and 12.403 respectively. As a verification, we adopted a backtracking simulation module in our system, which maps trades to actual test data consisting of the last 30 days of open market on the ANF asset. Overall, the results were promising bringing a total profit factor of 3.2% in just one month from a very modest budget of $100. This was possible because the system reduced the number of trades by choosing the most effective and efficient trades, saving on commissions and slippage costs.", "link": "http://arxiv.org/abs/2201.12286v1"}, {"index": 328, "title": "How easy is it for investment managers to deploy their talent in green and brown stocks?", "abstract": "We explore the realized alpha-performance heterogeneity in green and brown stocks' universes using the peer performance ratios of Ardia and Boudt (2018). Focusing on S&P 500 index firms over 2014-2020 and defining peer groups in terms of firms' greenhouse gas emission levels, we find that, on average, about 20% of the stocks differentiate themselves from their peers in terms of future performance. We see a much higher time-variation in this opportunity set within brown stocks. Furthermore, the performance heterogeneity has decreased over time, especially for green stocks, implying that it is now more difficult for investment managers to deploy their skills when choosing among low-GHG intensity stocks.", "link": "http://dx.doi.org/10.1016/j.frl.2022.102992"}, {"index": 329, "title": "Precise Stock Price Prediction for Robust Portfolio Design from Selected Sectors of the Indian Stock Market", "abstract": "Stock price prediction is a challenging task and a lot of propositions exist in the literature in this area. Portfolio construction is a process of choosing a group of stocks and investing in them optimally to maximize the return while minimizing the risk. Since the time when Markowitz proposed the Modern Portfolio Theory, several advancements have happened in the area of building efficient portfolios. An investor can get the best benefit out of the stock market if the investor invests in an efficient portfolio and could take the buy or sell decision in advance, by estimating the future asset value of the portfolio with a high level of precision. In this project, we have built an efficient portfolio and to predict the future asset value by means of individual stock price prediction of the stocks in the portfolio. As part of building an efficient portfolio we have studied multiple portfolio optimization methods beginning with the Modern Portfolio theory. We have built the minimum variance portfolio and optimal risk portfolio for all the five chosen sectors by using past daily stock prices over the past five years as the training data, and have also conducted back testing to check the performance of the portfolio. A comparative study of minimum variance portfolio and optimal risk portfolio with equal weight portfolio is done by backtesting.", "link": "http://arxiv.org/abs/2201.05570v1"}, {"index": 330, "title": "Strategic mean-variance investing under mean-reverting stock returns", "abstract": "In this report we derive the strategic (deterministic) allocation to bonds and stocks resulting in the optimal mean-variance trade-off on a given investment horizon. The underlying capital market features a mean-reverting process for equity returns, and the primary question of interest is how mean-reversion effects the optimal strategy and the resulting portfolio value at the horizon. In particular, we are interested in knowing under which assumptions and on which horizons, the risk-reward trade-off is so favourable that the value of the portfolio is effectively bounded from below on the horizon. In this case, we might think of the portfolio as providing a stochastic excess return on top of a \"guarantee\" (the lower bound).   Deriving optimal strategies is a well-known discipline in mathematical finance. The modern approach is to derive and solve the Hamilton-Jacobi-Bellman (HJB) differential equation characterizing the strategy leading to highest expected utility, for given utility function. However, for two reasons we approach the problem differently in this work. First, we wish to find the optimal strategy depending on time only, i.e., we do not allow for dependencies on capital market state variables, nor the value of the portfolio itself. This constraint characterizes the strategic allocation of long-term investors. Second, to gain insights on the role of mean-reversion, we wish to identify the entire family of extremal strategies, not only the optimal strategies. To derive the strategies we employ methods from calculus of variations, rather than the usual HJB approach.", "link": "http://arxiv.org/abs/2201.05375v1"}, {"index": 331, "title": "Stock Movement Prediction Based on Bi-typed Hybrid-relational Market Knowledge Graph via Dual Attention Networks", "abstract": "Stock Movement Prediction (SMP) aims at predicting listed companies' stock future price trend, which is a challenging task due to the volatile nature of financial markets. Recent financial studies show that the momentum spillover effect plays a significant role in stock fluctuation. However, previous studies typically only learn the simple connection information among related companies, which inevitably fail to model complex relations of listed companies in the real financial market. To address this issue, we first construct a more comprehensive Market Knowledge Graph (MKG) which contains bi-typed entities including listed companies and their associated executives, and hybrid-relations including the explicit relations and implicit relations. Afterward, we propose DanSmp, a novel Dual Attention Networks to learn the momentum spillover signals based upon the constructed MKG for stock prediction. The empirical experiments on our constructed datasets against nine SOTA baselines demonstrate that the proposed DanSmp is capable of improving stock prediction with the constructed MKG.", "link": "http://arxiv.org/abs/2201.04965v2"}, {"index": 332, "title": "The Interpretability of LSTM Models for Predicting Oil Company Stocks: Impact of Correlated Features", "abstract": "Oil companies are among the largest companies in the world whose economic indicators in the global stock market have a great impact on the world economy\\cite{ec00} and market due to their relation to gold\\cite{ec01}, crude oil\\cite{ec02}, and the dollar\\cite{ec03}. This study investigates the impact of correlated features on the interpretability of Long Short-Term Memory(LSTM)\\cite{ec04} models for predicting oil company stocks. To achieve this, we designed a Standard Long Short-Term Memory (LSTM) network and trained it using various correlated datasets. Our approach aims to improve the accuracy of stock price prediction by considering the multiple factors affecting the market, such as crude oil prices, gold prices, and the US dollar. The results demonstrate that adding a feature correlated with oil stocks does not improve the interpretability of LSTM models. These findings suggest that while LSTM models may be effective in predicting stock prices, their interpretability may be limited. Caution should be exercised when relying solely on LSTM models for stock price prediction as their lack of interpretability may make it difficult to fully understand the underlying factors driving stock price movements. We have employed complexity analysis to support our argument, considering that financial markets encompass a form of physical complex system\\cite{ec05}. One of the fundamental challenges faced in utilizing LSTM models for financial markets lies in interpreting the unexpected feedback dynamics within them.", "link": "http://arxiv.org/abs/2201.00350v5"}, {"index": 333, "title": "Improving Nonparametric Classification via Local Radial Regression with an Application to Stock Prediction", "abstract": "For supervised classification problems, this paper considers estimating the query's label probability through local regression using observed covariates. Well-known nonparametric kernel smoother and $k$-nearest neighbor ($k$-NN) estimator, which take label average over a ball around the query, are consistent but asymptotically biased particularly for a large radius of the ball. To eradicate such bias, local polynomial regression (LPoR) and multiscale $k$-NN (MS-$k$-NN) learn the bias term by local regression around the query and extrapolate it to the query itself. However, their theoretical optimality has been shown for the limit of the infinite number of training samples. For correcting the asymptotic bias with fewer observations, this paper proposes a \\emph{local radial regression (LRR)} and its logistic regression variant called \\emph{local radial logistic regression~(LRLR)}, by combining the advantages of LPoR and MS-$k$-NN. The idea is quite simple: we fit the local regression to observed labels by taking only the radial distance as the explanatory variable and then extrapolate the estimated label probability to zero distance. The usefulness of the proposed method is shown theoretically and experimentally. We prove the convergence rate of the $L^2$ risk for LRR with reference to MS-$k$-NN, and our numerical experiments, including real-world datasets of daily stock indices, demonstrate that LRLR outperforms LPoR and MS-$k$-NN.", "link": "http://arxiv.org/abs/2112.13951v2"}, {"index": 334, "title": "Multi-modal Attention Network for Stock Movements Prediction", "abstract": "Stock prices move as piece-wise trending fluctuation rather than a purely random walk. Traditionally, the prediction of future stock movements is based on the historical trading record. Nowadays, with the development of social media, many active participants in the market choose to publicize their strategies, which provides a window to glimpse over the whole market's attitude towards future movements by extracting the semantics behind social media. However, social media contains conflicting information and cannot replace historical records completely. In this work, we propose a multi-modality attention network to reduce conflicts and integrate semantic and numeric features to predict future stock movements comprehensively. Specifically, we first extract semantic information from social media and estimate their credibility based on posters' identity and public reputation. Then we incorporate the semantic from online posts and numeric features from historical records to make the trading strategy. Experimental results show that our approach outperforms previous methods by a significant margin in both prediction accuracy (61.20\\%) and trading profits (9.13\\%). It demonstrates that our method improves the performance of stock movements prediction and informs future research on multi-modality fusion towards stock prediction.", "link": "http://arxiv.org/abs/2112.13593v5"}, {"index": 335, "title": "Stationarity analysis of the stock market data and its application to mechanical trading", "abstract": "This study proposes a scheme for stationarity analysis of stock price fluctuations based on KM$_2$O-Langevin theory. Using this scheme, we classify the time-series data of stock price fluctuations into three periods: stationary, non-stationary, and intermediate. We then suggest an example of a low-risk stock trading strategy to demonstrate the usefulness of our scheme by using actual stock index data. Our strategy uses a trend-based indicator, moving averages, for stationary periods and an oscillator-based indicator, psychological lines, for non-stationary periods to make trading decisions. Finally, we confirm that our strategy is a safe trading strategy with small maximum drawdown by back testing on the Nikkei Stock Average. Our study, the first to apply the stationarity analysis of KM$_2$O-Langevin theory to actual mechanical trading, opens up new avenues for stock price prediction.", "link": "http://arxiv.org/abs/2112.12459v3"}, {"index": 336, "title": "Stock prices and Macroeconomic indicators: Investigating a correlation in Indian context", "abstract": "The objective of this paper is to find the existence of a relationship between stock market prices and the fundamental macroeconomic indicators. We build a Vector Auto Regression (VAR) model comprising of nine major macroeconomic indicators (interest rate, inflation, exchange rate, money supply, gdp, fdi, trade-gdp ratio, oil prices, gold prices) and then try to forecast them for next 5 years. Finally we calculate cross-correlation of these forecasted values with the BSE Sensex closing price for each of those years. We find very high correlation of the closing price with exchange rate and money supply in the Indian economy.", "link": "http://arxiv.org/abs/2112.08071v2"}, {"index": 337, "title": "Lunatic Stocks: Moon Phases as Irregular Sampling Features for Pattern Recognition in the Stock Markets", "abstract": "This paper presents a novel idea on incorporating the Moon phases to the classic Gregorian (Solar) calendar time sampling methods for finding meaningful patterns in the stock markets. The four main Moon phases (New Moon, First quarter, Full Moon and Third quarter) are irregular in time but with well defined sampling structure as the Moon orbits the Earth completing its period. A Full Moon may appear in one month of the year on the 2nd, on the next month the Full moon may appear on the 4th and in the next ten years on the 13th of the same month. This structure which is irregular in time makes it interesting to study together with the stock market data. Moreover, the moon affects multiple physical things on the earth, such as the ocean tides, the behavior of living organisms as well as humans mood and decision when risking and investing.", "link": "http://arxiv.org/abs/2112.15426v1"}, {"index": 338, "title": "Mesoscopic Structure of the Stock Market and Portfolio Optimization", "abstract": "The idiosyncratic (microscopic) and systemic (macroscopic) components of market structure have been shown to be responsible for the departure of the optimal mean-variance allocation from the heuristic `equally-weighted' portfolio. In this paper, we exploit clustering techniques derived from Random Matrix Theory (RMT) to study a third, intermediate (mesoscopic) market structure that turns out to be the most stable over time and provides important practical insights from a portfolio management perspective. First, we illustrate the benefits, in terms of predicted and realized risk profiles, of constructing portfolios by filtering out both random and systemic co-movements from the correlation matrix. Second, we redefine the portfolio optimization problem in terms of stock clusters that emerge after filtering. Finally, we propose a new wealth allocation scheme that attaches equal importance to stocks belonging to the same community and show that it further increases the reliability of the constructed portfolios. Results are robust across different time spans, cross-sectional dimensions and set of constraints defining the optimization problem", "link": "http://arxiv.org/abs/2112.06544v1"}, {"index": 339, "title": "COVID-19 Forecasts via Stock Market Indicators", "abstract": "Reliable short term forecasting can provide potentially lifesaving insights into logistical planning, and in particular, into the optimal allocation of resources such as hospital staff and equipment. By reinterpreting COVID-19 daily cases in terms of candlesticks, we are able to apply some of the most popular stock market technical indicators to obtain predictive power over the course of the pandemics. By providing a quantitative assessment of MACD, RSI, and candlestick analyses, we show their statistical significance in making predictions for both stock market data and WHO COVID-19 data. In particular, we show the utility of this novel approach by considering the identification of the beginnings of subsequent waves of the pandemic. Finally, our new methods are used to assess whether current health policies are impacting the growth in new COVID-19 cases.", "link": "http://arxiv.org/abs/2112.06393v1"}, {"index": 340, "title": "A q-spin Potts model of markets: Gain-loss asymmetry in stock indices as an emergent phenomenon", "abstract": "Spin models of markets inspired by physics models of magnetism, as the Ising model, allow for the study of the collective dynamics of interacting agents in a market. The number of possible states has been mostly limited to two (buy or sell) or three options. However, herding effects of competing stocks and the collective dynamics of a whole market may escape our reach in the simplest models. Here I study a q-spin Potts model version of a simple Ising market model to represent the dynamics of a stock market index in a spin model. As a result, a self-organized gain-loss asymmetry in the time series of an index variable composed of stocks in this market is observed.", "link": "http://arxiv.org/abs/2112.06290v1"}, {"index": 341, "title": "High-Dimensional Stock Portfolio Trading with Deep Reinforcement Learning", "abstract": "This paper proposes a Deep Reinforcement Learning algorithm for financial portfolio trading based on Deep Q-learning. The algorithm is capable of trading high-dimensional portfolios from cross-sectional datasets of any size which may include data gaps and non-unique history lengths in the assets. We sequentially set up environments by sampling one asset for each environment while rewarding investments with the resulting asset's return and cash reservation with the average return of the set of assets. This enforces the agent to strategically assign capital to assets that it predicts to perform above-average. We apply our methodology in an out-of-sample analysis to 48 US stock portfolio setups, varying in the number of stocks from ten up to 500 stocks, in the selection criteria and in the level of transaction costs. The algorithm on average outperforms all considered passive and active benchmark investment strategies by a large margin using only one hyperparameter setup for all portfolios.", "link": "http://arxiv.org/abs/2112.04755v1"}, {"index": 342, "title": "Deep Q-Learning Market Makers in a Multi-Agent Simulated Stock Market", "abstract": "Market makers play a key role in financial markets by providing liquidity. They usually fill order books with buy and sell limit orders in order to provide traders alternative price levels to operate. This paper focuses precisely on the study of these markets makers strategies from an agent-based perspective. In particular, we propose the application of Reinforcement Learning (RL) for the creation of intelligent market markers in simulated stock markets. This research analyzes how RL market maker agents behaves in non-competitive (only one RL market maker learning at the same time) and competitive scenarios (multiple RL market markers learning at the same time), and how they adapt their strategies in a Sim2Real scope with interesting results. Furthermore, it covers the application of policy transfer between different experiments, describing the impact of competing environments on RL agents performance. RL and deep RL techniques are proven as profitable market maker approaches, leading to a better understanding of their behavior in stock markets.", "link": "http://dx.doi.org/10.1145/3490354.3494448"}, {"index": 343, "title": "ESAN: Efficient Sentiment Analysis Network of A-Shares Research Reports for Stock Price Prediction", "abstract": "In this paper, we are going to develop a natural language processing model to help us to predict stocks in the long term. The whole network includes two modules. The first module is a natural language processing model which seeks out reliable factors from input reports. While the other is a time-series forecasting model which takes the factors as input and aims to predict stocks earnings yield. To indicate the efficiency of our model to combine the sentiment analysis module and the time-series forecasting module, we name our method ESAN.", "link": "http://arxiv.org/abs/2112.11444v1"}, {"index": 344, "title": "Optimal Portfolio Choice and Stock Centrality for Tail Risk Events", "abstract": "We propose a novel risk matrix to characterize the optimal portfolio choice of an investor with tail concerns. The diagonal of the matrix contains the Value-at-Risk of each asset in the portfolio and the off-diagonal the pairwise Delta-CoVaR measures reflecting tail connections between assets. First, we derive the conditions under which the associated quadratic risk function has a closed-form solution. Second, we examine the relationship between portfolio risk and eigenvector centrality. Third, we show that portfolio risk is not necessarily increasing with respect to stock centrality. Forth, we demonstrate under certain conditions that asset centrality increases the optimal weight allocation of the asset to the portfolio. Overall, our empirical study indicates that a network topology which exhibits low connectivity is outperformed by high connectivity based on a Sharpe ratio test.", "link": "http://arxiv.org/abs/2112.12031v1"}, {"index": 345, "title": "Generative Adversarial Network (GAN) and Enhanced Root Mean Square Error (ERMSE): Deep Learning for Stock Price Movement Prediction", "abstract": "The prediction of stock price movement direction is significant in financial circles and academic. Stock price contains complex, incomplete, and fuzzy information which makes it an extremely difficult task to predict its development trend. Predicting and analysing financial data is a nonlinear, time-dependent problem. With rapid development in machine learning and deep learning, this task can be performed more effectively by a purposely designed network. This paper aims to improve prediction accuracy and minimizing forecasting error loss through deep learning architecture by using Generative Adversarial Networks. It was proposed a generic model consisting of Phase-space Reconstruction (PSR) method for reconstructing price series and Generative Adversarial Network (GAN) which is a combination of two neural networks which are Long Short-Term Memory (LSTM) as Generative model and Convolutional Neural Network (CNN) as Discriminative model for adversarial training to forecast the stock market. LSTM will generate new instances based on historical basic indicators information and then CNN will estimate whether the data is predicted by LSTM or is real. It was found that the Generative Adversarial Network (GAN) has performed well on the enhanced root mean square error to LSTM, as it was 4.35% more accurate in predicting the direction and reduced processing time and RMSE by 78 secs and 0.029, respectively. This study provides a better result in the accuracy of the stock index. It seems that the proposed system concentrates on minimizing the root mean square error and processing time and improving the direction prediction accuracy, and provides a better result in the accuracy of the stock index.", "link": "http://dx.doi.org/10.1007/s11042-021-11670-w"}, {"index": 346, "title": "Improved Method of Stock Trading under Reinforcement Learning Based on DRQN and Sentiment Indicators ARBR", "abstract": "With the application of artificial intelligence in the financial field, quantitative trading is considered to be profitable. Based on this, this paper proposes an improved deep recurrent DRQN-ARBR model because the existing quantitative trading model ignores the impact of irrational investor behavior on the market, making the application effect poor in an environment where the stock market in China is non-efficiency. By changing the fully connected layer in the original model to the LSTM layer and using the emotion indicator ARBR to construct a trading strategy, this model solves the problems of the traditional DQN model with limited memory for empirical data storage and the impact of observable Markov properties on performance. At the same time, this paper also improved the shortcomings of the original model with fewer stock states and chose more technical indicators as the input values of the model. The experimental results show that the DRQN-ARBR algorithm proposed in this paper can significantly improve the performance of reinforcement learning in stock trading.", "link": "http://arxiv.org/abs/2111.15356v1"}, {"index": 347, "title": "Effect of the U.S.--China Trade War on Stock Markets: A Financial Contagion Perspective", "abstract": "In this paper, we investigate the effect of the U.S.--China trade war on stock markets from a financial contagion perspective, based on high-frequency financial data. Specifically, to account for risk contagion between the U.S. and China stock markets, we develop a novel jump-diffusion process. For example, we consider three channels for volatility contagion--such as integrated volatility, positive jump variation, and negative jump variation--and each stock market is able to affect the other stock market as an overnight risk factor. We develop a quasi-maximum likelihood estimator for model parameters and establish its asymptotic properties. Furthermore, to identify contagion channels and test the existence of a structural break, we propose hypothesis test procedures. From the empirical study, we find evidence of financial contagion from the U.S. to China and evidence that the risk contagion channel has changed from integrated volatility to negative jump variation.", "link": "http://arxiv.org/abs/2111.09655v1"}, {"index": 348, "title": "A Multi-criteria Approach to Evolve Sparse Neural Architectures for Stock Market Forecasting", "abstract": "This study proposes a new framework to evolve efficacious yet parsimonious neural architectures for the movement prediction of stock market indices using technical indicators as inputs. In the light of a sparse signal-to-noise ratio under the Efficient Market hypothesis, developing machine learning methods to predict the movement of a financial market using technical indicators has shown to be a challenging problem. To this end, the neural architecture search is posed as a multi-criteria optimization problem to balance the efficacy with the complexity of architectures. In addition, the implications of different dominant trading tendencies which may be present in the pre-COVID and within-COVID time periods are investigated. An $\\epsilon-$ constraint framework is proposed as a remedy to extract any concordant information underlying the possibly conflicting pre-COVID data. Further, a new search paradigm, Two-Dimensional Swarms (2DS) is proposed for the multi-criteria neural architecture search, which explicitly integrates sparsity as an additional search dimension in particle swarms. A detailed comparative evaluation of the proposed approach is carried out by considering genetic algorithm and several combinations of empirical neural design rules with a filter-based feature selection method (mRMR) as baseline approaches. The results of this study convincingly demonstrate that the proposed approach can evolve parsimonious networks with better generalization capabilities.", "link": "http://arxiv.org/abs/2111.08060v1"}, {"index": 349, "title": "Profit warnings and stock returns: Evidence from moroccan stock exchange", "abstract": "There is an important literature focused on profit warnings and its impact on stock returns. We provide evidence from Moroccan stock market which aims to become an African financial hub. Despite this practical improvement, academic researches that focused on this market are scarce and our study is a first investigation in this context. Using the event study methodology and a sample of companies listed in Casablanca Stock Exchange for the period of 2009 to 2016, we examined whether the effect of qualitative warning is more negative compared to quantitative warnings in a short event window. Our empirical findings show that the average abnormal return on the date of announcement is negative and statistically significant. The magnitude of this negative abnormal return is greater for qualitative warnings than quantitative ones.", "link": "http://arxiv.org/abs/2111.06655v1"}, {"index": 350, "title": "Analysis of Sectoral Profitability of the Indian Stock Market Using an LSTM Regression Model", "abstract": "Predictive model design for accurately predicting future stock prices has always been considered an interesting and challenging research problem. The task becomes complex due to the volatile and stochastic nature of the stock prices in the real world which is affected by numerous controllable and uncontrollable variables. This paper presents an optimized predictive model built on long-and-short-term memory (LSTM) architecture for automatically extracting past stock prices from the web over a specified time interval and predicting their future prices for a specified forecast horizon, and forecasts the future stock prices. The model is deployed for making buy and sell transactions based on its predicted results for 70 important stocks from seven different sectors listed in the National Stock Exchange (NSE) of India. The profitability of each sector is derived based on the total profit yielded by the stocks in that sector over a period from Jan 1, 2010 to Aug 26, 2021. The sectors are compared based on their profitability values. The prediction accuracy of the model is also evaluated for each sector. The results indicate that the model is highly accurate in predicting future stock prices.", "link": "http://arxiv.org/abs/2111.04976v1"}, {"index": 351, "title": "Stock Portfolio Optimization Using a Deep Learning LSTM Model", "abstract": "Predicting future stock prices and their movement patterns is a complex problem. Hence, building a portfolio of capital assets using the predicted prices to achieve the optimization between its return and risk is an even more difficult task. This work has carried out an analysis of the time series of the historical prices of the top five stocks from the nine different sectors of the Indian stock market from January 1, 2016, to December 31, 2020. Optimum portfolios are built for each of these sectors. For predicting future stock prices, a long-and-short-term memory (LSTM) model is also designed and fine-tuned. After five months of the portfolio construction, the actual and the predicted returns and risks of each portfolio are computed. The predicted and the actual returns of each portfolio are found to be high, indicating the high precision of the LSTM model.", "link": "http://dx.doi.org/10.1109/MysuruCon52639.2021.9641662"}, {"index": 352, "title": "Data-driven Hedging of Stock Index Options via Deep Learning", "abstract": "We develop deep learning models to learn the hedge ratio for S&P500 index options directly from options data. We compare different combinations of features and show that a feedforward neural network model with time to maturity, Black-Scholes delta and a sentiment variable (VIX for calls and index return for puts) as input features performs the best in the out-of-sample test. This model significantly outperforms the standard hedging practice that uses the Black-Scholes delta and a recent data-driven model. Our results demonstrate the importance of market sentiment for hedging efficiency, a factor previously ignored in developing hedging strategies.", "link": "http://arxiv.org/abs/2111.03477v1"}, {"index": 353, "title": "Structural Breaks in Interactive Effects Panels and the Stock Market Reaction to COVID-19", "abstract": "Dealing with structural breaks is an important step in most, if not all, empirical economic research. This is particularly true in panel data comprised of many cross-sectional units, such as individuals, firms or countries, which are all affected by major events. The COVID-19 pandemic has affected most sectors of the global economy, and there is by now plenty of evidence to support this. The impact on stock markets is, however, still unclear. The fact that most markets seem to have partly recovered while the pandemic is still ongoing suggests that the relationship between stock returns and COVID-19 has been subject to structural change. It is therefore important to know if a structural break has occurred and, if it has, to infer the date of the break. In the present paper we take this last observation as a source of motivation to develop a new break detection toolbox that is applicable to different sized panels, easy to implement and robust to general forms of unobserved heterogeneity. The toolbox, which is the first of its kind, includes a test for structural change, a break date estimator, and a break date confidence interval. Application to a panel covering 61 countries from January 3 to September 25, 2020, leads to the detection of a structural break that is dated to the first week of April. The effect of COVID-19 is negative before the break and zero thereafter, implying that while markets did react, the reaction was short-lived. A possible explanation for this is the quantitative easing programs announced by central banks all over the world in the second half of March.", "link": "http://arxiv.org/abs/2111.03035v1"}, {"index": 354, "title": "Stochastic simulation of residential building occupant-driven energy use in a bottom-up model of the U.S. housing stock", "abstract": "The residential buildings sector is one of the largest electricity consumers worldwide and contributes disproportionally to peak electricity demand in many regions. Strongly driven by occupant activities at home, household energy consumption is stochastic and heterogeneous in nature. However, most residential building energy models applied by industry use homogeneous, deterministic occupant activity schedules, which work well for predictions of annual energy consumption, but can result in unrealistic hourly or sub-hourly electric load profiles, with exaggerated or muted peaks. This mattered less in the past, but the increasing proportion of variable renewable energy generators in power systems means that representing the heterogeneity and stochasticity of occupant behavior is crucial for reliable energy planning. This is particularly true for systems that include distributed energy resources, such as grid-interactive efficient buildings, solar photovoltaics, and battery storage. This work presents a stochastic occupant behavior simulator that models the energy use behavior of individual household members. It also presents an integration with a building stock model to simulate residential building loads more accurately at community, city, state, and national scales. More specifically, we first employ clustering techniques to identify distinct patterns of occupant behavior. Then, we combine time-inhomogeneous Markov chain simulations with probabilistic sampling of event durations to realistically simulate occupant behaviors. This stochastic simulator is integrated with ResStock, a large-scale residential building stock simulation tool, to demonstrate the capability of stochastic residential building load modeling at scale. The simulation results were validated against both American Time Use Survey data and measured end-use electricity data for accuracy and reliability.", "link": "http://arxiv.org/abs/2111.01881v2"}, {"index": 355, "title": "Stock Price Prediction Using Time Series, Econometric, Machine Learning, and Deep Learning Models", "abstract": "For a long-time, researchers have been developing a reliable and accurate predictive model for stock price prediction. According to the literature, if predictive models are correctly designed and refined, they can painstakingly and faithfully estimate future stock values. This paper demonstrates a set of time series, econometric, and various learning-based models for stock price prediction. The data of Infosys, ICICI, and SUN PHARMA from the period of January 2004 to December 2019 was used here for training and testing the models to know which model performs best in which sector. One time series model (Holt-Winters Exponential Smoothing), one econometric model (ARIMA), two machine Learning models (Random Forest and MARS), and two deep learning-based models (simple RNN and LSTM) have been included in this paper. MARS has been proved to be the best performing machine learning model, while LSTM has proved to be the best performing deep learning model. But overall, for all three sectors - IT (on Infosys data), Banking (on ICICI data), and Health (on SUN PHARMA data), MARS has proved to be the best performing model in sales forecasting.", "link": "http://dx.doi.org/10.1109/MysuruCon52639.2021.9641610"}, {"index": 356, "title": "Strong solution of modified 3D-Navier-stockes equations", "abstract": "In this paper we study the incompressible Navier-Stokes equations with logarithme damping {\\alpha} log(e + |u|2)|u|2u, where we used new methods, new tools and Fourier analysis", "link": "http://arxiv.org/abs/2111.00859v2"}, {"index": 357, "title": "HIST: A Graph-based Framework for Stock Trend Forecasting via Mining Concept-Oriented Shared Information", "abstract": "Stock trend forecasting, which forecasts stock prices' future trends, plays an essential role in investment. The stocks in a market can share information so that their stock prices are highly correlated. Several methods were recently proposed to mine the shared information through stock concepts (e.g., technology, Internet Retail) extracted from the Web to improve the forecasting results. However, previous work assumes the connections between stocks and concepts are stationary, and neglects the dynamic relevance between stocks and concepts, limiting the forecasting results. Moreover, existing methods overlook the invaluable shared information carried by hidden concepts, which measure stocks' commonness beyond the manually defined stock concepts. To overcome the shortcomings of previous work, we proposed a novel stock trend forecasting framework that can adequately mine the concept-oriented shared information from predefined concepts and hidden concepts. The proposed framework simultaneously utilize the stock's shared information and individual information to improve the stock trend forecasting performance. Experimental results on the real-world tasks demonstrate the efficiency of our framework on stock trend forecasting. The investment simulation shows that our framework can achieve a higher investment return than the baselines.", "link": "http://arxiv.org/abs/2110.13716v2"}, {"index": 358, "title": "Stock exchange shares ranking and binary-ternary compressive coding", "abstract": "This paper proposes a method for ranking the investment attractiveness of exchange-traded stocks where investment risk is not related to the volatility indicator but instead is related to the indicator of compression of the time series of price changes. The article describes in detail the ranking algorithm, provides an example of ranking the shares of all companies included in the Dow Jones stock index. The paper additionally compares the results of ranking these stocks by volatility and compression and also shows the strengths of the second indicator, which is formed using the method of binary-ternary compression of historical financial data.", "link": "http://arxiv.org/abs/2201.11507v1"}, {"index": 359, "title": "Media abnormal tone, earnings announcements, and the stock market", "abstract": "We conduct a tone-based event study to examine the aggregate abnormal tone dynamics in media articles around earnings announcements. We test whether they convey incremental information that is useful for price discovery for nonfinancial S&P 500 firms. The relation we find between the abnormal tone and abnormal returns suggests that media articles provide incremental information relative to the information contained in earnings press releases and earnings calls.", "link": "http://dx.doi.org/10.1016/j.finmar.2021.100683"}, {"index": 360, "title": "Brownian Motion & The Stochastic Behaviour of Stocks", "abstract": "We begin by exploring the intuition of Brownian motion by explaining its birth through the observations of Robert Brown and later through Bachelier's work on its applications to the financial market and finally its rigorous and concretized form proposed by Norbert Wiener. The aforementioned motivates a stochastic differential equation to model the future price fluctuations of a stock traded wherein It\\^o integration is prominent and consequently expanded upon. The final part of this paper focuses on the accuracy of the model by backtesting it with Apple stock and deriving a correlation coefficient.", "link": "http://arxiv.org/abs/2110.12001v1"}, {"index": 361, "title": "Exploring the Endogenous Nature of Meme Stocks Using the Log-Periodic Power Law Model and Confidence Indicator", "abstract": "This study examined the endogenous nature of negative bubbles forming in meme stocks with the Log-Periodic Power Law (LPPL) Confidence Indicator (CI). A meme stock is a stock that has gained a significant amount of attention on a large social media platform such as Yahoo! or Reddit. This study examined four meme stocks including Tesla, Inc. (TSLA), GameStop Corp. (GME), Koss Corporation (KOSS), and AMC Entertainment Holdings Inc (AMC). The CI was able to detect numerous bubbles forming in meme stocks, but had difficulty in significantly predicting social media-induced exogenous rallies. This may have been due to price movements affected by external causes such as short squeezes. However, the model did provide proof for the formation of previous bubbles that could have been a catalyst for the meme stocks rallies. This study outlines the real unpredictability of many black-swan events, and further studies could be done examining exogenous bubbles.", "link": "http://arxiv.org/abs/2110.06190v1"}, {"index": 362, "title": "Volumetric Dimensioning of Strategic Stock; SOP, a step further toward a better flow control", "abstract": "This paper is presenting a real case study. It focuses on a drug stock management problem within a Tunisian monopoly in drugs distribution, PCT. The commercial service aims to optimize the drug stock management and procurement while reducing drug shortage and cost of stock management and to have a clear vision on the estimation of the strategic stock of products. Precisely, I have investigated a set of the real depots dataset and the Tunisians hospitals depots of the country in particular. This analysis phase has yield to suggest some important actions, such as the drugs classification, the establishment of an adequate inventory policy for each drug family and the volumetric quantification of strategic stock.", "link": "http://arxiv.org/abs/2110.04201v1"}, {"index": 363, "title": "A sentiment-based modeling and analysis of stock price during the COVID-19: U- and Swoosh-shaped recovery", "abstract": "Recently, a stock price model is proposed by A. Mahata et al. [Physica A, 574, 126008 (2021)] to understand the effect of COVID-19 on stock market. It describes V- and L-shaped recovery of the stocks and indices, but fails to simulate the U- and Swoosh-shaped recovery that arises due to sharp crisis and prolong drop followed by quick recovery (U-shaped) or slow recovery for longer period (Swoosh-shaped recovery). We propose a modified model by introducing a new variable $\\theta$ that quantifies the sentiment of the investors. $\\theta=+1,~0,~-1$ for positive, neutral and negative sentiment, respectively. The model explains the movement of sectoral indices with positive $\\phi$ showing U- and Swoosh-shaped recovery. The simulation using synthetic fund-flow ($\\Psi_{st}$) with different shock lengths ($T_S$), $\\phi$, negative sentiment period ($T_N$) and portion of fund-flow ($\\lambda$) during recovery period show U- and Swoosh-shaped recovery. The results show that the recovery of the indices with positive $\\phi$ becomes very weak with the extended $T_S$ and $T_N$. The stocks with higher $\\phi$ and $\\lambda$ recover quickly. The simulation of the Nifty Bank, Nifty Financial and Nifty Realty show U-shaped recovery and Nifty IT shows Swoosh-shaped recovery. The simulation result is consistent with the real stock price movement. The time-scale ($\\tau$) of the shock and recovery of these indices during the COVID-19 are consistent with the time duration of the change of negative sentiment from the onset of the COVID-19. This study may help the investors to plan their investment during different crises.", "link": "http://dx.doi.org/10.1016/j.physa.2021.126810"}, {"index": 364, "title": "A New Multivariate Predictive Model for Stock Returns", "abstract": "One of the most important studies in finance is to find out whether stock returns could be predicted. This research aims to create a new multivariate model, which includes dividend yield, earnings-to-price ratio, book-to-market ratio as well as consumption-wealth ratio as explanatory variables, for future stock returns predictions. The new multivariate model will be assessed for its forecasting performance using empirical analysis. The empirical analysis is performed on S&P500 quarterly data from Quarter 1, 1952 to Quarter 4, 2019 as well as S&P500 monthly data from Month 12, 1920 to Month 12, 2019. Results have shown this new multivariate model has predictability for future stock returns. When compared to other benchmark models, the new multivariate model performs the best in terms of the Root Mean Squared Error (RMSE) most of the time.", "link": "http://arxiv.org/abs/2110.01873v1"}, {"index": 365, "title": "Stock Index Prediction using Cointegration test and Quantile Loss", "abstract": "Recent researches on stock prediction using deep learning methods has been actively studied. This is the task to predict the movement of stock prices in the future based on historical trends. The approach to predicting the movement based solely on the pattern of the historical movement of it on charts, not on fundamental values, is called the Technical Analysis, which can be divided into univariate and multivariate methods in the regression task. According to the latter approach, it is important to select different factors well as inputs to enhance the performance of the model. Moreover, its performance can depend on which loss is used to train the model. However, most studies tend to focus on building the structures of models, not on how to select informative factors as inputs to train them. In this paper, we propose a method that can get better performance in terms of returns when selecting informative factors using the cointegration test and learning the model using quantile loss. We compare the two RNN variants with quantile loss with only five factors obtained through the cointegration test among the entire 15 stock index factors collected in the experiment. The Cumulative return and Sharpe ratio were used to evaluate the performance of trained models. Our experimental results show that our proposed method outperforms the other conventional approaches.", "link": "http://arxiv.org/abs/2109.15045v1"}, {"index": 366, "title": "Stellar Population Astrophysics (SPA) with the TNG: Stock 2, a little-studied open cluster with an eMSTO", "abstract": "Stock 2 is a little-studied open cluster that shows an extended main-sequence turnoff (eMSTO). In order to investigate this phenomenon and characterise the cluster itself we performed high-resolution spectroscopy in the framework of the Stellar Population Astrophysics (SPA) project. We employed the High Accuracy Radial velocity Planet Searcher in North hemisphere spectrograph (HARPS-N) at the Telescopio Nazionale Galileo (TNG). We completed our observations with additional spectra taken with the Catania Astrophysical Observatory Spectrograph (CAOS). In total we observed 46 stars (dwarfs and giants), which represent, by far, the largest sample collected for this cluster to date. We provide the stellar parameters, extinction, radial and projected rotational velocities for most of the stars. Chemical abundances for 21 species with atomic numbers up to 56 have also been derived. We notice a differential reddening in the cluster field whose average value is 0.27 mag. It seems to be the main responsible for the observed eMSTO, since it cannot be explained as the result of different rotational velocities, as found in other clusters. We estimate an age for Stock 2 of 450$\\pm$150 Ma which corresponds to a MSTO stellar mass of $\\approx$2.8 M$_{\\odot}$. The cluster mean radial velocity is around 8.0 km s$^{-1}$. We find a solar-like metallicity for the cluster, [Fe/H]=$-$0.07$\\pm$0.06, compatible with its Galactocentric distance. MS stars and giants show chemical abundances compatible within the errors, with the exceptions of Barium and Strontium, which are clearly overabundant in giants, and Cobalt, which is only marginally overabundant. Finally, Stock 2 presents a chemical composition fully compatible with that observed in other open clusters of the Galactic thin disc.", "link": "http://dx.doi.org/10.1051/0004-6361/202141747"}, {"index": 367, "title": "The effects of random and seasonal environmental fluctuations on optimal harvesting and stocking", "abstract": "We analyze the harvesting and stocking of a population that is affected by random and seasonal environmental fluctuations. The main novelty comes from having three layers of environmental fluctuations. The first layer is due to the environment switching at random times between different environmental states. This is similar to having sudden environmental changes or catastrophes. The second layer is due to seasonal variation, where there is a significant change in the dynamics between seasons. Finally, the third layer is due to the constant presence of environmental stochasticity -- between the seasonal or random regime switches, the species is affected by fluctuations which can be modelled by white noise. This framework is more realistic because it can capture both significant random and deterministic environmental shifts as well as small and frequent fluctuations in abiotic factors. Our framework also allows for the price or cost of harvesting to change deterministically and stochastically, something that is more realistic from an economic point of view.   The combined effects of seasonal and random fluctuations make it impossible to find the optimal harvesting-stocking strategy analytically. We get around this roadblock by developing rigorous numerical approximations and proving that they converge to the optimal harvesting-stocking strategy. We apply our methods to multiple population models and explore how prices, or costs, and environmental fluctuations influence the optimal harvesting-stocking strategy. We show that in many situations the optimal way of harvesting and stocking is not of threshold type.", "link": "http://arxiv.org/abs/2109.13169v2"}, {"index": 368, "title": "A Reinforcement Learning Approach to the Stochastic Cutting Stock Problem", "abstract": "We propose a formulation of the stochastic cutting stock problem as a discounted infinite-horizon Markov decision process. At each decision epoch, given current inventory of items, an agent chooses in which patterns to cut objects in stock in anticipation of the unknown demand. An optimal solution corresponds to a policy that associates each state with a decision and minimizes the expected total cost. Since exact algorithms scale exponentially with the state-space dimension, we develop a heuristic solution approach based on reinforcement learning. We propose an approximate policy iteration algorithm in which we apply a linear model to approximate the action-value function of a policy. Policy evaluation is performed by solving the projected Bellman equation from a sample of state transitions, decisions and costs obtained by simulation. Due to the large decision space, policy improvement is performed via the cross-entropy method. Computational experiments are carried out with the use of realistic data to illustrate the application of the algorithm. Heuristic policies obtained with polynomial and Fourier basis functions are compared with myopic and random policies. Results indicate the possibility of obtaining policies capable of adequately controlling inventories with an average cost up to 80% lower than the cost obtained by a myopic policy.", "link": "http://dx.doi.org/10.1016/j.ejco.2022.100027"}, {"index": 369, "title": "Optimising Rolling Stock Planning including Maintenance with Constraint Programming and Quantum Annealing", "abstract": "We propose and compare Constraint Programming (CP) and Quantum Annealing (QA) approaches for rolling stock assignment optimisation considering necessary maintenance tasks. In the CP approach, we model the problem with an Alldifferent constraint, extensions of the Element constraint, and logical implications, among others. For the QA approach, we develop a quadratic unconstrained binary optimisation (QUBO) model. For evaluation, we use data sets based on real data from Deutsche Bahn and run the QA approach on real quantum computers from D-Wave. Classical computers are used to evaluate the CP approach as well as tabu search for the QUBO model. At the current development stage of the physical quantum annealers, we find that both approaches tend to produce comparable results.", "link": "http://arxiv.org/abs/2109.07212v3"}, {"index": 370, "title": "Stock Price Prediction Under Anomalous Circumstances", "abstract": "The stock market is volatile and complicated, especially in 2020. Because of a series of global and regional \"black swans,\" such as the COVID-19 pandemic, the U.S. stock market triggered the circuit breaker three times within one week of March 9 to 16, which is unprecedented throughout history. Affected by the whole circumstance, the stock prices of individual corporations also plummeted by rates that were never predicted by any pre-developed forecasting models. It reveals that there was a lack of satisfactory models that could predict the changes in stocks prices when catastrophic, highly unlikely events occur. To fill the void of such models and to help prevent investors from heavy losses during uncertain times, this paper aims to capture the movement pattern of stock prices under anomalous circumstances. First, we detect outliers in sequential stock prices by fitting a standard ARIMA model and identifying the points where predictions deviate significantly from actual values. With the selected data points, we train ARIMA and LSTM models at the single-stock level, industry level, and general market level, respectively. Since the public moods affect the stock market tremendously, a sentiment analysis is also incorporated into the models in the form of sentiment scores, which are converted from comments about specific stocks on Reddit. Based on 100 companies' stock prices in the period of 2016 to 2020, the models achieve an average prediction accuracy of 98% which can be used to optimize existing prediction methodologies.", "link": "http://dx.doi.org/10.1109/BigData50022.2020.9378030"}, {"index": 371, "title": "Detection of Structural Regimes and Analyzing the Impact of Crude Oil Market on Canadian Stock Market: Markov Regime-Switching Approach", "abstract": "This study aims to analyze the impact of the crude oil market on the Toronto Stock Exchange Index (TSX)c based on monthly data from 1970 to 2021 using Markov-switching vector autoregressive (MSI-VAR) model. The results indicate that TSX return contains two regimes, including: positive return (regime 1), when growth rate of stock index is positive; and negative return (regime 2), when growth rate of stock index is negative. Moreover, regime 1 is more volatile than regime 2. The findings also show the crude oil market has negative effect on the stock market in regime 1, while it has positive effect on the stock market in regime 2. In addition, we can see this effect in regime 1 more significantly in comparison to regime 2. Furthermore, two period lag of oil price decreases stock return in regime 1, while it increases stock return in regime 2.", "link": "http://arxiv.org/abs/2109.01046v3"}, {"index": 372, "title": "Stock index futures trading impact on spot price volatility. The CSI 300 studied with a TGARCH model", "abstract": "A TGARCH modeling is argued to be the optimal basis for investigating the impact of index futures trading on spot price variability. We discuss the CSI-300 index (China-Shanghai-Shenzhen-300-Stock Index) as a test case. The results prove that the introduction of CSI-300 index futures (CSI-300-IF) trading significantly reduces the volatility in the corresponding spot market. It is also found that there is a stationary equilibrium relationship between the CSI-300 spot and CCSI-300-IF markets. A bidirectional Granger causality is also detected. ''Finally'', it is deduced that spot prices are predicted with greater accuracy over a 3 or 4 lag day time span.", "link": "http://dx.doi.org/10.1016/j/eswa.2020.113688"}, {"index": 373, "title": "Statistical Inference for Linear Mediation Models with High-dimensional Mediators and Application to Studying Stock Reaction to COVID-19 Pandemic", "abstract": "Mediation analysis draws increasing attention in many scientific areas such as genomics, epidemiology and finance. In this paper, we propose new statistical inference procedures for high dimensional mediation models, in which both the outcome model and the mediator model are linear with high dimensional mediators. Traditional procedures for mediation analysis cannot be used to make statistical inference for high dimensional linear mediation models due to high-dimensionality of the mediators. We propose an estimation procedure for the indirect effects of the models via a partial penalized least squares method, and further establish its theoretical properties. We further develop a partial penalized Wald test on the indirect effects, and prove that the proposed test has a $\\chi^2$ limiting null distribution. We also propose an $F$-type test for direct effects and show that the proposed test asymptotically follows a $\\chi^2$-distribution under null hypothesis and a noncentral $\\chi^2$-distribution under local alternatives. Monte Carlo simulations are conducted to examine the finite sample performance of the proposed tests and compare their performance with existing ones. We further apply the newly proposed statistical inference procedures to study stock reaction to COVID-19 pandemic via an empirical analysis of studying the mediation effects of financial metrics that bridge company's sector and stock return.", "link": "http://arxiv.org/abs/2108.12329v1"}, {"index": 374, "title": "S&P 500 Stock Price Prediction Using Technical, Fundamental and Text Data", "abstract": "We summarized both common and novel predictive models used for stock price prediction and combined them with technical indices, fundamental characteristics and text-based sentiment data to predict S&P stock prices. A 66.18% accuracy in S&P 500 index directional prediction and 62.09% accuracy in individual stock directional prediction was achieved by combining different machine learning models such as Random Forest and LSTM together into state-of-the-art ensemble models. The data we use contains weekly historical prices, finance reports, and text information from news items associated with 518 different common stocks issued by current and former S&P 500 large-cap companies, from January 1, 2000 to December 31, 2019. Our study's innovation includes utilizing deep language models to categorize and infer financial news item sentiment; fusing different models containing different combinations of variables and stocks to jointly make predictions; and overcoming the insufficient data problem for machine learning models in time series by using data across different stocks.", "link": "http://dx.doi.org/10.19139/soic-2310-5070-1362"}, {"index": 375, "title": "Wealth disparities and economic flow: Assessment using an asset exchange model with the surplus stock of the wealthy", "abstract": "How can we limit wealth disparities while stimulating economic flows in sustainable societies? To examine the link between these concepts, we propose an econophysics asset exchange model with the surplus stock of the wealthy. The wealthy are one of the two exchange agents and have more assets than the poor. Our simulation model converts the surplus contribution rate of the wealthy to a new variable parameter alongside the saving rate and introduces the total exchange (flow) and rank correlation coefficient (metabolism) as new evaluation indexes, adding to the Gini index (disparities), thereby assessing both wealth distribution and the relationships among the disparities, flow, and metabolism. We show that these result in a gamma-like wealth distribution, and our model reveals a trade-off between limiting disparities and vitalizing the market. To limit disparities and increase flow and metabolism, we also find the need to restrain savings and use the wealthy surplus stock. This relationship is explicitly expressed in the new equation introduced herein. The insights gained by uncovering the root of disparities may present a persuasive case for investments in social security measures or social businesses involving stock redistribution or sharing.", "link": "http://dx.doi.org/10.1371/journal.pone.0259323"}, {"index": 376, "title": "Factor Representation and Decision Making in Stock Markets Using Deep Reinforcement Learning", "abstract": "Deep Reinforcement learning is a branch of unsupervised learning in which an agent learns to act based on environment state in order to maximize its total reward. Deep reinforcement learning provides good opportunity to model the complexity of portfolio choice in high-dimensional and data-driven environment by leveraging the powerful representation of deep neural networks. In this paper, we build a portfolio management system using direct deep reinforcement learning to make optimal portfolio choice periodically among S\\&P500 underlying stocks by learning a good factor representation (as input). The result shows that an effective learning of market conditions and optimal portfolio allocations can significantly outperform the average market.", "link": "http://arxiv.org/abs/2108.01758v1"}, {"index": 377, "title": "Evaluating the impact of increasing temperatures on changes in Soil Organic Carbon stocks: sensitivity analysis and non-standard discrete approximation", "abstract": "A novel model is here introduced for the SOC change index defined as the normalized difference between the actual Soil Organic Carbon and the value assumed at an initial reference year. It is tailored on the RothC carbon model dynamics and assumes as baseline the value of the SOC equilibrium under constant environmental conditions. A sensitivity analysis is performed to evaluate the response of the model to changes of temperature, Net Primary Production (NPP), and land use soil class (forest, grassland, arable). A non-standard monthly time-stepping procedure has been proposed to approximate the SOC change index in the Alta Murgia National Park, a protected area in the Italian Apulia region, selected as test site. In the case of arable class, the SOC change index exhibits a negative trend which can be inverted by a suitable organic fertilization program here proposed.", "link": "http://arxiv.org/abs/2108.00077v1"}, {"index": 378, "title": "A data-science-driven short-term analysis of Amazon, Apple, Google, and Microsoft stocks", "abstract": "In this paper, we implement a combination of technical analysis and machine/deep learning-based analysis to build a trend classification model. The goal of the paper is to apprehend short-term market movement, and incorporate it to improve the underlying stochastic model. Also, the analysis presented in this paper can be implemented in a \\emph{model-independent} fashion. We execute a data-science-driven technique that makes short-term forecasts dependent on the price trends of current stock market data. Based on the analysis, three different labels are generated for a data set: $+1$ (buy signal), $0$ (hold signal), or $-1$ (sell signal). We propose a detailed analysis of four major stocks- Amazon, Apple, Google, and Microsoft. We implement various technical indicators to label the data set according to the trend and train various models for trend estimation. Statistical analysis of the outputs and classification results are obtained.", "link": "http://arxiv.org/abs/2107.14695v1"}, {"index": 379, "title": "Combining Machine Learning Classifiers for Stock Trading with Effective Feature Extraction", "abstract": "The unpredictability and volatility of the stock market render it challenging to make a substantial profit using any generalised scheme. Many previous studies tried different techniques to build a machine learning model, which can make a significant profit in the US stock market by performing live trading. However, very few studies have focused on the importance of finding the best features for a particular trading period. Our top approach used the performance to narrow down the features from a total of 148 to about 30. Furthermore, the top 25 features were dynamically selected before each time training our machine learning model. It uses ensemble learning with four classifiers: Gaussian Naive Bayes, Decision Tree, Logistic Regression with L1 regularization, and Stochastic Gradient Descent, to decide whether to go long or short on a particular stock. Our best model performed daily trade between July 2011 and January 2019, generating 54.35% profit. Finally, our work showcased that mixtures of weighted classifiers perform better than any individual predictor of making trading decisions in the stock market.", "link": "http://dx.doi.org/10.1504/IJCSE.2023.129152"}, {"index": 380, "title": "A forward-looking matheuristic approach for the multi-period two-dimensional non-guillotine cutting stock problem with usable leftovers", "abstract": "In [E. G. Birgin, O. C. Rom\\~ao, and D. P. Ronconi, The multi-period two-dimensional non-guillotine cutting stock problem with usable leftovers, International Transactions in Operational Research 27(3), 1392-1418, 2020] the multi-period two-dimensional non-guillotine cutting stock problem with usable leftovers was introduced. At each decision instant, the problem consists in determining a cutting pattern for a set of ordered items using a set of objects that can be purchased or can be leftovers of previous periods; the goal being the minimization of the overall cost of the objects up to the considered time horizon. Among solutions with minimum cost, a solution that maximizes the value of the leftovers at the end of the considered horizon is sought. A forward-looking matheuristic approach that applies to this problem is introduced in the present work. At each decision instant, the objects and the cutting pattern that will be used is determined, taking into account the impact of this decision in future states of the system. More specifically, for each potentially used object, an attempt is made to estimate the utilization rate of its leftovers and thereby determine whether the object should be used or not. The approach's performance is compared to the performance of a myopic technique. Numerical experiments show the efficacy of the proposed approach.", "link": "http://dx.doi.org/10.1016/j.eswa.2023.119866"}, {"index": 381, "title": "Optimum Risk Portfolio and Eigen Portfolio: A Comparative Analysis Using Selected Stocks from the Indian Stock Market", "abstract": "Designing an optimum portfolio that allocates weights to its constituent stocks in a way that achieves the best trade-off between the return and the risk is a challenging research problem. The classical mean-variance theory of portfolio proposed by Markowitz is found to perform sub-optimally on the real-world stock market data since the error in estimation for the expected returns adversely affects the performance of the portfolio. This paper presents three approaches to portfolio design, viz, the minimum risk portfolio, the optimum risk portfolio, and the Eigen portfolio, for seven important sectors of the Indian stock market. The daily historical prices of the stocks are scraped from Yahoo Finance website from January 1, 2016, to December 31, 2020. Three portfolios are built for each of the seven sectors chosen for this study, and the portfolios are analyzed on the training data based on several metrics such as annualized return and risk, weights assigned to the constituent stocks, the correlation heatmaps, and the principal components of the Eigen portfolios. Finally, the optimum risk portfolios and the Eigen portfolios for all sectors are tested on their return over a period of a six-month period. The performances of the portfolios are compared and the portfolio yielding the higher return for each sector is identified.", "link": "http://arxiv.org/abs/2107.11371v1"}, {"index": 382, "title": "Graph-Based Learning for Stock Movement Prediction with Textual and Relational Data", "abstract": "Predicting stock prices from textual information is a challenging task due to the uncertainty of the market and the difficulty understanding the natural language from a machine's perspective. Previous researches focus mostly on sentiment extraction based on single news. However, the stocks on the financial market can be highly correlated, one news regarding one stock can quickly impact the prices of other stocks. To take this effect into account, we propose a new stock movement prediction framework: Multi-Graph Recurrent Network for Stock Forecasting (MGRN). This architecture allows to combine the textual sentiment from financial news and multiple relational information extracted from other financial data. Through an accuracy test and a trading simulation on the stocks in the STOXX Europe 600 index, we demonstrate a better performance from our model than other benchmarks.", "link": "http://dx.doi.org/10.1145/3533271.3561663"}, {"index": 383, "title": "Temporal-Relational Hypergraph Tri-Attention Networks for Stock Trend Prediction", "abstract": "Predicting the future price trends of stocks is a challenging yet intriguing problem given its critical role to help investors make profitable decisions. In this paper, we present a collaborative temporal-relational modeling framework for end-to-end stock trend prediction. The temporal dynamics of stocks is firstly captured with an attention-based recurrent neural network. Then, different from existing studies relying on the pairwise correlations between stocks, we argue that stocks are naturally connected as a collective group, and introduce the hypergraph structures to jointly characterize the stock group-wise relationships of industry-belonging and fund-holding. A novel hypergraph tri-attention network (HGTAN) is proposed to augment the hypergraph convolutional networks with a hierarchical organization of intra-hyperedge, inter-hyperedge, and inter-hypergraph attention modules. In this manner, HGTAN adaptively determines the importance of nodes, hyperedges, and hypergraphs during the information propagation among stocks, so that the potential synergies between stock movements can be fully exploited. Extensive experiments on real-world data demonstrate the effectiveness of our approach. Also, the results of investment simulation show that our approach can achieve a more desirable risk-adjusted return. The data and codes of our work have been released at https://github.com/lixiaojieff/HGTAN.", "link": "http://arxiv.org/abs/2107.14033v2"}, {"index": 384, "title": "Stock Movement Prediction with Financial News using Contextualized Embedding from BERT", "abstract": "News events can greatly influence equity markets. In this paper, we are interested in predicting the short-term movement of stock prices after financial news events using only the headlines of the news. To achieve this goal, we introduce a new text mining method called Fine-Tuned Contextualized-Embedding Recurrent Neural Network (FT-CE-RNN). Compared with previous approaches which use static vector representations of the news (static embedding), our model uses contextualized vector representations of the headlines (contextualized embeddings) generated from Bidirectional Encoder Representations from Transformers (BERT). Our model obtains the state-of-the-art result on this stock movement prediction task. It shows significant improvement compared with other baseline models, in both accuracy and trading simulations. Through various trading simulations based on millions of headlines from Bloomberg News, we demonstrate the ability of this model in real scenarios.", "link": "http://arxiv.org/abs/2107.08721v1"}, {"index": 385, "title": "Stock price prediction using BERT and GAN", "abstract": "The stock market has been a popular topic of interest in the recent past. The growth in the inflation rate has compelled people to invest in the stock and commodity markets and other areas rather than saving. Further, the ability of Deep Learning models to make predictions on the time series data has been proven time and again. Technical analysis on the stock market with the help of technical indicators has been the most common practice among traders and investors. One more aspect is the sentiment analysis - the emotion of the investors that shows the willingness to invest. A variety of techniques have been used by people around the globe involving basic Machine Learning and Neural Networks. Ranging from the basic linear regression to the advanced neural networks people have experimented with all possible techniques to predict the stock market. It's evident from recent events how news and headlines affect the stock markets and cryptocurrencies. This paper proposes an ensemble of state-of-the-art methods for predicting stock prices. Firstly sentiment analysis of the news and the headlines for the company Apple Inc, listed on the NASDAQ is performed using a version of BERT, which is a pre-trained transformer model by Google for Natural Language Processing (NLP). Afterward, a Generative Adversarial Network (GAN) predicts the stock price for Apple Inc using the technical indicators, stock indexes of various countries, some commodities, and historical prices along with the sentiment scores. Comparison is done with baseline models like - Long Short Term Memory (LSTM), Gated Recurrent Units (GRU), vanilla GAN, and Auto-Regressive Integrated Moving Average (ARIMA) model.", "link": "http://arxiv.org/abs/2107.09055v1"}, {"index": 386, "title": "High carbon stock mapping at large scale with optical satellite imagery and spaceborne LIDAR", "abstract": "The increasing demand for commodities is leading to changes in land use worldwide. In the tropics, deforestation, which causes high carbon emissions and threatens biodiversity, is often linked to agricultural expansion. While the need for deforestation-free global supply chains is widely recognized, making progress in practice remains a challenge. Here, we propose an automated approach that aims to support conservation and sustainable land use planning decisions by mapping tropical landscapes at large scale and high spatial resolution following the High Carbon Stock (HCS) approach. A deep learning approach is developed that estimates canopy height for each 10 m Sentinel-2 pixel by learning from sparse GEDI LIDAR reference data, achieving an overall RMSE of 6.3 m. We show that these wall-to-wall maps of canopy top height are predictive for classifying HCS forests and degraded areas with an overall accuracy of 86 % and produce a first high carbon stock map for Indonesia, Malaysia, and the Philippines.", "link": "http://arxiv.org/abs/2107.07431v1"}, {"index": 387, "title": "Sensitivity Analysis with respect to a Stock Price Model with Rough Volatility via a Bismut-Elworthy-Li Formula for Singular SDEs", "abstract": "In this paper, we show the existence of unique Malliavin differentiable solutions to SDE`s driven by a fractional Brownian motion with Hurst parameter H<1/2 and singular, unbounded drift vector fields, for which we also prove a stability result. Further, using the latter results, we propose a stock price model with rough and correlated volatility, which also allows for capturing regime switching effects. Finally, we also derive a Bismut-Elworthy-Li formula with respect to our stock price model for certain classes of vector fields.", "link": "http://arxiv.org/abs/2107.06022v2"}, {"index": 388, "title": "Measuring Financial Time Series Similarity With a View to Identifying Profitable Stock Market Opportunities", "abstract": "Forecasting stock returns is a challenging problem due to the highly stochastic nature of the market and the vast array of factors and events that can influence trading volume and prices. Nevertheless it has proven to be an attractive target for machine learning research because of the potential for even modest levels of prediction accuracy to deliver significant benefits. In this paper, we describe a case-based reasoning approach to predicting stock market returns using only historical pricing data. We argue that one of the impediments for case-based stock prediction has been the lack of a suitable similarity metric when it comes to identifying similar pricing histories as the basis for a future prediction -- traditional Euclidean and correlation based approaches are not effective for a variety of reasons -- and in this regard, a key contribution of this work is the development of a novel similarity metric for comparing historical pricing data. We demonstrate the benefits of this metric and the case-based approach in a real-world application in comparison to a variety of conventional benchmarks.", "link": "http://dx.doi.org/10.1007/978-3-030-86957-1_5"}, {"index": 389, "title": "A Novel Deep Reinforcement Learning Based Stock Direction Prediction using Knowledge Graph and Community Aware Sentiments", "abstract": "Stock market prediction has been an important topic for investors, researchers, and analysts. Because it is affected by too many factors, stock market prediction is a difficult task to handle. In this study, we propose a novel method that is based on deep reinforcement learning methodologies for the direction prediction of stocks using sentiments of community and knowledge graph. For this purpose, we firstly construct a social knowledge graph of users by analyzing relations between connections. After that, time series analysis of related stock and sentiment analysis is blended with deep reinforcement methodology. Turkish version of Bidirectional Encoder Representations from Transformers (BerTurk) is employed to analyze the sentiments of the users while deep Q-learning methodology is used for the deep reinforcement learning side of the proposed model to construct the deep Q network. In order to demonstrate the effectiveness of the proposed model, Garanti Bank (GARAN), Akbank (AKBNK), T\\\"urkiye \\.I\\c{s} Bankas{\\i} (ISCTR) stocks in Istanbul Stock Exchange are used as a case study. Experiment results show that the proposed novel model achieves remarkable results for stock market prediction task.", "link": "http://arxiv.org/abs/2107.00931v1"}, {"index": 390, "title": "Reinforcement Learning Provides a Flexible Approach for Realistic Supply Chain Safety Stock Optimisation", "abstract": "Although safety stock optimisation has been studied for more than 60 years, most companies still use simplistic means to calculate necessary safety stock levels, partly due to the mismatch between existing analytical methods' emphases on deriving provably optimal solutions and companies' preferences to sacrifice optimal results in favour of more realistic problem settings. A newly emerging method from the field of Artificial Intelligence (AI), namely Reinforcement Learning (RL), offers promise in finding optimal solutions while accommodating more realistic problem features. Unlike analytical-based models, RL treats the problem as a black-box simulation environment mitigating against the problem of oversimplifying reality. As such, assumptions on stock keeping policy can be relaxed and a higher number of problem variables can be accommodated. While RL has been popular in other domains, its applications in safety stock optimisation remain scarce. In this paper, we investigate three RL methods, namely, Q-Learning, Temporal Difference Advantage Actor-Critic and Multi-agent Temporal Difference Advantage Actor-Critic for optimising safety stock in a linear chain of independent agents. We find that RL can simultaneously optimise both safety stock level and order quantity parameters of an inventory policy, unlike classical safety stock optimisation models where only safety stock level is optimised while order quantity is predetermined based on simple rules. This allows RL to model more complex supply chain procurement behaviour. However, RL takes longer time to arrive at solutions, necessitating future research on identifying and improving trade-offs between the use of AI and mathematical models are needed.", "link": "http://arxiv.org/abs/2107.00913v1"}, {"index": 391, "title": "Effectiveness of Artificial Intelligence in Stock Market Prediction based on Machine Learning", "abstract": "This paper tries to address the problem of stock market prediction leveraging artificial intelligence (AI) strategies. The stock market prediction can be modeled based on two principal analyses called technical and fundamental. In the technical analysis approach, the regression machine learning (ML) algorithms are employed to predict the stock price trend at the end of a business day based on the historical price data. In contrast, in the fundamental analysis, the classification ML algorithms are applied to classify the public sentiment based on news and social media. In the technical analysis, the historical price data is exploited from Yahoo Finance, and in fundamental analysis, public tweets on Twitter associated with the stock market are investigated to assess the impact of sentiments on the stock market's forecast. The results show a median performance, implying that with the current technology of AI, it is too soon to claim AI can beat the stock markets.", "link": "http://dx.doi.org/10.5120/ijca2021921347"}, {"index": 392, "title": "\"Stabilizer\" or \"catalyst\"? How green technology innovation affects the risk of stock price crashes: an analysis based on the quantity and quality of patents", "abstract": "To explore the relationship between corporate green technological innovation and the risk of stock price crashes, we first analyzed the data of listed companies in China from 2008 to 2018 and constructed indicators for the quantity and quality of corporate green technology innovation. The study found that the quantity of green technology innovation is not related to the risk of stock price crashes, while the quality of green technology innovation is negatively related to the risk of stock price crashes. Second, we studied the impact of corporate ownership on the relationship between the quality of green technological innovation and the risk of stock price crashes and found that in nonstate-owned enterprises, the quality of green technological innovation is negatively correlated with the risk of a stock price collapse, while in state-owned enterprises, the quality of green technological innovation and the risk of a stock price collapse are positive and not significant. Furthermore, we studied the mediating effect of the number of negative news reports in the media of listed companies on the relationship between the quality of corporate green technology innovation and the stock price crash and found that the quality of green technology innovation is positively correlated with the number of negative news reports in the media of listed companies, while the number of negative news reports in the media of listed companies is positively correlated with the risk of a stock price collapse. Finally, we conducted a DID regression by using the impact of exogenous policy shocks on the quality of green technology innovation, and the main results passed the robustness test.", "link": "http://arxiv.org/abs/2106.16177v3"}, {"index": 393, "title": "Learning Multiple Stock Trading Patterns with Temporal Routing Adaptor and Optimal Transport", "abstract": "Successful quantitative investment usually relies on precise predictions of the future movement of the stock price. Recently, machine learning based solutions have shown their capacity to give more accurate stock prediction and become indispensable components in modern quantitative investment systems. However, the i.i.d. assumption behind existing methods is inconsistent with the existence of diverse trading patterns in the stock market, which inevitably limits their ability to achieve better stock prediction performance. In this paper, we propose a novel architecture, Temporal Routing Adaptor (TRA), to empower existing stock prediction models with the ability to model multiple stock trading patterns. Essentially, TRA is a lightweight module that consists of a set of independent predictors for learning multiple patterns as well as a router to dispatch samples to different predictors. Nevertheless, the lack of explicit pattern identifiers makes it quite challenging to train an effective TRA-based model. To tackle this challenge, we further design a learning algorithm based on Optimal Transport (OT) to obtain the optimal sample to predictor assignment and effectively optimize the router with such assignment through an auxiliary loss term. Experiments on the real-world stock ranking task show that compared to the state-of-the-art baselines, e.g., Attention LSTM and Transformer, the proposed method can improve information coefficient (IC) from 0.053 to 0.059 and 0.051 to 0.056 respectively. Our dataset and code used in this work are publicly available: https://github.com/microsoft/qlib/tree/main/examples/benchmarks/TRA.", "link": "http://arxiv.org/abs/2106.12950v2"}, {"index": 394, "title": "Stock Market Analysis with Text Data: A Review", "abstract": "Stock market movements are influenced by public and private information shared through news articles, company reports, and social media discussions. Analyzing these vast sources of data can give market participants an edge to make profit. However, the majority of the studies in the literature are based on traditional approaches that come short in analyzing unstructured, vast textual data. In this study, we provide a review on the immense amount of existing literature of text-based stock market analysis. We present input data types and cover main textual data sources and variations. Feature representation techniques are then presented. Then, we cover the analysis techniques and create a taxonomy of the main stock market forecast models. Importantly, we discuss representative work in each category of the taxonomy, analyzing their respective contributions. Finally, this paper shows the findings on unaddressed open problems and gives suggestions for future work. The aim of this study is to survey the main stock market analysis models, text representation techniques for financial market prediction, shortcomings of existing techniques, and propose promising directions for future research.", "link": "http://arxiv.org/abs/2106.12985v2"}, {"index": 395, "title": "FinGAT: Financial Graph Attention Networks for Recommending Top-K Profitable Stocks", "abstract": "Financial technology (FinTech) has drawn much attention among investors and companies. While conventional stock analysis in FinTech targets at predicting stock prices, less effort is made for profitable stock recommendation. Besides, in existing approaches on modeling time series of stock prices, the relationships among stocks and sectors (i.e., categories of stocks) are either neglected or pre-defined. Ignoring stock relationships will miss the information shared between stocks while using pre-defined relationships cannot depict the latent interactions or influence of stock prices between stocks. In this work, we aim at recommending the top-K profitable stocks in terms of return ratio using time series of stock prices and sector information. We propose a novel deep learning-based model, Financial Graph Attention Networks (FinGAT), to tackle the task under the setting that no pre-defined relationships between stocks are given. The idea of FinGAT is three-fold. First, we devise a hierarchical learning component to learn short-term and long-term sequential patterns from stock time series. Second, a fully-connected graph between stocks and a fully-connected graph between sectors are constructed, along with graph attention networks, to learn the latent interactions among stocks and sectors. Third, a multi-task objective is devised to jointly recommend the profitable stocks and predict the stock movement. Experiments conducted on Taiwan Stock, S&P 500, and NASDAQ datasets exhibit remarkable recommendation performance of our FinGAT, comparing to state-of-the-art methods.", "link": "http://arxiv.org/abs/2106.10159v1"}, {"index": 396, "title": "Design and Analysis of Robust Deep Learning Models for Stock Price Prediction", "abstract": "Building predictive models for robust and accurate prediction of stock prices and stock price movement is a challenging research problem to solve. The well-known efficient market hypothesis believes in the impossibility of accurate prediction of future stock prices in an efficient stock market as the stock prices are assumed to be purely stochastic. However, numerous works proposed by researchers have demonstrated that it is possible to predict future stock prices with a high level of precision using sophisticated algorithms, model architectures, and the selection of appropriate variables in the models. This chapter proposes a collection of predictive regression models built on deep learning architecture for robust and precise prediction of the future prices of a stock listed in the diversified sectors in the National Stock Exchange (NSE) of India. The Metastock tool is used to download the historical stock prices over a period of two years (2013- 2014) at 5 minutes intervals. While the records for the first year are used to train the models, the testing is carried out using the remaining records. The design approaches of all the models and their performance results are presented in detail. The models are also compared based on their execution time and accuracy of prediction.", "link": "http://dx.doi.org/10.5772/intechopen.99982"}, {"index": 397, "title": "StockBabble: A Conversational Financial Agent to support Stock Market Investors", "abstract": "We introduce StockBabble, a conversational agent designed to support understanding and engagement with the stock market. StockBabble's value and novelty is in its ability to empower retail investors -- many of which may be new to investing -- and supplement their informational needs using a user-friendly agent. Users have the ability to query information on companies to retrieve a general and financial overview of a stock, including accessing the latest news and trading recommendations. They can also request charts which contain live prices and technical investment indicators, and add shares to a personal portfolio to allow performance monitoring over time. To evaluate our agent's potential, we conducted a user study with 15 participants. In total, 73% (11/15) of respondents said that they felt more confident in investing after using StockBabble, and all 15 would consider recommending it to others. These results are encouraging and suggest a wider appeal for such agents. Moreover, we believe this research can help to inform the design and development of future intelligent, financial personal assistants.", "link": "http://dx.doi.org/10.1145/3469595.3469620"}, {"index": 398, "title": "How does economic policy uncertainty comove with stock markets: New evidence from symmetric thermal optimal path method", "abstract": "We revisit the dynamic relationship between domestic economic policy uncertainty and stock markets using the symmetric thermal optimal path (TOPS) method. We observe different interaction patterns in emerging and developed markets. Economic policy uncertainty drives the stock market in China, while stock markets play a leading role in the UK and the US. Meanwhile, the lead-lag relationship of the three countries reacts significantly to extreme events. Our findings have important implications for investors and policy makers.", "link": "http://dx.doi.org/10.1016/j.physa.2022.127745"}, {"index": 399, "title": "On the \"mementum\" of Meme Stocks", "abstract": "The meme stock phenomenon is yet to be explored. In this note, we provide evidence that these stocks display common stylized facts on the dynamics of price, trading volume, and social media activity. Using a regime-switching cointegration model, we identify the meme stock \"mementum\" which exhibits a different characterization with respect to other stocks with high volumes of activity (persistent and not) on social media. Understanding these properties helps the investors and market authorities in their decision.", "link": "http://arxiv.org/abs/2106.03691v1"}, {"index": 400, "title": "Price graphs: Utilizing the structural information of financial time series for stock prediction", "abstract": "Great research efforts have been devoted to exploiting deep neural networks in stock prediction. While long-range dependencies and chaotic property are still two major issues that lower the performance of state-of-the-art deep learning models in forecasting future price trends. In this study, we propose a novel framework to address both issues. Specifically, in terms of transforming time series into complex networks, we convert market price series into graphs. Then, structural information, referring to associations among temporal points and the node weights, is extracted from the mapped graphs to resolve the problems regarding long-range dependencies and the chaotic property. We take graph embeddings to represent the associations among temporal points as the prediction model inputs. Node weights are used as a priori knowledge to enhance the learning of temporal attention. The effectiveness of our proposed framework is validated using real-world stock data, and our approach obtains the best performance among several state-of-the-art benchmarks. Moreover, in the conducted trading simulations, our framework further obtains the highest cumulative profits. Our results supplement the existing applications of complex network methods in the financial realm and provide insightful implications for investment applications regarding decision support in financial markets.", "link": "http://arxiv.org/abs/2106.02522v5"}, {"index": 401, "title": "Convolutional Neural Network(CNN/ConvNet) in Stock Price Movement Prediction", "abstract": "With technological advancements and the exponential growth of data, we have been unfolding different capabilities of neural networks in different sectors. In this paper, I have tried to use a specific type of Neural Network known as Convolutional Neural Network(CNN/ConvNet) in the stock market. In other words, I have tried to construct and train a convolutional neural network on past stock prices data and then tried to predict the movement of stock price i.e. whether the stock price would rise or fall, in the coming time.", "link": "http://arxiv.org/abs/2106.01920v1"}, {"index": 402, "title": "The relationship between the US broad money supply and US GDP for the time period 2001 to 2019 with that of the corresponding time series for US national property and stock market indices, using an information entropy methodology", "abstract": "The primary objective of this paper was to investigate whether the growth in the major US asset indices could be a function of the US broad money supply and/or US GDP, over the time period 2001 to 2019, using an information entropy methodology. The four US asset indices investigated were: (1) US National Property index; (2) Russell 2000 index; (3) S&P 500 index; and (4) NASDAQ index. Notwithstanding the financial crisis of 2007-2008, US real GDP increased exponentially over the period 2001 to 2019, with an average annual growth rate of approximately 2%. However, over this time period, the average annual rate of growth of US GDP was considerably lower than the average annual rate of growth of the US broad money supply (5.7%). The main determinant of the average growth rate for all four US asset indices studied would appear to be the growth rate in the US broad money supply. In addition, the growth rate in the US Russell 2000 stock index and the NASDAQ index would appear to be a function of the combined positive effects of both the growth rate in the US Broad Money Supply and the growth rate of US GDP.", "link": "http://arxiv.org/abs/2106.07354v1"}, {"index": 403, "title": "Volatility Modeling of Stocks from Selected Sectors of the Indian Economy Using GARCH", "abstract": "Volatility clustering is an important characteristic that has a significant effect on the behavior of stock markets. However, designing robust models for accurate prediction of future volatilities of stock prices is a very challenging research problem. We present several volatility models based on generalized autoregressive conditional heteroscedasticity (GARCH) framework for modeling the volatility of ten stocks listed in the national stock exchange (NSE) of India. The stocks are selected from the auto sector and the banking sector of the Indian economy, and they have a significant impact on the sectoral index of their respective sectors in the NSE. The historical stock price records from Jan 1, 2010, to Apr 30, 2021, are scraped from the Yahoo Finance website using the DataReader API of the Pandas module in the Python programming language. The GARCH modules are built and fine-tuned on the training data and then tested on the out-of-sample data to evaluate the performance of the models. The analysis of the results shows that asymmetric GARCH models yield more accurate forecasts on the future volatility of stocks.", "link": "http://dx.doi.org/10.1109/ASIANCON51346.2021.9544977"}, {"index": 404, "title": "Short-Term Stock Price-Trend Prediction Using Meta-Learning", "abstract": "Although conventional machine learning algorithms have been widely adopted for stock-price predictions in recent years, the massive volume of specific labeled data required are not always available. In contrast, meta-learning technology uses relatively small amounts of training data, called fast learners. Such methods are beneficial under conditions of limited data availability, which often obtain for trend prediction based on time-series data limited by sparse information. In this study, we consider short-term stock price prediction using a meta-learning framework with several convolutional neural networks, including the temporal convolution network, fully convolutional network, and residual neural network. We propose a sliding time horizon to label stocks according to their predicted price trends, referred to as called slope-detection labeling, using prediction labels including \"rise plus,\" \"rise,\" \"fall,\" and \"fall plus\". The effectiveness of the proposed meta-learning framework was evaluated by application to the S&P500. The experimental results show that the inclusion of the proposed meta-learning framework significantly improved both regular and balanced prediction accuracy and profitability.", "link": "http://dx.doi.org/10.1109/SMC52423.2021.9658607"}, {"index": 405, "title": "Look inside. Predicting stock prices by analysing an enterprise intranet social network and using word co-occurrence networks", "abstract": "This study looks into employees' communication, offering novel metrics which can help to predict a company's stock price. We studied the intranet forum of a large Italian company, exploring the interactions and the use of language of about 8,000 employees. We built a network linking words included in the general discourse. In this network, we focused on the position of the node representing the company brand. We found that a lower sentiment, a higher betweenness centrality of the company brand, a denser word co-occurrence network and more equally distributed centrality scores of employees (lower group betweenness centrality) are all significant predictors of higher stock prices. Our findings offers new metrics that can be helpful for scholars, company managers and professional investors and could be integrated into existing forecasting models to improve their accuracy. Lastly, we contribute to the research on word co-occurrence networks by extending their field of application.", "link": "http://dx.doi.org/10.1504/IJESB.2019.098986"}, {"index": 406, "title": "Dynamic analysis of influential stocks based on conserved networks", "abstract": "Characterizing temporal evolution of stock markets is a fundamental and challenging problem. The literature on analyzing the dynamics of the markets has focused so far on macro measures with less predictive power. This paper addresses this issue from a micro point of view. Given an investigating period, a series of stock networks are constructed first by the moving-window method and the significance test of stock correlations. Then, several conserved networks are generated to extract different backbones of the market under different states. Finally, influential stocks and corresponding sectors are identified from each conserved network, based on which the longitudinal analysis is performed to describe the evolution of the market. The application of the above procedure to stocks belonging to Standard \\& Pool's 500 Index from January 2006 to April 2010 recovers the 2008 financial crisis from the evolutionary perspective.", "link": "http://dx.doi.org/10.1088/1742-5468/ac25f8"}, {"index": 407, "title": "Application of deep reinforcement learning for Indian stock trading automation", "abstract": "In stock trading, feature extraction and trading strategy design are the two important tasks to achieve long-term benefits using machine learning techniques. Several methods have been proposed to design trading strategy by acquiring trading signals to maximize the rewards. In the present paper the theory of deep reinforcement learning is applied for stock trading strategy and investment decisions to Indian markets. The experiments are performed systematically with three classical Deep Reinforcement Learning models Deep Q-Network, Double Deep Q-Network and Dueling Double Deep Q-Network on ten Indian stock datasets. The performance of the models are evaluated and comparison is made.", "link": "http://arxiv.org/abs/2106.16088v1"}, {"index": 408, "title": "Stock Price Forecasting in Presence of Covid-19 Pandemic and Evaluating Performances of Machine Learning Models for Time-Series Forecasting", "abstract": "With the heightened volatility in stock prices during the Covid-19 pandemic, the need for price forecasting has become more critical. We investigated the forecast performance of four models including Long-Short Term Memory, XGBoost, Autoregression, and Last Value on stock prices of Facebook, Amazon, Tesla, Google, and Apple in COVID-19 pandemic time to understand the accuracy and predictability of the models in this highly volatile time region. To train the models, the data of all stocks are split into train and test datasets. The test dataset starts from January 2020 to April 2021 which covers the COVID-19 pandemic period. The results show that the Autoregression and Last value models have higher accuracy in predicting the stock prices because of the strong correlation between the previous day and the next day's price value. Additionally, the results suggest that the machine learning models (Long-Short Term Memory and XGBoost) are not performing as well as Autoregression models when the market experiences high volatility.", "link": "http://arxiv.org/abs/2105.02785v1"}, {"index": 409, "title": "Using Twitter Attribute Information to Predict Stock Prices", "abstract": "Being able to predict stock prices might be the unspoken wish of stock investors. Although stock prices are complicated to predict, there are many theories about what affects their movements, including interest rates, news and social media. With the help of Machine Learning, complex patterns in data can be identified beyond the human intellect. In this thesis, a Machine Learning model for time series forecasting is created and tested to predict stock prices. The model is based on a neural network with several layers of LSTM and fully connected layers. It is trained with historical stock values, technical indicators and Twitter attribute information retrieved, extracted and calculated from posts on the social media platform Twitter. These attributes are sentiment score, favourites, followers, retweets and if an account is verified. To collect data from Twitter, Twitter's API is used. Sentiment analysis is conducted with VADER. The results show that by adding more Twitter attributes, the MSE between the predicted prices and the actual prices improved by 3%. With technical analysis taken into account, MSE decreases from 0.1617 to 0.1437, which is an improvement of around 11%. The restrictions of this study include that the selected stock has to be publicly listed on the stock market and popular on Twitter and among individual investors. Besides, the stock markets' opening hours differ from Twitter, which constantly available. It may therefore introduce noises in the model.", "link": "http://arxiv.org/abs/2105.01402v1"}, {"index": 410, "title": "Constructing long-short stock portfolio with a new listwise learn-to-rank algorithm", "abstract": "Factor strategies have gained growing popularity in industry with the fast development of machine learning. Usually, multi-factors are fed to an algorithm for some cross-sectional return predictions, which are further used to construct a long-short portfolio. Instead of predicting the value of the stock return, emerging studies predict a ranked stock list using the mature learn-to-rank technology. In this study, we propose a new listwise learn-to-rank loss function which aims to emphasize both the top and the bottom of a rank list. Our loss function, motivated by the long-short strategy, is endogenously shift-invariant and can be viewed as a direct generalization of ListMLE. Under different transformation functions, our loss can lead to consistency with binary classification loss or permutation level 0-1 loss. A probabilistic explanation for our model is also given as a generalized Plackett-Luce model. Based on a dataset of 68 factors in China A-share market from 2006 to 2019, our empirical study has demonstrated the strength of our method which achieves an out-of-sample annual return of 38% with the Sharpe ratio being 2.", "link": "http://arxiv.org/abs/2104.12484v1"}, {"index": 411, "title": "Stock Market Trend Analysis Using Hidden Markov Model and Long Short Term Memory", "abstract": "This paper intends to apply the Hidden Markov Model into stock market and and make predictions. Moreover, four different methods of improvement, which are GMM-HMM, XGB-HMM, GMM-HMM+LSTM and XGB-HMM+LSTM, will be discussed later with the results of experiment respectively. After that we will analyze the pros and cons of different models. And finally, one of the best will be used into stock market for timing strategy.", "link": "http://arxiv.org/abs/2104.09700v1"}, {"index": 412, "title": "Applying Convolutional Neural Networks for Stock Market Trends Identification", "abstract": "In this paper we apply a specific type ANNs - convolutional neural networks (CNNs) - to the problem of finding start and endpoints of trends, which are the optimal points for entering and leaving the market. We aim to explore long-term trends, which last several months, not days. The key distinction of our model is that its labels are fully based on expert opinion data. Despite the various models based solely on stock price data, some market experts still argue that traders are able to see hidden opportunities. The labelling was done via the GUI interface, which means that the experts worked directly with images, not numerical data. This fact makes CNN the natural choice of algorithm. The proposed framework requires the sequential interaction of three CNN submodels, which identify the presence of a changepoint in a window, locate it and finally recognize the type of new tendency - upward, downward or flat. These submodels have certain pitfalls, therefore the calibration of their hyperparameters is the main direction of further research. The research addresses such issues as imbalanced datasets and contradicting labels, as well as the need for specific quality metrics to keep up with practical applicability. This paper is the full text of the research, presented at the 20th International Conference on Artificial Intelligence and Soft Computing Web System (ICAISC 2021)", "link": "http://arxiv.org/abs/2104.13948v1"}, {"index": 413, "title": "A comparative study of Different Machine Learning Regressors For Stock Market Prediction", "abstract": "For the development of successful share trading strategies, forecasting the course of action of the stock market index is important. Effective prediction of closing stock prices could guarantee investors attractive benefits. Machine learning algorithms have the ability to process and forecast almost reliable closing prices for historical stock patterns. In this article, we intensively studied NASDAQ stock market and targeted to choose the portfolio of ten different companies belongs to different sectors. The objective is to compute opening price of next day stock using historical data. To fulfill this task nine different Machine Learning regressor applied on this data and evaluated using MSE and R2 as performance metric.", "link": "http://arxiv.org/abs/2104.07469v1"}, {"index": 414, "title": "Loss of structural balance in stock markets", "abstract": "We use rank correlations as distance functions to establish the interconnectivity between stock returns, building weighted signed networks for the stocks of seven European countries, the US and Japan. We establish the theoretical relationship between the level of balance in a network and stock predictability, studying its evolution from 2005 to the third quarter of 2020. We find a clear balance-unbalance transition for six of the nine countries, following the August 2011 Black Monday in the US, when the Economic Policy Uncertainty index for this country reached its highest monthly level before the COVID-19 crisis. This sudden loss of balance is mainly caused by a reorganization of the market networks triggered by a group of low capitalization stocks belonging to the non-financial sector. After the transition, the stocks of companies in these groups become all negatively correlated between them and with most of the rest of the stocks in the market. The implied change in the network topology is directly related to a decrease in stocks predictability, a finding with novel important implications for asset allocation and portfolio hedging strategies.", "link": "http://arxiv.org/abs/2104.06254v1"}, {"index": 415, "title": "Oil-US Stock Market Nexus: Some insights about the New Coronavirus Crisis", "abstract": "We provide a new investigation of the relationship between oil and stock prices in the context of the outbreak of the new coronavirus crisis. Specifically, we assess to what extent the uncertainty induced by COVID-19 affects the interaction between oil and the United States (US) stock markets. To this end, we use a wavelet approach and daily data from February 18, 2020 to August 15, 2020. We identify the lead-lag relationship between oil and stock prices, and the intensity of this relationship at different frequency cycles and moments in time. Our unique findings show that co-movements between oil and stock prices manifest at 3-5-day cycle and are stronger in the first part of March and the second part of April 2020, when oil prices are leading stock prices. The partial wavelet coherence analysis, controlling for the effect of COVID-19 and US economic policy-induced uncertainty, reveals that the coronavirus crisis amplifies the shock propagation between oil and stock prices.", "link": "http://arxiv.org/abs/2104.05273v1"}, {"index": 416, "title": "A Fast Evidential Approach for Stock Forecasting", "abstract": "Within the framework of evidence theory, the confidence functions of different information can be combined into a combined confidence function to solve uncertain problems. The Dempster combination rule is a classic method of fusing different information. This paper proposes a similar confidence function for the time point in the time series. The Dempster combination rule can be used to fuse the growth rate of the last time point, and finally a relatively accurate forecast data can be obtained. Stock price forecasting is a concern of economics. The stock price data is large in volume, and more accurate forecasts are required at the same time. The classic methods of time series, such as ARIMA, cannot balance forecasting efficiency and forecasting accuracy at the same time. In this paper, the fusion method of evidence theory is applied to stock price prediction. Evidence theory deals with the uncertainty of stock price prediction and improves the accuracy of prediction. At the same time, the fusion method of evidence theory has low time complexity and fast prediction processing speed.", "link": "http://dx.doi.org/10.1002/int.22598"}, {"index": 417, "title": "Profitability Analysis in Stock Investment Using an LSTM-Based Deep Learning Model", "abstract": "Designing robust systems for precise prediction of future prices of stocks has always been considered a very challenging research problem. Even more challenging is to build a system for constructing an optimum portfolio of stocks based on the forecasted future stock prices. We present a deep learning-based regression model built on a long-and-short-term memory network (LSTM) network that automatically scraps the web and extracts historical stock prices based on a stock's ticker name for a specified pair of start and end dates, and forecasts the future stock prices. We deploy the model on 75 significant stocks chosen from 15 critical sectors of the Indian stock market. For each of the stocks, the model is evaluated for its forecast accuracy. Moreover, the predicted values of the stock prices are used as the basis for investment decisions, and the returns on the investments are computed. Extensive results are presented on the performance of the model. The analysis of the results demonstrates the efficacy and effectiveness of the system and enables us to compare the profitability of the sectors from the point of view of the investors in the stock market.", "link": "http://dx.doi.org/10.1109/INCET51464.2021.9456385"}, {"index": 418, "title": "Taking Stock of the Present and Future of Smart Technologies for Older Adults and Caregivers", "abstract": "Technology has the opportunity to assist older adults as they age in place, coordinate caregiving resources, and meet unmet needs through access to resources. Currently, older adults use consumer technologies to support everyday life, however these technologies are not always accessible or as useful as they can be. Indeed, industry has attempted to create smart home technologies with older adults as a target user group, however these solutions are often more focused on the technical aspects and are short lived. In this paper, we advocate for older adults being involved in the design process - from initial ideation to product development to deployment. We encourage federally funded researchers and industry to create compensated, diverse older adult advisory boards to address stereotypes about aging while ensuring their needs are considered.   We envision artificial intelligence systems that augment resources instead of replacing them - especially in under-resourced communities. Older adults rely on their caregiver networks and community organizations for social, emotional, and physical support; thus, AI should be used to coordinate resources better and lower the burden of connecting with these resources. Although sociotechnical smart systems can help identify needs of older adults, the lack of affordable research infrastructure and translation of findings into consumer technology perpetuates inequities in designing for diverse older adults. In addition, there is a disconnect between the creation of smart sensing systems and creating understandable, actionable data for older adults and caregivers to utilize. We ultimately advocate for a well-coordinated research effort across the United States that connects older adults, caregivers, community organizations, and researchers together to catalyze innovative and practical research for all stakeholders.", "link": "http://arxiv.org/abs/2104.00096v1"}, {"index": 419, "title": "Ising formulations for two-dimensional cutting stock problem with setup cost", "abstract": "We proposed the method that translates the 2-D CSP for minimizing the number of cuts to the Ising model. After that, we conducted computer experiments of the proposed model using the benchmark problem. From the above, the following results are obtained. (1) The proposed Ising model adequately represents the target problem. (2) Acceptance rates were low as 0.2% to 9.8% and from 21.8% to 49.4%. (3) Error rates from optimal solution were broad as 0% to 25.9%. As the future work, (1) Improve the Hamiltonian for Constraints. (2) Improve the proposed model to adjust more complex 2-D CSP and reduce the number of spins when it deals with large materials and components. (3) Conduct experiments using a quantum annealer.", "link": "http://arxiv.org/abs/2103.16796v1"}, {"index": 420, "title": "A Comparative Evaluation of Predominant Deep Learning Quantified Stock Trading Strategies", "abstract": "This study first reconstructs three deep learning powered stock trading models and their associated strategies that are representative of distinct approaches to the problem and established upon different aspects of the many theories evolved around deep learning. It then seeks to compare the performance of these strategies from different perspectives through trading simulations ran on three scenarios when the benchmarks are kept at historical low points for extended periods of time. The results show that in extremely adverse market climates, investment portfolios managed by deep learning powered algorithms are able to avert accumulated losses by generating return sequences that shift the constantly negative CSI 300 benchmark return upward. Among the three, the LSTM model's strategy yields the best performance when the benchmark sustains continued loss.", "link": "http://arxiv.org/abs/2103.15304v2"}, {"index": 421, "title": "Accurate Stock Price Forecasting Using Robust and Optimized Deep Learning Models", "abstract": "Designing robust frameworks for precise prediction of future prices of stocks has always been considered a very challenging research problem. The advocates of the classical efficient market hypothesis affirm that it is impossible to accurately predict the future prices in an efficiently operating market due to the stochastic nature of the stock price variables. However, numerous propositions exist in the literature with varying degrees of sophistication and complexity that illustrate how algorithms and models can be designed for making efficient, accurate, and robust predictions of stock prices. We present a gamut of ten deep learning models of regression for precise and robust prediction of the future prices of the stock of a critical company in the auto sector of India. Using a very granular stock price collected at 5 minutes intervals, we train the models based on the records from 31st Dec, 2012 to 27th Dec, 2013. The testing of the models is done using records from 30th Dec, 2013 to 9th Jan 2015. We explain the design principles of the models and analyze the results of their performance based on accuracy in forecasting and speed of execution.", "link": "http://dx.doi.org/10.1109/CONIT51480.2021.9498565"}, {"index": 422, "title": "Intraday trading strategy based on time series and machine learning for Chinese stock market", "abstract": "This article comes up with an intraday trading strategy under T+1 using Markowitz optimization and Multilayer Perceptron (MLP) with published stock data obtained from the Shenzhen Stock Exchange and Shanghai Stock Exchange. The empirical results reveal the profitability of Markowitz portfolio optimization and validate the intraday stock price prediction using MLP. The findings further combine the Markowitz optimization, an MLP with the trading strategy, to clarify this strategy's feasibility.", "link": "http://arxiv.org/abs/2103.13507v1"}, {"index": 423, "title": "Support Vector Regression Parameters Optimization using Golden Sine Algorithm and its application in stock market", "abstract": "Support vector machine modeling is a new approach in machine learning for classification showing good performance on forecasting problems of small samples and high dimensions. Later, it promoted to Support Vector Regression (SVR) for regression problems. A big challenge for achieving reliable is the choice of appropriate parameters. Here, a novel Golden sine algorithm (GSA) based SVR is proposed for proper selection of the parameters. For comparison, the performance of the proposed algorithm is compared with eleven other meta-heuristic algorithms on some historical stock prices of technological companies from Yahoo Finance website based on Mean Squared Error and Mean Absolute Percent Error. The results demonstrate that the given algorithm is efficient for tuning the parameters and is indeed competitive in terms of accuracy and computing time.", "link": "http://arxiv.org/abs/2103.11459v1"}, {"index": 424, "title": "A Deep Deterministic Policy Gradient-based Strategy for Stocks Portfolio Management", "abstract": "With the improvement of computer performance and the development of GPU-accelerated technology, trading with machine learning algorithms has attracted the attention of many researchers and practitioners. In this research, we propose a novel portfolio management strategy based on the framework of Deep Deterministic Policy Gradient, a policy-based reinforcement learning framework, and compare its performance to that of other trading strategies. In our framework, two Long Short-Term Memory neural networks and two fully connected neural networks are constructed. We also investigate the performance of our strategy with and without transaction costs. Experimentally, we choose eight US stocks consisting of four low-volatility stocks and four high-volatility stocks. We compare the compound annual return rate of our strategy against seven other strategies, e.g., Uniform Buy and Hold, Exponential Gradient and Universal Portfolios. In our case, the compound annual return rate is 14.12%, outperforming all other strategies. Furthermore, in terms of Sharpe Ratio (0.5988), our strategy is nearly 33% higher than that of the second-best performing strategy.", "link": "http://arxiv.org/abs/2103.11455v1"}, {"index": 425, "title": "Stock price forecast with deep learning", "abstract": "In this paper, we compare various approaches to stock price prediction using neural networks. We analyze the performance fully connected, convolutional, and recurrent architectures in predicting the next day value of S&P 500 index based on its previous values. We further expand our analysis by including three different optimization techniques: Stochastic Gradient Descent, Root Mean Square Propagation, and Adaptive Moment Estimation. The numerical experiments reveal that a single layer recurrent neural network with RMSprop optimizer produces optimal results with validation and test Mean Absolute Error of 0.0150 and 0.0148 respectively.", "link": "http://dx.doi.org/10.1109/DASA51403.2020.9317260"}, {"index": 426, "title": "Modeling of crisis periods in stock markets", "abstract": "We exploit a recent computational framework to model and detect financial crises in stock markets, as well as shock events in cryptocurrency markets, which are characterized by a sudden or severe drop in prices. Our method manages to detect all past crises in the French industrial stock market starting with the crash of 1929, including financial crises after 1990 (e.g. dot-com bubble burst of 2000, stock market downturn of 2002), and all past crashes in the cryptocurrency market, namely in 2018, and also in 2020 due to covid-19. We leverage copulae clustering, based on the distance between probability distributions, in order to validate the reliability of the framework; we show that clusters contain copulae from similar market states such as normal states, or crises. Moreover, we propose a novel regression model that can detect successfully all past events using less than 10% of the information that the previous framework requires. We train our model by historical data on the industry assets, and we are able to detect all past shock events in the cryptocurrency market. Our tools provide the essential components of our software framework that offers fast and reliable detection, or even prediction, of shock events in stock and cryptocurrency markets of hundreds of assets.", "link": "http://arxiv.org/abs/2103.13294v1"}, {"index": 427, "title": "Impact of the COVID-19 outbreak on Italy's country reputation and stock market performance: a sentiment analysis approach", "abstract": "During the recent Coronavirus disease 2019 (COVID-19) outbreak, the microblogging service Twitter has been widely used to share opinions and reactions to events. Italy was one of the first European countries to be severely affected by the outbreak and to establish lockdown and stay-at-home orders, potentially leading to country reputation damage. We resort to sentiment analysis to investigate changes in opinions about Italy reported on Twitter before and after the COVID-19 outbreak. Using different lexicons-based methods, we find a breakpoint corresponding to the date of the first established case of COVID-19 in Italy that causes a relevant change in sentiment scores used as proxy of the country reputation. Next, we demonstrate that sentiment scores about Italy are strongly associated with the levels of the FTSE-MIB index, the Italian Stock Exchange main index, as they serve as early detection signals of changes in the values of FTSE-MIB. Finally, we make a content-based classification of tweets into positive and negative and use two machine learning classifiers to validate the assigned polarity of tweets posted before and after the outbreak.", "link": "http://arxiv.org/abs/2103.13871v1"}, {"index": 428, "title": "Feature Learning for Stock Price Prediction Shows a Significant Role of Analyst Rating", "abstract": "To reject the Efficient Market Hypothesis a set of 5 technical indicators and 23 fundamental indicators was identified to establish the possibility of generating excess returns on the stock market. Leveraging these data points and various classification machine learning models, trading data of the 505 equities on the US S&P500 over the past 20 years was analysed to develop a classifier effective for our cause. From any given day, we were able to predict the direction of change in price by 1% up to 10 days in the future. The predictions had an overall accuracy of 83.62% with a precision of 85% for buy signals and a recall of 100% for sell signals. Moreover, we grouped equities by their sector and repeated the experiment to see if grouping similar assets together positively effected the results but concluded that it showed no significant improvements in the performance rejecting the idea of sector-based analysis. Also, using feature ranking we could identify an even smaller set of 6 indicators while maintaining similar accuracies as that from the original 28 features and also uncovered the importance of buy, hold and sell analyst ratings as they came out to be the top contributors in the model. Finally, to evaluate the effectiveness of the classifier in real-life situations, it was backtested on FAANG equities using a modest trading strategy where it generated high returns of above 60% over the term of the testing dataset. In conclusion, our proposed methodology with the combination of purposefully picked features shows an improvement over the previous studies, and our model predicts the direction of 1% price changes on the 10th day with high confidence and with enough buffer to even build a robotic trading system.", "link": "http://dx.doi.org/10.3390/asi4010017"}, {"index": 429, "title": "A Survey of Forex and Stock Price Prediction Using Deep Learning", "abstract": "The prediction of stock and foreign exchange (Forex) had always been a hot and profitable area of study. Deep learning application had proven to yields better accuracy and return in the field of financial prediction and forecasting. In this survey we selected papers from the DBLP database for comparison and analysis. We classified papers according to different deep learning methods, which included: Convolutional neural network (CNN), Long Short-Term Memory (LSTM), Deep neural network (DNN), Recurrent Neural Network (RNN), Reinforcement Learning, and other deep learning methods such as HAN, NLP, and Wavenet. Furthermore, this paper reviewed the dataset, variable, model, and results of each article. The survey presented the results through the most used performance metrics: RMSE, MAPE, MAE, MSE, accuracy, Sharpe ratio, and return rate. We identified that recent models that combined LSTM with other methods, for example, DNN, are widely researched. Reinforcement learning and other deep learning method yielded great returns and performances. We conclude that in recent years the trend of using deep-learning based method for financial modeling is exponentially rising.", "link": "http://dx.doi.org/10.3390/asi4010009"}, {"index": 430, "title": "Text Mining of Stocktwits Data for Predicting Stock Prices", "abstract": "Stock price prediction can be made more efficient by considering the price fluctuations and understanding the sentiments of people. A limited number of models understand financial jargon or have labelled datasets concerning stock price change. To overcome this challenge, we introduced FinALBERT, an ALBERT based model trained to handle financial domain text classification tasks by labelling Stocktwits text data based on stock price change. We collected Stocktwits data for over ten years for 25 different companies, including the major five FAANG (Facebook, Amazon, Apple, Netflix, Google). These datasets were labelled with three labelling techniques based on stock price changes. Our proposed model FinALBERT is fine-tuned with these labels to achieve optimal results. We experimented with the labelled dataset by training it on traditional machine learning, BERT, and FinBERT models, which helped us understand how these labels behaved with different model architectures. Our labelling method competitive advantage is that it can help analyse the historical data effectively, and the mathematical function can be easily customised to predict stock movement.", "link": "http://dx.doi.org/10.3390/asi4010013"}, {"index": 431, "title": "Risk-dependent centrality in the Brazilian stock market", "abstract": "The purpose of this paper is to calculate the risk-dependent centrality (RDC) of the Brazilian stock market. We computed the RDC for assets traded on the Brazilian stock market between January 2008 to June 2020 at different levels of external risk. We observed that the ranking of assets based on the RDC depends on the external risk. Rankings' volatility is related to crisis events, capturing the recent Brazilian economic-political crisis. Moreover, we have found a negative correlation between the average volatility of assets' ranking based on the RDC and the average daily returns on the stock market. It goes in hand with the hypothesis that the rankings' volatility is higher in periods of crisis.", "link": "http://arxiv.org/abs/2103.09059v1"}, {"index": 432, "title": "Complex decision-making strategies in a stock market experiment explained as the combination of few simple strategies", "abstract": "Many studies have shown that there are regularities in the way human beings make decisions. However, our ability to obtain models that capture such regularities and can accurately predict unobserved decisions is still limited. We tackle this problem in the context of individuals who are given information relative to the evolution of market prices and asked to guess the direction of the market. We use a networks inference approach with stochastic block models (SBM) to find the model and network representation that is most predictive of unobserved decisions. Our results suggest that users mostly use recent information (about the market and about their previous decisions) to guess. Furthermore, the analysis of SBM groups reveals a set of strategies used by players to process information and make decisions that is analogous to behaviors observed in other contexts. Our study provides and example on how to quantitatively explore human behavior strategies by representing decisions as networks and using rigorous inference and model-selection approaches.", "link": "http://arxiv.org/abs/2103.06121v1"}, {"index": 433, "title": "Extreme Volatility Prediction in Stock Market: When GameStop meets Long Short-Term Memory Networks", "abstract": "The beginning of 2021 saw a surge in volatility for certain stocks such as GameStop company stock (Ticker GME under NYSE). GameStop stock increased around 10 fold from its decade-long average to its peak at \\$485. In this paper, we hypothesize a buy-and-hold strategy can be outperformed in the presence of extreme volatility by predicting and trading consolidation breakouts. We investigate GME stock for its volatility and compare it to SPY as a benchmark (since it is a less volatile ETF fund) from February 2002 to February 2021. For strategy 1, we develop a Long Short-term Memory (LSTM) Neural Network to predict stock prices recurrently with a very short look ahead period in the presence of extreme volatility. For our strategy 2, we develop an LSTM autoencoder network specifically designed to trade only on consolidation breakouts after predicting anomalies in the stock price. When back-tested in our simulations, our strategy 1 executes 863 trades for SPY and 452 trades for GME. Our strategy 2 executes 931 trades for SPY and 325 trades for GME. We compare both strategies to buying and holding one single share for the period that we picked as a benchmark. In our simulations, SPY returns \\$281.160 from buying and holding one single share, \\$110.29 from strategy 1 with 53.5% success rate and \\$4.34 from strategy 2 with 57.6% success rate. GME returns \\$45.63 from buying and holding one single share, \\$69.046 from strategy 1 with 47.12% success rate and \\$2.10 from strategy 2 with 48% success rate. Overall, buying and holding outperforms all deep-learning assisted prediction models in our study except for when the LSTM-based prediction model (strategy 1) is applied to GME. We hope that our study sheds more light into the field of extreme volatility predictions based on LSTMs to outperform buying and holding strategy.", "link": "http://arxiv.org/abs/2103.01121v2"}, {"index": 434, "title": "Stock market's physical properties description based on Stokes law", "abstract": "We propose in this paper to consider the stock market as a physical system assimilate to a fluid evolving in a macroscopic space subject to a Force that influences its movement over time where this last is arising from the collision between the supply and the demand of Financial agents. In fluid mechanics, this Force also results from the collisions of fluid molecules led by its physical property such as density, viscosity, and surface tension. The purpose of this article is to show that the dynamism of the stock market behavior can be explained qualitatively and quantitatively by considering the supply & demand collision as the result of Financial agents physical properties defined by Stokes Law. The first objective of this article is to show theoretically that fluid mechanics equations can be used to describe stock market physical properties. The second objective based on the knowledge of stock market physical properties is to propose an Econophysics analog of the stock market viscosity and Reynolds number to measure stock market conditions, whether laminar, transitory, or turbulent. The Reynolds Number defined in this way can be applied in research into the study and classification of stock market dynamics phases through for instance the creation of Econophysics analog of Moddy diagram, this last could be seen as a physical way to quantify asset and stock index idiosyncratic risk. The last objective is to present evidence from a computer simulation that the stock market behavior can be a priori, and posteriori explained by physical properties (viscosity & density) quantifiable by fluid mechanics law (Stokes law) and measurable with the stock market Reynolds Number.", "link": "http://arxiv.org/abs/2103.00721v1"}, {"index": 435, "title": "The Maintenance Scheduling and Location Choice Problem for Railway Rolling Stock", "abstract": "Due to increasing railway use, the capacity at railway yards and maintenance locations is becoming limiting. Therefore, the scheduling of rolling stock maintenance and the choice regarding optimal locations to perform maintenance is increasingly complicated. This research introduces a Maintenance Scheduling and Location Choice Problem (MSLCP). It simultaneously determines maintenance locations and maintenance schedules of rolling stock, while it also considers the available capacity of maintenance locations, measured in the number of available teams. To solve the MSLCP, an optimization framework based on Logic-Based Benders' Decomposition (LBBD) is proposed by combining two models, the Maintenance Location Choice Problem (MLCP) and the Activity Planning Problem (APP), to assess the capacity of a MLCP solution. Within the LBBD, four cut generation procedures are introduced to improve the computational performance: a naive procedure, two heuristic procedures and the so-called min-cut procedure that aims to exploit the specific characteristics of the problem at hand. The framework is demonstrated on a realistic scenarios from the Dutch railways. It is shown that the best choice for cut generation procedure depends on the objective: when aiming to find a good but not necessarily optimal solution, the min-cut procedure performs best, whereas when aiming for the optimal solution, one of the heuristic procedures is the preferred option. The techniques used in the current research are new to the current field and offer interesting next research opportunities.", "link": "http://arxiv.org/abs/2103.00454v1"}, {"index": 436, "title": "TI-Capsule: Capsule Network for Stock Exchange Prediction", "abstract": "Today, the use of social networking data has attracted a lot of academic and commercial attention in predicting the stock market. In most studies in this area, the sentiment analysis of the content of user posts on social networks is used to predict market fluctuations. Predicting stock marketing is challenging because of the variables involved. In the short run, the market behaves like a voting machine, but in the long run, it acts like a weighing machine. The purpose of this study is to predict EUR/USD stock behavior using Capsule Network on finance texts and Candlestick images. One of the most important features of Capsule Network is the maintenance of features in a vector, which also takes into account the space between features. The proposed model, TI-Capsule (Text and Image information based Capsule Neural Network), is trained with both the text and image information simultaneously. Extensive experiments carried on the collected dataset have demonstrated the effectiveness of TI-Capsule in solving the stock exchange prediction problem with 91% accuracy.", "link": "http://arxiv.org/abs/2102.07718v1"}, {"index": 437, "title": "REST: Relational Event-driven Stock Trend Forecasting", "abstract": "Stock trend forecasting, aiming at predicting the stock future trends, is crucial for investors to seek maximized profits from the stock market. Many event-driven methods utilized the events extracted from news, social media, and discussion board to forecast the stock trend in recent years. However, existing event-driven methods have two main shortcomings: 1) overlooking the influence of event information differentiated by the stock-dependent properties; 2) neglecting the effect of event information from other related stocks. In this paper, we propose a relational event-driven stock trend forecasting (REST) framework, which can address the shortcoming of existing methods. To remedy the first shortcoming, we propose to model the stock context and learn the effect of event information on the stocks under different contexts. To address the second shortcoming, we construct a stock graph and design a new propagation layer to propagate the effect of event information from related stocks. The experimental studies on the real-world data demonstrate the efficiency of our REST framework. The results of investment simulation show that our framework can achieve a higher return of investment than baselines.", "link": "http://dx.doi.org/10.1145/3442381.3450032"}, {"index": 438, "title": "The Impact of COVID-19 on Stock Market Volatility in Pakistan", "abstract": "This paper examines the impact of coronavirus (COVID-19) on stock market volatility (SMV) in Pakistan by controlling the effect of exchange rate, interest rate and government/central bank interventions to combat the pandemic. We used the vector autoregressive (VAR) model over a sample period ranging from February 25, 2020 to December 7, 2020. We find that a shock to total daily coronavirus cases in Pakistan lead to a significant increase in SMV. This result is aligned with a vast literature on pandemics and investors uncertainty and remains robust to several robustness checks applied in our analysis.", "link": "http://arxiv.org/abs/2103.03219v1"}, {"index": 439, "title": "Dynamic Structural Impact of the COVID-19 Outbreak on the Stock Market and the Exchange Rate: A Cross-country Analysis Among BRICS Nations", "abstract": "COVID-19 has impacted the economy of almost every country in the world. Of particular interest are the responses of the economic indicators of developing nations (such as BRICS) to the COVID-19 shock. As an extension to our earlier work on the dynamic associations of pandemic growth, exchange rate, and stock market indices in the context of India, we look at the same question with respect to the BRICS nations. We use structural variable autoregression (SVAR) to identify the dynamic underlying associations across the normalized growth measurements of the COVID-19 cumulative case, recovery, and death counts, and those of the exchange rate, and stock market indices, using data over 203 days (March 12 - September 30, 2020). Using impulse response analyses, the COVID-19 shock to the growth of exchange rate was seen to persist for around 10+ days, and that for stock exchange was seen to be around 15 days. The models capture the contemporaneous nature of these shocks and the subsequent responses, potentially guiding to inform policy decisions at a national level. Further, causal inference-based analyses would allow us to infer relationships that are stronger than mere associations.", "link": "http://arxiv.org/abs/2102.05554v1"}, {"index": 440, "title": "Pyramid scheme in stock market: a kind of financial market simulation", "abstract": "Artificial stock market simulation based on agent is an important means to study financial market. Based on the assumption that the investors are composed of a main fund, small trend and contrarian investors characterized by four parameters, we simulate and research a kind of financial phenomenon with the characteristics of pyramid schemes. Our simulation results and theoretical analysis reveal the relationships between the rate of return of the main fund and the proportion of the trend investors in all small investors, the small investors' parameters of taking profit and stopping loss, the order size of the main fund and the strategies adopted by the main fund. Our work are helpful to explain the financial phenomenon with the characteristics of pyramid schemes in financial markets, design trading rules for regulators and develop trading strategies for investors.", "link": "http://dx.doi.org/10.1088/1674-1056/abeef3"}, {"index": 441, "title": "Unraveling S&P500 stock volatility and networks -- An encoding-and-decoding approach", "abstract": "Volatility of financial stock is referring to the degree of uncertainty or risk embedded within a stock's dynamics. Such risk has been received huge amounts of attention from diverse financial researchers. By following the concept of regime-switching model, we proposed a non-parametric approach, named encoding-and-decoding, to discover multiple volatility states embedded within a discrete time series of stock returns. The encoding is performed across the entire span of temporal time points for relatively extreme events with respect to a chosen quantile-based threshold. As such the return time series is transformed into Bernoulli-variable processes. In the decoding phase, we computationally seek for locations of change points via estimations based on a new searching algorithm in conjunction with the information criterion applied on the observed collection of recurrence times upon the binary process. Besides the independence required for building the Geometric distributional likelihood function, the proposed approach can functionally partition the entire return time series into a collection of homogeneous segments without any assumptions of dynamic structure and underlying distributions. In the numerical experiments, our approach is found favorably compared with parametric models like Hidden Markov Model. In the real data applications, we introduce the application of our approach in forecasting stock returns. Finally, volatility dynamic of every single stock of S&P500 is revealed, and a stock network is consequently established to represent dependency relations derived through concurrent volatility states among S&P500.", "link": "http://arxiv.org/abs/2101.09395v3"}, {"index": 442, "title": "Artificial intelligence prediction of stock prices using social media", "abstract": "The primary objective of this work is to develop a Neural Network based on LSTM to predict stock market movements using tweets. Word embeddings, used in the LSTM network, are initialised using Stanford's GloVe embeddings, pretrained specifically on 2 billion tweets. To overcome the limited size of the dataset, an augmentation strategy is proposed to split each input sequence into 150 subsets. To achieve further improvements in the original configuration, hyperparameter optimisation is performed. The effects of variation in hyperparameters such as dropout rate, batch size, and LSTM hidden state output size are assessed individually. Furthermore, an exhaustive set of parameter combinations is examined to determine the optimal model configuration. The best performance on the validation dataset is achieved by hyperparameter combination 0.4,8,100 for the dropout, batch size, and hidden units respectively. The final testing accuracy of the model is 76.14%.", "link": "http://arxiv.org/abs/2101.08986v1"}, {"index": 443, "title": "Analysis of stock index with a generalized BN-S model: an approach based on machine learning and fuzzy parameters", "abstract": "In this paper we implement a combination of data-science and fuzzy theory to improve the classical Barndorff-Nielsen and Shephard model, and implement this to analyze the S&P 500 index. We pre-process the index data based on fuzzy theory. After that, S&P 500 stock index data for the past ten years are analyzed, and a deterministic parameter is extracted using various machine and deep learning methods. The results show that the new model, where fuzzy parameters are incorporated, can incorporate the long-term dependence in the classical Barndorff-Nielsen and Shephard model. The modification is based on only a few changes compared to the classical model. At the same time, the resulting analysis effectively captures the stochastic dynamics of the stock index time series.", "link": "http://arxiv.org/abs/2101.08984v3"}, {"index": 444, "title": "Seed Stocking Via Multi-Task Learning", "abstract": "Sellers of crop seeds need to plan for the variety and quantity of seeds to stock at least a year in advance. There are a large number of seed varieties of one crop, and each can perform best under different growing conditions. Given the unpredictability of weather, farmers need to make decisions that balance high yield and low risk. A seed vendor needs to be able to anticipate the needs of farmers and have them ready. In this study, we propose an analytical framework for estimating seed demand with three major steps. First, we will estimate the yield and risk of each variety as if they were planted at each location. Since past experiments performed with different seed varieties are highly unbalanced across varieties, and the combination of growing conditions is sparse, we employ multi-task learning to borrow information from similar varieties. Second, we will determine the best mix of seeds for each location by seeking a tradeoff between yield and risk. Third, we will aggregate such mix and pick the top five varieties to re-balance the yield and risk for each growing location. We find that multi-task learning provides a viable solution for yield prediction, and our overall analytical framework has resulted in a good performance.", "link": "http://arxiv.org/abs/2101.04333v1"}, {"index": 445, "title": "The 'COVID' Crash of the 2020 U.S. Stock Market", "abstract": "We employed the log-periodic power law singularity (LPPLS) methodology to systematically investigate the 2020 stock market crash in the U.S. equities sectors with different levels of total market capitalizations through four major U.S. stock market indexes, including the Wilshire 5000 Total Market index, the S&P 500 index, the S&P MidCap 400 index, and the Russell 2000 index, representing the stocks overall, the large capitalization stocks, the middle capitalization stocks and the small capitalization stocks, respectively. During the 2020 U.S. stock market crash, all four indexes lost more than a third of their values within five weeks, while both the middle capitalization stocks and the small capitalization stocks have suffered much greater losses than the large capitalization stocks and stocks overall. Our results indicate that the price trajectories of these four stock market indexes prior to the 2020 stock market crash have clearly featured the obvious LPPLS bubble pattern and were indeed in a positive bubble regime. Contrary to the popular belief that the COVID-19 led to the 2020 stock market crash, the 2020 U.S. stock market crash was endogenous, stemming from the increasingly systemic instability of the stock market itself. We also performed the complementary post-mortem analysis of the 2020 U.S. stock market crash. Our analyses indicate that the 2020 U.S. stock market crash originated from a bubble which began to form as early as September 2018; and the bubbles in stocks with different levels of total market capitalizations have significantly different starting time profiles. This study not only sheds new light on the making of the 2020 U.S. stock market crash but also creates a novel pipeline for future real-time crash detection and mechanism dissection of any financial market and/or economic index.", "link": "http://arxiv.org/abs/2101.03625v1"}, {"index": 446, "title": "Absolute Value Constraint: The Reason for Invalid Performance Evaluation Results of Neural Network Models for Stock Price Prediction", "abstract": "Neural networks for stock price prediction(NNSPP) have been popular for decades. However, most of its study results remain in the research paper and cannot truly play a role in the securities market. One of the main reasons leading to this situation is that the prediction error(PE) based evaluation results have statistical flaws. Its prediction results cannot represent the most critical financial direction attributes. So it cannot provide investors with convincing, interpretable, and consistent model performance evaluation results for practical applications in the securities market. To illustrate, we have used data selected from 20 stock datasets over six years from the Shanghai and Shenzhen stock market in China, and 20 stock datasets from NASDAQ and NYSE in the USA. We implement six shallow and deep neural networks to predict stock prices and use four prediction error measures for evaluation. The results show that the prediction error value only partially reflects the model accuracy of the stock price prediction, and cannot reflect the change in the direction of the model predicted stock price. This characteristic determines that PE is not suitable as an evaluation indicator of NNSPP. Otherwise, it will bring huge potential risks to investors. Therefore, this paper establishes an experiment platform to confirm that the PE method is not suitable for the NNSPP evaluation, and provides a theoretical basis for the necessity of creating a new NNSPP evaluation method in the future.", "link": "http://arxiv.org/abs/2101.10942v2"}, {"index": 447, "title": "Visualizing the Financial Impact of Presidential Tweets on Stock Markets", "abstract": "As more and more data being created every day, all of it can help take better decisions with data analysis. It is not different from data generated in financial markets. Here we examine the process of how the global economy is affected by the market sentiment influenced by the micro-blogging data (tweets) of American President Donald Trump. The news feed is gathered from The Guardian and Bloomberg from the period between December 2016 and October 2019, which are used to further identify the potential tweets that influenced the markets as measured by changes in equity indices.", "link": "http://arxiv.org/abs/2101.03205v1"}, {"index": 448, "title": "A Reinforcement Learning Based Encoder-Decoder Framework for Learning Stock Trading Rules", "abstract": "A wide variety of deep reinforcement learning (DRL) models have recently been proposed to learn profitable investment strategies. The rules learned by these models outperform the previous strategies specially in high frequency trading environments. However, it is shown that the quality of the extracted features from a long-term sequence of raw prices of the instruments greatly affects the performance of the trading rules learned by these models. Employing a neural encoder-decoder structure to extract informative features from complex input time-series has proved very effective in other popular tasks like neural machine translation and video captioning in which the models face a similar problem. The encoder-decoder framework extracts highly informative features from a long sequence of prices along with learning how to generate outputs based on the extracted features. In this paper, a novel end-to-end model based on the neural encoder-decoder framework combined with DRL is proposed to learn single instrument trading strategies from a long sequence of raw prices of the instrument. The proposed model consists of an encoder which is a neural structure responsible for learning informative features from the input sequence, and a decoder which is a DRL model responsible for learning profitable strategies based on the features extracted by the encoder. The parameters of the encoder and the decoder structures are learned jointly, which enables the encoder to extract features fitted to the task of the decoder DRL. In addition, the effects of different structures for the encoder and various forms of the input sequences on the performance of the learned strategies are investigated. Experimental results showed that the proposed model outperforms other state-of-the-art models in highly dynamic environments.", "link": "http://arxiv.org/abs/2101.03867v1"}, {"index": 449, "title": "COVID19-HPSMP: COVID-19 Adopted Hybrid and Parallel Deep Information Fusion Framework for Stock Price Movement Prediction", "abstract": "The novel of coronavirus (COVID-19) has suddenly and abruptly changed the world as we knew at the start of the 3rd decade of the 21st century. Particularly, COVID-19 pandemic has negatively affected financial econometrics and stock markets across the globe. Artificial Intelligence (AI) and Machine Learning (ML)-based prediction models, especially Deep Neural Network (DNN) architectures, have the potential to act as a key enabling factor to reduce the adverse effects of the COVID-19 pandemic and future possible ones on financial markets. In this regard, first, a unique COVID-19 related PRIce MOvement prediction (COVID19 PRIMO) dataset is introduced in this paper, which incorporates effects of social media trends related to COVID-19 on stock market price movements. Afterwards, a novel hybrid and parallel DNN-based framework is proposed that integrates different and diversified learning architectures. Referred to as the COVID-19 adopted Hybrid and Parallel deep fusion framework for Stock price Movement Prediction (COVID19-HPSMP), innovative fusion strategies are used to combine scattered social media news related to COVID-19 with historical mark data. The proposed COVID19-HPSMP consists of two parallel paths (hence hybrid), one based on Convolutional Neural Network (CNN) with Local/Global Attention modules, and one integrated CNN and Bi-directional Long Short term Memory (BLSTM) path. The two parallel paths are followed by a multilayer fusion layer acting as a fusion centre that combines localized features. Performance evaluations are performed based on the introduced COVID19 PRIMO dataset illustrating superior performance of the proposed framework.", "link": "http://arxiv.org/abs/2101.02287v2"}, {"index": 450, "title": "The 2020 Global Stock Market Crash: Endogenous or Exogenous?", "abstract": "Starting on February 20, 2020, the global stock markets began to suffer the worst decline since the Great Recession in 2008, and the COVID-19 has been widely blamed on the stock market crashes. In this study, we applied the log-periodic power law singularity (LPPLS) methodology based on multilevel time series to unravel the underlying mechanisms of the 2020 global stock market crash by analyzing the trajectories of 10 major stock market indexes from both developed and emergent stock markets, including the S&P 500, DJIA, NASDAQ, FTSE, DAX, NIKKEI, CSI 300, HSI, BSESN, and BOVESPA. In order to effectively distinguish between endogenous crash and exogenous crash, we proposed using the LPPLS confidence indicator as a classification proxy. The results show that the apparent LPPLS bubble patterns of the super-exponential increase, corrected by the accelerating logarithm-periodic oscillations, have indeed presented in the price trajectories of the seven indexes: S&P 500, DJIA, NASDAQ, DAX, CSI 300, BSESN, and BOVESPA, indicating that the large positive bubbles have formed endogenously prior to the 2020 stock market crash, and the subsequent crashes for the seven indexes are endogenous, stemming from the increasingly systemic instability of the stock markets, while the well-known external shocks such as the COVID-19 pandemic etc. only acted as sparks during the 2020 global stock market crash. In contrast, the obvious signatures of the LPPLS model have not been observed in the price trajectories of the three remaining indexes: FTSE, NIKKEI, and HSI, signifying that the crashes in these three indexes are exogenous, stemming from external shocks. The novel classification method of crash types proposed in this study can also be used to analyze regime changes of any price trajectories in global financial markets.", "link": "http://dx.doi.org/10.1016/j.physa.2021.126425"}, {"index": 451, "title": "A Stock Options Metaphor for Content Delivery Networks", "abstract": "The concept of Stock Options is used to address the scarcity of resources, not adequately addressed by the previous tools of our Prediction Mechanism. Using a Predictive Reservation Scheme, network and disk resources are being monitored through well-established techniques (Kernel Regression Estimators) in a given time frame. Next, an Secondary Market mechanism significantly improves the efficiency and robustness of our Predictive Reservation Scheme by allowing the fast exchange of unused (remaining) resources between the Origin Servers (CDN Clients). This exchange can happen, either by implementing socially optimal practices or by allowing automatic electronic auctions at the end of the day or at shorter time intervals. Finally, we further enhance our Prediction Mechanism; Stock Options are obtained and exercised, depending on the lack of resources at the end of day. As a result, Origin Servers may acquire resources (if required) at a normal price. The effectiveness of our mechanism further improves.", "link": "http://dx.doi.org/10.1007/s11066-022-09153-7"}, {"index": 452, "title": "Deep Stock Trading: A Hierarchical Reinforcement Learning Framework for Portfolio Optimization and Order Execution", "abstract": "Portfolio management via reinforcement learning is at the forefront of fintech research, which explores how to optimally reallocate a fund into different financial assets over the long term by trial-and-error. Existing methods are impractical since they usually assume each reallocation can be finished immediately and thus ignoring the price slippage as part of the trading cost. To address these issues, we propose a hierarchical reinforced stock trading system for portfolio management (HRPM). Concretely, we decompose the trading process into a hierarchy of portfolio management over trade execution and train the corresponding policies. The high-level policy gives portfolio weights at a lower frequency to maximize the long term profit and invokes the low-level policy to sell or buy the corresponding shares within a short time window at a higher frequency to minimize the trading cost. We train two levels of policies via pre-training scheme and iterative training scheme for data efficiency. Extensive experimental results in the U.S. market and the China market demonstrate that HRPM achieves significant improvement against many state-of-the-art approaches.", "link": "http://arxiv.org/abs/2012.12620v2"}, {"index": 453, "title": "If Global or Local Investor Sentiments are Prone to Developing an Impact on Stock Returns, is there an Industry Effect?", "abstract": "This paper investigates the heterogeneous impacts of either Global or Local Investor Sentiments on stock returns. We study 10 industry sectors through the lens of 6 (so called) emerging countries: China, Brazil, India, Mexico, Indonesia and Turkey, over the 2000 to 2014 period. Using a panel data framework, our study sheds light on a significant effect of Local Investor Sentiments on expected returns for basic materials, consumer goods, industrial, and financial industries. Moreover, our results suggest that from Global Investor Sentiments alone, one cannot predict expected stock returns in these markets.", "link": "http://dx.doi.org/10.1002/ijfe.2216"}, {"index": 454, "title": "National Accounts as a Stock-Flow Consistent System, Part 1: The Real Accounts", "abstract": "The 2008 economic crisis was not forecastable by at that time existing models of macroeconomics. Thus macroeconomics needs new tools. We introduce a model based on National Accounts that shows how macroeconomic sectors are interconnected. These connections explain the spread of business cycles from one industry to another and from financial sector to the real economy. These lingages cannot be explained by General Equilibrium type of models. Our model describes the real part of National Accounts (NA) of an economy. The accounts are presented in the form of a money flow diagram between the following macro-sectors: Non-financial firms, financial firms, households, government, and rest of the world. The model contains all main items in NA and the corresponding simulation model creates time paths for 59 key macroeconomic quantities for an unlimited future. Finnish data of NA from time period 1975-2012 is used in calibrating the parameters of the model, and the model follows the historical data with sufficient accuracy. Our study serves as a basis for systems analytic macro-models that can explain the positive and negative feed-backs in the production system of an economy. These feed-backs are born from interactions between economic units and between real and financial markets. JEL E01, E10.   Key words: Stock-Flow Models, National Accounts, Simulation model.", "link": "http://arxiv.org/abs/2012.11282v1"}, {"index": 455, "title": "Trader-Company Method: A Metaheuristic for Interpretable Stock Price Prediction", "abstract": "Investors try to predict returns of financial assets to make successful investment. Many quantitative analysts have used machine learning-based methods to find unknown profitable market rules from large amounts of market data. However, there are several challenges in financial markets hindering practical applications of machine learning-based models. First, in financial markets, there is no single model that can consistently make accurate prediction because traders in markets quickly adapt to newly available information. Instead, there are a number of ephemeral and partially correct models called \"alpha factors\". Second, since financial markets are highly uncertain, ensuring interpretability of prediction models is quite important to make reliable trading strategies. To overcome these challenges, we propose the Trader-Company method, a novel evolutionary model that mimics the roles of a financial institute and traders belonging to it. Our method predicts future stock returns by aggregating suggestions from multiple weak learners called Traders. A Trader holds a collection of simple mathematical formulae, each of which represents a candidate of an alpha factor and would be interpretable for real-world investors. The aggregation algorithm, called a Company, maintains multiple Traders. By randomly generating new Traders and retraining them, Companies can efficiently find financially meaningful formulae whilst avoiding overfitting to a transient state of the market. We show the effectiveness of our method by conducting experiments on real market data.", "link": "http://arxiv.org/abs/2012.10215v1"}, {"index": 456, "title": "Dynamical Characteristics of Global Stock Markets Based on Time Dependent Tsallis Non-Extensive Statistics and Generalized Hurst Exponents", "abstract": "We perform non-linear analysis on stock market indices using time-dependent extended Tsallis statistics. Specifically, we evaluate the q-triplet for particular time periods with the purpose of demonstrating the temporal dependence of the extended characteristics of the underlying market dynamics. We apply the analysis on daily close price timeseries of four major global markets (S&P 500, Tokyo-NIKKEI, Frankfurt-DAX, London-LSE). For comparison, we also compute time-dependent Generalized Hurst Exponents (GHE) Hq using the GHE method, thus estimating the temporal evolution of the multiscaling characteristics of the index dynamics. We focus on periods before and after critical market events such as stock market bubbles (2000 dot.com bubble, Japanese 1990 bubble, 2008 US real estate crisis) and find that the temporal trends of q-triplet values significantly differ among these periods indicating that in the rising period before a bubble break, the underlying extended statistics of the market dynamics strongly deviates from purely stochastic behavior, whereas, after the breakdown, it gradually converges to the Gaussian-like behavior which is a characteristic of an efficient market. We also conclude that relative temporal variation patterns of the Tsallis q-triplet can be connected to different aspects of market dynamics and reveals useful information about market conditions especially those underlying the development of a stock market bubble. We found specific temporal patterns and trends in the relative variation of the indices in the q-triplet that distinguish periods just before and just after a stock-market bubble break. Differences between endogenous and exogenous stock market crises are also captured by the temporal changes in the Tsallis q-triplet. Finally, we introduce two new time-dependent empirical metrics (Q-metrics) that are functions of the Tsallis q-triplet.", "link": "http://dx.doi.org/10.1016/j.physa.2021.126121"}, {"index": 457, "title": "ADD: Augmented Disentanglement Distillation Framework for Improving Stock Trend Forecasting", "abstract": "Stock trend forecasting has become a popular research direction that attracts widespread attention in the financial field. Though deep learning methods have achieved promising results, there are still many limitations, for example, how to extract clean features from the raw stock data. In this paper, we introduce an \\emph{Augmented Disentanglement Distillation (ADD)} approach to remove interferential features from the noised raw data. Specifically, we present 1) a disentanglement structure to separate excess and market information from the stock data to avoid the two factors disturbing each other's own prediction. Besides, by applying 2) a dynamic self-distillation method over the disentanglement framework, other implicit interference factors can also be removed. Further, thanks to the decoder module in our framework, 3) a novel strategy is proposed to augment the training samples based on the different excess and market features to improve performance. We conduct experiments on the Chinese stock market data. Results show that our method significantly improves the stock trend forecasting performances, as well as the actual investment income through backtesting, which strongly demonstrates the effectiveness of our approach.", "link": "http://arxiv.org/abs/2012.06289v1"}, {"index": 458, "title": "Deep Reinforcement Learning for Stock Portfolio Optimization", "abstract": "Stock portfolio optimization is the process of constant re-distribution of money to a pool of various stocks. In this paper, we will formulate the problem such that we can apply Reinforcement Learning for the task properly. To maintain a realistic assumption about the market, we will incorporate transaction cost and risk factor into the state as well. On top of that, we will apply various state-of-the-art Deep Reinforcement Learning algorithms for comparison. Since the action space is continuous, the realistic formulation were tested under a family of state-of-the-art continuous policy gradients algorithms: Deep Deterministic Policy Gradient (DDPG), Generalized Deterministic Policy Gradient (GDPG) and Proximal Policy Optimization (PPO), where the former two perform much better than the last one. Next, we will present the end-to-end solution for the task with Minimum Variance Portfolio Theory for stock subset selection, and Wavelet Transform for extracting multi-frequency data pattern. Observations and hypothesis were discussed about the results, as well as possible future research directions.1", "link": "http://dx.doi.org/10.7763/IJMO.2020.V10.761"}, {"index": 459, "title": "The Maintenance Location Choice Problem for Railway Rolling Stock", "abstract": "Due to increasing railway use, the capacity at railway yards and maintenance locations is becoming limiting to accommodate existing rolling stock. To reduce capacity issues at maintenance locations during nighttime, railway undertakings consider performing more daytime maintenance, but the choice at which locations personnel needs to be stationed for daytime maintenance is not straightforward. Among other things, it depends on the planned rolling stock circulation and the maintenance activities that need to be performed. This paper presents the Maintenance Location Choice Problem (MLCP) and provides a Mixed Integer Linear Programming model for this problem. The model demonstrates that for a representative rolling stock circulation from the Dutch railways a substantial amount of maintenance activities can be performed during daytime. Also, it is shown that the location choice delivered by the model is robust under various time horizons and rolling stock circulations. Moreover, the running time for optimizing the model is considered acceptable for planning purposes.", "link": "http://arxiv.org/abs/2012.04565v1"}, {"index": 460, "title": "Statistical properties of the aftershocks of stock market crashes revisited: Analysis based on the 1987 crash, financial-crisis-2008 and COVID-19 pandemic", "abstract": "During any unique crisis, panic sell-off leads to a massive stock market crash that may continue for more than a day, termed as mainshock. The effect of a mainshock in the form of aftershocks can be felt throughout the recovery phase of stock price. As the market remains in stress during recovery, any small perturbation leads to a relatively smaller aftershock. The duration of the recovery phase has been estimated using structural break analysis. We have carried out statistical analyses of the 1987 stock market crash, 2008 financial crisis and 2020 COVID-19 pandemic considering the actual crash-times of the mainshock and aftershocks. Earlier, such analyses were done considering an absolute one-day return, which cannot capture a crash properly. The results show that the mainshock and aftershock in the stock market follow the Gutenberg-Richter (GR) power law. Further, we obtained a higher $\\beta$ value for the COVID-19 crash compared to the financial-crisis-2008 from the GR law. This implies that the recovery of stock price during COVID-19 may be faster than the financial-crisis-2008. The result is consistent with the present recovery of the market from the COVID-19 pandemic. The analysis shows that the high magnitude aftershocks are rare, and low magnitude aftershocks are frequent during the recovery phase. The analysis also shows that the distribution $P(\\tau_i)$ follows the generalized Pareto distribution, i.e., $\\displaystyle~P(\\tau_i)\\propto\\frac{1}{\\{1+\\lambda(q-1)\\tau_i\\}^{\\frac{1}{(q-1)}}}$, where $\\lambda$ and $q$ are constants and $\\tau_i$ is the inter-occurrence time. This analysis may help investors to restructure their portfolios during a market crash.", "link": "http://dx.doi.org/10.1142/S012918312250019X"}, {"index": 461, "title": "A Study on the Efficiency of the Indian Stock Market", "abstract": "The efficiency of the stock market has a significant impact on the potential return on investment. An efficient market eliminates the possibility of arbitrage and unexploited profit opportunities. This study analyzes the weak form efficiency of the Indian Stock market based on the two major Indian stock exchanges, viz., BSE and NSE. The daily closing values of Sensex and Nifty indices for the period from April 2010 to March 2019 are used to perform the Runs test, the Autocorrelation test, and the Autoregression test. The study confirms that the Indian Stock market is weak form inefficient and can thus be outperformed.", "link": "http://arxiv.org/abs/2012.01160v1"}, {"index": 462, "title": "Collective dynamics of stock market efficiency", "abstract": "Summarized by the efficient market hypothesis, the idea that stock prices fully reflect all available information is always confronted with the behavior of real-world markets. While there is plenty of evidence indicating and quantifying the efficiency of stock markets, most studies assume this efficiency to be constant over time so that its dynamical and collective aspects remain poorly understood. Here we define the time-varying efficiency of stock markets by calculating the permutation entropy within sliding time-windows of log-returns of stock market indices. We show that major world stock markets can be hierarchically classified into several groups that display similar long-term efficiency profiles. However, we also show that efficiency ranks and clusters of markets with similar trends are only stable for a few months at a time. We thus propose a network representation of stock markets that aggregates their short-term efficiency patterns into a global and coherent picture. We find this financial network to be strongly entangled while also having a modular structure that consists of two distinct groups of stock markets. Our results suggest that stock market efficiency is a collective phenomenon that can drive its operation at a high level of informational efficiency, but also places the entire system under risk of failure.", "link": "http://dx.doi.org/10.1038/s41598-020-78707-2"}, {"index": 463, "title": "Optimal exploitation of renewable resource stocks: Necessary conditions", "abstract": "We study a model for the exploitation of renewable stocks developed in Clark et al. (Econometrica 47 (1979), 25-47). In this particular control problem, the control law contains a measurable and an impulsive control component. We formulate Pontryagin's maximum principle for this kind of control problems, proving first order necessary conditions of optimality. Manipulating the correspondent Lagrange multipliers we are able to define two special switch functions, that allow us to describe the optimal trajectories and control policies nearly completely for all possible initial conditions in the phase plane.", "link": "http://dx.doi.org/10.1002/oca.737"}, {"index": 464, "title": "Imperfect Oracles: The Effect of Strategic Information on Stock Markets", "abstract": "Modern financial market dynamics warrant detailed analysis due to their significant impact on the world. This, however, often proves intractable; massive numbers of agents, strategies and their change over time in reaction to each other leads to difficulties in both theoretical and simulational approaches. Notable work has been done on strategy dominance in stock markets with respect to the ratios of agents with certain strategies. Perfect knowledge of the strategies employed could then put an individual agent at a consistent trading advantage. This research reports the effects of imperfect oracles on the system - dispensing noisy information about strategies - information which would normally be hidden from market participants. The effect and achievable profits of a singular trader with access to an oracle were tested exhaustively with previously unexplored factors such as changing order schedules. Additionally, the effect of noise on strategic information was traced through its effect on trader efficiency.", "link": "http://arxiv.org/abs/2011.10837v1"}, {"index": 465, "title": "FinRL: A Deep Reinforcement Learning Library for Automated Stock Trading in Quantitative Finance", "abstract": "As deep reinforcement learning (DRL) has been recognized as an effective approach in quantitative finance, getting hands-on experiences is attractive to beginners. However, to train a practical DRL trading agent that decides where to trade, at what price, and what quantity involves error-prone and arduous development and debugging. In this paper, we introduce a DRL library FinRL that facilitates beginners to expose themselves to quantitative finance and to develop their own stock trading strategies. Along with easily-reproducible tutorials, FinRL library allows users to streamline their own developments and to compare with existing schemes easily. Within FinRL, virtual environments are configured with stock market datasets, trading agents are trained with neural networks, and extensive backtesting is analyzed via trading performance. Moreover, it incorporates important trading constraints such as transaction cost, market liquidity and the investor's degree of risk-aversion. FinRL is featured with completeness, hands-on tutorial and reproducibility that favors beginners: (i) at multiple levels of time granularity, FinRL simulates trading environments across various stock markets, including NASDAQ-100, DJIA, S&P 500, HSI, SSE 50, and CSI 300; (ii) organized in a layered architecture with modular structure, FinRL provides fine-tuned state-of-the-art DRL algorithms (DQN, DDPG, PPO, SAC, A2C, TD3, etc.), commonly-used reward functions and standard evaluation baselines to alleviate the debugging workloads and promote the reproducibility, and (iii) being highly extendable, FinRL reserves a complete set of user-import interfaces. Furthermore, we incorporated three application demonstrations, namely single stock trading, multiple stock trading, and portfolio allocation. The FinRL library will be available on Github at link https://github.com/AI4Finance-LLC/FinRL-Library.", "link": "http://arxiv.org/abs/2011.09607v2"}, {"index": 466, "title": "On Simultaneous Long-Short Stock Trading Controllers with Cross-Coupling", "abstract": "The Simultaneous Long-Short(SLS) controller for trading a single stock is known to guarantee positive expected value of the resulting gain-loss function with respect to a large class of stock price dynamics. In the literature, this is known as the Robust Positive Expectation(RPE)property. An obvious way to extend this theory to the trading of two stocks is to trade each one of them using its own independent SLS controller. Motivated by the fact that such a scheme does not exploit any correlation between the two stocks, we study the case when the relative sign between the drifts of the two stocks is known. The main contributions of this paper are three-fold: First, we put forward a novel architecture in which we cross-couple two SLS controllers for the two-stock case. Second, we derive a closed-form expression for the expected value of the gain-loss function. Third, we use this closed-form expression to prove that the RPE property is guaranteed with respect to a large class of stock-price dynamics. When more information over and above the relative sign is assumed, additional benefits of the new architecture are seen. For example, when bounds or precise values for the means and covariances of the stock returns are included in the model, numerical simulations suggest that our new controller can achieve lower trading risk than a pair of decoupled SLS controllers for the same level of expected trading gain.", "link": "http://arxiv.org/abs/2011.09109v1"}, {"index": 467, "title": "COVID-19 and the stock market: evidence from Twitter", "abstract": "COVID-19 has had a much larger impact on the financial markets compared to previous epidemics because the news information is transferred over the social networks at a speed of light. Using Twitter's API, we compiled a unique dataset with more than 26 million COVID-19 related Tweets collected from February 2nd until May 1st, 2020. We find that more frequent use of the word \"stock\" in daily Tweets is associated with a substantial decline in log returns of three key US indices - Dow Jones Industrial Average, S&P500, and NASDAQ. The results remain virtually unchanged in multiple robustness checks.", "link": "http://arxiv.org/abs/2011.08717v1"}, {"index": 468, "title": "Contingent Capital with Stock Price Triggers in Interbank Networks", "abstract": "This paper studies existence and uniqueness of equilibrium prices in a model of the banking sector in which banks trade contingent convertible bonds with stock price triggers among each other. This type of financial product was proposed as an instrument for stabilizing the global banking system after the financial crisis. Yet it was recognized early on that these products may create circularity problems in the definition of stock prices - even in the absence of trade. We find that if conversion thresholds are such that bond holders are indifferent about marginal conversions, there exists a unique equilibrium irrespective of the network structure. When thresholds are lower, existence of equilibrium breaks down while higher thresholds may lead to multiplicity of equilibria. Moreover, there are complex network effects. One bank's conversion may trigger further conversions - or prevent them, depending on the constellations of asset values and conversion triggers.", "link": "http://arxiv.org/abs/2011.06474v1"}, {"index": 469, "title": "Pattern recognition in micro-trading behaviors before stock price jumps: A framework based on multivariate time series analysis", "abstract": "Studying the micro-trading behaviors before stock price jumps is an important problem for financial regulations and investment decisions. In this study, we provide a new framework to study pre-jump trading behaviors based on multivariate time series analysis. Different from the existing literature, our methodology takes into account the temporal information embedded in the trading-related attributes and can better evaluate and compare the abnormality levels of different attributes. Moreover, it can explore the joint informativeness of the attributes as well as select a subset of highly informative but minimally redundant attributes to analyze the homogeneous and idiosyncratic patterns in the pre-jump trades of individual stocks. In addition, our analysis involves a set of technical indicators to describe micro-trading behaviors. To illustrate the viability of the proposed methodology, an application case is conducted based on the level-2 data of 189 constituent stocks of the China Security Index 300. The individual and joint informativeness levels of the attributes in predicting price jumps are evaluated and compared. To this end, our experiment provides a set of jump indicators that can represent the pre-jump trading behaviors in the Chinese stock market and have detected some stocks with extremely abnormal pre-jump trades.", "link": "http://arxiv.org/abs/2011.04939v2"}, {"index": 470, "title": "Reel Stock Analysis for an Integrated Paper Packaging Company", "abstract": "The production of corrugated paper boxes accounts for roughly one third of the world's total paper production and, as a result of both COVID-19 and the rise of e-commerce, is a growing market. We provide a fresh approach to determining near-optimal stock policies for integrated paper companies. The new approach shows that existing policies can be improved by a significant margin. In a case study we saw a reduction in total waste by 9%, with a simultaneous decrease in logistics costs.", "link": "http://arxiv.org/abs/2011.05858v2"}, {"index": 471, "title": "Robust Analysis of Stock Price Time Series Using CNN and LSTM-Based Deep Learning Models", "abstract": "Prediction of stock price and stock price movement patterns has always been a critical area of research. While the well-known efficient market hypothesis rules out any possibility of accurate prediction of stock prices, there are formal propositions in the literature demonstrating accurate modeling of the predictive systems that can enable us to predict stock prices with a very high level of accuracy. In this paper, we present a suite of deep learning-based regression models that yields a very high level of accuracy in stock price prediction. To build our predictive models, we use the historical stock price data of a well-known company listed in the National Stock Exchange (NSE) of India during the period December 31, 2012 to January 9, 2015. The stock prices are recorded at five minutes intervals of time during each working day in a week. Using these extremely granular stock price data, we build four convolutional neural network (CNN) and five long- and short-term memory (LSTM)-based deep learning models for accurate forecasting of the future stock prices. We provide detailed results on the forecasting accuracies of all our proposed models based on their execution time and their root mean square error (RMSE) values.", "link": "http://dx.doi.org/10.1109/ICECA49313.2020.9297652"}, {"index": 472, "title": "Tree species effects on topsoil carbon stock and concentration are mediated by tree species type, mycorrhizal association, and N-fixing ability at the global scale", "abstract": "Selection of appropriate tree species is an important forest management decision that may affect sequestration of carbon (C) in soil. However, information about tree species effects on soil C stocks at the global scale remains unclear. Here, we quantitatively synthesized 850 observations from field studies that were conducted in a common garden or monoculture plantations to assess how tree species type (broadleaf vs. conifer), mycorrhizal association (arbuscular mycorrhizal (AM) vs. ectomycorrhizal (ECM)), and N-fixing ability (N-fixing vs. non-N-fixing), directly and indirectly, affect topsoil (with a median depth of 10 cm) C concentration and stock, and how such effects were influenced by environmental factors such as geographical location and climate. We found that (1) tree species type, mycorrhizal association, and N-fixing ability were all important factors affecting soil C, with lower forest floor C stocks under broadleaved (44%), AM (39%), or N-fixing (28%) trees respectively, but higher mineral soil C concentration (11%, 22%, and 156%) and stock (9%, 10%, and 6%) under broadleaved, AM, and N-fixing trees respectively; (2) tree species type, mycorrhizal association, and N-fixing ability affected forest floor C stock and mineral soil C concentration and stock directly or indirectly through impacting soil properties such as microbial biomass C and nitrogen; (3) tree species effects on mineral soil C concentration and stock were mediated by latitude, MAT, MAP, and forest stand age. These results reveal how tree species and their specific traits influence forest floor C stock and mineral soil C concentration and stock at a global scale. Insights into the underlying mechanisms of tree species effects found in our study would be useful to inform tree species selection in forest management or afforestation aiming to sequester more atmospheric C in soil for mitigation of climate change.", "link": "http://dx.doi.org/10.1016/j.foreco.2020.118510"}, {"index": 473, "title": "Picking Efficient Portfolios from 3,171 US Common Stocks with New Quantum and Classical Solvers", "abstract": "We analyze 3,171 US common stocks to create an efficient portfolio based on the Chicago Quantum Net Score (CQNS) and portfolio optimization. We begin with classical solvers and incorporate quantum annealing. We add a simulated bifurcator as a new classical solver and the new D-Wave Advantage(TM) quantum annealing computer as our new quantum solver.", "link": "http://arxiv.org/abs/2011.01308v1"}, {"index": 474, "title": "Augmenting transferred representations for stock classification", "abstract": "Stock classification is a challenging task due to high levels of noise and volatility of stocks returns. In this paper we show that using transfer learning can help with this task, by pre-training a model to extract universal features on the full universe of stocks of the S$\\&$P500 index and then transferring it to another model to directly learn a trading rule. Transferred models present more than double the risk-adjusted returns than their counterparts trained from zero. In addition, we propose the use of data augmentation on the feature space defined as the output of a pre-trained model (i.e. augmenting the aggregated time-series representation). We compare this augmentation approach with the standard one, i.e. augmenting the time-series in the input space. We show that augmentation methods on the feature space leads to $20\\%$ increase in risk-adjusted return compared to a model trained with transfer learning but without augmentation.", "link": "http://arxiv.org/abs/2011.04545v1"}, {"index": 475, "title": "Options Pricing for Two Stocks by Black Sholes Time Fractional Order NonLinear Partial Differential Equation", "abstract": "The BS equations with fractional order two asset price models give a better prediction of options pricing in the monetary market. In this paper, the changed form of BS-condition with two asset price models dependent on the Liovelle-Caputo derivative for good predictions of options prices are utilized. The analytical solution is demonstrated in form of convergent infinite series and obtained by the properties of Samudu Transform.", "link": "http://dx.doi.org/10.1109/iCoMET48670.2020.9073866"}, {"index": 476, "title": "Event-Driven Learning of Systematic Behaviours in Stock Markets", "abstract": "It is reported that financial news, especially financial events expressed in news, provide information to investors' long/short decisions and influence the movements of stock markets. Motivated by this, we leverage financial event streams to train a classification neural network that detects latent event-stock linkages and stock markets' systematic behaviours in the U.S. stock market. Our proposed pipeline includes (1) a combined event extraction method that utilizes Open Information Extraction and neural co-reference resolution, (2) a BERT/ALBERT enhanced representation of events, and (3) an extended hierarchical attention network that includes attentions on event, news and temporal levels. Our pipeline achieves significantly better accuracies and higher simulated annualized returns than state-of-the-art models when being applied to predicting Standard\\&Poor 500, Dow Jones, Nasdaq indices and 10 individual stocks.", "link": "http://arxiv.org/abs/2010.15586v1"}, {"index": 477, "title": "Stock Price Prediction Using CNN and LSTM-Based Deep Learning Models", "abstract": "Designing robust and accurate predictive models for stock price prediction has been an active area of research for a long time. While on one side, the supporters of the efficient market hypothesis claim that it is impossible to forecast stock prices accurately, many researchers believe otherwise. There exist propositions in the literature that have demonstrated that if properly designed and optimized, predictive models can very accurately and reliably predict future values of stock prices. This paper presents a suite of deep learning based models for stock price prediction. We use the historical records of the NIFTY 50 index listed in the National Stock Exchange of India, during the period from December 29, 2008 to July 31, 2020, for training and testing the models. Our proposition includes two regression models built on convolutional neural networks and three long and short term memory network based predictive models. To forecast the open values of the NIFTY 50 index records, we adopted a multi step prediction technique with walk forward validation. In this approach, the open values of the NIFTY 50 index are predicted on a time horizon of one week, and once a week is over, the actual index values are included in the training set before the model is trained again, and the forecasts for the next week are made. We present detailed results on the forecasting accuracies for all our proposed models. The results show that while all the models are very accurate in forecasting the NIFTY 50 open values, the univariate encoder decoder convolutional LSTM with the previous two weeks data as the input is the most accurate model. On the other hand, a univariate CNN model with previous one week data as the input is found to be the fastest model in terms of its execution speed.", "link": "http://dx.doi.org/10.1109/DASA51403.2020.9317207"}, {"index": 478, "title": "Are Crises Predictable? A Review of the Early Warning Systems in Currency and Stock Markets", "abstract": "The study efforts to explore and extend the crisis predictability by synthetically reviewing and comparing a full mixture of early warning models into two constitutions: crisis identifications and predictive models. Given empirical results on Chinese currency and stock markets, three-strata findings are concluded as (i) the SWARCH model conditional on an elastic thresholding methodology can most accurately classify crisis observations and greatly contribute to boosting the predicting precision, (ii) stylized machine learning models are preferred given higher precision in predicting and greater benefit in practicing, (iii) leading factors sign the crisis in a diversified way for different types of markets and varied prediction periods.", "link": "http://arxiv.org/abs/2010.10132v1"}, {"index": 479, "title": "Taking Over the Stock Market: Adversarial Perturbations Against Algorithmic Traders", "abstract": "In recent years, machine learning has become prevalent in numerous tasks, including algorithmic trading. Stock market traders utilize machine learning models to predict the market's behavior and execute an investment strategy accordingly. However, machine learning models have been shown to be susceptible to input manipulations called adversarial examples. Despite this risk, the trading domain remains largely unexplored in the context of adversarial learning. In this study, we present a realistic scenario in which an attacker influences algorithmic trading systems by using adversarial learning techniques to manipulate the input data stream in real time. The attacker creates a universal perturbation that is agnostic to the target model and time of use, which, when added to the input stream, remains imperceptible. We evaluate our attack on a real-world market data stream and target three different trading algorithms. We show that when added to the input stream, our perturbation can fool the trading algorithms at future unseen data points, in both white-box and black-box settings. Finally, we present various mitigation methods and discuss their limitations, which stem from the algorithmic trading domain. We believe that these findings should serve as an alert to the finance community about the threats in this area and promote further research on the risks associated with using automated learning models in the trading domain.", "link": "http://arxiv.org/abs/2010.09246v2"}, {"index": 480, "title": "Analysis of the impact of maker-taker fees on the stock market using agent-based simulation", "abstract": "Recently, most stock exchanges in the U.S. employ maker-taker fees, in which an exchange pays rebates to traders placing orders in the order book and charges fees to traders taking orders from the order book. Maker-taker fees encourage traders to place many orders that provide market liquidity to the exchange. However, it is not clear how maker-taker fees affect the total cost of a taking order, including all the charged fees and the market impact. In this study, we investigated the effect of maker-taker fees on the total cost of a taking order with our artificial market model, which is an agent-based model for financial markets. We found that maker-taker fees encourage market efficiency but increase the total costs of taking orders.", "link": "http://arxiv.org/abs/2010.08992v1"}, {"index": 481, "title": "Information Coefficient as a Performance Measure of Stock Selection Models", "abstract": "Information coefficient (IC) is a widely used metric for measuring investment managers' skills in selecting stocks. However, its adequacy and effectiveness for evaluating stock selection models has not been clearly understood, as IC from a realistic stock selection model can hardly be materially different from zero and is often accompanies with high volatility. In this paper, we investigate the behavior of IC as a performance measure of stick selection models. Through simulation and simple statistical modeling, we examine the IC behavior both statically and dynamically. The examination helps us propose two practical procedures that one may use for IC-based ongoing performance monitoring of stock selection models.", "link": "http://arxiv.org/abs/2010.08601v1"}, {"index": 482, "title": "Unconventional Policies Effects on Stock Market Volatility: A MAP Approach", "abstract": "Taking the European Central Bank unconventional policies as a reference, we suggest a class of Multiplicative Error Models (MEM) taylored to analyze the impact such policies have on stock market volatility. The new set of models, called MEM with Asymmetry and Policy effects (MAP), keeps the base volatility dynamics separate from a component reproducing policy effects, with an increase in volatility on announcement days and a decrease unfolding implementation effects. When applied to four Eurozone markets, a Model Confidence Set approach finds a significant improvement of the forecasting power of the proxy after the Expanded Asset Purchase Programme implementation; a multi--step ahead forecasting exercise estimates the duration of the effect, and, by shocking the policy variable, we are able to quantify the reduction in volatility which is more marked for debt--troubled countries.", "link": "http://arxiv.org/abs/2010.08259v2"}, {"index": 483, "title": "Choosing News Topics to Explain Stock Market Returns", "abstract": "We analyze methods for selecting topics in news articles to explain stock returns. We find, through empirical and theoretical results, that supervised Latent Dirichlet Allocation (sLDA) implemented through Gibbs sampling in a stochastic EM algorithm will often overfit returns to the detriment of the topic model. We obtain better out-of-sample performance through a random search of plain LDA models. A branching procedure that reinforces effective topic assignments often performs best. We test methods on an archive of over 90,000 news articles about S&P 500 firms.", "link": "http://arxiv.org/abs/2010.07289v1"}, {"index": 484, "title": "Preventing crash in stock market: The role of economic policy uncertainty during COVID-19", "abstract": "This paper investigates the impact of economic policy uncertainty (EPU) on the crash risk of US stock market during the COVID-19 pandemic. To this end, we use the GARCH-S (GARCH with skewness) model to estimate daily skewness as a proxy for the stock market crash risk. The empirical results show the significantly negative correlation between EPU and stock market crash risk, indicating the aggravation of EPU increase the crash risk. Moreover, the negative correlation gets stronger after the global COVID-19 outbreak, which shows the crash risk of the US stock market will be more affected by EPU during the pandemic.", "link": "http://dx.doi.org/10.1186/s40854-021-00248-y"}, {"index": 485, "title": "Stock2Vec: A Hybrid Deep Learning Framework for Stock Market Prediction with Representation Learning and Temporal Convolutional Network", "abstract": "We have proposed to develop a global hybrid deep learning framework to predict the daily prices in the stock market. With representation learning, we derived an embedding called Stock2Vec, which gives us insight for the relationship among different stocks, while the temporal convolutional layers are used for automatically capturing effective temporal patterns both within and across series. Evaluated on S&P 500, our hybrid framework integrates both advantages and achieves better performance on the stock price prediction task than several popular benchmarked models.", "link": "http://arxiv.org/abs/2010.01197v1"}, {"index": 486, "title": "Modeling and analysis of the effect of COVID-19 on the stock price: V and L-shape recovery", "abstract": "The emergence of the COVID-19 pandemic, a new and novel risk factor, leads to the stock price crash due to the investors' rapid and synchronous sell-off. However, within a short period, the quality sectors start recovering from the bottom. A stock price model has been developed during such crises based on the net-fund-flow ($\\Psi_t$) due to institutional investors, and financial antifragility ($\\phi$) of a company. We assume that during the crash, the stock price fall is independent of the $\\phi$. We study the effects of shock lengths and $\\phi$ on the stock price during the crises period using the $\\Psi_t$ obtained from synthetic and real fund flow data. We observed that the possibility of recovery of stock with $\\phi>0$, termed as quality stock, decreases with an increase in shock-length beyond a specific period. A quality stock with higher $\\phi$ shows V-shape recovery and outperform others. The shock length and recovery period of quality stock are almost equal that is seen in the Indian market. Financially stressed stocks, i.e., the stocks with $\\phi<0$, show L-shape recovery during the pandemic. The stock data and model analysis shows that the investors, in uncertainty like COVID-19, invest in quality stocks to restructure their portfolio to reduce the risk. The study may help the investors to make the right investment decision during a crisis.", "link": "http://dx.doi.org/10.1016/j.physa.2021.126008"}, {"index": 487, "title": "Game theory to enhance stock management of Personal Protective Equipment (PPE) during the COVID-19 outbreak", "abstract": "Since the outbreak of the COVID-19 pandemic, many healthcare facilities have suffered from shortages in medical resources, particularly in Personal Protective Equipment (PPE). In this paper, we propose a game-theoretic approach to schedule PPE orders among healthcare facilities. In this PPE game, each independent healthcare facility optimises its own storage utilisation in order to keep its PPE cost at a minimum. Such a model can reduce peak demand considerably when applied to a variable PPE consumption profile. Experiments conducted for NHS England regions using actual data confirm that the challenge of securing PPE supply during disasters such as COVID-19 can be eased if proper stock management procedures are adopted. These procedures can include early stockpiling, increasing storage capacities and implementing measures that can prolong the time period between successive infection waves, such as social distancing measures. Simulation results suggest that the provision of PPE dedicated storage space can be a viable solution to avoid straining PPE supply chains in case a second wave of COVID-19 infections occurs.", "link": "http://dx.doi.org/10.1371/journal.pone.0246110"}, {"index": 488, "title": "Distillation of News Flow into Analysis of Stock Reactions", "abstract": "The gargantuan plethora of opinions, facts and tweets on financial business offers the opportunity to test and analyze the influence of such text sources on future directions of stocks. It also creates though the necessity to distill via statistical technology the informative elements of this prodigious and indeed colossal data source. Using mixed text sources from professional platforms, blog fora and stock message boards we distill via different lexica sentiment variables. These are employed for an analysis of stock reactions: volatility, volume and returns. An increased sentiment, especially for those with negative prospection, will influence volatility as well as volume. This influence is contingent on the lexical projection and different across Global Industry Classification Standard (GICS) sectors. Based on review articles on 100 S&P 500 constituents for the period of October 20, 2009, to October 13, 2014, we project into BL, MPQA, LM lexica and use the distilled sentiment variables to forecast individual stock indicators in a panel context. Exploiting different lexical projections to test different stock reaction indicators we aim at answering the following research questions: (i) Are the lexica consistent in their analytic ability? (ii) To which degree is there an asymmetric response given the sentiment scales (positive v.s. negative)? (iii) Are the news of high attention firms diffusing faster and result in more timely and efficient stock reaction? (iv) Is there a sector-specific reaction from the distilled sentiment measures? We find there is significant incremental information in the distilled news flow and the sentiment effect is characterized as an asymmetric, attention-specific and sector-specific response of stock reactions.", "link": "http://dx.doi.org/10.1080/07350015.2015.1110525"}, {"index": 489, "title": "Stock Price Prediction Using Machine Learning and LSTM-Based Deep Learning Models", "abstract": "Prediction of stock prices has been an important area of research for a long time. While supporters of the efficient market hypothesis believe that it is impossible to predict stock prices accurately, there are formal propositions demonstrating that accurate modeling and designing of appropriate variables may lead to models using which stock prices and stock price movement patterns can be very accurately predicted. In this work, we propose an approach of hybrid modeling for stock price prediction building different machine learning and deep learning-based models. For the purpose of our study, we have used NIFTY 50 index values of the National Stock Exchange (NSE) of India, during the period December 29, 2014 till July 31, 2020. We have built eight regression models using the training data that consisted of NIFTY 50 index records during December 29, 2014 till December 28, 2018. Using these regression models, we predicted the open values of NIFTY 50 for the period December 31, 2018 till July 31, 2020. We, then, augment the predictive power of our forecasting framework by building four deep learning-based regression models using long-and short-term memory (LSTM) networks with a novel approach of walk-forward validation. We exploit the power of LSTM regression models in forecasting the future NIFTY 50 open values using four different models that differ in their architecture and in the structure of their input data. Extensive results are presented on various metrics for the all the regression models. The results clearly indicate that the LSTM-based univariate model that uses one-week prior data as input for predicting the next week open value of the NIFTY 50 time series is the most accurate model.", "link": "http://dx.doi.org/10.1007/978-981-16-0419-5_8"}, {"index": 490, "title": "The impact of COVID-19 on the stock market crash risk in China", "abstract": "This study investigates the impact of the COVID-19 pandemic on the stock market crash risk in China. For this purpose, we first estimated the conditional skewness of the return distribution from a GARCH with skewness (GARCH-S) model as the proxy for the equity market crash risk of the Shanghai Stock Exchange. We then constructed a fear index for COVID-19 using data from the Baidu Index. Based on the findings, conditional skewness reacts negatively to daily growth in total confirmed cases, indicating that the pandemic increases stock market crash risk. Moreover, the fear sentiment exacerbates such risk, especially with regard to the impact of COVID-19. In other words, when the fear sentiment is high, the stock market crash risk is more strongly affected by the pandemic. Our evidence is robust for the number of daily deaths and global cases.", "link": "http://dx.doi.org/10.1016/j.ribaf.2021.101419"}, {"index": 491, "title": "Is Factor Momentum More than Stock Momentum?", "abstract": "Yes, but only at short lags. In this paper we investigate the relationship between factor momentum and stock momentum. Using a sample of 72 factors documented in the literature, we first replicate earlier findings that factor momentum exists and works both directionally and cross-sectionally. We then ask if factor momentum is spanned by stock momentum. A simple spanning test reveals that after controlling for stock momentum and factor exposure, statistically significant Sharpe ratios only belong to implementations which include the last month of returns. We conclude this study with a simple theoretical model that captures these forces: (1) there is stock-level mean reversion at short lags and momentum at longer lags, (2) there is stock and factor momentum at all lags and (3) there is natural comovement between the PNLs of stock and factor momentums at all horizons.", "link": "http://arxiv.org/abs/2009.04824v1"}, {"index": 492, "title": "Nondiagonal Mixture of Dirichlet Network Distributions for Analyzing a Stock Ownership Network", "abstract": "Block modeling is widely used in studies on complex networks. The cornerstone model is the stochastic block model (SBM), widely used over the past decades. However, the SBM is limited in analyzing complex networks as the model is, in essence, a random graph model that cannot reproduce the basic properties of many complex networks, such as sparsity and heavy-tailed degree distribution. In this paper, we provide an edge exchangeable block model that incorporates such basic features and simultaneously infers the latent block structure of a given complex network. Our model is a Bayesian nonparametric model that flexibly estimates the number of blocks and takes into account the possibility of unseen nodes. Using one synthetic dataset and one real-world stock ownership dataset, we show that our model outperforms state-of-the-art SBMs for held-out link prediction tasks.", "link": "http://arxiv.org/abs/2009.04446v2"}, {"index": 493, "title": "A Stock Prediction Model Based on DCNN", "abstract": "The prediction of a stock price has always been a challenging issue, as its volatility can be affected by many factors such as national policies, company financial reports, industry performance, and investor sentiment etc.. In this paper, we present a prediction model based on deep CNN and the candle charts, the continuous time stock information is processed. According to different information richness, prediction time interval and classification method, the original data is divided into multiple categories as the training set of CNN. In addition, the convolutional neural network is used to predict the stock market and analyze the difference in accuracy under different classification methods.   The results show that the method has the best performance when the forecast time interval is 20 days. Moreover, the Moving Average Convergence Divergence and three kinds of moving average are added as input. This method can accurately predict the stock trend of the US NDAQ exchange for 92.2%. Meanwhile, this article distinguishes three conventional classification methods to provide guidance for future research.", "link": "http://arxiv.org/abs/2009.03239v1"}, {"index": 494, "title": "The behavior of stock market prices throughout the episodes of capital inflows", "abstract": "This study aims to investigate the behavior of stock prices throughout the episodes of foreign capital flows using data of daily stock prices and quarterly foreign capital flows from 14 EMEs. To this end, the episodes of capital flows are identified using the threshold and the k-means clustering approaches. Next, the stock index changepoints are detected using the Pruned Exact Linear Time (PELT) method. Finally, we combine the results by distributing the detected changepoints over the identified capital flows. The results reveal that the stock indices have been rarely pushed further during the entire surge episodes identified by both approaches, and thus surges of capital flows do not necessarily lead to further appreciation of stock prices. In the meantime, a significant appreciation of stock prices is observed during the normal state of capital flows. On the other hand, it is noticed that the stock prices have not often depreciated during the episodes of foreign capital outflows in all the selected EMEs, which means that stock prices have been less vulnerable to reversals of foreign capital flows", "link": "http://arxiv.org/abs/2008.13472v1"}, {"index": 495, "title": "Quantifying the impact of COVID-19 on the US stock market: An analysis from multi-source information", "abstract": "We develop a novel temporal complex network approach to quantify the US county level spread dynamics of COVID-19. The objective is to study the effects of the local spread dynamics, COVID-19 cases and death, and Google search activities on the US stock market. We use both conventional econometric and Machine Learning (ML) models. The results suggest that COVID-19 cases and deaths, its local spread, and Google searches have impacts on abnormal stock prices between January 2020 to May 2020. In addition, incorporating information about local spread significantly improves the performance of forecasting models of the abnormal stock prices at longer forecasting horizons. On the other hand, although a few COVID-19 related variables, e.g., US total deaths and US new cases exhibit causal relationships on price volatility, COVID-19 cases and deaths, local spread of COVID-19, and Google search activities do not have impacts on price volatility.", "link": "http://arxiv.org/abs/2008.10885v3"}, {"index": 496, "title": "Towards Earnings Call and Stock Price Movement", "abstract": "Earnings calls are hosted by management of public companies to discuss the company's financial performance with analysts and investors. Information disclosed during an earnings call is an essential source of data for analysts and investors to make investment decisions. Thus, we leverage earnings call transcripts to predict future stock price dynamics. We propose to model the language in transcripts using a deep learning framework, where an attention mechanism is applied to encode the text data into vectors for the discriminative network classifier to predict stock price movements. Our empirical experiments show that the proposed model is superior to the traditional machine learning baselines and earnings call information can boost the stock price prediction performance.", "link": "http://arxiv.org/abs/2009.01317v1"}, {"index": 497, "title": "Portfolio Optimization of 60 Stocks Using Classical and Quantum Algorithms", "abstract": "We continue to investigate the use of quantum computers for building an optimal portfolio out of a universe of 60 U.S. listed, liquid equities. Starting from historical market data, we apply our unique problem formulation on the D-Wave Systems Inc. D-Wave 2000Q (TM) quantum annealing system (hereafter called D-Wave) to find the optimal risk vs return portfolio. We approach this first classically, then using the D-Wave, to select efficient buy and hold portfolios. Our results show that practitioners can use either classical or quantum annealing methods to select attractive portfolios. This builds upon our prior work on optimization of 40 stocks.", "link": "http://arxiv.org/abs/2008.08669v1"}, {"index": 498, "title": "Stock Index Prediction with Multi-task Learning and Word Polarity Over Time", "abstract": "Sentiment-based stock prediction systems aim to explore sentiment or event signals from online corpora and attempt to relate the signals to stock price variations. Both the feature-based and neural-networks-based approaches have delivered promising results. However, the frequently minor fluctuations of the stock prices restrict learning the sentiment of text from price patterns, and learning market sentiment from text can be biased if the text is irrelevant to the underlying market. In addition, when using discrete word features, the polarity of a certain term can change over time according to different events. To address these issues, we propose a two-stage system that consists of a sentiment extractor to extract the opinion on the market trend and a summarizer that predicts the direction of the index movement of following week given the opinions of the news over the current week. We adopt BERT with multitask learning which additionally predicts the worthiness of the news and propose a metric called Polarity-Over-Time to extract the word polarity among different event periods. A Weekly-Monday prediction framework and a new dataset, the 10-year Reuters financial news dataset, are also proposed.", "link": "http://arxiv.org/abs/2008.07605v1"}, {"index": 499, "title": "A free boundary problem arising from a multi-state regime-switching stock trading model", "abstract": "In this paper, we study a free boundary problem, which arises from an optimal trading problem of a stock that is driven by a uncertain market status process. The free boundary problem is a variational inequality system of three functions with a degenerate operator. The main contribution of this paper is that we not only prove all the four switching free boundaries are no-overlapping, monotonic and $C^{\\infty}$-smooth, but also completely determine their relative localities and provide the optimal trading strategies for the stock trading problem.", "link": "http://arxiv.org/abs/2008.07082v1"}, {"index": 500, "title": "Short Term Stress of Covid-19 On World Major Stock Indices", "abstract": "The main objective of this study is to check short term stress of COVID-19 on the American, European, Asian, and Pacific stock market indices, furthermore, the correlation between all the stock markets during the pandemic. Secondary data of 41 stock exchange from 32 countries have been collected from investing.com website from 1st July 2019 to 14th May 2020 for the stock market and the COVID-19 data has been collected according to the first cases reported in the country, stocks market are classified either developed or emerging economy, further divided according to the subcontinent i.e. America, Europe, and Pacific/Asia, the main focus in the data is the report of first COVID-19 cases. The study reveals that there is volatility in the all the 41 stock market (American, Europe, Asia, and Pacific) after reporting of the first case and volatility increase with the increase of COVID-19 cases, moreover, there is a significant negative relationship between the number of COVID-19 cases and 41 major stock indices of American, Europe, Asia and Pacific, European subcontinent market found more effected from the COVID-19 than another subcontinent, there is Clustering effect of COVID-19 on all the stock market except American's stock market due to smart capital investing.", "link": "http://arxiv.org/abs/2008.06450v1"}, {"index": 501, "title": "On the correlation analysis of illiquid stocks", "abstract": "The serial correlations of illiquid stock's price changes are studied, allowing for unconditional heteroscedasticity and time-varying zero returns probability. Depending on the set up, we investigate how the usual autocorrelations can be accommodated, to deliver an accurate representation of the price changes serial correlations. We shed some light on the properties of the different serial correlations measures, by mean of Monte Carlo experiments. The theoretical arguments are illustrated considering shares from the Chilean stock market.", "link": "http://arxiv.org/abs/2008.06168v3"}, {"index": 502, "title": "The Time Function of Stock Price", "abstract": "This paper tends to define the quantitative relationship between the stock price and time as a time function. Based on the empirical evidence that the log-return of a stock is the series of white noise, a mathematical model of the integral white noise is established to describe the phenomenon of stock price movement. A deductive approach is used to derive the auto-correlation function, displacement formula and power spectral density of the stock price movement, which reveals not only the characteristics and rules of the movement but also the predictability of the stock price. The deductive fundamental is provided for the price analysis, prediction and risk management of portfolio investment.", "link": "http://arxiv.org/abs/2008.11806v2"}, {"index": 503, "title": "A Novel Ensemble Deep Learning Model for Stock Prediction Based on Stock Prices and News", "abstract": "In recent years, machine learning and deep learning have become popular methods for financial data analysis, including financial textual data, numerical data, and graphical data. This paper proposes to use sentiment analysis to extract useful information from multiple textual data sources and a blending ensemble deep learning model to predict future stock movement. The blending ensemble model contains two levels. The first level contains two Recurrent Neural Networks (RNNs), one Long-Short Term Memory network (LSTM) and one Gated Recurrent Units network (GRU), followed by a fully connected neural network as the second level model. The RNNs, LSTM, and GRU models can effectively capture the time-series events in the input data, and the fully connected neural network is used to ensemble several individual prediction results to further improve the prediction accuracy. The purpose of this work is to explain our design philosophy and show that ensemble deep learning technologies can truly predict future stock price trends more effectively and can better assist investors in making the right investment decision than other traditional methods.", "link": "http://arxiv.org/abs/2007.12620v1"}, {"index": 504, "title": "Can animal manure be used to increase soil organic carbon stocks in the Mediterranean as a mitigation climate change strategy?", "abstract": "Soil organic carbon (SOC) plays an important role on improving soil conditions and soil functions. Increasing land use changes have induced an important decline of SOC content at global scale. Increasing SOC in agricultural soils has been proposed as a strategy to mitigate climate change. Animal manure has the characteristic of enriching SOC, when applied to crop fields, while, in parallel, it could constitute a natural fertilizer for the crops. In this paper, a simulation is performed using the area of Catalonia, Spain as a case study for the characteristic low SOC in the Mediterranean, to examine whether animal manure can improve substantially the SOC of agricultural fields, when applied as organic fertilizers. Our results show that the policy goals of the 4x1000 strategy can be achieved only partially by using manure transported to the fields. This implies that the proposed approach needs to be combined with other strategies.", "link": "http://arxiv.org/abs/2007.10823v1"}, {"index": 505, "title": "Uncovering a factor-based expected return conditioning structure with Regression Trees jointly for many stocks", "abstract": "Given the success and almost universal acceptance of the simple linear regression three-factor model, it is interesting to analyze the informational content of the three factors in explaining stock returns when the analysis is allowed to consider non-linear dependencies between factors and stock returns. In order to better understand factor-based conditioning information with respect to expected stock returns within a regression tree setting, the analysis of stock returns is demonstrated using daily stock return data for 5 major US corporations. The first finding is that in all cases (solo and joint) the most informative factor is always the market excess return factor. Further, three major issues are discussed: a) the balance of a depth=1 tree as it relates to properties of the stock return distribution, b) the mechanism behind depth=1 tree balance in a joint regression tree and c) the dominant stock in a joint regression tree. It is shown that high skew values alone cannot explain the imbalance of the resulting tree split as stocks with pronounced skew may produce balanced tree splits.", "link": "http://arxiv.org/abs/2007.08115v1"}, {"index": 506, "title": "How does stock market reflect the change in economic demand? A study on the industry-specific volatility spillover networks of China's stock market during the outbreak of COVID-19", "abstract": "Using the carefully selected industry classification standard, we divide 102 industry securities indices in China's stock market into four demand-oriented sector groups and identify demand-oriented industry-specific volatility spillover networks. The \"deman-oriented\" is a new idea of reconstructing the structure of the networks considering the relationship between industry sectors and the economic demand their outputs meeting. Networks with the new structure help us improve the understanding of the economic demand change, especially when the macroeconomic is dramatically influenced by exogenous shocks like the outbreak of COVID-19. At the beginning of the outbreak of COVID-19, in China's stock market, spillover effects from industry indices of sectors meeting the investment demand to those meeting the consumption demands rose significantly. However, these spillover effects fell after the outbreak containment in China appeared to be effective. Besides, some services sectors including utility, transportation and information services have played increasingly important roles in the networks of industry-specific volatility spillovers as of the COVID-19 out broke. By implication, firstly, being led by Chinese government, the COVID-19 is successfully contained and the work resumption is organized with a high efficiency in China. The risk of the investment demand therefore was controlled and eliminated relatively fast. Secondly, the intensive using of non-pharmaceutical interventions (NPIs) led to supply restriction in services in China. It will still be a potential threat for the Chinese economic recovery in the next stage.", "link": "http://arxiv.org/abs/2007.07487v1"}, {"index": 507, "title": "A Research on Cross-sectional Return Dispersion and Volatility of US Stock Market during COVID-19", "abstract": "We studied the volatility and cross-sectional return dispersion effect of S&P Health Care Sector under the covid-19 epidemic. We innovatively used the Google index to proxy the impact of the epidemic and modeled the volatility. We also studied the influencing factors of the log-return of S&P Energy Sector and S&P Health Care Sector. We found that volatility is significantly affected by both the epidemic and cross-sectional return dispersion, and the coefficients in front of them are all positive, which means that the herding behaviour did not exist and as the cross-sectional return dispersion increases and the epidemic becomes more severe, the volatility of stock returns is also increasing. We also found that the epidemic has a significant negative impact on the return of the energy sector, and finally we provided our suggestions to investors.", "link": "http://arxiv.org/abs/2007.11546v2"}, {"index": 508, "title": "Impact of COVID-19 on Forecasting Stock Prices: An Integration of Stationary Wavelet Transform and Bidirectional Long Short-Term Memory", "abstract": "COVID-19 is an infectious disease that mostly affects the respiratory system. At the time of this research being performed, there were more than 1.4 million cases of COVID-19, and one of the biggest anxieties is not just our health, but our livelihoods, too. In this research, authors investigate the impact of COVID-19 on the global economy, more specifically, the impact of COVID-19 on financial movement of Crude Oil price and three U.S. stock indexes: DJI, S&P 500 and NASDAQ Composite. The proposed system for predicting commodity and stock prices integrates the Stationary Wavelet Transform (SWT) and Bidirectional Long Short-Term Memory (BDLSTM) networks. Firstly, SWT is used to decompose the data into approximation and detail coefficients. After decomposition, data of Crude Oil price and stock market indexes along with COVID-19 confirmed cases were used as input variables for future price movement forecasting. As a result, the proposed system BDLSTM+WT-ADA achieved satisfactory results in terms of five-day Crude Oil price forecast.", "link": "http://arxiv.org/abs/2007.02673v1"}, {"index": 509, "title": "Portfolio Optimization of 40 Stocks Using the DWave Quantum Annealer", "abstract": "We investigate the use of quantum computers for building a portfolio out of a universe of U.S. listed, liquid equities that contains an optimal set of stocks. Starting from historical market data, we look at various problem formulations on the D-Wave Systems Inc. D-Wave 2000Q(TM) System (hereafter called DWave) to find the optimal risk vs return portfolio; an optimized portfolio based on the Markowitz formulation and the Sharpe ratio, a simplified Chicago Quantum Ratio (CQR), then a new Chicago Quantum Net Score (CQNS). We approach this first classically, then by our new method on DWave. Our results show that practitioners can use a DWave to select attractive portfolios out of 40 U.S. liquid equities.", "link": "http://arxiv.org/abs/2007.01430v1"}, {"index": 510, "title": "Construction of confidence interval for a univariate stock price signal predicted through Long Short Term Memory Network", "abstract": "In this paper, we show an innovative way to construct bootstrap confidence interval of a signal estimated based on a univariate LSTM model. We take three different types of bootstrap methods for dependent set up. We prescribe some useful suggestions to select the optimal block length while performing the bootstrapping of the sample. We also propose a benchmark to compare the confidence interval measured through different bootstrap strategies. We illustrate the experimental results through some stock price data set.", "link": "http://arxiv.org/abs/2007.00254v1"}, {"index": 511, "title": "Testing and Support Recovery of Correlation Structures for Matrix-Valued Observations with an Application to Stock Market Data", "abstract": "Estimation of the covariance matrix of asset returns is crucial to portfolio construction. As suggested by economic theories, the correlation structure among assets differs between emerging markets and developed countries. It is therefore imperative to make rigorous statistical inference on correlation matrix equality between the two groups of countries. However, if the traditional vector-valued approach is undertaken, such inference is either infeasible due to limited number of countries comparing to the relatively abundant assets, or invalid due to the violations of temporal independence assumption. This highlights the necessity of treating the observations as matrix-valued rather than vector-valued. With matrix-valued observations, our problem of interest can be formulated as statistical inference on covariance structures under sub-Gaussian distributions, i.e., testing non-correlation and correlation equality, as well as the corresponding support estimations. We develop procedures that are asymptotically optimal under some regularity conditions. Simulation results demonstrate the computational and statistical advantages of our procedures over certain existing state-of-the-art methods for both normal and non-normal distributions. Application of our procedures to stock market data reveals interesting patterns and validates several economic propositions via rigorous statistical testing.", "link": "http://arxiv.org/abs/2006.16501v2"}, {"index": 512, "title": "Hierarchical stock assessment methods improve management performance in multi-species, data-limited fisheries", "abstract": "Management performance of five alternative stock assessment methods was evaluated by using them to set harvest levels targeting multi-species maximum yield in a multi-species flatfish fishery, including single-species and hierarchical multi-species models, and methods that pooled data across species and spatial strata, with catch outcomes of each method under three data scenarios compared to catch under an omniscient manager simulation. Operating models included technical interactions between species intended to produce choke effects often observed in output controlled multi-species fisheries. Hierarchical multi-species models outperformed all other methods under data-poor and data-moderate scenarios, and outperformed single-species models under the data-rich scenario. Hierarchical models were least sensitive to prior precision, sometimes improving in performance when prior precision was reduced. Choke effects were found to both positive and negative effects, sometimes leading to underfishing of non-choke species, but at other times preventing overfishing of non-choke species. We highlight the importance of including technical interactions in multi-species assessment models and management objectives, how choke species can indicate mismatches between management objectives and system dynamics, and recommend hierarchical multi-species models for multi-species fishery management systems.", "link": "http://arxiv.org/abs/2006.14357v1"}, {"index": 513, "title": "Examining the Effect of COVID-19 on Foreign Exchange Rate and Stock Market -- An Applied Insight into the Variable Effects of Lockdown on Indian Economy", "abstract": "Since March 25, 2020, India had been under a nation-wide lockdown announced as a response to the spread of SARS-CoV-2 and COVID-19 and has resorted to a process of 'unlocking' the lockdown over the past couple of months. This work attempts to examine the effect of novel coronavirus 2019 (COVID-19) and its resulting disease, the COVID-19, on the foreign exchange rates and stock market performances of India using secondary data over a span of 112 days spanning between March 11 and June 30, 2020. The study explores whether the causal relationships and directions among the growth rate of confirmed cases (GROWTHC), exchange rate (GEX) and SENSEX value (GSENSEX) are remaining the same across different pre and post-lockdown phases, attempting to capture any potential changes over time via the vector autoregressive (VAR) models. A positive correlation is found between the growth rate of confirmed cases and the growth rate of exchange rate, and a negative correlation between the growth rate of confirmed cases and the growth rate of SENSEX value. However, on applying a vector autoregressive (VAR) model, it is observed that an increase in the confirmed COVID-19 cases causes no significant change in the values of the exchange rate and SENSEX index. The result varies if the analysis is split across different time periods - before lockdown, the four phases of lockdown, and the first phase of unlock. Nuanced and sensible interpretations of the numeric results indicate significant variability across time in terms of the relation between the variables of interest. The detailed knowledge about the varying patterns of dependence could potentially help the policy makers and investors of India in order to develop their strategies to cope up with the situation.", "link": "http://arxiv.org/abs/2006.14499v4"}, {"index": 514, "title": "Using Company Specific Headlines and Convolutional Neural Networks to Predict Stock Fluctuations", "abstract": "This work presents a Convolutional Neural Network (CNN) for the prediction of next-day stock fluctuations using company-specific news headlines. Experiments to evaluate model performance using various configurations of word-embeddings and convolutional filter widths are reported. The total number of convolutional filters used is far fewer than is common, reducing the dimensionality of the task without loss of accuracy. Furthermore, multiple hidden layers with decreasing dimensionality are employed. A classification accuracy of 61.7\\% is achieved using pre-learned embeddings, that are fine-tuned during training to represent the specific context of this task. Multiple filter widths are also implemented to detect different length phrases that are key for classification. Trading simulations are conducted using the presented classification results. Initial investments are more than tripled over a 838 day testing period using the optimal classification configuration and a simple trading strategy. Two novel methods are presented to reduce the risk of the trading simulations. Adjustment of the sigmoid class threshold and re-labelling headlines using multiple classes form the basis of these methods. A combination of these approaches is found to more than double the Average Trade Profit (ATP) achieved during baseline simulations.", "link": "http://arxiv.org/abs/2006.12426v1"}, {"index": 515, "title": "Investment Disputes and Abnormal Volatility of Stocks", "abstract": "Dramatic growth of investment disputes between foreign investors and host states rises serious questions about the impact of those disputes on investors. This paper is the first to explain increased uncertainty of investors about the outcome of arbitration, which may or may not lead to compensation for damages claimed by the investor. We find robust evidence that investment disputes lead to abnormal share fluctuations of companies involved in disputes with host countries. Importantly, while a positive outcome for an investor decreases uncertainty back to original levels, we document strong increase in the volatility of companies with negative outcome for the investor. We find that several variables including size of the award, political instability, location of arbitration, country of origin of investor or public policy considerations in host country explain large portion of the investor's uncertainty.", "link": "http://arxiv.org/abs/2006.10505v1"}, {"index": 516, "title": "A Tweet-based Dataset for Company-Level Stock Return Prediction", "abstract": "Public opinion influences events, especially related to stock market movement, in which a subtle hint can influence the local outcome of the market. In this paper, we present a dataset that allows for company-level analysis of tweet based impact on one-, two-, three-, and seven-day stock returns. Our dataset consists of 862, 231 labelled instances from twitter in English, we also release a cleaned subset of 85, 176 labelled instances to the community. We also provide baselines using standard machine learning algorithms and a multi-view learning based approach that makes use of different types of features. Our dataset, scripts and models are publicly available at: https://github.com/ImperialNLP/stockreturnpred.", "link": "http://arxiv.org/abs/2006.09723v1"}, {"index": 517, "title": "Deep Stock Predictions", "abstract": "Forecasting stock prices can be interpreted as a time series prediction problem, for which Long Short Term Memory (LSTM) neural networks are often used due to their architecture specifically built to solve such problems. In this paper, we consider the design of a trading strategy that performs portfolio optimization using the LSTM stock price prediction for four different companies. We then customize the loss function used to train the LSTM to increase the profit earned. Moreover, we propose a data driven approach for optimal selection of window length and multi-step prediction length, and consider the addition of analyst calls as technical indicators to a multi-stack Bidirectional LSTM strengthened by the addition of Attention units. We find the LSTM model with the customized loss function to have an improved performance in the training bot over a regressive baseline such as ARIMA, while the addition of analyst call does improve the performance for certain datasets.", "link": "http://arxiv.org/abs/2006.04992v1"}, {"index": 518, "title": "Generating Realistic Stock Market Order Streams", "abstract": "We propose an approach to generate realistic and high-fidelity stock market data based on generative adversarial networks (GANs). Our Stock-GAN model employs a conditional Wasserstein GAN to capture history dependence of orders. The generator design includes specially crafted aspects including components that approximate the market's auction mechanism, augmenting the order history with order-book constructions to improve the generation task. We perform an ablation study to verify the usefulness of aspects of our network structure. We provide a mathematical characterization of distribution learned by the generator. We also propose statistics to measure the quality of generated orders. We test our approach with synthetic and actual market data, compare to many baseline generative models, and find the generated data to be close to real data.", "link": "http://arxiv.org/abs/2006.04212v1"}, {"index": 519, "title": "Optimum Production for a heaped stock dependent breakable item through variational principle", "abstract": "Breakability rate of fragile item depends on the accumulated stress of heaped stock level. So breakablility rate can be considered as dependent parameter of stock variable. The unit production cost is a function of production rate and also dependent on raw material cost, development cost and wear-tear cost. The holding cost is assumed to be non-linear, dependent on time. Here optimal control problem for a fragile item under finite time horizon is considered. The profit function which consists of revenue, production and holding costs is formulated as a Fixed-Final Time and Fixed State System(cf. Naidu (2000)) optimal control problem with finite time horizon. Here production rate is unknown and considered as a control variable and stock level is taken as a state variable. It is formulated to optimize the production rate so that total profit is maximum. As particular cases, models are evaluated with and without breakability. The models are solved by using conventional Variational Principle along with the non-linear optimization technique-Generalised Reduced Gradient Method (LINGO 12.0). The optimum results are illustrated both numerically and graphically. Some sensitivity analysis on breakability coefficient are presented.", "link": "http://arxiv.org/abs/2006.01740v1"}, {"index": 520, "title": "The impacts of asymmetry on modeling and forecasting realized volatility in Japanese stock markets", "abstract": "This study investigates the impacts of asymmetry on the modeling and forecasting of realized volatility in the Japanese futures and spot stock markets. We employ heterogeneous autoregressive (HAR) models allowing for three types of asymmetry: positive and negative realized semivariance (RSV), asymmetric jumps, and leverage effects. The estimation results show that leverage effects clearly influence the modeling of realized volatility models. Leverage effects exist for both the spot and futures markets in the Nikkei 225. Although realized semivariance aids better modeling, the estimations of RSV models depend on whether these models have leverage effects. Asymmetric jump components do not have a clear influence on realized volatility models. While leverage effects and realized semivariance also improve the out-of-sample forecast performance of volatility models, asymmetric jumps are not useful for predictive ability. The empirical results of this study indicate that asymmetric information, in particular, leverage effects and realized semivariance, yield better modeling and more accurate forecast performance. Accordingly, asymmetric information should be included when we model and forecast the realized volatility of Japanese stock markets.", "link": "http://arxiv.org/abs/2006.00158v1"}, {"index": 521, "title": "Stocks and Cryptocurrencies: Anti-fragile or Robust?", "abstract": "In contrast with robust systems that resist noise or fragile systems that break with noise, antifragility is defined as a property of complex systems that benefit from noise or disorder. Here we define and test a simple measure of antifragility for complex dynamical systems. In this work we use our antifragility measure to analyze real data from return prices in the stock and cryptocurrency markets. Our definition of antifragility is the product of the return price and a perturbation. We explore different types of perturbations that typically arise from within the system. Our results suggest that for both the stock market and the cryptocurrency market, the tendency among the 'top performers' is to be robust rather than antifragile. It would be important to explore other possible definitions of antifragility to understand its role in financial markets and in complex dynamical systems in general.", "link": "http://dx.doi.org/10.1371/journal.pone.0280487"}, {"index": 522, "title": "A Novel Distributed Representation of News (DRNews) for Stock Market Predictions", "abstract": "In this study, a novel Distributed Representation of News (DRNews) model is developed and applied in deep learning-based stock market predictions. With the merit of integrating contextual information and cross-documental knowledge, the DRNews model creates news vectors that describe both the semantic information and potential linkages among news events through an attributed news network. Two stock market prediction tasks, namely the short-term stock movement prediction and stock crises early warning, are implemented in the framework of the attention-based Long Short Term-Memory (LSTM) network. It is suggested that DRNews substantially enhances the results of both tasks comparing with five baselines of news embedding models. Further, the attention mechanism suggests that short-term stock trend and stock market crises both receive influences from daily news with the former demonstrates more critical responses on the information related to the stock market {\\em per se}, whilst the latter draws more concerns on the banking sector and economic policies.", "link": "http://arxiv.org/abs/2005.11706v2"}, {"index": 523, "title": "Informed recruitment or the importance of taking stock", "abstract": "One important decision, especially for long-lived species, is where and when to start reproduction, i.e. where and when to recruit. For an informed decision on recruitment, individuals may prospect potential breeding sites and gather information on the future breeding site, hence reducing uncertainty. Recruitment may also be delayed or advanced over a range of sexually mature ages and this individual decision may influence survival costs of first reproduction, senescence patterns and ultimately lifetime reproductive success. Here we show that recruitment in the long-lived Audouin's gull is mostly informed, meaning that mainly occurs when the individual has visited the colony before. Individuals recruiting without gathering information were all young first-time breeders. Interestingly, these recruits were affected by demographic carry-over effects: first, they were much less prone to reproduce in subsequent seasons than individuals that performed informed recruitment. More strikingly, uninformed recruitment also affected survival, which was much lower for those individuals breeding without gathering information on the breeding site. This study suggests that taking stock before recruitment may be crucial for reducing environmental uncertainty and for maximising individual fitness prospects.", "link": "http://arxiv.org/abs/2005.06248v1"}, {"index": 524, "title": "Multi-Graph Convolutional Network for Relationship-Driven Stock Movement Prediction", "abstract": "Stock price movement prediction is commonly accepted as a very challenging task due to the volatile nature of financial markets. Previous works typically predict the stock price mainly based on its own information, neglecting the cross effect among involved stocks. However, it is well known that an individual stock price is correlated with prices of other stocks in complex ways. To take the cross effect into consideration, we propose a deep learning framework, called Multi-GCGRU, which comprises graph convolutional network (GCN) and gated recurrent unit (GRU) to predict stock movement. Specifically, we first encode multiple relationships among stocks into graphs based on financial domain knowledge and utilize GCN to extract the cross effect based on these pre-defined graphs. To further get rid of prior knowledge, we explore an adaptive relationship learned by data automatically. The cross-correlation features produced by GCN are concatenated with historical records and then fed into GRU to model the temporal dependency of stock prices. Experiments on two stock indexes in China market show that our model outperforms other baselines. Note that our model is rather feasible to incorporate more effective stock relationships containing expert knowledge, as well as learn data-driven relationship.", "link": "http://dx.doi.org/10.1109/ICPR48806.2021.9412695"}, {"index": 525, "title": "Methods for forecasting the effect of exogenous risk on stock markets", "abstract": "Markets are subjected to both endogenous and exogenous risks that have caused disruptions to financial and economic markets around the globe, leading eventually to fast stock market declines. In the past, markets have recovered after any economic disruption. On this basis, we focus on the outbreak of COVID-19 as a case study of an exogenous risk and analyze its impact on the Standard and Poor's 500 (S\\&P500) index. We assumed that the S\\&P500 index reaches a minimum before rising again in the not-too-distant future. Here we present two cases to forecast the S\\&P500 index. The first case uses an estimation of expected deaths released on 02/04/2020 by the University of Washington. For the second case, it is assumed that the peak number of deaths will occur 2-months since the first confirmed case occurred in the USA. The decline and recovery in the index were estimated for the following three months after the initial point of the predicted trend. The forecast is a projection of a prediction with stochastic fluctuations described by $q$-gaussian diffusion process with three spatio-temporal regimes. Our forecast was made on the premise that any market response can be decomposed into an overall deterministic trend and a stochastic term. The prediction was based on the deterministic part and for this case study is approximated by the extrapolation of the S\\&P500 data trend in the initial stages of the outbreak. The stochastic fluctuations have the same structure as the one derived from the past 24 years. A reasonable forecast was achieved with 85\\% of accuracy.", "link": "http://dx.doi.org/10.1016/j.physa.2020.125587"}, {"index": 526, "title": "Value relevance of the components of oil and gas reserve quantity change disclosures of upstream oil and gas companies in the london stock exchange", "abstract": "The high level of risk and uncertainty in harnessing oil and gas reserves poses an accounting dilemma in the reporting of reserves quantity information; information which is critical and relied on by investors for decision making. Different studies have indicated that reserves disclosure information is fundamental to understanding the value of the firm. This study attempts to contribute to the growing value relevance literature on reserves disclosures by examining the value relevance of the components of oil and gas reserve quantity change disclosures of upstream oil and gas companies in the London Stock Exchange. Particularly, it investigates the relationship between average historical share returns and changes in reserves from explorations, acquisitions, production, revisions and sale. It also examines the value relevance of the quality of these disclosures. Using archival data from LSE, databases and annual reports, and applying a multifactor framework, the empirical results suggested that changes in reserves as well as the components of these changes where associated with share returns though insignificantly due to the significant impact of oil price and longitudinal effect posed by applying the measurement approach with utilizes historical returns. However, the quality of reserves disclosures has a positively significant relationship with share returns. The volatility and decline in oil price is also reflected in both low average share returns at -0.4% and low average growth in reserves at 8.94% for the last 8 years in the sector.", "link": "http://arxiv.org/abs/2005.14659v1"}, {"index": 527, "title": "ESG2Risk: A Deep Learning Framework from ESG News to Stock Volatility Prediction", "abstract": "Incorporating environmental, social, and governance (ESG) considerations into systematic investments has drawn numerous attention recently. In this paper, we focus on the ESG events in financial news flow and exploring the predictive power of ESG related financial news on stock volatility. In particular, we develop a pipeline of ESG news extraction, news representations, and Bayesian inference of deep learning models. Experimental evaluation on real data and different markets demonstrates the superior predicting performance as well as the relation of high volatility prediction to stocks with potential high risk and low return. It also shows the prospect of the proposed pipeline as a flexible predicting framework for various textual data and target variables.", "link": "http://arxiv.org/abs/2005.02527v1"}, {"index": 528, "title": "Defining an intrinsic stickiness parameter of stock price returns", "abstract": "We introduce a non linear pricing model of individual stock returns that defines a stickiness parameter of the returns. The pricing model resembles the capital asset pricing model used in finance but has a non linear component inspired from models of earth quake tectonic plate movements. The link to tectonic plate movements happens, since price movements of a given stock index is seen adding stress to its components of individual stock returns, in order to follow the index. How closely individual stocks follow the indexs price movements, can then be used to define their stickiness", "link": "http://dx.doi.org/10.1016/j.physa.2020.124464"}, {"index": 529, "title": "Stocks Vote with Their Feet: Can a Piece of Paper Document Fights the COVID-19 Pandemic?", "abstract": "Assessing the trend of the COVID-19 pandemic and policy effectiveness is essential for both policymakers and stock investors, but challenging because the crisis has unfolded with extreme speed and the previous index was not suitable for measuring policy effectiveness for COVID-19. This paper builds an index of policy effectiveness on fighting COVID-19 pandemic, whose building method is similar to the index of Policy Uncertainty, based on province-level paper documents released in China from Jan.1st to Apr.16th of 2020. This paper also studies the relationships among COVID-19 daily confirmed cases, stock market volatility, and document-based policy effectiveness in China. This paper uses the DCC-GARCH model to fit conditional covariance's change rule of multi-series. This paper finally tests four hypotheses, about the time-space difference of policy effectiveness and its overflow effect both on the COVID-19 pandemic and stock market. Through the inner interaction of this triad structure, we can bring forward more specific and scientific suggestions to maintain stability in the stock market at such exceptional times.", "link": "http://arxiv.org/abs/2005.02034v1"}, {"index": 530, "title": "Decision-Making, Sub-Additive Recursive \"Matching\" Noise And Biases In Risk-Weighted Stock/Bond Index Calculation Methods In Incomplete Markets With Partially Observable Multi-Attribute Preferences", "abstract": "While Indices, Index tracking funds and ETFs have grown in popularity during then last ten years, there are many structural problems inherent in Index calculation methodologies and the legal/economic structure of ETFs. These problems raise actionable issues of Suitability and fraud under US securities laws, because most Indices and ETFs are misleading, have substantial tracking errors and dont reflect what they are supposed to track. This article contributes to the existing literature by: a) introducing and characterizing the errors and Biases inherent in risk-adjusted index weighting methods and the associated adverse effects; b) showing how these biases/effects inherent in Index calculation methods reduce social welfare, and can form the basis for harmful arbitrage activities.", "link": "http://dx.doi.org/10.1142/S1793830913500201"}, {"index": 531, "title": "Generalization of Affine Feedback Stock Trading Results to Include Stop-Loss Orders", "abstract": "The takeoff point of this paper is to generalize the existing stock trading results for a class of affine feedback controller to include consideration of a stop-loss order. Using the geometric Brownian motion as the underlying stock price model, our main result is to provide a closed-form expression for the cumulative distribution function for the trading profit or loss. In addition, we show that the affine feedback controller with stop-loss order indeed generalizes the result without stop order in the sense of distribution function. Some simulations and illustrative examples are also provided as supporting evidence of the theory. Moreover, we provide some technical results aimed at addressing the issues about survivability, cash-financing considerations, long-only property, and lower bound of the expected gain or loss.", "link": "http://dx.doi.org/10.1016/j.automatica.2021.110051"}, {"index": 532, "title": "A New Metric for Lumpy and Intermittent Demand Forecasts: Stock-keeping-oriented Prediction Error Costs", "abstract": "Forecasts of product demand are essential for short- and long-term optimization of logistics and production. Thus, the most accurate prediction possible is desirable. In order to optimally train predictive models, the deviation of the forecast compared to the actual demand needs to be assessed by a proper metric. However, if a metric does not represent the actual prediction error, predictive models are insufficiently optimized and, consequently, will yield inaccurate predictions. The most common metrics such as MAPE or RMSE, however, are not suitable for the evaluation of forecasting errors, especially for lumpy and intermittent demand patterns, as they do not sufficiently account for, e.g., temporal shifts (prediction before or after actual demand) or cost-related aspects. Therefore, we propose a novel metric that, in addition to statistical considerations, also addresses business aspects. Additionally, we evaluate the metric based on simulated and real demand time series from the automotive aftermarket.", "link": "http://arxiv.org/abs/2004.10537v1"}, {"index": 533, "title": "Forecasting directional movements of stock prices for intraday trading using LSTM and random forests", "abstract": "We employ both random forests and LSTM networks (more precisely CuDNNLSTM) as training methodologies to analyze their effectiveness in forecasting out-of-sample directional movements of constituent stocks of the S&P 500 from January 1993 till December 2018 for intraday trading. We introduce a multi-feature setting consisting not only of the returns with respect to the closing prices, but also with respect to the opening prices and intraday returns. As trading strategy, we use Krauss et al. (2017) and Fischer & Krauss (2018) as benchmark. On each trading day, we buy the 10 stocks with the highest probability and sell short the 10 stocks with the lowest probability to outperform the market in terms of intraday returns -- all with equal monetary weight. Our empirical results show that the multi-feature setting provides a daily return, prior to transaction costs, of 0.64% using LSTM networks, and 0.54% using random forests. Hence we outperform the single-feature setting in Fischer & Krauss (2018) and Krauss et al. (2017) consisting only of the daily returns with respect to the closing prices, having corresponding daily returns of 0.41% and of 0.39% with respect to LSTM and random forests, respectively.", "link": "http://arxiv.org/abs/2004.10178v2"}, {"index": 534, "title": "Information flow networks of Chinese stock market sectors", "abstract": "Transfer entropy measures the strength and direction of information flow between different time series. We study the information flow networks of the Chinese stock market and identify important sectors and information flow paths. This paper uses the daily closing price data of the 28 level-1 sectors from Shenyin \\& Wanguo Securities ranging from 2000 to 2017 to study the information transmission between different sectors. We construct information flow networks with the sectors as the nodes and the transfer entropy between them as the corresponding edges. Then we adopt the maximum spanning arborescence (MSA) to extracting important information flows and the hierarchical structure of the networks. We find that, during the whole sample period, the \\textit{composite} sector is an information source of the whole stock market, while the \\textit{non-bank financial} sector is the information sink. We also find that the \\textit{non-bank finance}, \\textit{bank}, \\textit{computer}, \\textit{media}, \\textit{real estate}, \\textit{medical biology} and \\textit{non-ferrous metals} sectors appear as high-degree root nodes in the outgoing and incoming information flow MSAs. Especially, the \\textit{non-bank finance} and \\textit{bank} sectors have significantly high degrees after 2008 in the outgoing information flow networks. We uncover how stock market turmoils affect the structure of the MSAs. Finally, we reveal the specificity of information source and sink sectors and make a conclusion that the root node sector as the information sink of the incoming information flow networks. Overall, our analyses show that the structure of information flow networks changes with time and the market exhibits a sector rotation phenomenon. Our work has important implications for market participants and policy makers in managing market risks and controlling the contagion of risks.", "link": "http://dx.doi.org/10.1109/ACCESS.2020.2966278"}, {"index": 535, "title": "Long memory in select stock returns using an alternative wavelet log-scale alignment approach", "abstract": "This study investigates the efficiency of some select stock markets. Using an improved wavelet estimator of long range dependence, we show evidence of long memory in the stock returns of some emerging Asian economies. However, developed markets of Europe and the United States did not exhibit long memory thereby confirming the efficiency of developed stock markets. On the other hand, emerging Asian markets are found to be less efficient as long memory is more pronounced in these markets.", "link": "http://arxiv.org/abs/2004.08550v1"}, {"index": 536, "title": "A Time Series Analysis-Based Stock Price Prediction Using Machine Learning and Deep Learning Models", "abstract": "Prediction of future movement of stock prices has always been a challenging task for the researchers. While the advocates of the efficient market hypothesis (EMH) believe that it is impossible to design any predictive framework that can accurately predict the movement of stock prices, there are seminal work in the literature that have clearly demonstrated that the seemingly random movement patterns in the time series of a stock price can be predicted with a high level of accuracy. Design of such predictive models requires choice of appropriate variables, right transformation methods of the variables, and tuning of the parameters of the models. In this work, we present a very robust and accurate framework of stock price prediction that consists of an agglomeration of statistical, machine learning and deep learning models. We use the daily stock price data, collected at five minutes interval of time, of a very well known company that is listed in the National Stock Exchange (NSE) of India. The granular data is aggregated into three slots in a day, and the aggregated data is used for building and training the forecasting models. We contend that the agglomerative approach of model building that uses a combination of statistical, machine learning, and deep learning approaches, can very effectively learn from the volatile and random movement patterns in a stock price data. We build eight classification and eight regression models based on statistical and machine learning approaches. In addition to these models, a deep learning regression model using a long-and-short-term memory (LSTM) network is also built. Extensive results have been presented on the performance of these models, and the results are critically analyzed.", "link": "http://dx.doi.org/10.1504/IJBFMI.2020.115691"}, {"index": 537, "title": "Information transfer between stock market sectors: A comparison between the USA and China", "abstract": "Information diffusion within financial markets plays a crucial role in the process of price formation and the propagation of sentiment and risk. We perform a comparative analysis of information transfer between industry sectors of the Chinese and the USA stock markets, using daily sector indices for the period from 2000 to 2017. The information flow from one sector to another is measured by the transfer entropy of the daily returns of the two sector indices. We find that the most active sector in information exchange (i.e., the largest total information inflow and outflow) is the {\\textit{non-bank financial}} sector in the Chinese market and the {\\textit{technology}} sector in the USA market. This is consistent with the role of the non-bank sector in corporate financing in China and the impact of technological innovation in the USA. In each market, the most active sector is also the largest information sink that has the largest information inflow (i.e., inflow minus outflow). In contrast, we identify that the main information source is the {\\textit{bank}} sector in the Chinese market and the {\\textit{energy}} sector in the USA market. In the case of China, this is due to the importance of net bank lending as a signal of corporate activity and the role of energy pricing in affecting corporate profitability. There are sectors such as the {\\textit{real estate}} sector that could be an information sink in one market but an information source in the other, showing the complex behavior of different markets. Overall, these findings show that stock markets are more synchronized, or ordered, during periods of turmoil than during periods of stability.", "link": "http://dx.doi.org/10.3390/e22020194"}, {"index": 538, "title": "The interdependency structure in the Mexican stock exchange: A network approach", "abstract": "Our goal in this paper is to study and characterize the interdependency structure of the Mexican Stock Exchange (mainly stocks from BMV) in the period 2000-2019 and provide visualizations which in a one shot provide a big-picture panorama. To this end, we estimate correlation/concentration matrices from different models and then compute metrics from network theory including eigencentralities and network modularity", "link": "http://arxiv.org/abs/2004.06676v1"}, {"index": 539, "title": "Speech Translation and the End-to-End Promise: Taking Stock of Where We Are", "abstract": "Over its three decade history, speech translation has experienced several shifts in its primary research themes; moving from loosely coupled cascades of speech recognition and machine translation, to exploring questions of tight coupling, and finally to end-to-end models that have recently attracted much attention. This paper provides a brief survey of these developments, along with a discussion of the main challenges of traditional approaches which stem from committing to intermediate representations from the speech recognizer, and from training cascaded models separately towards different objectives.   Recent end-to-end modeling techniques promise a principled way of overcoming these issues by allowing joint training of all model components and removing the need for explicit intermediate representations. However, a closer look reveals that many end-to-end models fall short of solving these issues, due to compromises made to address data scarcity. This paper provides a unifying categorization and nomenclature that covers both traditional and recent approaches and that may help researchers by highlighting both trade-offs and open research questions.", "link": "http://arxiv.org/abs/2004.06358v1"}, {"index": 540, "title": "Holding-Based Evaluation upon Actively Managed Stock Mutual Funds in China", "abstract": "We analyze actively managed mutual funds in China from 2005 to 2017. We develop performance measures for asset allocation and selection. We find that stock selection ability from holding-based model is positively correlated with selection ability estimated from Fama-French three-factor model, which is price-based regression model. We also find that industry allocation from holding-based model is positively correlated with timing ability estimated from price-based Treynor-Mazuy model most of the time. We conclude that most actively managed funds have positive stock selection ability but not asset allocation ability, which is due to the difficulty in predicting policy changes.", "link": "http://arxiv.org/abs/2004.05322v2"}, {"index": 541, "title": "Spanning analysis of stock market anomalies under Prospect Stochastic Dominance", "abstract": "We develop and implement methods for determining whether introducing new securities or relaxing investment constraints improves the investment opportunity set for prospect investors. We formulate a new testing procedure for prospect spanning for two nested portfolio sets based on subsampling and Linear Programming. In an application, we use the prospect spanning framework to evaluate whether well-known anomalies are spanned by standard factors. We find that of the strategies considered, many expand the opportunity set of the prospect type investors, thus have real economic value for them. In-sample and out-of-sample results prove remarkably consistent in identifying genuine anomalies for prospect investors.", "link": "http://arxiv.org/abs/2004.02670v1"}, {"index": 542, "title": "The illiquidity network of stocks in China's market crash", "abstract": "The Chinese stock market experienced an abrupt crash in 2015, and over one-third of its market value evaporated. Given its associations with fear and the fine resolution with respect to frequency, the illiquidity of stocks may offer a promising perspective for understanding and even signaling a market crash. In this study, by connecting stocks with illiquidity comovements, an illiquidity network is established to model the market. Compared to noncrash days, on crash days, the market is more densely connected due to heavier but more homogeneous illiquidity dependencies that facilitate abrupt collapses. Critical stocks in the illiquidity network, particularly those in the finance sector, are targeted for inspection because of their crucial roles in accumulating and passing on illiquidity losses. The cascading failures of stocks in market crashes are profiled as disseminating from small degrees to high degrees that are usually located in the core of the illiquidity network and then back to the periphery. By counting the days with random failures in the previous five days, an early signal is implemented to successfully predict more than half of the crash days, especially consecutive days in the early phase. Additional evidence from both the Granger causality network and the random network further testifies to the robustness of the signal. Our results could help market practitioners such as regulators detect and prevent the risk of crashes in advance.", "link": "http://arxiv.org/abs/2004.01917v3"}, {"index": 543, "title": "News-Driven Stock Prediction With Attention-Based Noisy Recurrent State Transition", "abstract": "We consider direct modeling of underlying stock value movement sequences over time in the news-driven stock movement prediction. A recurrent state transition model is constructed, which better captures a gradual process of stock movement continuously by modeling the correlation between past and future price movements. By separating the effects of news and noise, a noisy random factor is also explicitly fitted based on the recurrent states. Results show that the proposed model outperforms strong baselines. Thanks to the use of attention over news events, our model is also more explainable. To our knowledge, we are the first to explicitly model both events and noise over a fundamental stock value state for news-driven stock movement prediction.", "link": "http://dx.doi.org/10.1016/j.neucom.2021.10.092"}, {"index": 544, "title": "Inside the Mind of a Stock Market Crash", "abstract": "We analyze how investor expectations about economic growth and stock returns changed during the February-March 2020 stock market crash induced by the COVID-19 pandemic, as well as during the subsequent partial stock market recovery. We surveyed retail investors who are clients of Vanguard at three points in time: (i) on February 11-12, around the all-time stock market high, (ii) on March 11-12, after the stock market had collapsed by over 20\\%, and (iii) on April 16-17, after the market had rallied 25\\% from its lowest point. Following the crash, the average investor turned more pessimistic about the short-run performance of both the stock market and the real economy. Investors also perceived higher probabilities of both further extreme stock market declines and large declines in short-run real economic activity. In contrast, investor expectations about long-run (10-year) economic and stock market outcomes remained largely unchanged, and, if anything, improved. Disagreement among investors about economic and stock market outcomes also increased substantially following the stock market crash, with the disagreement persisting through the partial market recovery. Those respondents who were the most optimistic in February saw the largest decline in expectations, and sold the most equity. Those respondents who were the most pessimistic in February largely left their portfolios unchanged during and after the crash.", "link": "http://arxiv.org/abs/2004.01831v2"}, {"index": 545, "title": "Regression Approach for Modeling COVID-19 Spread and its Impact On Stock Market", "abstract": "The paper studies different regression approaches for modeling COVID-19 spread and its impact on the stock market. The logistic curve model was used with Bayesian regression for predictive analytics of the coronavirus spread. The impact of COVID-19 was studied using regression approach and compared to other crises influence. In practical analytics, it is important to find the maximum of coronavirus cases per day, this point means the estimated half time of coronavirus spread in the region under investigation. The obtained results show that different crises with different reasons have different impact on the same stocks. It is important to analyze their impact separately. Bayesian inference makes it possible to analyze the uncertainty of crisis impacts.", "link": "http://arxiv.org/abs/2004.01489v1"}, {"index": 546, "title": "Deep learning for Stock Market Prediction", "abstract": "Prediction of stock groups' values has always been attractive and challenging for shareholders. This paper concentrates on the future prediction of stock market groups. Four groups named diversified financials, petroleum, non-metallic minerals and basic metals from Tehran stock exchange are chosen for experimental evaluations. Data are collected for the groups based on ten years of historical records. The values predictions are created for 1, 2, 5, 10, 15, 20 and 30 days in advance. The machine learning algorithms utilized for prediction of future values of stock market groups. We employed Decision Tree, Bagging, Random Forest, Adaptive Boosting (Adaboost), Gradient Boosting and eXtreme Gradient Boosting (XGBoost), and Artificial neural network (ANN), Recurrent Neural Network (RNN) and Long short-term memory (LSTM). Ten technical indicators are selected as the inputs into each of the prediction models. Finally, the result of predictions is presented for each technique based on three metrics. Among all the algorithms used in this paper, LSTM shows more accurate results with the highest model fitting ability. Also, for tree-based models, there is often an intense competition between Adaboost, Gradient Boosting, and XGBoost.", "link": "http://dx.doi.org/10.3390/e22080840"}, {"index": 547, "title": "Effects of MiFID II on stock price formation", "abstract": "This paper examines effects of MiFID II on European stock markets. We study the effects of the new tick size regime, both intraday and in the closing auction. An increase (decrease) in tick size is associated with a decrease (increase) in intraday liquidity, but a more (less) stable market. In the closing auction an increase in tick size has a positive effect on liquidity. Moreover, we report a positive relationship between tick size and transacted volume, in particular in the closing auction. Finally, closing auction volumes increased heavily since MiFID II and price formation in closing auctions became more efficient.", "link": "http://arxiv.org/abs/2003.10353v2"}, {"index": 548, "title": "Graham's Formula for Valuing Growth Stocks", "abstract": "Benjamin Graham introduced a very simple formula for valuing a growth stock in 1962. How does it work and why? What is a sensible way to calculate this across many stocks and provide a scoring system to compare stocks amongst each other? We are presenting a methodology here which is put into practice.", "link": "http://dx.doi.org/10.13140/RG.2.2.25154.32969"}, {"index": 549, "title": "EB-dynaRE: Real-Time Adjustor for Brownian Movement with Examples of Predicting Stock Trends Based on a Novel Event-Based Supervised Learning Algorithm", "abstract": "Stock prices are influenced over time by underlying macroeconomic factors. Jumping out of the box of conventional assumptions about the unpredictability of the market noise, we modeled the changes of stock prices over time through the Markov Decision Process, a discrete stochastic control process that aids decision making in a situation that is partly random. We then did a \"Region of Interest\" (RoI) Pooling of the stock time-series graphs in order to predict future prices with existing ones. Generative Adversarial Network (GAN) is then used based on a competing pair of supervised learning algorithms, to regenerate future stock price projections on a real-time basis. The supervised learning algorithm used in this research, moreover, is original to this study and will have wider uses. With the ensemble of these algorithms, we are able to identify, to what extent, each specific macroeconomic factor influences the change of the Brownian/random market movement. In addition, our model will have a wider influence on the predictions of other Brownian movements.", "link": "http://arxiv.org/abs/2003.11473v1"}, {"index": 550, "title": "Multidimensional Analysis of Monthly Stock Market Returns", "abstract": "This study examines the monthly returns in Turkish and American stock market indices to investigate whether these markets experience abnormal returns during some months of the calendar year. The data used in this research includes 212 observations between January 1996 and August 2014. I apply statistical summary analysis, decomposition technique, dummy variable estimation, and binary logistic regression to check for the monthly market anomalies. The multidimensional methods used in this article suggest weak evidence against the efficient market hypothesis on monthly returns. While some months tend to show abnormal returns, there is no absolute unanimity in the applied approaches. Nevertheless, there is a strikingly negative May effect on the Turkish stocks following a positive return in April. Stocks tend to be bullish in December in both markets, yet we do not observe anya significant January effect is not observed.", "link": "http://dx.doi.org/10.2478/aicue-2014-0013"}, {"index": 551, "title": "Predicting Stock Returns with Batched AROW", "abstract": "We extend the AROW regression algorithm developed by Vaits and Crammer in [VC11] to handle synchronous mini-batch updates and apply it to stock return prediction. By design, the model should be more robust to noise and adapt better to non-stationarity compared to a simple rolling regression. We empirically show that the new model outperforms more classical approaches by backtesting a strategy on S\\&P500 stocks.", "link": "http://arxiv.org/abs/2003.03076v2"}, {"index": 552, "title": "Combining social media and survey data to nowcast migrant stocks in the United States", "abstract": "Measuring and forecasting migration patterns, and how they change over time, has important implications for understanding broader population trends, for designing policy effectively and for allocating resources. However, data on migration and mobility are often lacking, and those that do exist are not available in a timely manner. Social media data offer new opportunities to provide more up-to-date demographic estimates and to complement more traditional data sources. Facebook, for example, can be thought of as a large digital census that is regularly updated. However, its users are not representative of the underlying population. This paper proposes a statistical framework to combine social media data with traditional survey data to produce timely `nowcasts' of migrant stocks by state in the United States. The model incorporates bias adjustment of the Facebook data, and a pooled principal component time series approach, to account for correlations across age, time and space. We illustrate the results for migrants from Mexico, India and Germany, and show that the model outperforms alternatives that rely solely on either social media or survey data.", "link": "http://dx.doi.org/10.1007/s11113-020-09599-3"}, {"index": 553, "title": "Time-varying neural network for stock return prediction", "abstract": "We consider the problem of neural network training in a time-varying context. Machine learning algorithms have excelled in problems that do not change over time. However, problems encountered in financial markets are often time-varying. We propose the online early stopping algorithm and show that a neural network trained using this algorithm can track a function changing with unknown dynamics. We compare the proposed algorithm to current approaches on predicting monthly U.S. stock returns and show its superiority. We also show that prominent factors (such as the size and momentum effects) and industry indicators, exhibit time varying stock return predictiveness. We find that during market distress, industry indicators experience an increase in importance at the expense of firm level features. This indicates that industries play a role in explaining stock returns during periods of heightened risk.", "link": "http://arxiv.org/abs/2003.02515v4"}, {"index": 554, "title": "Joint Estimation of Discrete Choice Model and Arrival Rate with Unobserved Stock-out Events", "abstract": "This paper studies the joint estimation problem of a discrete choice model and the arrival rate of potential customers when unobserved stock-out events occur. In this paper, we generalize [Anupindi et al., 1998] and [Conlon and Mortimer, 2013] in the sense that (1) we work with generic choice models, (2) we allow arbitrary numbers of products and stock-out events, and (3) we consider the existence of the null alternative, and estimates the overall arrival rate of potential customers. In addition, we point out that the modeling in [Conlon and Mortimer, 2013] is problematic, and present the correct formulation.", "link": "http://arxiv.org/abs/2003.02313v1"}, {"index": 555, "title": "Applications of deep learning in stock market prediction: recent progress", "abstract": "Stock market prediction has been a classical yet challenging problem, with the attention from both economists and computer scientists. With the purpose of building an effective prediction model, both linear and machine learning tools have been explored for the past couple of decades. Lately, deep learning models have been introduced as new frontiers for this topic and the rapid development is too fast to catch up. Hence, our motivation for this survey is to give a latest review of recent works on deep learning models for stock market prediction. We not only category the different data sources, various neural network structures, and common used evaluation metrics, but also the implementation and reproducibility. Our goal is to help the interested researchers to synchronize with the latest progress and also help them to easily reproduce the previous studies as baselines. Base on the summary, we also highlight some future research directions in this topic.", "link": "http://dx.doi.org/10.1016/j.eswa.2021.115537"}, {"index": 556, "title": "Sector connectedness in the Chinese stock markets", "abstract": "Uncovering the risk transmitting path within economic sectors in China is crucial for understanding the stability of the Chinese economic system, especially under the current situation of the China-US trade conflicts. In this paper, we try to uncover the risk spreading channels by means of volatility spillovers within the Chinese sectors using stock market data. By applying the generalized variance decomposition framework based on the VAR model and the rolling window approach, a set of connectedness matrices is obtained to reveal the overall and dynamic spillovers within sectors. It is found that 17 sectors (mechanical equipment, electrical equipment, utilities, and so on) are risk transmitters and 11 sectors (national defence, bank, non-bank finance, and so on) are risk takers during the whole period. During the periods with the extreme risk events (the global financial crisis, the Chinese interbank liquidity crisis, the Chinese stock market plunge, and the China-US trade war), we observe that the connectedness measures significantly increase and the financial sectors play a buffer role in stabilizing the economic system. The robust tests suggest that our results are not sensitive to the changes of model parameters. Our results not only uncover the spillover effects within the Chinese sectors, but also highlight the deep understanding of the risk contagion patterns in the Chinese stock markets.", "link": "http://arxiv.org/abs/2002.09097v1"}, {"index": 557, "title": "Cross-sectional Stock Price Prediction using Deep Learning for Actual Investment Management", "abstract": "Stock price prediction has been an important research theme both academically and practically. Various methods to predict stock prices have been studied until now. The feature that explains the stock price by a cross-section analysis is called a \"factor\" in the field of finance. Many empirical studies in finance have identified which stocks having features in the cross-section relatively increase and which decrease in terms of price. Recently, stock price prediction methods using machine learning, especially deep learning, have been proposed since the relationship between these factors and stock prices is complex and non-linear. However, there are no practical examples for actual investment management. In this paper, therefore, we present a cross-sectional daily stock price prediction framework using deep learning for actual investment management. For example, we build a portfolio with information available at the time of market closing and invest at the time of market opening the next day. We perform empirical analysis in the Japanese stock market and confirm the profitability of our framework.", "link": "http://dx.doi.org/10.1145/3399871.3399889"}, {"index": 558, "title": "Trimming the Sail: A Second-order Learning Paradigm for Stock Prediction", "abstract": "Nowadays, machine learning methods have been widely used in stock prediction. Traditional approaches assume an identical data distribution, under which a learned model on the training data is fixed and applied directly in the test data. Although such assumption has made traditional machine learning techniques succeed in many real-world tasks, the highly dynamic nature of the stock market invalidates the strict assumption in stock prediction. To address this challenge, we propose the second-order identical distribution assumption, where the data distribution is assumed to be fluctuating over time with certain patterns. Based on such assumption, we develop a second-order learning paradigm with multi-scale patterns. Extensive experiments on real-world Chinese stock data demonstrate the effectiveness of our second-order learning paradigm in stock prediction.", "link": "http://arxiv.org/abs/2002.06878v1"}, {"index": 559, "title": "Improving S&P stock prediction with time series stock similarity", "abstract": "Stock market prediction with forecasting algorithms is a popular topic these days where most of the forecasting algorithms train only on data collected on a particular stock. In this paper, we enriched the stock data with related stocks just as a professional trader would have done to improve the stock prediction models. We tested five different similarities functions and found co-integration similarity to have the best improvement on the prediction model. We evaluate the models on seven S&P stocks from various industries over five years period. The prediction model we trained on similar stocks had significantly better results with 0.55 mean accuracy, and 19.782 profit compare to the state of the art model with an accuracy of 0.52 and profit of 6.6.", "link": "http://arxiv.org/abs/2002.05784v1"}, {"index": 560, "title": "The Impact of Oil and Gold Prices Shock on Tehran Stock Exchange: A Copula Approach", "abstract": "There are several researches that deal with the behavior of SEs and their relationships with different economical factors. These range from papers dealing with this subject through econometrical procedures to statistical methods known as copula. This article considers the impact of oil and gold price on Tehran Stock Exchange market (TSE). Oil and gold are two factors that are essential for the economy of Iran and their price are determined in the global market. The model used in this study is ARIMA-Copula. We used data from January 1998 to January 2011 as training data to find the appropriate model. The cross validation of model is measured by data from January 2011 to June 2011. We conclude that: (i) there is no significant direct relationship between gold price and the TSE index, but the TSE is indirectly influenced by gold price through other factors such as oil; and (ii) the TSE is not independent of the volatility in oil price and Clayton copula can describe such dependence structure between TSE and the oil price. Based on the property of Clayton copula, which has lower tail dependency, as the oil price drops, stock index falls. This means that decrease in oil price has an adverse effect on Iranian economy.", "link": "http://arxiv.org/abs/2001.11275v1"}, {"index": 561, "title": "Hyperparameter Optimization for Forecasting Stock Returns", "abstract": "In recent years, hyperparameter optimization (HPO) has become an increasingly important issue in the field of machine learning for the development of more accurate forecasting models. In this study, we explore the potential of HPO in modeling stock returns using a deep neural network (DNN). The potential of this approach was evaluated using technical indicators and fundamentals examined based on the effect the regularization of dropouts and batch normalization for all input data. We found that the model using technical indicators and dropout regularization significantly outperforms three other models, showing a positive predictability of 0.53% in-sample and 1.11% out-of-sample, thereby indicating the possibility of beating the historical average. We also demonstrate the stability of the model in terms of the changes in its feature importance over time.", "link": "http://arxiv.org/abs/2001.10278v1"}, {"index": 562, "title": "From Stock Prediction to Financial Relevance: Repurposing Attention Weights to Assess News Relevance Without Manual Annotations", "abstract": "We present a method to automatically identify financially relevant news using stock price movements and news headlines as input. The method repurposes the attention weights of a neural network initially trained to predict stock prices to assign a relevance score to each headline, eliminating the need for manually labeled training data. Our experiments on the four most relevant US stock indices and 1.5M news headlines show that the method ranks relevant news highly, positively correlated with the accuracy of the initial stock price prediction task.", "link": "http://arxiv.org/abs/2001.09466v3"}, {"index": 563, "title": "Corporate Governance, Noise Trading and Liquidity of Stocks", "abstract": "Our main task is to study the effect of corporate governance on the market liquidity of listed companies' stocks. We establish a theoretical model that contains the heterogeneity of investors' beliefs to explain the mechanisms by which corporate governance improves liquidity of the corporate stocks. In this process we found that the existence of noise traders who are semi-informed in the market is an important condition for corporate governance to have the effect of improving liquidity of the stocks. We further find that the strength of this effect is affected by the degree of noise traders' participation in market transactions. Our model reveals that corporate governance and the degree of noise traders' participation in transactions have a synergistic effect on improving the liquidity of the stocks.", "link": "http://arxiv.org/abs/2001.06275v1"}, {"index": 564, "title": "Stock Price Prediction Using Convolutional Neural Networks on a Multivariate Timeseries", "abstract": "Prediction of future movement of stock prices has been a subject matter of many research work. In this work, we propose a hybrid approach for stock price prediction using machine learning and deep learning-based methods. We select the NIFTY 50 index values of the National Stock Exchange of India, over a period of four years, from January 2015 till December 2019. Based on the NIFTY data during the said period, we build various predictive models using machine learning approaches, and then use those models to predict the Close value of NIFTY 50 for the year 2019, with a forecast horizon of one week. For predicting the NIFTY index movement patterns, we use a number of classification methods, while for forecasting the actual Close values of NIFTY index, various regression models are built. We, then, augment our predictive power of the models by building a deep learning-based regression model using Convolutional Neural Network with a walk-forward validation. The CNN model is fine-tuned for its parameters so that the validation loss stabilizes with increasing number of iterations, and the training and validation accuracies converge. We exploit the power of CNN in forecasting the future NIFTY index values using three approaches which differ in number of variables used in forecasting, number of sub-models used in the overall models and, size of the input data for training the models. Extensive results are presented on various metrics for all classification and regression models. The results clearly indicate that CNN-based multivariate forecasting model is the most effective and accurate in predicting the movement of NIFTY index values with a weekly forecast horizon.", "link": "http://dx.doi.org/10.36227/techrxiv.15088734.v1"}, {"index": 565, "title": "Testing marginal homogeneity in Hilbert spaces with applications to stock market returns", "abstract": "The paper considers a paired data framework and discuss the question of marginal homogeneity of bivariate high dimensional or functional data. The related testing problem can be endowed into a more general setting for paired random variables taking values in a general Hilbert space. To address this problem, a Cramer-von-Mises type test statistic is applied and a bootstrap procedure is suggested to obtain critical values and finally a consistent test. The desired properties of a bootstrap test can be derived, that are asymptotic exactness under the null hypothesis and consistency under alternatives. Simulations show the quality of the test in the finite sample case. A possible application is the comparison of two possibly dependent stock market returns on the basis of functional data. The approach is demonstrated on the basis of historical data for different stock market indices.", "link": "http://arxiv.org/abs/2001.02488v2"}, {"index": 566, "title": "Housing Investment, Stock Market Participation and Household Portfolio choice: Evidence from China's Urban Areas", "abstract": "This paper employs the survey data of CHFS (2013) to investigate the impact of housing investment on household stock market participation and portfolio choice. The results show that larger housing investment encourages the household participation in the stock market, but reduces the proportion of their stockholding. The above conclusion remains true even when the endogeneity problem is controlled with risk attitude classification, Heckman model test and subsample regression. This study shows that the growth in the housing market will not lead to stock market development because of lack of household financial literacy and the low expected yield on stock market.", "link": "http://arxiv.org/abs/2001.01641v1"}, {"index": 567, "title": "An Optimal Algorithm for 1-D Cutting Stock Problem", "abstract": "We present an $n\\Delta^{O(k^2)}$ time algorithm to obtain an optimal solution for $1$-dimensional cutting stock problem: the bin packing problem of packing $n$ items onto unit capacity bins under the restriction that the number of item sizes $k$ is fixed, where $\\Delta$ is the reciprocal of the size of the smallest item. We employ elementary ideas in both the design and analysis our algorithm.", "link": "http://arxiv.org/abs/2001.01531v1"}, {"index": 568, "title": "Bottom-up energy supply optimization of a national building stock", "abstract": "The installation and operation distributed energy resources (DER) and the electrification of the heat supply significantly changes the interaction of the residential building stock with the grid infrastructure. Evaluating the mass deployment of DER at the national level would require analyzing millions of individual buildings, entailing significant computational burden. To overcome this, this work proposes a novel bottom-up model that consists of an aggregation algorithm to create a spatially distributed set of typical residential buildings from census data. Each typical building is then optimized with a Mixed-Integer Linear Program to derive its cost optimal technology adoption and operation, determining its changing grid load in future scenarios. The model is validated for Germany, with 200 typical buildings considered to sufficiently represent the diversity of the residential building stock. In a future scenario for 2050, photovoltaic and heat pumps are predicted to be the most economically and ecologically robust supply solutions for the different building types. Nevertheless, their electricity generation and demand temporally do not match, resulting in a doubling of the peak electricity grid load in the rural areas during the winter. The urban areas can compensate this with efficient co-generation units, which are not cost-efficient in the rural areas.", "link": "http://dx.doi.org/10.1016/j.enbuild.2019.109667"}, {"index": 569, "title": "Effect of Franchised Business models on Fast Food Company Stock Prices in Recession and Recovery with Weibull Analysis", "abstract": "At the initial stages of this research, the assumption was that the franchised businesses perhaps should not be affected much by recession as there are multiple cash pools available inherent to the franchised business model. However, after analyzing the available data, it indicated otherwise, the stock price performance as discussed indicates a different pattern. The stock price data is analyzed with an unconventional tool, Weibull distribution and observations confirmed the presence of either a reverse trend in franchised business than what is observed for non-franchised or the franchised stock followed large food suppliers. There is a layered ownership and cash flow in a franchised business model. The parent company run by franchiser depends on the performance of child companies run by franchisees. Both parent and child companies are run as independent businesses but only the parent company is listed as a stock ticker in stock exchange. Does this double layer of vertical operation, cash reserve, and cash flow protect them better in recession? The data analyzed in this paper indicates that the recession effect can be more severe; and if it dives with the average market, expect a slower recovery of stock prices in a franchised business model. This paper characterizes the differences and explains the natural experiment with available financial data.", "link": "http://arxiv.org/abs/1912.12940v1"}, {"index": 570, "title": "Dynamics of the Price Behavior in Stock Market: A Statistical Physics Approach", "abstract": "We study in this paper the time evolution of stock markets using a statistical physics approach. Each agent is represented by a spin having a number of discrete states $q$ or continuous states, describing the tendency of the agent for buying or selling. The market ambiance is represented by a parameter $T$ which plays the role of the temperature in physics. We show that there is a critical value of $T$, say $T_c$, where strong fluctuations between individual states lead to a disordered situation in which there is no majority: the numbers of sellers and buyers are equal, namely the market clearing. We have considered three models: $q=3$ ( sell, buy, wait), $q=5$ (5 states between absolutely buy and absolutely sell), and $q=\\infty$. The specific measure, by the government or by economic organisms, is parameterized by $H$ applied on the market at the time $t_1$ and removed at the time $t_2$. We have used Monte Carlo simulations to study the time evolution of the price as functions of those parameters. Many striking results are obtained. In particular we show that the price strongly fluctuates near $T_c$ and there exists a critical value $H_c$ above which the boosting effect remains after $H$ is removed. This happens only if $H$ is applied in the critical region. Otherwise, the effect of $H$ lasts only during the time of the application of $H$. The second party of the paper deals with the price variation using a time-dependent mean-field theory. By supposing that the sellers and the buyers belong to two distinct communities with their characteristics different in both intra-group and inter-group interactions, we find the price oscillation with time.", "link": "http://arxiv.org/abs/1912.11665v2"}, {"index": 571, "title": "DP-LSTM: Differential Privacy-inspired LSTM for Stock Prediction Using Financial News", "abstract": "Stock price prediction is important for value investments in the stock market. In particular, short-term prediction that exploits financial news articles is promising in recent years. In this paper, we propose a novel deep neural network DP-LSTM for stock price prediction, which incorporates the news articles as hidden information and integrates difference news sources through the differential privacy mechanism. First, based on the autoregressive moving average model (ARMA), a sentiment-ARMA is formulated by taking into consideration the information of financial news articles in the model. Then, an LSTM-based deep neural network is designed, which consists of three components: LSTM, VADER model and differential privacy (DP) mechanism. The proposed DP-LSTM scheme can reduce prediction errors and increase the robustness. Extensive experiments on S&P 500 stocks show that (i) the proposed DP-LSTM achieves 0.32% improvement in mean MPA of prediction result, and (ii) for the prediction of the market index S&P 500, we achieve up to 65.79% improvement in MSE.", "link": "http://arxiv.org/abs/1912.10806v1"}, {"index": 572, "title": "On the probability flow in the Stock market I: The Black-Scholes case", "abstract": "It is known that the probability is not a conserved quantity in the stock market, given the fact that it corresponds to an open system. In this paper we analyze the flow of probability in this system by expressing the ideal Black-Scholes equation in the Hamiltonian form. We then analyze how the non-conservation of probability affects the stability of the prices of the Stocks. Finally, we find the conditions under which the probability might be conserved in the market, challenging in this way the non-Hermitian nature of the Black-Scholes Hamiltonian.", "link": "http://arxiv.org/abs/2001.00516v1"}, {"index": 573, "title": "Machine Learning-based Estimation of Forest Carbon Stocks to increase Transparency of Forest Preservation Efforts", "abstract": "An increasing amount of companies and cities plan to become CO2-neutral, which requires them to invest in renewable energies and carbon emission offsetting solutions. One of the cheapest carbon offsetting solutions is preventing deforestation in developing nations, a major contributor in global greenhouse gas emissions. However, forest preservation projects historically display an issue of trust and transparency, which drives companies to invest in transparent, but expensive air carbon capture facilities. Preservation projects could conduct accurate forest inventories (tree diameter, species, height etc.) to transparently estimate the biomass and amount of stored carbon. However, current rainforest inventories are too inaccurate, because they are often based on a few expensive ground-based samples and/or low-resolution satellite imagery. LiDAR-based solutions, used in US forests, are accurate, but cost-prohibitive, and hardly-accessible in the Amazon rainforest. We propose accurate and cheap forest inventory analyses through Deep Learning-based processing of drone imagery. The more transparent estimation of stored carbon will create higher transparency towards clients and thereby increase trust and investment into forest preservation projects.", "link": "http://arxiv.org/abs/1912.07850v1"}, {"index": 574, "title": "Predicting intraday jumps in stock prices using liquidity measures and technical indicators", "abstract": "Predicting the intraday stock jumps is a significant but challenging problem in finance. Due to the instantaneity and imperceptibility characteristics of intraday stock jumps, relevant studies on their predictability remain limited. This paper proposes a data-driven approach to predict intraday stock jumps using the information embedded in liquidity measures and technical indicators. Specifically, a trading day is divided into a series of 5-minute intervals, and at the end of each interval, the candidate attributes defined by liquidity measures and technical indicators are input into machine learning algorithms to predict the arrival of a stock jump as well as its direction in the following 5-minute interval. Empirical study is conducted on the level-2 high-frequency data of 1271 stocks in the Shenzhen Stock Exchange of China to validate our approach. The result provides initial evidence of the predictability of jump arrivals and jump directions using level-2 stock data as well as the effectiveness of using a combination of liquidity measures and technical indicators in this prediction. We also reveal the superiority of using random forest compared to other machine learning algorithms in building prediction models. Importantly, our study provides a portable data-driven approach that exploits liquidity and technical information from level-2 stock data to predict intraday price jumps of individual stocks.", "link": "http://arxiv.org/abs/1912.07165v1"}, {"index": 575, "title": "Fairness in Multi-agent Reinforcement Learning for Stock Trading", "abstract": "Unfair stock trading strategies have been shown to be one of the most negative perceptions that customers can have concerning trading and may result in long-term losses for a company. Investment banks usually place trading orders for multiple clients with the same target assets but different order sizes and diverse requirements such as time frame and risk aversion level, thereby total earning and individual earning cannot be optimized at the same time. Orders executed earlier would affect the market price level, so late execution usually means additional implementation cost. In this paper, we propose a novel scheme that utilizes multi-agent reinforcement learning systems to derive stock trading strategies for all clients which keep a balance between revenue and fairness. First, we demonstrate that Reinforcement learning (RL) is able to learn from experience and adapt the trading strategies to the complex market environment. Secondly, we show that the Multi-agent RL system allows developing trading strategies for all clients individually, thus optimizing individual revenue. Thirdly, we use the Generalized Gini Index (GGI) aggregation function to control the fairness level of the revenue across all clients. Lastly, we empirically demonstrate the superiority of the novel scheme in improving fairness meanwhile maintaining optimization of revenue.", "link": "http://arxiv.org/abs/2001.00918v1"}, {"index": 576, "title": "Portfolio liquidation under transient price impact -- theoretical solution and implementation with 100 NASDAQ stocks", "abstract": "We derive an explicit solution for deterministic market impact parameters in the Graewe and Horst (2017) portfolio liquidation model. The model allows to combine various forms of market impact, namely instantaneous, permanent and temporary. We show that the solutions to the two benchmark models of Almgren and Chris (2001) and of Obizhaeva and Wang (2013) are obtained as special cases. We relate the different forms of market impact to the microstructure of limit order book markets and show how the impact parameters can be estimated from public market data. We investigate the numerical performance of the derived optimal trading strategy based on high frequency limit order books of 100 NASDAQ stocks that represent a range of market impact profiles. It shows the strategy achieves significant cost savings compared to the benchmark models of Almgren and Chris (2001) and of Obizhaeva and Wang (2013).", "link": "http://arxiv.org/abs/1912.06426v1"}, {"index": 577, "title": "A Robust Predictive Model for Stock Price Prediction Using Deep Learning and Natural Language Processing", "abstract": "Prediction of future movement of stock prices has been a subject matter of many research work. There is a gamut of literature of technical analysis of stock prices where the objective is to identify patterns in stock price movements and derive profit from it. Improving the prediction accuracy remains the single most challenge in this area of research. We propose a hybrid approach for stock price movement prediction using machine learning, deep learning, and natural language processing. We select the NIFTY 50 index values of the National Stock Exchange of India, and collect its daily price movement over a period of three years (2015 to 2017). Based on the data of 2015 to 2017, we build various predictive models using machine learning, and then use those models to predict the closing value of NIFTY 50 for the period January 2018 till June 2019 with a prediction horizon of one week. For predicting the price movement patterns, we use a number of classification techniques, while for predicting the actual closing price of the stock, various regression models have been used. We also build a Long and Short-Term Memory - based deep learning network for predicting the closing price of the stocks and compare the prediction accuracies of the machine learning models with the LSTM model. We further augment the predictive model by integrating a sentiment analysis module on twitter data to correlate the public sentiment of stock prices with the market sentiment. This has been done using twitter sentiment and previous week closing values to predict stock price movement for the next week. We tested our proposed scheme using a cross validation method based on Self Organizing Fuzzy Neural Networks and found extremely interesting results.", "link": "http://dx.doi.org/10.36227/techrxiv.15023361.v1"}, {"index": 578, "title": "Sanction or Financial Crisis? An Artificial Neural Network-Based Approach to model the impact of oil price volatility on Stock and industry indices", "abstract": "In this paper, we model the impact of oil price volatility on Tehranstock and industry indices in two periods of international sanctions and post-sanction. To analyse the purpose of study, we use Feed-forward neural net-works. The period of study is from 2008 to 2018 that is split in two periods during international energy sanction and post-sanction. The results show that Feed-forward neural networks perform well in predicting stock market and industry, which means oil price volatility has a significant impact on stock and industry market indices. During post-sanction and global financial crisis, the model performs better in predicting industry index. Additionally, oil price-stock market index prediction performs better in the period of international sanctions. Herein, these results are, up to some extent, important for financial market analysts and policy makers to understand which factors and when influence the financial market, especially in an oil-dependent country such asIran with uncertainty in the international politics. Keywords: Feed-forward neural networks,Industry index,International energy sanction,Oil price volatility,Tehran stock index", "link": "http://arxiv.org/abs/1912.04015v2"}, {"index": 579, "title": "A bi-integrated model for coupling lot-sizing and cutting-stock problems", "abstract": "In this paper, a framework that addresses the core of the papermaking process is proposed, starting from the production of jumbos and ending with the paper sheets used in daily life. The first phase of the process is modelled according to a lot-sizing problem, where the quantities of jumbos are determined in order to meet the demand of the entire chain. The second phase follows a one-dimensional cutting-stock formulation, where these jumbos are cut into smaller reels of predetermined lengths. Some of these are intended to fulfil a portfolio of orders, while others are used as raw material for the third phase of the process, when the reels are cut into sheets with specific dimensions and demands, following a two-dimensional cutting-stock problem. The model is called the Bi-Integrated Model, since it is composed of two integrated models. The heuristic method developed uses the Simplex Method with column generation for the two cutting-stock phases and applies the Relax-and-Fix technique to obtain the rounded-integer solution. Computational experiments comparing the solutions of the Bi-Integrated Model to other strategies of modelling the production process indicate average cost gains reaching 26.63%. Additional analyses of the model behaviour under several situations resulted in remarkable findings.", "link": "http://arxiv.org/abs/1912.02242v1"}, {"index": 580, "title": "An Integrated Early Warning System for Stock Market Turbulence", "abstract": "This study constructs an integrated early warning system (EWS) that identifies and predicts stock market turbulence. Based on switching ARCH (SWARCH) filtering probabilities of the high volatility regime, the proposed EWS first classifies stock market crises according to an indicator function with thresholds dynamically selected by the two-peak method. A hybrid algorithm is then developed in the framework of a long short-term memory (LSTM) network to make daily predictions that alert turmoils. In the empirical evaluation based on ten-year Chinese stock data, the proposed EWS yields satisfying results with the test-set accuracy of $96.6\\%$ and on average $2.4$ days of the forewarned period. The model's stability and practical value in real-time decision-making are also proven by the cross-validation and back-testing.", "link": "http://arxiv.org/abs/1911.12596v1"}, {"index": 581, "title": "U-CNNpred: A Universal CNN-based Predictor for Stock Markets", "abstract": "The performance of financial market prediction systems depends heavily on the quality of features it is using. While researchers have used various techniques for enhancing the stock specific features, less attention has been paid to extracting features that represent general mechanism of financial markets. In this paper, we investigate the importance of extracting such general features in stock market prediction domain and show how it can improve the performance of financial market prediction. We present a framework called U-CNNpred, that uses a CNN-based structure. A base model is trained in a specially designed layer-wise training procedure over a pool of historical data from many financial markets, in order to extract the common patterns from different markets. Our experiments, in which we have used hundreds of stocks in S\\&P 500 as well as 14 famous indices around the world, show that this model can outperform baseline algorithms when predicting the directional movement of the markets for which it has been trained for. We also show that the base model can be fine-tuned for predicting new markets and achieve a better performance compared to the state of the art baseline algorithms that focus on constructing market-specific models from scratch.", "link": "http://arxiv.org/abs/1911.12540v1"}, {"index": 582, "title": "Financial ratios and stock returns reappraised through a topological data analysis lens", "abstract": "Firm financials are well established as return predictors, being the inspiration for a large set of anomalies in the asset pricing literature. Employing topological data analysis we revisit the question of association between seven of the most commonly studied financial ratios and stock returns. Specifically the TDA Ball Mapper algorithm is applied to visualise the point cloud of financial ratios as an abstract two-dimensional graph readily allowing for identification of interdependencies between factors. These relationships are seldom monotonic, opportunities for investors to profitably exploit this knowledge provided by TDA abound. Clear potential offered by the tools of TDA to shed new light on asset pricing models is demonstrated. Scope for benefit is limited only by the availability of information to the analyst.", "link": "http://arxiv.org/abs/1911.10297v1"}, {"index": 583, "title": "Forecasting significant stock price changes using neural networks", "abstract": "Stock price prediction is a rich research topic that has attracted interest from various areas of science. The recent success of machine learning in speech and image recognition has prompted researchers to apply these methods to asset price prediction. The majority of literature has been devoted to predicting either the actual asset price or the direction of price movement. In this paper, we study a hitherto little explored question of predicting significant changes in stock price based on previous changes using machine learning algorithms. We are particularly interested in the performance of neural network classifiers in the given context. To this end, we construct and test three neural network models including multi-layer perceptron, convolutional net, and long short term memory net. As benchmark models we use random forest and relative strength index methods. The models are tested using 10-year daily stock price data of four major US public companies. Test results show that predicting significant changes in stock price can be accomplished with a high degree of accuracy. In particular, we obtain substantially better results than similar studies that forecast the direction of price change.", "link": "http://dx.doi.org/10.1007/s00521-020-04942-3"}, {"index": 584, "title": "Celebrating Three Decades of Worldwide Stock Market Manipulation", "abstract": "As the decade turns, we reflect on nearly thirty years of successful manipulation of the world's public equity markets. This reflection highlights a few of the key enabling ingredients and lessons learned along the way. A quantitative understanding of market impact and its decay, which we cover briefly, lets you move long-term market prices to your advantage at acceptable cost. Hiding your footprints turns out to be less important than moving prices in the direction most people want them to move. Widespread (if misplaced) trust of market prices -- buttressed by overestimates of the cost of manipulation and underestimates of the benefits to certain market participants -- makes price manipulation a particularly valuable and profitable tool. Of the many recent stories heralding the dawn of the present golden age of misinformation, the manipulation leading to the remarkable increase in the market capitalization of the world's publicly traded companies over the past three decades is among the best.", "link": "http://arxiv.org/abs/1912.01708v1"}, {"index": 585, "title": "Unveil stock correlation via a new tensor-based decomposition method", "abstract": "Portfolio allocation and risk management make use of correlation matrices and heavily rely on the choice of a proper correlation matrix to be used. In this regard, one important question is related to the choice of the proper sample period to be used to estimate a stable correlation matrix. This paper addresses this question and proposes a new methodology to estimate the correlation matrix which doesn't depend on the chosen sample period. This new methodology is based on tensor factorization techniques. In particular, combining and normalizing factor components, we build a correlation matrix which shows emerging structural dependency properties not affected by the sample period. To retrieve the factor components, we propose a new tensor decomposition (which we name Slice-Diagonal Tensor (SDT) factorization) and compare it to the two most used tensor decompositions, the Tucker and the PARAFAC. We have that the new factorization is more parsimonious than the Tucker decomposition and more flexible than the PARAFAC. Moreover, this methodology applied to both simulated and empirical data shows results which are robust to two non-parametric tests, namely Kruskal-Wallis and Kolmogorov-Smirnov tests. Since the resulting correlation matrix features stability and emerging structural dependency properties, it can be used as alternative to other correlation matrices type of measures, including the Person correlation.", "link": "http://arxiv.org/abs/1911.06126v2"}, {"index": 586, "title": "Measuring the Time-Varying Market Efficiency in the Prewar Japanese Stock Market, 1924-1943", "abstract": "This study explores the time-varying structure of market efficiency for the prewar Japanese stock market using a new market capitalization-weighted stock price index based on the adaptive market hypothesis (AMH). First, we find that the degree of market efficiency in the prewar Japanese stock market varies over time and with major historical events. Second, the AMH is supported in this market. Third, this study concludes that market efficiency was maintained throughout the period, whereas previous studies did not come to the same conclusion due to differences in the calculation methods of stock indices. Finally, as government intervention in the market intensified throughout the 1930s, the market efficiency declined, as well as rapidly taking into account the war risk premium, especially from the time when the Pacific War became inevitable.", "link": "http://arxiv.org/abs/1911.04059v5"}, {"index": 587, "title": "Predicting Indian stock market using the psycho-linguistic features of financial news", "abstract": "Financial forecasting using news articles is an emerging field. In this paper, we proposed hybrid intelligent models for stock market prediction using the psycholinguistic variables (LIWC and TAALES) extracted from news articles as predictor variables. For prediction purpose, we employed various intelligent techniques such as Multilayer Perceptron (MLP), Group Method of Data Handling (GMDH), General Regression Neural Network (GRNN), Random Forest (RF), Quantile Regression Random Forest (QRRF), Classification and regression tree (CART) and Support Vector Regression (SVR). We experimented on the data of 12 companies stocks, which are listed in the Bombay Stock Exchange (BSE). We employed chi-squared and maximum relevance and minimum redundancy (MRMR) feature selection techniques on the psycho-linguistic features obtained from the new articles etc. After extensive experimentation, using the Diebold-Mariano test, we conclude that GMDH and GRNN are statistically the best techniques in that order with respect to the MAPE and NRMSE values.", "link": "http://arxiv.org/abs/1911.06193v1"}, {"index": 588, "title": "Deep Learning for Stock Selection Based on High Frequency Price-Volume Data", "abstract": "Training a practical and effective model for stock selection has been a greatly concerned problem in the field of artificial intelligence. Even though some of the models from previous works have achieved good performance in the U.S. market by using low-frequency data and features, training a suitable model with high-frequency stock data is still a problem worth exploring. Based on the high-frequency price data of the past several days, we construct two separate models-Convolution Neural Network and Long Short-Term Memory-which can predict the expected return rate of stocks on the current day, and select the stocks with the highest expected yield at the opening to maximize the total return. In our CNN model, we propose improvements on the CNNpred model presented by E. Hoseinzade and S. Haratizadeh in their paper which deals with low-frequency features. Such improvements enable our CNN model to exploit the convolution layer's ability to extract high-level factors and avoid excessive loss of original information at the same time. Our LSTM model utilizes Recurrent Neural Network'advantages in handling time series data. Despite considerable transaction fees due to the daily changes of our stock position, annualized net rate of return is 62.27% for our CNN model, and 50.31% for our LSTM model.", "link": "http://arxiv.org/abs/1911.02502v1"}, {"index": 589, "title": "A Rational Finance Explanation of the Stock Predictability Puzzle", "abstract": "In this paper, we address one of the main puzzles in finance observed in the stock market by proponents of behavioral finance: the stock predictability puzzle. We offer a statistical model within the context of rational finance which can be used without relying on behavioral finance assumptions to model the predictability of stock returns. We incorporate the predictability of stock returns into the well-known Black-Scholes option pricing formula. Empirically, we analyze the option and spot trader's market predictability of stock prices by defining a forward-looking measure which we call \"implied excess predictability\". The empirical results indicate the effect of option trader's predictability of stock returns on the price of stock options is an increasing function of moneyness, while this effect is decreasing for spot traders. These empirical results indicate potential asymmetric predictability of stock prices by spot and option traders. We show in pricing options with the strike price significantly higher or lower than the stock price, the predictability of the underlying stock's return should be incorporated into the option pricing formula. In pricing options that have moneyness close to one, stock return predictability is not incorporated into the option pricing model because stock return predictability is the same for both types of traders. In other words, spot traders and option traders are equally informed about the future value of the stock market in this case. Comparing different volatility measures, we find that the difference between implied and realized variances or variance risk premium can potentially be used as a stock return predictor.", "link": "http://arxiv.org/abs/1911.02194v1"}, {"index": 590, "title": "A Regulated Market Under Sanctions: On Tail Dependence Between Oil, Gold, and Tehran Stock Exchange Index", "abstract": "We demonstrate that the tail dependence should always be taken into account as a proxy for systematic risk of loss for investments. We provide the clear statistical evidence of that the structure of investment portfolios on a regulated market should be adjusted to the price of gold. Our finding suggests that the active bartering of oil for goods would prevent collapsing the national market facing international sanctions.", "link": "http://dx.doi.org/10.5890/JVTSD.2019.09.004"}, {"index": 591, "title": "Horse race of weekly idiosyncratic momentum strategies with respect to various risk metrics: Evidence from the Chinese stock market", "abstract": "This paper focuses on the horse race of weekly idiosyncratic momentum (IMOM) with respect to various idiosyncratic risk metrics. Using the A-share individual stocks in the Chinese market from January 1997 to December 2017, we first evaluate the performance of the weekly momentum based on raw returns and idiosyncratic returns, respectively. After that the univariate portfolio analysis is conducted to investigate the return predictability with respect to various idiosyncratic risk metrics. Further, we perform a comparative study on the performance of the IMOM portfolios with respect to various risk metrics. At last, we explore the possible explanations to IMOM as well as risk based IMOM portfolios. We find that 1) there are prevailing contrarian effect and IMOM effect for the whole sample; 2) the negative relations exist between most of the idiosyncratic risk metrics and the cross-sectional stock returns, and better performance is linked to idiosyncratic volatility (IVol) and maximum drawdowns (IMDs); 3) additionally, the IVol-based and IMD-based IMOM portfolios exhibit better explanatory power to the IMOM portfolios with respect to other risk metrics; 4) finally, higher profitability of IMOM as well as IVol-based and IMD-based IMOM portfolios is found to be related to upside market states, high levels of liquidity and high levels of investor sentiment.", "link": "http://dx.doi.org/10.1016/j.najef.2021.101478"}, {"index": 592, "title": "Fundamental Analysis in China: An Empirical Study of the Relationship between Financial Ratios and Stock Prices", "abstract": "The informational context is regularly questioned in a transitional economic regime like the one implemented in China or Vietnam. This article investigates this issue and the predictive power of fundamental analysis in such context and more precisely in a Chinese context with an analysis of 3 different industries (media, power, and steel). Through 3 different kinds of correlation, we examine 25 financial determinants for 60 Chinese listed companies between 2011 and 2015. Our results show that fundamental analysis can effectively be used as an investment tool in transitional economic context. Contrasting with the EMH for which the accounting information is instantaneously integrated into the financial information (stock prices), our study suggests that these two levels of information are not synchronized in China opening therefore a door for a fundamental analysis based prediction. Furthermore, our results also indicate that accounting information illustrates quite well the economic reality since financial reports in each industry can disclose a part of stock value information in line with the economic situation of the industry under consideration.", "link": "http://dx.doi.org/10.4236/tel.2018.815209"}, {"index": 593, "title": "sPortfolio: Stratified Visual Analysis of Stock Portfolios", "abstract": "Quantitative Investment, built on the solid foundation of robust financial theories, is at the center stage in investment industry today. The essence of quantitative investment is the multi-factor model, which explains the relationship between the risk and return of equities. However, the multi-factor model generates enormous quantities of factor data, through which even experienced portfolio managers find it difficult to navigate. This has led to portfolio analysis and factor research being limited by a lack of intuitive visual analytics tools. Previous portfolio visualization systems have mainly focused on the relationship between the portfolio return and stock holdings, which is insufficient for making actionable insights or understanding market trends. In this paper, we present sPortfolio, which, to the best of our knowledge, is the first visualization that attempts to explore the factor investment area. In particular, sPortfolio provides a holistic overview of the factor data and aims to facilitate the analysis at three different levels: a Risk-Factor level, for a general market situation analysis; a Multiple-Portfolio level, for understanding the portfolio strategies; and a Single-Portfolio level, for investigating detailed operations. The system's effectiveness and usability are demonstrated through three case studies. The system has passed its pilot study and is soon to be deployed in industry.", "link": "http://dx.doi.org/10.1109/TVCG.2019.2934660"}, {"index": 594, "title": "Incorporating Fine-grained Events in Stock Movement Prediction", "abstract": "Considering event structure information has proven helpful in text-based stock movement prediction. However, existing works mainly adopt the coarse-grained events, which loses the specific semantic information of diverse event types. In this work, we propose to incorporate the fine-grained events in stock movement prediction. Firstly, we propose a professional finance event dictionary built by domain experts and use it to extract fine-grained events automatically from finance news. Then we design a neural model to combine finance news with fine-grained event structure and stock trade data to predict the stock movement. Besides, in order to improve the generalizability of the proposed method, we design an advanced model that uses the extracted fine-grained events as the distant supervised label to train a multi-task framework of event extraction and stock prediction. The experimental results show that our method outperforms all the baselines and has good generalizability.", "link": "http://arxiv.org/abs/1910.05078v1"}, {"index": 595, "title": "Mesoscale impact of trader psychology on stock markets: a multi-agent AI approach", "abstract": "Recent advances in the fields of machine learning and neurofinance have yielded new exciting research perspectives in practical inference of behavioural economy in financial markets and microstructure study. We here present the latest results from a recently published stock market simulator built around a multi-agent system architecture, in which each agent is an autonomous investor trading stocks by reinforcement learning (RL) via a centralised double-auction limit order book. The RL framework allows for the implementation of specific behavioural and cognitive traits known to trader psychology, and thus to study the impact of these traits on the whole stock market at the mesoscale. More precisely, we narrowed our agent design to three such psychological biases known to have a direct correspondence with RL theory, namely delay discounting, greed, and fear. We compared ensuing simulated data to real stock market data over the past decade or so, and find that market stability benefits from larger populations of agents prone to delay discounting and most astonishingly, to greed.", "link": "http://arxiv.org/abs/1910.10099v1"}, {"index": 596, "title": "Stock price formation: useful insights from a multi-agent reinforcement learning model", "abstract": "In the past, financial stock markets have been studied with previous generations of multi-agent systems (MAS) that relied on zero-intelligence agents, and often the necessity to implement so-called noise traders to sub-optimally emulate price formation processes. However recent advances in the fields of neuroscience and machine learning have overall brought the possibility for new tools to the bottom-up statistical inference of complex systems. Most importantly, such tools allows for studying new fields, such as agent learning, which in finance is central to information and stock price estimation. We present here the results of a new generation MAS stock market simulator, where each agent autonomously learns to do price forecasting and stock trading via model-free reinforcement learning, and where the collective behaviour of all agents decisions to trade feed a centralised double-auction limit order book, emulating price and volume microstructures. We study here what such agents learn in detail, and how heterogenous are the policies they develop over time. We also show how the agents learning rates, and their propensity to be chartist or fundamentalist impacts the overall market stability and agent individual performance. We conclude with a study on the impact of agent information via random trading.", "link": "http://arxiv.org/abs/1910.05137v1"}, {"index": 597, "title": "Stationarity of the detrended price return in stock markets", "abstract": "This paper proposes a governing equation for stock market indexes that accounts for non-stationary effects. This is a linear Fokker-Planck equation (FPE) that describes the time evolution of the probability distribution function (PDF) of the price return. By applying Ito's lemma, this FPE is associated with a stochastic differential equation (SDE) that models the time evolution of the price return in a fashion different from the classical Black-Scholes equation. Both FPE and SDE equations account for a deterministic part or trend, and a stationary, stochastic part as a q-Gaussian noise. The model is validated using the S\\&P500 index's data. After removing the trend from the index, we show that the detrended part is stationary by evaluating the Hurst exponent of the multifractal time series, its power spectrum, and its autocorrelation.", "link": "http://arxiv.org/abs/1910.01034v2"}, {"index": 598, "title": "Stock Market Forecasting Based on Text Mining Technology: A Support Vector Machine Method", "abstract": "News items have a significant impact on stock markets but the ways are obscure. Many previous works have aimed at finding accurate stock market forecasting models. In this paper, we use text mining and sentiment analysis on Chinese online financial news, to predict Chinese stock tendency and stock prices based on support vector machine (SVM). Firstly, we collect 2,302,692 news items, which date from 1/1/2008 to 1/1/2015. Secondly, based on this dataset, a specific domain stop-word dictionary and a precise sentiment dictionary are formed. Thirdly, we propose a forecasting model using SVM. On the algorithm of SVM implementation, we also propose two-parameter optimization algorithms to search for the best initial parameter setting. The result shows that parameter G has the main effect, while parameter C's effect is not obvious. Furthermore, support vector regression (SVR) models for different Chinese stocks are similar whereas in support vector classification (SVC) models best parameters are quite differential. Series of contrast experiments show that: a) News has significant influence on stock market; b) Expansion input vector for additional situations when that day has no news data is better than normal input in SVR, yet is worse in SVC; c) SVR shows a fantastic degree of fitting in predicting stock fluctuation while such result has some time lag; d) News effect time lag for stock market is less than two days; e) In SVC, historic stock data has a most efficient time lag which is about 10 days, whereas in SVR this effect is not obvious. Besides, based on the special structure of the input vector, we also design a method to calculate the financial source impact factor. Result suggests that the news quality and audience number both have a significant effect on the source impact factor. Besides, for Chinese investors, traditional media has more influence than digital media.", "link": "http://dx.doi.org/10.17706/jcp.12.6.500-510"}, {"index": 599, "title": "Stock Prices Prediction using Deep Learning Models", "abstract": "Financial markets have a vital role in the development of modern society. They allow the deployment of economic resources. Changes in stock prices reflect changes in the market. In this study, we focus on predicting stock prices by deep learning model. This is a challenge task, because there is much noise and uncertainty in information that is related to stock prices. So this work uses sparse autoencoders with one-dimension (1-D) residual convolutional networks which is a deep learning model, to de-noise the data. Long-short term memory (LSTM) is then used to predict the stock price. The prices, indices and macroeconomic variables in past are the features used to predict the next day's price. Experiment results show that 1-D residual convolutional networks can de-noise data and extract deep features better than a model that combines wavelet transforms (WT) and stacked autoencoders (SAEs). In addition, we compare the performances of model with two different forecast targets of stock price: absolute stock price and price rate of change. The results show that predicting stock price through price rate of change is better than predicting absolute prices directly.", "link": "http://arxiv.org/abs/1909.12227v1"}, {"index": 600, "title": "Exploring Graph Neural Networks for Stock Market Predictions with Rolling Window Analysis", "abstract": "Recently, there has been a surge of interest in the use of machine learning to help aid in the accurate predictions of financial markets. Despite the exciting advances in this cross-section of finance and AI, many of the current approaches are limited to using technical analysis to capture historical trends of each stock price and thus limited to certain experimental setups to obtain good prediction results. On the other hand, professional investors additionally use their rich knowledge of inter-market and inter-company relations to map the connectivity of companies and events, and use this map to make better market predictions. For instance, they would predict the movement of a certain company's stock price based not only on its former stock price trends but also on the performance of its suppliers or customers, the overall industry, macroeconomic factors and trade policies. This paper investigates the effectiveness of work at the intersection of market predictions and graph neural networks, which hold the potential to mimic the ways in which investors make decisions by incorporating company knowledge graphs directly into the predictive model. The main goal of this work is to test the validity of this approach across different markets and longer time horizons for backtesting using rolling window analysis. In this work, we concentrate on the prediction of individual stock prices in the Japanese Nikkei 225 market over a period of roughly 20 years. For the knowledge graph, we use the Nikkei Value Search data, which is a rich dataset showing mainly supplier relations among Japanese and foreign companies. Our preliminary results show a 29.5% increase and a 2.2-fold increase in the return ratio and Sharpe ratio, respectively, when compared to the market benchmark, as well as a 6.32% increase and 1.3-fold increase, respectively, compared to the baseline LSTM model.", "link": "http://arxiv.org/abs/1909.10660v3"}, {"index": 601, "title": "Gradient Boost with Convolution Neural Network for Stock Forecast", "abstract": "Market economy closely connects aspects to all walks of life. The stock forecast is one of task among studies on the market economy. However, information on markets economy contains a lot of noise and uncertainties, which lead economy forecasting to become a challenging task. Ensemble learning and deep learning are the most methods to solve the stock forecast task. In this paper, we present a model combining the advantages of two methods to forecast the change of stock price. The proposed method combines CNN and GBoost. The experimental results on six market indexes show that the proposed method has better performance against current popular methods.", "link": "http://arxiv.org/abs/1909.09563v1"}, {"index": 602, "title": "Stock market microstructure inference via multi-agent reinforcement learning", "abstract": "Quantitative finance has had a long tradition of a bottom-up approach to complex systems inference via multi-agent systems (MAS). These statistical tools are based on modelling agents trading via a centralised order book, in order to emulate complex and diverse market phenomena. These past financial models have all relied on so-called zero-intelligence agents, so that the crucial issues of agent information and learning, central to price formation and hence to all market activity, could not be properly assessed. In order to address this, we designed a next-generation MAS stock market simulator, in which each agent learns to trade autonomously via model-free reinforcement learning. We calibrate the model to real market data from the London Stock Exchange over the years $2007$ to $2018$, and show that it can faithfully reproduce key market microstructure metrics, such as various price autocorrelation scalars over multiple time intervals. Agent learning thus enables model emulation of the microstructure with greater realism.", "link": "http://arxiv.org/abs/1909.07748v5"}, {"index": 603, "title": "Comparative Companies' Stock Valuation through Financial Metrics and its Social Implications", "abstract": "Out of the companies, Dolby is the company with the best overall financial and operation health. According to the table that accounted its financial statements for the past three years, Dolby has stable profit margins that generates a revenue in the billions, the only company in ten figures. Corporate competition to gain more patents as old ones expire may mean new jobs created, increased funding for schools, investment in technology or engineering education, and further need for purchase of marketing and salespeople.", "link": "http://arxiv.org/abs/1909.06332v3"}, {"index": 604, "title": "Validating Weak-form Market Efficiency in United States Stock Markets with Trend Deterministic Price Data and Machine Learning", "abstract": "The Efficient Market Hypothesis has been a staple of economics research for decades. In particular, weak-form market efficiency -- the notion that past prices cannot predict future performance -- is strongly supported by econometric evidence. In contrast, machine learning algorithms implemented to predict stock price have been touted, to varying degrees, as successful. Moreover, some data scientists boast the ability to garner above-market returns using price data alone. This study endeavors to connect existing econometric research on weak-form efficient markets with data science innovations in algorithmic trading. First, a traditional exploration of stationarity in stock index prices over the past decade is conducted with Augmented Dickey-Fuller and Variance Ratio tests. Then, an algorithmic trading platform is implemented with the use of five machine learning algorithms. Econometric findings identify potential stationarity, hinting technical evaluation may be possible, though algorithmic trading results find little predictive power in any machine learning model, even when using trend-specific metrics. Accounting for transaction costs and risk, no system achieved above-market returns consistently. Our findings reinforce the validity of weak-form market efficiency.", "link": "http://arxiv.org/abs/1909.05151v1"}, {"index": 605, "title": "To Detect Irregular Trade Behaviors In Stock Market By Using Graph Based Ranking Methods", "abstract": "To detect the irregular trade behaviors in the stock market is the important problem in machine learning field. These irregular trade behaviors are obviously illegal. To detect these irregular trade behaviors in the stock market, data scientists normally employ the supervised learning techniques. In this paper, we employ the three graph Laplacian based semi-supervised ranking methods to solve the irregular trade behavior detection problem. Experimental results show that that the un-normalized and symmetric normalized graph Laplacian based semi-supervised ranking methods outperform the random walk Laplacian based semi-supervised ranking method.", "link": "http://arxiv.org/abs/1909.08964v1"}, {"index": 606, "title": "CCD UBV photometric and Gaia astrometric study of eight open clusters- ASCC 115, Collinder 421, NGC 6793, NGC 7031, NGC 7039, NGC 7086, Roslund 1 and Stock 21", "abstract": "In this study, we carried out CCD UBV photometry of eight open clusters, ASCC 115, Collinder 421, NGC 6793, NGC 7031, NGC 7039, NGC 7086, Roslund 1, Stock 21, and determined their reddening, metallicity, distance, age, and mass functions. We used new Gaia Data Release 2 (DR2) astrometric data to separate cluster member stars from the field stars and obtain precise structural and astrophysical parameters. To identify cluster member stars we utilized an unsupervised membership assignment code (UPMASK), which is based on the photometric and astrometric data. The density distributions for the open clusters show good fits with the empirical King model except for Roslund 1 and Stock 21 not having central concentration. The colour excesses and metallicities were derived separately using U-B vs B-V two-colour diagrams. Keeping these parameters as constants, we simultaneously calculated distance moduli and ages of the clusters from V vs B-V and V vs U-B colour-magnitude diagrams using PARSEC theoretical isochrones. Taking into account Gaia DR2 proper motion components and parallaxes of the member stars, we also calculated mean proper motions and distances for the clusters. Distances derived both from isochrone fitting to colour-magnitude diagrams of the clusters and Gaia DR2 trigonometric parallaxes are compatible with each other. Slopes of the mass functions of the eight open clusters are in good agreement with Salpeter (1955) value of 1.35.", "link": "http://dx.doi.org/10.1007/s10509-019-3640-y"}, {"index": 607, "title": "Interdependency between the Stock Market and Financial News", "abstract": "Stock prices are driven by various factors. In particular, many individual investors who have relatively little financial knowledge rely heavily on the information from news stories when making investment decisions in the stock market. However, these stories may not reflect future stock prices because of the subjectivity in the news; stock prices may instead affect the news contents. This study aims to discover whether it is news or stock prices that have a greater impact on the other. To achieve this, we analyze the relationship between news sentiment and stock prices based on time series analysis using five different classification models. Our experimental results show that stock prices have a bigger impact on the news contents than news does on stock prices.", "link": "http://arxiv.org/abs/1909.00344v1"}, {"index": 608, "title": "Tehran Stock Exchange Prediction Using Sentiment Analysis of Online Textual Opinions", "abstract": "In this paper, we investigate the impact of the social media data in predicting the Tehran Stock Exchange (TSE) variables for the first time. We consider the closing price and daily return of three different stocks for this investigation. We collected our social media data from Sahamyab.com/stocktwits for about three months. To extract information from online comments, we propose a hybrid sentiment analysis approach that combines lexicon-based and learning-based methods. Since lexicons that are available for the Persian language are not practical for sentiment analysis in the stock market domain, we built a particular sentiment lexicon for this domain. After designing and calculating daily sentiment indices using the sentiment of the comments, we examine their impact on the baseline models that only use historical market data and propose new predictor models using multi regression analysis. In addition to the sentiments, we also examine the comments volume and the users' reliabilities. We conclude that the predictability of various stocks in TSE is different depending on their attributes. Moreover, we indicate that for predicting the closing price only comments volume and for predicting the daily return both the volume and the sentiment of the comments could be useful. We demonstrate that Users' Trust coefficients have different behaviors toward the three stocks.", "link": "http://dx.doi.org/10.1002/isaf.1465"}, {"index": 609, "title": "Real-time stock analysis for blending recipes in industrial plants", "abstract": "Many companies use Excel spreadsheets to keep stock records and to calculate process-specific data. These spreadsheets are often hard to understand and track. And if the user does not protect them, there is a risk that the user randomly changes or erase formulas. The paper focuses on the stocks of products used in a blending process with a known recipe. Developing an application that can bring this data in a centralized form and that can assist the operator in decide is a necessity. When a programmer implements an application that uses data from plants he needs to consider one fundamental aspect as reading real-time data from the process. The real-time stock analysis application takes into account all the above elements. The application is easy to use by an operator in the command room of installation because of the planning algorithms integrated into it. The algorithms proposed and implemented in this paper have well-defined goals: identifying the ingredients needed to achieve the blending process for required quantities, determine the quantities of the finished product that can be made with the existing ingredients and determine the optimum quantities of the finished product. The application implemented in C# intensively uses these algorithms and gives the user the ability to build the result step by step.", "link": "http://dx.doi.org/10.1109/ICSTCC.2019.8886147"}, {"index": 610, "title": "Stock Price Forecasting and Hypothesis Testing Using Neural Networks", "abstract": "In this work we use Recurrent Neural Networks and Multilayer Perceptrons to predict NYSE, NASDAQ and AMEX stock prices from historical data. We experiment with different architectures and compare data normalization techniques. Then, we leverage those findings to question the efficient-market hypothesis through a formal statistical test.", "link": "http://arxiv.org/abs/1908.11212v1"}, {"index": 611, "title": "Martingale transport with homogeneous stock movements", "abstract": "We study a variant of the martingale optimal transport problem in a multi-period setting to derive robust price bounds of a financial derivative. On top of marginal and martingale constraints, we introduce a time-homogeneity assumption, which restricts the variability of the forward-looking transitions of the martingale across time. We provide a dual formulation in terms of superhedging and discuss relaxations of the time-homogeneity assumption by adding market frictions. In financial terms, the introduced time-homogeneity corresponds to a time-consistency condition for call prices, given the state of the stock. The time homogeneity assumption leads to improved price bounds as market data from many time points can be incorporated effectively. The approach is illustrated with two numerical examples.", "link": "http://dx.doi.org/10.1080/14697688.2020.1787493"}, {"index": 612, "title": "A Complete Algebraic Solution to the Optimal Dynamic Rationing Policy in the Stock-Rationing Queue with Two Demand Classes", "abstract": "In this paper, we study a stock-rationing queue with two demand classes by means of the sensitivity-based optimization, and develop a complete algebraic solution to the optimal dynamic rationing policy. We show that the optimal dynamic rationing policy must be of transformational threshold type. Based on this finding, we can refine three sufficient conditions under each of which the optimal dynamic rationing policy is of threshold type (i.e., critical rationing level). To do this, we use the performance difference equation to characterize the monotonicity and optimality of the long-run average profit of this system, and thus establish some new structural properties of the optimal dynamic rationing policy by observing any given reference policy. Finally, we use numerical experiments to demonstrate our theoretical results of the optimal dynamic rationing policy. We believe that the methodology and results developed in this paper can shed light on the study of stock-rationing queues and open a series of potentially promising research.", "link": "http://arxiv.org/abs/1908.09295v3"}, {"index": 613, "title": "The emergence of critical stocks in market crash", "abstract": "In complex systems like financial market, risk tolerance of individuals is crucial for system resilience.The single-security price limit, designed as risk tolerance to protect investors by avoiding sharp price fluctuation, is blamed for feeding market panic in times of crash.The relationship between the critical market confidence which stabilizes the whole system and the price limit is therefore an important aspect of system resilience. Using a simplified dynamic model on networks of investors and stocks, an unexpected linear association between price limit and critical market confidence is theoretically derived and empirically verified in this paper. Our results highlight the importance of relatively `small' but critical stocks that drive the system to collapse by passing the failure from periphery to core. These small stocks, largely originating from homogeneous investment strategies across the market, has unintentionally suppressed system resilience with the exclusive increment of individual risk tolerance. Imposing random investment requirements to mitigate herding behavior can thus improve the market resilience.", "link": "http://arxiv.org/abs/1908.07244v1"}, {"index": 614, "title": "Entropic Dynamics of Stocks and European Options", "abstract": "We develop an entropic framework to model the dynamics of stocks and European Options. Entropic inference is an inductive inference framework equipped with proper tools to handle situations where incomplete information is available. The objective of the paper is to lay down an alternative framework for modeling dynamics. An important information about the dynamics of a stock's price is scale invariance. By imposing the scale invariant symmetry, we arrive at choosing the logarithm of the stock's price as the proper variable to model. The dynamics of stock log price is derived using two pieces of information, the continuity of motion and the directionality constraint. The resulting model is the same as the Geometric Brownian Motion, GBM, of the stock price which is manifestly scale invariant. Furthermore, we come up with the dynamics of probability density function, which is a Fokker--Planck equation. Next, we extend the model to value the European Options on a stock. Derivative securities ought to be prices such that there is no arbitrage. To ensure the no-arbitrage pricing, we derive the risk-neutral measure by incorporating the risk-neutral information. Consequently, the Black--Scholes model and the Black--Scholes-Merton differential equation are derived.", "link": "http://dx.doi.org/10.3390/e21080765"}, {"index": 615, "title": "Modeling microstructure price dynamics with symmetric Hawkes and diffusion model using ultra-high-frequency stock data", "abstract": "This study examine the theoretical and empirical perspectives of the symmetric Hawkes model of the price tick structure. Combined with the maximum likelihood estimation, the model provides a proper method of volatility estimation specialized in ultra-high-frequency analysis. Empirical studies based on the model using the ultra-high-frequency data of stocks in the S\\&P 500 are performed. The performance of the volatility measure, intraday estimation, and the dynamics of the parameters are discussed. A new approach of diffusion analogy to the symmetric Hawkes model is proposed with the distributional properties very close to the Hawkes model. As a diffusion process, the model provides more analytical simplicity when computing the variance formula, incorporating skewness and examining the probabilistic property. An estimation of the diffusion model is performed using the simulated maximum likelihood method and shows similar patterns to the Hawkes model.", "link": "http://dx.doi.org/10.1016/j.jedc.2017.04.004"}, {"index": 616, "title": "HATS: A Hierarchical Graph Attention Network for Stock Movement Prediction", "abstract": "Many researchers both in academia and industry have long been interested in the stock market. Numerous approaches were developed to accurately predict future trends in stock prices. Recently, there has been a growing interest in utilizing graph-structured data in computer science research communities. Methods that use relational data for stock market prediction have been recently proposed, but they are still in their infancy. First, the quality of collected information from different types of relations can vary considerably. No existing work has focused on the effect of using different types of relations on stock market prediction or finding an effective way to selectively aggregate information on different relation types. Furthermore, existing works have focused on only individual stock prediction which is similar to the node classification task. To address this, we propose a hierarchical attention network for stock prediction (HATS) which uses relational data for stock market prediction. Our HATS method selectively aggregates information on different relation types and adds the information to the representations of each company. Specifically, node representations are initialized with features extracted from a feature extraction module. HATS is used as a relational modeling module with initialized node representations. Then, node representations with the added information are fed into a task-specific layer. Our method is used for predicting not only individual stock prices but also market index movements, which is similar to the graph classification task. The experimental results show that performance can change depending on the relational data used. HATS which can automatically select information outperformed all the existing methods.", "link": "http://arxiv.org/abs/1908.07999v3"}, {"index": 617, "title": "Statistical Arbitrage for Multiple Co-Integrated Stocks", "abstract": "In this article, we analyse optimal statistical arbitrage strategies from stochastic control and optimisation problems for multiple co-integrated stocks with eigenportfolios being factors. Optimal portfolio weights are found by solving a Hamilton-Jacobi-Bellman (HJB) partial differential equation, which we solve for both an unconstrained portfolio and a portfolio constrained to be market neutral. Our analyses demonstrate sufficient conditions on the model parameters to ensure long-term stability of the HJB solutions and stable growth rates for the optimal portfolios. To gauge how these optimal portfolios behave in practice, we perform backtests on historical stock prices of the S&P 500 constituents from year 2000 through year 2021. These backtests suggest three key conclusions: that the proposed co-integrated model with eigenportfolios being factors can generate a large number of co-integrated stocks over a long time horizon, that the optimal portfolios are sensitive to parameter estimation, and that the statistical arbitrage strategies are more profitable in periods when overall market volatilities are high.", "link": "http://arxiv.org/abs/1908.02164v5"}, {"index": 618, "title": "Risk Management via Anomaly Circumvent: Mnemonic Deep Learning for Midterm Stock Prediction", "abstract": "Midterm stock price prediction is crucial for value investments in the stock market. However, most deep learning models are essentially short-term and applying them to midterm predictions encounters large cumulative errors because they cannot avoid anomalies. In this paper, we propose a novel deep neural network Mid-LSTM for midterm stock prediction, which incorporates the market trend as hidden states. First, based on the autoregressive moving average model (ARMA), a midterm ARMA is formulated by taking into consideration both hidden states and the capital asset pricing model. Then, a midterm LSTM-based deep neural network is designed, which consists of three components: LSTM, hidden Markov model and linear regression networks. The proposed Mid-LSTM can avoid anomalies to reduce large prediction errors, and has good explanatory effects on the factors affecting stock prices. Extensive experiments on S&P 500 stocks show that (i) the proposed Mid-LSTM achieves 2-4% improvement in prediction accuracy, and (ii) in portfolio allocation investment, we achieve up to 120.16% annual return and 2.99 average Sharpe ratio.", "link": "http://arxiv.org/abs/1908.01112v1"}, {"index": 619, "title": "Taxable Stock Trading with Deep Reinforcement Learning", "abstract": "In this paper, we propose stock trading based on the average tax basis. Recall that when selling stocks, capital gain should be taxed while capital loss can earn certain tax rebate. We learn the optimal trading strategies with and without considering taxes by reinforcement learning. The result shows that tax ignorance could induce more than 62% loss on the average portfolio returns, implying that taxes should be embedded in the environment of continuous stock trading on AI platforms.", "link": "http://arxiv.org/abs/1907.12093v2"}, {"index": 620, "title": "Testing new property of elliptical model for stock returns distribution", "abstract": "Wide class of elliptically contoured distributions is a popular model of stock returns distribution. However the important question of adequacy of the model is open. There are some results which reject and approve such model. Such results are obtained by testing some properties of elliptical model for each pair of stocks from some markets. New property of equality of $\\tau$ Kendall correlation coefficient and probability of sign coincidence for any pair of random variables with elliptically contoured distribution is proved in the paper. Distribution free statistical tests for testing this property for any pair of stocks are constructed. Holm multiple hypotheses testing procedure based on the individual tests is constructed and applied for stock markets data for the concrete year. New procedure of testing the elliptical model for stock returns distribution for all years of observation for some period is proposed. The procedure is applied for the stock markets data of China, USA, Great Britain and Germany for the period from 2003 to 2014. It is shown that for USA, Great Britain and Germany stock markets the hypothesis of elliptical model of stock returns distribution could be accepted but for Chinese stock market is rejected for some cases.", "link": "http://arxiv.org/abs/1907.10306v1"}, {"index": 621, "title": "Option pricing in bilateral Gamma stock models", "abstract": "In the framework of bilateral Gamma stock models we seek for adequate option pricing measures, which have an economic interpretation and allow numerical calculations of option prices. Our investigations encompass Esscher transforms, minimal entropy martingale measures, $p$-optimal martingale measures, bilateral Esscher transforms and the minimal martingale measure. We illustrate our theory by a numerical example.", "link": "http://arxiv.org/abs/1907.09862v1"}, {"index": 622, "title": "A Stock Market Model Based on CAPM and Market Size", "abstract": "We introduce a new system of stochastic differential equations which models dependence of market beta and unsystematic risk upon size, measured by market capitalization. We fit our model using size deciles data from Kenneth French's data library. This model is somewhat similar to generalized volatility-stabilized models in (Pal, 2011; Pickova, 2013). The novelty of our work is twofold. First, we take into account the difference between price and total returns (in other words, between market size and wealth processes). Second, we work with actual market data. We study the long-term properties of this system of equations, and reproduce observed linearity of the capital distribution curve. Our model has two modifications: for price returns and for equity premium. Somewhat surprisingly, they exhibit the same fit, with very similar coefficients. In the Appendix, we analyze size-based real-world index funds.", "link": "http://arxiv.org/abs/1907.08911v8"}, {"index": 623, "title": "The Impact of Execution Delay on Kelly-Based Stock Trading: High-Frequency Versus Buy and Hold", "abstract": "Stock trading based on Kelly's celebrated Expected Logarithmic Growth (ELG) criterion, a well-known prescription for optimal resource allocation, has received considerable attention in the literature. Using ELG as the performance metric, we compare the impact of trade execution delay on the relative performance of high-frequency trading versus buy and hold. While it is intuitively obvious and straightforward to prove that in the presence of sufficiently high transaction costs, buy and hold is the better strategy, is it possible that with no transaction costs, buy and hold can still be the better strategy? When there is no delay in trade execution, we prove a theorem saying that the answer is ``no.'' However, when there is delay in trade execution, we present simulation results using a binary lattice stock model to show that the answer can be ``yes.'' This is seen to be true whether self-financing is imposed or not.", "link": "http://dx.doi.org/10.1109/CDC40024.2019.9029292"}, {"index": 624, "title": "Exponential stock models driven by tempered stable processes", "abstract": "We investigate exponential stock models driven by tempered stable processes, which constitute a rich family of purely discontinuous L\\'{e}vy processes. With a view of option pricing, we provide a systematic analysis of the existence of equivalent martingale measures, under which the model remains analytically tractable. This includes the existence of Esscher martingale measures and martingale measures having minimal distance to the physical probability measure. Moreover, we provide pricing formulae for European call options and perform a case study.", "link": "http://arxiv.org/abs/1907.05142v1"}, {"index": 625, "title": "Nonlinear price dynamics of S&P 100 stocks", "abstract": "The methodology presented provides a quantitative way to characterize investor behavior and price dynamics within a particular asset class and time period. The methodology is applied to a data set consisting of over 250,000 data points of the S&P 100 stocks during 2004-2018. Using a two-way fixed-effects model, we uncover trader motivations including evidence of both under- and overreaction within a unified setting. A nonlinear relationship is found between return and trend suggesting a small, positive trend increases the return, while a larger one tends to decrease it. The shape parameters of the nonlinearity quantify trader motivation to buy into trends or wait for bargains. The methodology allows the testing of any behavioral finance bias or technical analysis concept.", "link": "http://dx.doi.org/10.1016/j.physa.2019.122067"}, {"index": 626, "title": "Identification of short-term and long-term time scales in stock markets and effect of structural break", "abstract": "The paper presents the comparative study of the nature of stock markets in short-term and long-term time scales with and without structural break in the stock data. Structural break point has been identified by applying Zivot and Andrews structural trend break model to break the original time series (TSO) into time series before structural break (TSB) and time series after structural break (TSA). The empirical mode decomposition based Hurst exponent and variance techniques have been applied to the TSO, TSB and TSA to identify the time scales in short-term and long-term from the decomposed intrinsic mode functions. We found that for TSO, TSB and TSA the short-term time scales and long-term time scales are within the range of few days to 3 months and greater than 5 months respectively, which indicates that the short-term and long-term time scales are present in the stock market. The Hurst exponent is $\\sim 0.5$ and $\\geq 0.75$ for TSO, TSB and TSA in short-term and long-term respectively, which indicates that the market is random in short-term and strongly correlated in long-term. The identification of time scales at short-term and long-term investment horizon will be useful for investors to design investment and trading strategies.", "link": "http://dx.doi.org/10.1016/j.physa.2019.123612"}, {"index": 627, "title": "Regularities in stock markets", "abstract": "From the stock markets of six countries with high GDP, we study the stock indices, S&P 500 (NYSE, USA), SSE Composite (SSE, China), Nikkei (TSE, Japan), DAX (FSE, Germany), FTSE 100 (LSE, Britain) and NIFTY (NSE, India). The daily mean growth of the stock values is exponential. The daily price fluctuations about the mean growth are Gaussian, but with a non-zero asymptotic convergence. The growth of the monthly average of stock values is statistically self-similar to their daily growth. The monthly fluctuations of the price follow a Wiener process, with a decline of the volatility. The mean growth of the daily volume of trade is exponential. These observations are globally applicable and underline regularities across global stock markets.", "link": "http://dx.doi.org/10.1142/S0129183120501454"}, {"index": 628, "title": "Modelling Airway Geometry as Stock Market Data using Bayesian Changepoint Detection", "abstract": "Numerous lung diseases, such as idiopathic pulmonary fibrosis (IPF), exhibit dilation of the airways. Accurate measurement of dilatation enables assessment of the progression of disease. Unfortunately the combination of image noise and airway bifurcations causes high variability in the profiles of cross-sectional areas, rendering the identification of affected regions very difficult. Here we introduce a noise-robust method for automatically detecting the location of progressive airway dilatation given two profiles of the same airway acquired at different time points. We propose a probabilistic model of abrupt relative variations between profiles and perform inference via Reversible Jump Markov Chain Monte Carlo sampling. We demonstrate the efficacy of the proposed method on two datasets; (i) images of healthy airways with simulated dilatation; (ii) pairs of real images of IPF-affected airways acquired at 1 year intervals. Our model is able to detect the starting location of airway dilatation with an accuracy of 2.5mm on simulated data. The experiments on the IPF dataset display reasonable agreement with radiologists. We can compute a relative change in airway volume that may be useful for quantifying IPF disease progression. The code is available at https://github.com/quan14/Modelling_Airway_Geometry_as_Stock_Market_Data", "link": "http://dx.doi.org/10.1007/978-3-030-32692-0_40"}, {"index": 629, "title": "Against the Norm: Modeling Daily Stock Returns with the Laplace Distribution", "abstract": "Modeling stock returns is not a new task for mathematicians, investors, and portfolio managers, but it remains a difficult objective due to the ebb and flow of stock markets. One common solution is to approximate the distribution of stock returns with a normal distribution. However, normal distributions place infinitesimal probabilities on extreme outliers, but these outliers are of particular importance in the practice of investing. In this paper, we investigate the normality of the distribution of daily returns of major stock market indices. We find that the normal distribution is not a good model for stock returns, even over several years' worth of data. Moreover, we propose using the Laplace distribution as a model for daily stock returns.", "link": "http://arxiv.org/abs/1906.10325v1"}, {"index": 630, "title": "Metaheuristics optimized feedforward neural networks for efficient stock price prediction", "abstract": "The prediction of stock prices is an important task in economics, investment and making financial decisions. This has, for decades, spurred the interest of many researchers to make focused contributions to the design of accurate stock price predictive models; of which some have been utilized to predict the next day opening and closing prices of the stock indices. This paper proposes the design and implementation of a hybrid symbiotic organisms search trained feedforward neural network model for effective and accurate stock price prediction. The symbiotic organisms search algorithm is used as an efficient optimization technique to train the feedforward neural networks, while the resulting training process is used to build a better stock price prediction model. Furthermore, the study also presents a comparative performance evaluation of three different stock price forecasting models; namely, the particle swarm optimization trained feedforward neural network model, the genetic algorithm trained feedforward neural network model and the well-known ARIMA model. The system developed in support of this study utilizes sixteen stock indices as time series datasets for training and testing purpose. Three statistical evaluation measures are used to compare the results of the implemented models, namely the root mean squared error, the mean absolute percentage error and the mean absolution deviation. The computational results obtained reveal that the symbiotic organisms search trained feedforward neural network model exhibits outstanding predictive performance compared to the other models. However, the performance study shows that the three metaheuristics trained feedforward neural network models have promising predictive competence for solving problems of high dimensional nonlinear time series data, which are difficult to capture by traditional models.", "link": "http://arxiv.org/abs/1906.10121v3"}, {"index": 631, "title": "BERT-based Financial Sentiment Index and LSTM-based Stock Return Predictability", "abstract": "Traditional sentiment construction in finance relies heavily on the dictionary-based approach, with a few exceptions using simple machine learning techniques such as Naive Bayes classifier. While the current literature has not yet invoked the rapid advancement in the natural language processing, we construct in this research a textual-based sentiment index using a well-known pre-trained model BERT developed by Google, especially for three actively trading individual stocks in Hong Kong market with at the same time the hot discussion on Weibo.com. On the one hand, we demonstrate a significant enhancement of applying BERT in financial sentiment analysis when compared with the existing models. On the other hand, by combining with the other two commonly-used methods when it comes to building the sentiment index in the financial literature, i.e., the option-implied and the market-implied approaches, we propose a more general and comprehensive framework for the financial sentiment analysis, and further provide convincing outcomes for the predictability of individual stock return by combining LSTM (with a feature of a nonlinear mapping). It is significantly distinct with the dominating econometric methods in sentiment influence analysis which are all of a nature of linear regression.", "link": "http://arxiv.org/abs/1906.09024v2"}, {"index": 632, "title": "Optimistic Bull or Pessimistic Bear: Adaptive Deep Reinforcement Learning for Stock Portfolio Allocation", "abstract": "Portfolio allocation is crucial for investment companies. However, getting the best strategy in a complex and dynamic stock market is challenging. In this paper, we propose a novel Adaptive Deep Deterministic Reinforcement Learning scheme (Adaptive DDPG) for the portfolio allocation task, which incorporates optimistic or pessimistic deep reinforcement learning that is reflected in the influence from prediction errors. Dow Jones 30 component stocks are selected as our trading stocks and their daily prices are used as the training and testing data. We train the Adaptive DDPG agent and obtain a trading strategy. The Adaptive DDPG's performance is compared with the vanilla DDPG, Dow Jones Industrial Average index and the traditional min-variance and mean-variance portfolio allocation strategies. Adaptive DDPG outperforms the baselines in terms of the investment return and the Sharpe ratio.", "link": "http://arxiv.org/abs/1907.01503v1"}, {"index": 633, "title": "Investment Ranking Challenge: Identifying the best performing stocks based on their semi-annual returns", "abstract": "In the IEEE Investment ranking challenge 2018, participants were asked to build a model which would identify the best performing stocks based on their returns over a forward six months window. Anonymized financial predictors and semi-annual returns were provided for a group of anonymized stocks from 1996 to 2017, which were divided into 42 non-overlapping six months period. The second half of 2017 was used as an out-of-sample test of the model's performance. Metrics used were Spearman's Rank Correlation Coefficient and Normalized Discounted Cumulative Gain (NDCG) of the top 20% of a model's predicted rankings. The top six participants were invited to describe their approach. The solutions used were varied and were based on selecting a subset of data to train, combination of deep and shallow neural networks, different boosting algorithms, different models with different sets of features, linear support vector machine, combination of convoltional neural network (CNN) and Long short term memory (LSTM).", "link": "http://arxiv.org/abs/1906.08636v1"}, {"index": 634, "title": "Multi-Likelihood Methods for Developing Stock Relationship Networks Using Financial Big Data", "abstract": "Development of stock networks is an important approach to explore the relationship between different stocks in the era of big-data. Although a number of methods have been designed to construct the stock correlation networks, it is still a challenge to balance the selection of prominent correlations and connectivity of networks. To address this issue, we propose a new approach to select essential edges in stock networks and also maintain the connectivity of established networks. This approach uses different threshold values for choosing the edges connecting to a particular stock, rather than employing a single threshold value in the existing asset-value method. The innovation of our algorithm includes the multiple distributions in a maximum likelihood estimator for selecting the threshold value rather than the single distribution estimator in the existing methods. Using the Chinese Shanghai security market data of 151 stocks, we develop a stock relationship network and analyze the topological properties of the developed network. Our results suggest that the proposed method is able to develop networks that maintain appropriate connectivities in the type of assets threshold methods.", "link": "http://arxiv.org/abs/1906.08088v1"}, {"index": 635, "title": "Short period variable stars in young open cluster Stock 8", "abstract": "We present time series photometry in the field of Stock 8 and identified 130 short period variable stars. Twenty eight main-sequence and 23 pre-main-sequence variables are found to be part of cluster Stock 8. The main-sequence variables are classified as slow pulsator of the B type, $\\beta$ Cep and $\\delta$ Scuti stars. Fourteen main-sequence stars could be new class variables as discussed by Mowlavi et al. (2013) and Lata et al. (2014). The age and mass of pre-main-sequence variables are found to be $\\lesssim$ 5 Myr and in the mass range of 0.5 to 2.8 M$_{\\odot}$, respectively. These pre-main-sequence stars could be T-Tauri variables. We have found 5 and 2 of 23 PMS variables as classical T-Tauri stars and Herbig Ae/Be stars, respectively, whereas 16 PMS stars are classified as weak-line T Tauri stars.", "link": "http://dx.doi.org/10.3847/1538-3881/ab298c"}, {"index": 636, "title": "Time scales in stock markets", "abstract": "Different investment strategies are adopted in short-term and long-term depending on the time scales, even though time scales are adhoc in nature. Empirical mode decomposition based Hurst exponent analysis and variance technique have been applied to identify the time scales for short-term and long-term investment from the decomposed intrinsic mode functions(IMF). Hurst exponent ($H$) is around 0.5 for the IMFs with time scales from few days to 3 months, and $H\\geq0.75$ for the IMFs with the time scales $\\geq5$ months. Short term time series [$X_{ST}(t)$] with time scales from few days to 3 months and $H~0.5$ and long term time series [$X_{LT}(t)$] with time scales $\\geq5$ and $H\\geq0.75$, which represent the dynamics of the market, are constructed from the IMFs. The $X_{ST}(t)$ and $X_{LT}(t)$ show that the market is random in short-term and correlated in long term. The study also show that the $X_{LT}(t)$ is correlated with fundamentals of the company. The analysis will be useful for investors to design the investment and trading strategy.", "link": "http://dx.doi.org/10.3389/fphy.2020.590623"}, {"index": 637, "title": "Neural Network Models for Stock Selection Based on Fundamental Analysis", "abstract": "Application of neural network architectures for financial prediction has been actively studied in recent years. This paper presents a comparative study that investigates and compares feed-forward neural network (FNN) and adaptive neural fuzzy inference system (ANFIS) on stock prediction using fundamental financial ratios. The study is designed to evaluate the performance of each architecture based on the relative return of the selected portfolios with respect to the benchmark stock index. The results show that both architectures possess the ability to separate winners and losers from a sample universe of stocks, and the selected portfolios outperform the benchmark. Our study argues that FNN shows superior performance over ANFIS.", "link": "http://arxiv.org/abs/1906.05327v1"}, {"index": 638, "title": "Selecting stock pairs for pairs trading while incorporating lead-lag relationship", "abstract": "Pairs Trading is carried out in the financial market to earn huge profits from known equilibrium relation between pairs of stock. In financial markets, seldom it is seen that stock pairs are correlated at particular lead or lag. This lead-lag relationship has been empirically studied in various financial markets. Earlier research works have suggested various measures for identifying the best pairs for pairs trading, but they do not consider this lead-lag effect. The present study proposes a new distance measure which incorporates the lead-lag relationship between the stocks while selecting the best pairs for pairs trading. Further, the lead-lag value between the stocks is allowed to vary continuously over time. The proposed measures importance has been show-cased through experimentation on two different datasets, one corresponding to Indian companies and another corresponding to American companies. When the proposed measure is clubbed with SSD measure, i.e., when pairs are identified through optimising both these measures, then the selected pairs consistently generate the best profit, as compared to all other measures. Finally, possible generalisation and extension of the proposed distance measure have been discussed.", "link": "http://dx.doi.org/10.1016/j.physa.2019.124103"}, {"index": 639, "title": "A Top-Down Approach for the Multiple Exercises and Valuation of Employee Stock Options", "abstract": "We propose a new framework to value employee stock options (ESOs) that captures multiple exercises of different quantities over time. We also model the ESO holder's job termination risk and incorporate its impact on the payoffs of both vested and unvested ESOs. Numerical methods based on Fourier transform and finite differences are developed and implemented to solve the associated systems of PDEs. In addition, we introduce a new valuation method based on maturity randomization that yields analytic formulae for vested and unvested ESO costs. We examine the cost impact of job termination risk, exercise intensity, and various contractual features.", "link": "http://arxiv.org/abs/1906.03562v2"}, {"index": 640, "title": "A Statistical Recurrent Stochastic Volatility Model for Stock Markets", "abstract": "The Stochastic Volatility (SV) model and its variants are widely used in the financial sector while recurrent neural network (RNN) models are successfully used in many large-scale industrial applications of Deep Learning. Our article combines these two methods in a non-trivial way and proposes a model, which we call the Statistical Recurrent Stochastic Volatility (SR-SV) model, to capture the dynamics of stochastic volatility. The proposed model is able to capture complex volatility effects (e.g., non-linearity and long-memory auto-dependence) overlooked by the conventional SV models, is statistically interpretable and has an impressive out-of-sample forecast performance. These properties are carefully discussed and illustrated through extensive simulation studies and applications to five international stock index datasets: The German stock index DAX30, the Hong Kong stock index HSI50, the France market index CAC40, the US stock market index SP500 and the Canada market index TSX250. An user-friendly software package together with the examples reported in the paper are available at \\url{https://github.com/vbayeslab}.", "link": "http://arxiv.org/abs/1906.02884v3"}, {"index": 641, "title": "Forecasting Stock Market with Support Vector Regression and Butterfly Optimization Algorithm", "abstract": "Support Vector Regression (SVR) has achieved high performance on forecasting future behavior of random systems. However, the performance of SVR models highly depends upon the appropriate choice of SVR parameters. In this study, a novel BOA-SVR model based on Butterfly Optimization Algorithm (BOA) is presented. The performance of the proposed model is compared with eleven other meta-heuristic algorithms on a number of stocks from NASDAQ. The results indicate that the presented model here is capable to optimize the SVR parameters very well and indeed is one of the best models judged by both prediction performance accuracy and time consumption.", "link": "http://arxiv.org/abs/1905.11462v1"}, {"index": 642, "title": "Detection of Chinese Stock Market Bubbles with LPPLS Confidence Indicator", "abstract": "We present an advance bubble detection methodology based on the Log Periodic Power Law Singularity (LPPLS) confidence indicator for the early causal identification of positive and negative bubbles in the Chinese stock market using the daily data on the Shanghai Shenzhen CSI 300 stock market index from January 2002 through April 2018. We account for the damping condition of LPPLS model in the search space and implement the stricter filter conditions for the qualification of the valid LPPLS fits by taking account of the maximum relative error, performing the Lomb log-periodic test of the detrended residual, and unit-root tests of the logarithmic residual based on both the Phillips-Perron test and Dickey-Fuller test to improve the performance of LPPLS confidence indicator. Our analysis shows that the LPPLS detection strategy diagnoses the positive bubbles and negative bubbles corresponding to well-known historical events, implying the detection strategy based on the LPPLS confidence indicator has an outstanding performance to identify the bubbles in advance. We find that the probability density distribution of the estimated beginning time of bubbles appears to be skewed and the mass of the distribution is concentrated on the area where the price starts to have an obvious super-exponentially growth. This study is the first work in the literature that identifies the existence of bubbles in the Chinese stock market using the daily data of CSI 300 index with the advance bubble detection methodology of LPPLS confidence indicator. We have shown that it is possible to detect the potential positive and negative bubbles and crashes ahead of time, which in turn limits the bubble sizes and eventually minimizes the damages from the bubble crash.", "link": "http://dx.doi.org/10.1016/j.physa.2020.124892"}, {"index": 643, "title": "Diagnosis and Prediction of the 2015 Chinese Stock Market Bubble", "abstract": "In this study, we perform a novel analysis of the 2015 financial bubble in the Chinese stock market by calibrating the Log Periodic Power Law Singularity (LPPLS) model to two important Chinese stock indices, SSEC and SZSC, from early 2014 to June 2015. The back tests of the 2015 Chinese stock market bubbles indicates that the LPPLS model can readily detect the bubble behavior of the faster-than-exponential increase corrected by the accelerating logarithm-periodic oscillations in the 2015 Chinese Stock market. The existence of log-periodicity is detected by applying the Lomb spectral analysis on the detrended residuals. The Ornstein-Uhlenbeck property and the stationarity of the LPPLS fitting residuals are confirmed by the two Unit-root tests (Philips-Perron test and Dickery-Fuller test). According to our analysis, the actual critical day t_c can be well predicted by the LPPLS model as far back as two months before the actual bubble crash. Compared to the traditional optimization method used in the LPPLS model, we find the covariance matrix adaptation evolution strategy (CMA-ES) to have a significantly lower computation cost, and thus recommend this as a better alternative algorithm for LPPLS model fit. Furthermore, in the LPPLS fitting with expanding windows, the gap (tc -t2) shows a significant decrease when the end day t2 approaches the actual bubble crash time. The change rate of the gap (tc-t2) may be used as an additional indicator besides the key indicator tc to improve the prediction of bubble burst.", "link": "http://arxiv.org/abs/1905.09633v2"}, {"index": 644, "title": "Convolutional Feature Extraction and Neural Arithmetic Logic Units for Stock Prediction", "abstract": "Stock prediction is a topic undergoing intense study for many years. Finance experts and mathematicians have been working on a way to predict the future stock price so as to decide to buy the stock or sell it to make profit. Stock experts or economists, usually analyze on the previous stock values using technical indicators, sentiment analysis etc to predict the future stock price. In recent years, many researches have extensively used machine learning for predicting the stock behaviour. In this paper we propose data driven deep learning approach to predict the future stock value with the previous price with the feature extraction property of convolutional neural network and to use Neural Arithmetic Logic Units with it.", "link": "http://dx.doi.org/10.1007/978-981-13-9939-8_31"}, {"index": 645, "title": "A Stock Selection Method Based on Earning Yield Forecast Using Sequence Prediction Models", "abstract": "Long-term investors, different from short-term traders, focus on examining the underlying forces that affect the well-being of a company. They rely on fundamental analysis which attempts to measure the intrinsic value an equity. Quantitative investment researchers have identified some value factors to determine the cost of investment for a stock and compare different stocks. This paper proposes using sequence prediction models to forecast a value factor-the earning yield (EBIT/EV) of a company for stock selection. Two advanced sequence prediction models-Long Short-term Memory (LSTM) and Gated Recurrent Unit (GRU) networks are studied. These two models can overcome the inherent problems of a standard Recurrent Neural Network, i.e., vanishing and exploding gradients. This paper firstly introduces the theories of the networks. And then elaborates the workflow of stock pool creation, feature selection, data structuring, model setup and model evaluation. The LSTM and GRU models demonstrate superior performance of forecast accuracy over a traditional Feedforward Neural Network model. The GRU model slightly outperformed the LSTM model.", "link": "http://arxiv.org/abs/1905.04842v1"}, {"index": 646, "title": "A New Stock Market Valuation Measure with Applications to Retirement Planning", "abstract": "We generalize the classic Shiller cyclically adjusted price-earnings ratio (CAPE) used for prediction of future total returns of the stock market. We treat earnings growth as exogenous. The difference between log wealth and log earnings is modeled as an autoregression of order 1 with linear trend 4.5\\% and Gaussian innovations. Detrending gives us a new valuation measure. This autoregression is significantly different from the random walk. Therefore, our results disprove the Efficient Market Hypothesis. Therefore, long-run total returns equal long-run earnings growth plus 4.5\\%. We apply results to retirement planning. A withdrawal process governs how a retired capital owner withdraws a certain fraction of wealth annually. The fraction can vary from year to year. We study the long-term behavior of such processes.", "link": "http://arxiv.org/abs/1905.04603v14"}, {"index": 647, "title": "A class of recursive optimal stopping problems with applications to stock trading", "abstract": "In this paper we introduce and solve a class of optimal stopping problems of recursive type. In particular, the stopping payoff depends directly on the value function of the problem itself. In a multi-dimensional Markovian setting we show that the problem is well posed, in the sense that the value is indeed the unique solution to a fixed point problem in a suitable space of continuous functions, and an optimal stopping time exists. We then apply our class of problems to a model for stock trading in two different market venues and we determine the optimal stopping rule in that case.", "link": "http://arxiv.org/abs/1905.02650v4"}, {"index": 648, "title": "A hierarchical life cycle model for Atlantic salmon stock assessment at the North Atlantic basin scale", "abstract": "We developed an integrated hierarchical Bayesian life cycle model that simultaneously estimates the abundance of post-smolts at sea, post-smolt survival rates, and proportions maturing as 1SW, for all SU in Northern Europe, Southern Europe and North America. The model is an age- and stage-based life cycle model that considers 1SW and 2SW life history strategies and harmonizes the life history dynamics among SU in North America and Europe. The new framework brought a major contribution to improve the scientific basis for Atlantic salmon stock assessment. It is a benchmark for the assessment and forecast models currently used by ICES for Atlantic salmon stock assessment in the North Atlantic. ...", "link": "http://arxiv.org/abs/1905.00676v1"}, {"index": 649, "title": "Online reviews can predict long-term returns of individual stocks", "abstract": "Online reviews are feedback voluntarily posted by consumers about their consumption experiences. This feedback indicates customer attitudes such as affection, awareness and faith towards a brand or a firm and demonstrates inherent connections with a company's future sales, cash flow and stock pricing. However, the predicting power of online reviews for long-term returns on stocks, especially at the individual level, has received little research attention, making a comprehensive exploration necessary to resolve existing debates. In this paper, which is based exclusively on online reviews, a methodology framework for predicting long-term returns of individual stocks with competent performance is established. Specifically, 6,246 features of 13 categories inferred from more than 18 million product reviews are selected to build the prediction models. With the best classifier selected from cross-validation tests, a satisfactory increase in accuracy, 13.94%, was achieved compared to the cutting-edge solution with 10 technical indicators being features, representing an 18.28% improvement relative to the random value. The robustness of our model is further evaluated and testified in realistic scenarios. It is thus confirmed for the first time that long-term returns of individual stocks can be predicted by online reviews. This study provides new opportunities for investors with respect to long-term investments in individual stocks.", "link": "http://arxiv.org/abs/1905.03189v1"}, {"index": 650, "title": "Inefficiency of the Brazilian Stock Market: the IBOVESPA Future Contracts", "abstract": "We present some indications of inefficiency of the Brazilian stock market based on the existence of strong long-time cross-correlations with foreign markets and indices. Our results show a strong dependence on foreign markets indices as the S\\&P 500 and CAC 40, but not to the Shanghai SSE 180, indicating an intricate interdependence. We also show that the distribution of log-returns of the Brazilian BOVESPA index has a discrete fat tail in the time scale of a day, which is also a deviation of what is expected of an efficient equilibrated market. As a final argument of the inefficiency of the Brazilian stock market, we use a neural network approach to forecast the direction of movement of the value of the IBOVESPA future contracts, with an accuracy allowing financial returns over passive strategies.", "link": "http://dx.doi.org/10.1016/j.physa.2019.123200"}, {"index": 651, "title": "Stock Forecasting using M-Band Wavelet-Based SVR and RNN-LSTMs Models", "abstract": "The task of predicting future stock values has always been one that is heavily desired albeit very difficult. This difficulty arises from stocks with non-stationary behavior, and without any explicit form. Hence, predictions are best made through analysis of financial stock data. To handle big data sets, current convention involves the use of the Moving Average. However, by utilizing the Wavelet Transform in place of the Moving Average to denoise stock signals, financial data can be smoothened and more accurately broken down. This newly transformed, denoised, and more stable stock data can be followed up by non-parametric statistical methods, such as Support Vector Regression (SVR) and Recurrent Neural Network (RNN) based Long Short-Term Memory (LSTM) networks to predict future stock prices. Through the implementation of these methods, one is left with a more accurate stock forecast, and in turn, increased profits.", "link": "http://arxiv.org/abs/1904.08459v1"}, {"index": 652, "title": "A Weight-based Information Filtration Algorithm for Stock-Correlation Networks", "abstract": "Several algorithms have been proposed to filter information on a complete graph of correlations across stocks to build a stock-correlation network. Among them the planar maximally filtered graph (PMFG) algorithm uses $3n-6$ edges to build a graph whose features include a high frequency of small cliques and a good clustering of stocks. We propose a new algorithm which we call proportional degree (PD) to filter information on the complete graph of normalised mutual information (NMI) across stocks. Our results show that the PD algorithm produces a network showing better homogeneity with respect to cliques, as compared to economic sectoral classification than its PMFG counterpart. We also show that the partition of the PD network obtained through normalised spectral clustering (NSC) agrees better with the NSC of the complete graph than the corresponding one obtained from PMFG. Finally, we show that the clusters in the PD network are more robust with respect to the removal of random sets of edges than those in the PMFG network.", "link": "http://arxiv.org/abs/1904.06007v1"}, {"index": 653, "title": "On the Co-movement of Crude, Gold Prices and Stock Index in Indian Market", "abstract": "This non-linear relationship in the joint time-frequency domain has been studied for the Indian National Stock Exchange (NSE) with the international Gold price and WTI Crude Price being converted from Dollar to Indian National Rupee based on that week's closing exchange rate. Though a good correlation was obtained during some period, but as a whole no such cointegration relation can be found out. Using the \\textit{Discrete Wavelet Analysis}, the data was decomposed and the presence of Granger Causal relations was tested. Unfortunately no significant relationships are being found. We then studied the \\textit{Wavelet Coherence} of the two pairs viz. NSE-Nifty \\& Gold and NSE-Nifty \\& Crude. For different frequencies, the coherence between the pairs have been studied. At lower frequencies, some relatively good coherence have been found. In this paper, we report for the first time the co-movements between Crude Oil, Gold and Indian Stock Market Index using Wavelet Analysis (both Discrete and Continuous), a technique which is most sophisticated and recent in market analysis. Thus for long term traders they can include gold and/or crude in their portfolio along with NSE-Nifty index in order to decrease the risk(volatility) of the portfolio for Indian Market. But for short term traders, it will not be effective, not to include all the three in their portfolio.", "link": "http://arxiv.org/abs/1904.05317v1"}, {"index": 654, "title": "A long-term alternative formula for a stochastic stock price model", "abstract": "This study presents a long-term alternative formula for stock price variation described by a geometric Brownian motion on the basis of median instead of mean or expected values. The proposed method is motivated by the observation made in remote fields, where optimality of bet-hedging or diversification strategies is explained based on a measure different from expected value, like geometric mean. When the probability distribution of possible outcomes is significantly skewed, it is generally known that expected value leads to an erroneous picture owing to its sensitivity to outliers, extreme values of rare occurrence. Since geometric mean, or its counterpart median for the log-normal distribution, does not suffer from this drawback, it provides us with a more appropriate measure especially for evaluating long-term outcomes dominated by outliers. Thus, the present formula makes a more realistic prediction for long-term outcomes of a large volatility, for which the probability distribution becomes conspicuously heavy-tailed.", "link": "http://dx.doi.org/10.1007/s42452-022-05176-9"}, {"index": 655, "title": "Blindfolded monkeys or financial analysts: who is worth your money? New evidence on informational inefficiencies in the U.S. stock market", "abstract": "The efficient market hypothesis has been considered one of the most controversial arguments in finance, with the academia divided between who claims the impossibility of beating the market and who believes that it is possible to gain over the average profits. If the hypothesis holds, it means, as suggested by Burton Malkiel, that a blindfolded monkey selecting stocks by throwing darts at a newspaper's financial pages could perform as well as a financial analyst, or even better. In this paper we use a novel approach, based on confidence intervals for proportions, to assess the degree of inefficiency in the S&P 500 Index components concluding that several stocks are inefficient: we estimated the proportion of inefficient stocks in the index to be between 12.13% and 27.87%. This supports other studies proving that a financial analyst, probably, is a better investor than a blindfolded monkey.", "link": "http://dx.doi.org/10.1016/j.physa.2019.122900"}, {"index": 656, "title": "Fat Tails in Financial Return Distributions Revisited: Evidence from the Korean Stock Market", "abstract": "This study empirically re-examines fat tails in stock return distributions by applying statistical methods to an extensive dataset taken from the Korean stock market. The tails of the return distributions are shown to be much fatter in recent periods than in past periods and much fatter for small-capitalization stocks than for large-capitalization stocks. After controlling for the 1997 Korean foreign currency crisis and using the GARCH filter models to control for volatility clustering in the returns, the fat tails in the distribution of residuals are found to persist. We show that market crashes and volatility clustering may not sufficiently account for the existence of fat tails in return distributions. These findings are robust regardless of period or type of stock group.", "link": "http://dx.doi.org/10.1016/j.physa.2019.121055"}, {"index": 657, "title": "Multimodal Deep Learning for Finance: Integrating and Forecasting International Stock Markets", "abstract": "In today's increasingly international economy, return and volatility spillover effects across international equity markets are major macroeconomic drivers of stock dynamics. Thus, information regarding foreign markets is one of the most important factors in forecasting domestic stock prices. However, the cross-correlation between domestic and foreign markets is highly complex. Hence, it is extremely difficult to explicitly express this cross-correlation with a dynamical equation. In this study, we develop stock return prediction models that can jointly consider international markets, using multimodal deep learning. Our contributions are three-fold: (1) we visualize the transfer information between South Korea and US stock markets by using scatter plots; (2) we incorporate the information into the stock prediction models with the help of multimodal deep learning; (3) we conclusively demonstrate that the early and intermediate fusion models achieve a significant performance boost in comparison with the late fusion and single modality models. Our study indicates that jointly considering international stock markets can improve the prediction accuracy and deep neural networks are highly effective for such tasks.", "link": "http://arxiv.org/abs/1903.06478v2"}, {"index": 658, "title": "Stylized facts of the Indian Stock Market", "abstract": "Historical daily data for eleven years of the fifty constituent stocks of the NIFTY index traded on the National Stock Exchange have been analyzed to check for the stylized facts in the Indian market. It is observed that while some stylized facts of other markets are also observed in Indian market, there are significant deviations in three main aspects, namely leverage, asymmetry and autocorrelation. Leverage and asymmetry are both reversed making this a more promising market to invest in. While significant autocorrelation observed in the returns points towards market inefficiency, the increased predictive power is better for investors.", "link": "http://dx.doi.org/10.1007/s10690-019-09275-3"}, {"index": 659, "title": "Financial Trading Model with Stock Bar Chart Image Time Series with Deep Convolutional Neural Networks", "abstract": "Even though computational intelligence techniques have been extensively utilized in financial trading systems, almost all developed models use the time series data for price prediction or identifying buy-sell points. However, in this study we decided to use 2-D stock bar chart images directly without introducing any additional time series associated with the underlying stock. We propose a novel algorithmic trading model CNN-BI (Convolutional Neural Network with Bar Images) using a 2-D Convolutional Neural Network. We generated 2-D images of sliding windows of 30-day bar charts for Dow 30 stocks and trained a deep Convolutional Neural Network (CNN) model for our algorithmic trading model. We tested our model separately between 2007-2012 and 2012-2017 for representing different market conditions. The results indicate that the model was able to outperform Buy and Hold strategy, especially in trendless or bear markets. Since this is a preliminary study and probably one of the first attempts using such an unconventional approach, there is always potential for improvement. Overall, the results are promising and the model might be integrated as part of an ensemble trading model combined with different strategies.", "link": "http://arxiv.org/abs/1903.04610v1"}, {"index": 660, "title": "Cross-shareholding networks and stock price synchronicity: Evidence from China", "abstract": "This paper investigates the effect of cross-shareholding on stock price synchronicity, as a measure of price informativeness, of the listed firms in the Chinese stock market. We gauge firms' levels of cross-shareholdings in terms of centrality in the cross-shareholding network. It is confirmed that it is through a noise-reducing process that cross-shareholding promotes price synchronicity and reduces price delay. More importantly, this effect on price informativeness is pronounced for large firms and in the periods of market downturns. Overall, our analyses provide insights into the relation between the ownership structure and price informativeness.", "link": "http://dx.doi.org/10.1002/ijfe.1828"}, {"index": 661, "title": "Artificial Counselor System for Stock Investment", "abstract": "This paper proposes a novel trading system which plays the role of an artificial counselor for stock investment. In this paper, the stock future prices (technical features) are predicted using Support Vector Regression. Thereafter, the predicted prices are used to recommend which portions of the budget an investor should invest in different existing stocks to have an optimum expected profit considering their level of risk tolerance. Two different methods are used for suggesting best portions, which are Markowitz portfolio theory and fuzzy investment counselor. The first approach is an optimization-based method which considers merely technical features, while the second approach is based on Fuzzy Logic taking into account both technical and fundamental features of the stock market. The experimental results on New York Stock Exchange (NYSE) show the effectiveness of the proposed system.", "link": "http://dx.doi.org/10.1609/aaai.v33i01.33019558"}, {"index": 662, "title": "Trade-offs between carbon stocks and biodiversity in European temperate forests", "abstract": "Policies to mitigate climate change and biodiversity loss often assume that protecting carbon-rich forests provides co-benefits in terms of biodiversity, due to the spatial congruence of carbon stocks and biodiversity at biogeographic scales. However, it remains unclear whether this holds at the scales relevant for management, with particularly large knowledge gaps for temperate forests and for taxa other than trees. We built a comprehensive dataset of Central European temperate forest structure and multi-taxonomic diversity (beetles, birds, bryophytes, fungi, lichens, and plants) across 352 plots. We used Boosted Regression Trees to assess the relationship between above-ground live carbon stocks and (a) taxon-specific richness, (b) a unified multidiversity index. We used Threshold Indicator Taxa ANalysis to explore individual species' responses to changing above-ground carbon stocks and to detect change-points in species composition along the carbon-stock gradient. Our results reveal an overall weak and highly variable relationship between richness and carbon stock at the stand scale, both for individual taxonomic groups and for multidiversity. Similarly, the proportion of win-win and trade-off species (i.e. species favored or disadvantaged by increasing carbon stock, respectively) varied substantially across taxa. Win-win species gradually replaced trade-off species with increasing carbon, without clear thresholds along the above-ground carbon gradient, suggesting that community-level surrogates (e.g. richness) might fail to detect critical changes in biodiversity. Collectively, our analyses highlight that leveraging co-benefits between carbon and biodiversity in temperate forest may require stand-scale management that prioritizes either biodiversity or carbon-in order to maximize co-benefits at broader scales. Importantly, this contrasts with tropical forests, where climate [...]", "link": "http://dx.doi.org/10.1111/gcb.14503"}, {"index": 663, "title": "Global Stock Market Prediction Based on Stock Chart Images Using Deep Q-Network", "abstract": "We applied Deep Q-Network with a Convolutional Neural Network function approximator, which takes stock chart images as input, for making global stock market predictions. Our model not only yields profit in the stock market of the country where it was trained but generally yields profit in global stock markets. We trained our model only in the US market and tested it in 31 different countries over 12 years. The portfolios constructed based on our model's output generally yield about 0.1 to 1.0 percent return per transaction prior to transaction costs in 31 countries. The results show that there are some patterns on stock chart image, that tend to predict the same future stock price movements across global stock markets. Moreover, the results show that future stock prices can be predicted even if the training and testing procedures are done in different countries. Training procedure could be done in relatively large and liquid markets (e.g., USA) and tested in small markets. This result demonstrates that artificial intelligence based stock price forecasting models can be used in relatively small markets (emerging countries) even though they do not have a sufficient amount of data for training.", "link": "http://dx.doi.org/10.1109/ACCESS.2019.2953542"}, {"index": 664, "title": "Using Deep Learning Neural Networks and Candlestick Chart Representation to Predict Stock Market", "abstract": "Stock market prediction is still a challenging problem because there are many factors effect to the stock market price such as company news and performance, industry performance, investor sentiment, social media sentiment and economic factors. This work explores the predictability in the stock market using Deep Convolutional Network and candlestick charts. The outcome is utilized to design a decision support framework that can be used by traders to provide suggested indications of future stock price direction. We perform this work using various types of neural networks like convolutional neural network, residual network and visual geometry group network. From stock market historical data, we converted it to candlestick charts. Finally, these candlestick charts will be feed as input for training a Convolutional Neural Network model. This Convolutional Neural Network model will help us to analyze the patterns inside the candlestick chart and predict the future movements of stock market. The effectiveness of our method is evaluated in stock market prediction with a promising results 92.2% and 92.1% accuracy for Taiwan and Indonesian stock market dataset respectively. The constructed model have been implemented as a web-based system freely available at http://140.138.155.216/deepcandle/ for predicting stock market using candlestick chart and deep learning neural networks.", "link": "http://arxiv.org/abs/1903.12258v1"}, {"index": 665, "title": "Working Paper: Improved Stock Price Forecasting Algorithm based on Feature-weighed Support Vector Regression by using Grey Correlation Degree", "abstract": "With the widespread engineering applications ranging from artificial intelligence and big data decision-making, originally a lot of tedious financial data processing, processing and analysis have become more and more convenient and effective. This paper aims to improve the accuracy of stock price forecasting. It improves the support vector machine regression algorithm by using grey correlation analysis (GCA) and improves the accuracy of stock prediction. This article first divides the factors affecting the stock price movement into behavioral factors and technical factors. The behavioral factors mainly include weather indicators and emotional indicators. The technical factors mainly include the daily closing data and the HS 300 Index, and then measure relation through the method of grey correlation analysis. The relationship between the stock price and its impact factors during the trading day, and this relationship is transformed into the characteristic weight of each impact factor. The weight of the impact factors of all trading days is weighted by the feature weight, and finally the support vector regression (SVR) is used. The forecast of the revised stock trading data was compared based on the forecast results of technical indicators (MSE, MAE, SCC, and DS) and unmodified transaction data, and it was found that the forecast results were significantly improved.", "link": "http://arxiv.org/abs/1902.08938v1"}, {"index": 666, "title": "Forecasting the Volatilities of Philippine Stock Exchange Composite Index Using the Generalized Autoregressive Conditional Heteroskedasticity Modeling", "abstract": "This study was conducted to find an appropriate statistical model to forecast the volatilities of PSEi using the model Generalized Autoregressive Conditional Heteroskedasticity (GARCH). Using the R software, the log returns of PSEi is modeled using various ARIMA models and with the presence of heteroskedasticity, the log returns was modeled using GARCH. Based on the analysis, GARCH models are the most appropriate to use for the log returns of PSEi. Among the selected GARCH models, GARCH (1,2) has the lowest AIC value and also has the highest LL value implying that GARCH (1,2) is the best model for the log returns of PSEi.", "link": "http://arxiv.org/abs/1904.00749v1"}, {"index": 667, "title": "Uncovering networks amongst stocks returns by studying nonlinear interactions in high frequency data of the Indian Stock Market using mutual information", "abstract": "In this paper, we explore the detection of clusters of stocks that are in synergy in the Indian Stock Market and understand their behaviour in different circumstances. We have based our study on high frequency data for the year 2014. This was a year when general elections were held in India, keeping this in mind our data set was divided into 3 subsets, pre-election period: Jan-Feb 2014; election period: Mar-May 2014 and :post-election period: Jun-Dec 2014. On analysing the spectrum of the correlation matrix, quite a few deviations were observed from RMT indicating a correlation across all the stocks. We then used mutual information to capture the non-linearity of the data and compared our results with widely used correlation technique using minimum spanning tree method. With a larger value of power law exponent {\\alpha}, corresponding to distribution of degrees in a network, the nonlinear method of mutual information succeeds in establishing effective network in comparison to the correlation method. Of the two prominent clusters detected by our analysis, one corresponds to the financial sector and another to the energy sector. The financial sector emerged as an isolated, standalone cluster, which remain unaffected even during the election periods.", "link": "http://arxiv.org/abs/1903.03407v1"}, {"index": 668, "title": "Designing an Optimal Portfolio for Iran's Stock Market with Genetic Algorithm using Neural Network Prediction of Risk and Return Stocks", "abstract": "Optimal capital allocation between different assets is an important financial problem, which is generally framed as the portfolio optimization problem. General models include the single-period and multi-period cases. The traditional Mean-Variance model introduced by Harry Markowitz has been the basis of many models used to solve the portfolio optimization problem. The overall goal is to achieve the highest return and lowest risk in portfolio optimization problems. In this paper, we will present an optimal portfolio based the Markowitz Mean-Variance-Skewness with weight constraints model for short-term investment opportunities in Iran's stock market. We will use a neural network based predictor to predict the stock returns and measure the risk of stocks based on the prediction errors in the neural network. We will perform a series of experiments on our portfolio optimization model with the real data from Iran's stock market indices including Bank, Insurance, Investment, Petroleum Products and Chemicals indices. Finally, 8 different portfolios with low, medium and high risks for different type of investors (risk-averse or risk taker) using genetic algorithm will be designed and analyzed.", "link": "http://arxiv.org/abs/1903.06632v1"}, {"index": 669, "title": "Quantitative evaluation of consecutive resilience cycles in stock market performance: A systems-oriented approach", "abstract": "Financial markets can be seen as complex systems that are constantly evolving and sensitive to external disturbance, such as systemic risks and economic instabilities. Analysis of resilient market performance, therefore, becomes useful for investors. From a systems perspective, this paper proposes a novel function-based resilience metric that considers the effect of two fault-tolerance thresholds: the Robustness Range (RR) and the Elasticity Threshold (ET). We examined the consecutive resilience cycles and their dynamics in the performance of two stock markets, NASDAQ and SSE. The proposed metric was also compared with three well-documented resilience models. The results showed that this new metric could satisfactorily quantify the time-varying resilience cycles in the multi-cycle volatile performance of stock markets while also being more feasible in comparative analysis. Furthermore, analysis of dynamics revealed that those consecutive resilience cycles in market performance were distributed non-linearly, following a power-law behavior in the upper tail. Finally, sensitivity tests demonstrated the large-value resilience cycles were relatively sensitive to changes in RR. In practice, RR could indicate investors' psychological capability to withstand downturns. It supports the observation that perception on the market's resilient responses may vary among investors. This study provides a new tool and valuable insight for researchers, practitioners, and investors when evaluating market performance.", "link": "http://dx.doi.org/10.1016/j.physa.2019.121794"}, {"index": 670, "title": "Explainable Text-Driven Neural Network for Stock Prediction", "abstract": "It has been shown that financial news leads to the fluctuation of stock prices. However, previous work on news-driven financial market prediction focused only on predicting stock price movement without providing an explanation. In this paper, we propose a dual-layer attention-based neural network to address this issue. In the initial stage, we introduce a knowledge-based method to adaptively extract relevant financial news. Then, we use input attention to pay more attention to the more influential news and concatenate the day embeddings with the output of the news representation. Finally, we use an output attention mechanism to allocate different weights to different days in terms of their contribution to stock price movement. Thorough empirical studies based upon historical prices of several individual stocks demonstrate the superiority of our proposed method in stock price prediction compared to state-of-the-art methods.", "link": "http://arxiv.org/abs/1902.04994v1"}, {"index": 671, "title": "Discovering Language of the Stocks", "abstract": "Stock prediction has always been attractive area for researchers and investors since the financial gains can be substantial. However, stock prediction can be a challenging task since stocks are influenced by a multitude of factors whose influence vary rapidly through time. This paper proposes a novel approach (Word2Vec) for stock trend prediction combining NLP and Japanese candlesticks. First, we create a simple language of Japanese candlesticks from the source OHLC data. Then, sentences of words are used to train the NLP Word2Vec model where training data classification also takes into account trading commissions. Finally, the model is used to predict trading actions. The proposed approach was compared to three trading models Buy & Hold, MA and MACD according to the yield achieved. We first evaluated Word2Vec on three shares of Apple, Microsoft and Coca-Cola where it outperformed the comparative models. Next we evaluated Word2Vec on stocks from Russell Top 50 Index where our Word2Vec method was also very successful in test phase and only fall behind the Buy & Hold method in validation phase. Word2Vec achieved positive results in all scenarios while the average yields of MA and MACD were still lower compared to Word2Vec.", "link": "http://dx.doi.org/10.3233/978-1-61499-941-6-243"}, {"index": 672, "title": "Q-Gaussian diffusion in stock markets", "abstract": "We analyze the Standard & Poor's 500 stock market index from the last 22 years. The probability density function of price returns exhibits two well-distinguished regimes with self-similar structure: the first one displays strong super-diffusion together with short-time correlations, and the second one corresponds to weak super-diffusion with weak time correlations. Both regimes are well-described by q-Gaussian distributions. The porous media equation is used to derive the governing equation for these regimes, and the Black-Scholes diffusion coefficient is explicitly obtained from the governing equation.", "link": "http://arxiv.org/abs/1902.10500v1"}, {"index": 673, "title": "Comprehensive abundance analysis of red giants in the open clusters Stock 2, NGC 2168, 6475, 6991 and 7762", "abstract": "We have analysed high-dispersion echelle spectra ($R = 60000$) of red giant members of five open clusters to derive abundances for many elements from Na to Eu. The [Fe/H] values are $-0.06\\pm0.03$ for Stock 2, $-0.11\\pm0.03$ for NGC 2168, $-0.01\\pm0.03$ for NGC 6475, $0.00\\pm0.03$ for NGC 6991 and $-0.07\\pm0.03$ for NGC 7662. Sodium is enriched in the giants relative to the abundance expected of main sequence stars of the same metallicity. This enrichment of [Na/Fe] by about $+0.25$ attributed to the first dredge-up is discussed in the light of theoretical predictions and recently published abundance determinations. Abundance ratios [El/Fe] for other elements are with very few exceptions equal to those of field giants and dwarfs, i.e., [El/Fe] $\\simeq 0.00$ for [Fe/H] $\\sim 0.0$. An exception is the overabundance of La, Ce, Nd and Sm in NGC 6991 but this is consistent with our previous demonstration that the abundances of these $s$-process products vary by about $\\pm0.2$ among clusters of the same [Fe/H], a variation found also among field giants and dwarfs.", "link": "http://dx.doi.org/10.1093/mnras/stz468"}, {"index": 674, "title": "High-performance stock index trading: making effective use of a deep LSTM neural network", "abstract": "We present a deep long short-term memory (LSTM)-based neural network for predicting asset prices, together with a successful trading strategy for generating profits based on the model's predictions. Our work is motivated by the fact that the effectiveness of any prediction model is inherently coupled to the trading strategy it is used with, and vise versa. This highlights the difficulty in developing models and strategies which are jointly optimal, but also points to avenues of investigation which are broader than prevailing approaches. Our LSTM model is structurally simple and generates predictions based on price observations over a modest number of past trading days. The model's architecture is tuned to promote profitability, as opposed to accuracy, under a strategy that does not trade simply based on whether the price is predicted to rise or fall, but rather takes advantage of the distribution of predicted returns, and the fact that a prediction's position within that distribution carries useful information about the expected profitability of a trade. The proposed model and trading strategy were tested on the S&P 500, Dow Jones Industrial Average (DJIA), NASDAQ and Russel 2000 stock indices, and achieved cumulative returns of 340%, 185%, 371% and 360%, respectively, over 2010-2018, far outperforming the benchmark buy-and-hold strategy as well as other recent efforts.", "link": "http://arxiv.org/abs/1902.03125v2"}, {"index": 675, "title": "Top performing stocks recommendation strategy for portfolio", "abstract": "Stock return forecasting is of utmost importance in the business world. This has been the favourite topic of research for many academicians since decades. Recently, regularization techniques have reported to tremendously increase the forecast accuracy of the simple regression model. Still, this model cannot incorporate the effect of things like a major natural disaster, large foreign influence, etc. in its prediction. Such things affect the whole stock market and are very unpredictable. Thus, it is more important to recommend top stocks rather than predicting exact stock returns. The present paper modifies the regression task to output value for each stock which is more suitable for ranking the stocks by expected returns. Two large datasets consisting of altogether 1205 companies listed at Indian exchanges were used for experimentation. Five different metrics were used for evaluating the different models. Results were also analysed subjectively through plots. The results showed the superiority of the proposed techniques.", "link": "http://arxiv.org/abs/1901.11013v3"}, {"index": 676, "title": "Tangled String for Multi-Scale Explanation of Contextual Shifts in Stock Market", "abstract": "The original research question here is given by marketers in general, i.e., how to explain the changes in the desired timescale of the market. Tangled String, a sequence visualization tool based on the metaphor where contexts in a sequence are compared to tangled pills in a string, is here extended and diverted to detecting stocks that trigger changes in the market and to explaining the scenario of contextual shifts in the market. Here, the sequential data on the stocks of top 10 weekly increase rates in the First Section of the Tokyo Stock Exchange for 12 years are visualized by Tangled String. The changing in the prices of stocks is a mixture of various timescales and can be explained in the time-scale set as desired by using TS. Also, it is found that the change points found by TS coincided by high precision with the real changes in each stock price. As TS has been created from the data-driven innovation platform called Innovators Marketplace on Data Jackets and is extended to satisfy data users, this paper is as evidence of the contribution of the market of data to data-driven innovations.", "link": "http://dx.doi.org/10.3390/info10030118"}, {"index": 677, "title": "A Study on Neural Network Architecture Applied to the Prediction of Brazilian Stock Returns", "abstract": "In this paper we present a statistical analysis about the characteristics that we intend to influence in the performance of the neural networks in terms of assertiveness in the prediction of Brazilian stock returns. We created a population of architectures for analysis and extracted the sample that had the best assertive performance. It was verified how the characteristics of this sample stand out and affect the neural networks. In addition, we make inferences about what kind of influence the different architectures have on the performance of neural networks. In the study, the prediction of the return of a Brazilian stock traded on the stock exchange of S\\~ao Paulo to measure the error committed by the different architectures of constructed neural networks. The results are promising and indicate that some aspects of the neural network architecture have a significant impact on the assertiveness of the model.", "link": "http://dx.doi.org/10.6084/m9.figshare.7644959"}, {"index": 678, "title": "Nonextensive triplets in stock market indices", "abstract": "Stock market indices are one of the most investigated complex systems in econophysics. Here we extend the existing literature on stock markets in connection with nonextensive statistical mechanics. We explore the nonextensivity of price volatilities for 34 major stock market indices between 2010 and 2019. We discover that stock markets follow nonextensive statistics regarding equilibrium, relaxation and sensitivity. We find nonextensive behavior in stock markets for developed countries, but not for developing countries. Distances between nonextensive triplets suggest that some stock markets might share similar nonextensive dynamics, while others are widely different. The current findings strongly indicate that the stock market represents a system whose physics is properly described by nonextensive statistical mechanics. Our results shed light on the complex nature of stock market indices, and establish another formal link with the nonextensive theory.", "link": "http://dx.doi.org/10.1016/j.physa.2019.03.093"}, {"index": 679, "title": "Optimal redeeming strategy of stock loans under drift uncertainty", "abstract": "In practice, one must recognize the inevitable incompleteness of information while making decisions. In this paper, we consider the optimal redeeming problem of stock loans under a state of incomplete information presented by the uncertainty in the (bull or bear) trends of the underlying stock. This is called drift uncertainty. Due to the unavoidable need for the estimation of trends while making decisions, the related Hamilton-Jacobi-Bellman (HJB) equation is of a degenerate parabolic type. Hence, it is very hard to obtain its regularity using the standard approach, making the problem different from the existing optimal redeeming problems without drift uncertainty. We present a thorough and delicate probabilistic and functional analysis to obtain the regularity of the value function and the optimal redeeming strategies. The optimal redeeming strategies of stock loans appear significantly different in the bull and bear trends.", "link": "http://dx.doi.org/10.1287/moor.2019.0995"}, {"index": 680, "title": "Sutte Indicator: an approach to predict the direction of stock market movements", "abstract": "The purpose of this research is to apply technical analysis of Sutte Indicator in stock trading which will assist in the investment decision making process i.e. buying or selling shares. This research takes data of \"A\" on the Indonesia Stock Exchange(IDX or BEI) 29 November 2006 until 20 September 2016 period. To see the performance of Sutte Indicator, other technical analysis are used as a comparison, Simple Moving Average (SMA) and Moving Average Convergence/Divergence (MACD). To see a comparison of the level of reliability prediction, the stock data were compared using the mean absolute deviation (MAD), mean of square error (MSE), and mean absolute percentage error (MAPE). The result of this research is that Sutte Indicator can be used as a reference in predicting stock movements, and if it is compared to other indicator methods (SMA and MACD) via MAD, MSE, and MAPE, the Sutte Indicator has a better level of reliability.", "link": "http://arxiv.org/abs/1903.11642v1"}, {"index": 681, "title": "The Arrival of News and Return Jumps in Stock Markets: A Nonparametric Approach", "abstract": "This paper introduces a non-parametric framework to statistically examine how news events, such as company or macroeconomic announcements, contribute to the pre- and post-event jump dynamics of stock prices under the intraday seasonality of the news and jumps. We demonstrate our framework, which has several advantages over the existing methods, by using data for i) the S&P 500 index ETF, SPY, with macroeconomic announcements and ii) Nasdaq Nordic Large-Cap stocks with scheduled and non-scheduled company announcements. We provide strong evidence that non-scheduled company announcements and some macroeconomic announcements contribute jumps that follow the releases and also some evidence for pre-jumps that precede the scheduled arrivals of public information, which may indicate non-gradual information leakage. Especially interim reports of Nordic large-cap companies are found containing important information to yield jumps in stock prices. Additionally, our results show that releases of unexpected information are not reacted to uniformly across Nasdaq Nordic markets, even if they are jointly operated and are based on the same exchange rules.", "link": "http://arxiv.org/abs/1901.02691v1"}, {"index": 682, "title": "Predicting the Stock Price of Frontier Markets Using Modified Black-Scholes Option Pricing Model and Machine Learning", "abstract": "The Black-Scholes Option pricing model (BSOPM) has long been in use for valuation of equity options to find the prices of stocks. In this work, using BSOPM, we have come up with a comparative analytical approach and numerical technique to find the price of call option and put option and considered these two prices as buying price and selling price of stocks of frontier markets so that we can predict the stock price (close price). Changes have been made to the model to find the parameters strike price and the time of expiration for calculating stock price of frontier markets. To verify the result obtained using modified BSOPM we have used machine learning approach using the software Rapidminer, where we have adopted different algorithms like the decision tree, ensemble learning method and neural network. It has been observed that, the prediction of close price using machine learning is very similar to the one obtained using BSOPM. Machine learning approach stands out to be a better predictor over BSOPM, because Black-Scholes-Merton equation includes risk and dividend parameter, which changes continuously. We have also numerically calculated volatility. As the prices of the stocks goes high due to overpricing, volatility increases at a tremendous rate and when volatility becomes very high market tends to fall, which can be observed and determined using our modified BSOPM. The proposed modified BSOPM has also been explained based on the analogy of Schrodinger equation (and heat equation) of quantum physics.", "link": "http://arxiv.org/abs/1812.10619v1"}, {"index": 683, "title": "Multimodal deep learning for short-term stock volatility prediction", "abstract": "Stock market volatility forecasting is a task relevant to assessing market risk. We investigate the interaction between news and prices for the one-day-ahead volatility prediction using state-of-the-art deep learning approaches. The proposed models are trained either end-to-end or using sentence encoders transfered from other tasks. We evaluate a broad range of stock market sectors, namely Consumer Staples, Energy, Utilities, Heathcare, and Financials. Our experimental results show that adding news improves the volatility forecasting as compared to the mainstream models that rely only on price data. In particular, our model outperforms the widely-recognized GARCH(1,1) model for all sectors in terms of coefficient of determination $R^2$, $MSE$ and $MAE$, achieving the best performance when training from both news and price data.", "link": "http://arxiv.org/abs/1812.10479v1"}, {"index": 684, "title": "Emergence of stylized facts during the opening of stock markets", "abstract": "Financial markets show a number of non-stationarities, ranging from volatility fluctuations over ever changing technical and regulatory market conditions to seasonalities. On the other hand, financial markets show various stylized facts which are remarkably stable. It is thus an intriguing question to find out how these stylized facts emerge. As a first example, we here investigate how the bid-ask-spread between best sell and best buy offer for stocks develops during the trading day. For rescaled and properly smoothed data we observe collapsing curves for many different NASDAQ stocks, with a slow power law decline of the spread during the whole trading day. This effect emerges robustly after a highly fluctuating opening period. Some so called large-tick stocks behave differently because of technical boundaries. Their spread closes to one tick shortly after the market opening. We use our findings for identifying the duration of the market opening which we find to vary largely from stock to stock.", "link": "http://arxiv.org/abs/1812.07369v1"}, {"index": 685, "title": "Predicting the Effects of News Sentiments on the Stock Market", "abstract": "Stock market forecasting is very important in the planning of business activities. Stock price prediction has attracted many researchers in multiple disciplines including computer science, statistics, economics, finance, and operations research. Recent studies have shown that the vast amount of online information in the public domain such as Wikipedia usage pattern, news stories from the mainstream media, and social media discussions can have an observable effect on investors opinions towards financial markets. The reliability of the computational models on stock market prediction is important as it is very sensitive to the economy and can directly lead to financial loss. In this paper, we retrieved, extracted, and analyzed the effects of news sentiments on the stock market. Our main contributions include the development of a sentiment analysis dictionary for the financial sector, the development of a dictionary-based sentiment analysis model, and the evaluation of the model for gauging the effects of news sentiments on stocks for the pharmaceutical market. Using only news sentiments, we achieved a directional accuracy of 70.59% in predicting the trends in short-term stock price movement.", "link": "http://dx.doi.org/10.1109/BigData.2018.8621884"}, {"index": 686, "title": "Fast Training Algorithms for Deep Convolutional Fuzzy Systems with Application to Stock Index Prediction", "abstract": "A deep convolutional fuzzy system (DCFS) on a high-dimensional input space is a multi-layer connection of many low-dimensional fuzzy systems, where the input variables to the low-dimensional fuzzy systems are selected through a moving window across the input spaces of the layers. To design the DCFS based on input-output data pairs, we propose a bottom-up layer-by-layer scheme. Specifically, by viewing each of the first-layer fuzzy systems as a weak estimator of the output based only on a very small portion of the input variables, we design these fuzzy systems using the WM Method. After the first-layer fuzzy systems are designed, we pass the data through the first layer to form a new data set and design the second-layer fuzzy systems based on this new data set in the same way as designing the first-layer fuzzy systems. Repeating this process layer-by-layer we design the whole DCFS. We also propose a DCFS with parameter sharing to save memory and computation. We apply the DCFS models to predict a synthetic chaotic plus random time-series and the real Hang Seng Index of the Hong Kong stock market.", "link": "http://arxiv.org/abs/1812.11226v2"}, {"index": 687, "title": "Quantum Brownian oscillator for the stock market", "abstract": "We pursue the quantum-mechanical challenge to the efficient market hypothesis for the stock market by employing the quantum Brownian motion model. We utilize the quantum Caldeira-Leggett master equation as a possible phenomenological model for the stock-market-prices fluctuations while introducing the external harmonic field for the Brownian particle. Two quantum regimes are of particular interest: the exact regime as well as the approximate regime of the pure decoherence (\"recoilless\") limit of the Caldeira-Leggett equation. By calculating the standard deviation and the kurtosis for the particle's position observable, we can detect deviations of the quantum-mechanical behavior from the classical counterpart, which bases the efficient market hypothesis. By varying the damping factor, temperature as well as the oscillator's frequency, we are able to provide interpretation of different economic scenarios and possible situations that are not normally recognized by the efficient market hypothesis. Hence we recognize the quantum Brownian oscillator as a possibly useful model for the realistic behavior of stock prices.", "link": "http://arxiv.org/abs/1901.10544v1"}, {"index": 688, "title": "Predicting future stock market structure by combining social and financial network information", "abstract": "We demonstrate that future market correlation structure can be predicted with high out-of-sample accuracy using a multiplex network approach that combines information from social media and financial data. Market structure is measured by quantifying the co-movement of asset prices returns, while social structure is measured as the co-movement of social media opinion on those same assets. Predictions are obtained with a simple model that uses link persistence and link formation by triadic closure across both financial and social media layers. Results demonstrate that the proposed model can predict future market structure with up to a 40\\% out-of-sample performance improvement compared to a benchmark model that assumes a time-invariant financial correlation structure. Social media information leads to improved models for all settings tested, particularly in the long-term prediction of financial market structure. Surprisingly, financial market structure exhibited higher predictability than social opinion structure.", "link": "http://dx.doi.org/10.1016/j.physa.2019.122343"}, {"index": 689, "title": "Stratified pooling games: an extension with optimized stock levels", "abstract": "We consider a natural extension of stratified pooling games, by allowing players to optimize on the stock level of the joint spare parts pool as well. It is known that such type of extension can break the core non-emptiness result for spare parts pooling games. However, we are able to show core non-emptiness for our game.", "link": "http://arxiv.org/abs/1811.08145v1"}, {"index": 690, "title": "Practical Deep Reinforcement Learning Approach for Stock Trading", "abstract": "Stock trading strategy plays a crucial role in investment companies. However, it is challenging to obtain optimal strategy in the complex and dynamic stock market. We explore the potential of deep reinforcement learning to optimize stock trading strategy and thus maximize investment return. 30 stocks are selected as our trading stocks and their daily prices are used as the training and trading market environment. We train a deep reinforcement learning agent and obtain an adaptive trading strategy. The agent's performance is evaluated and compared with Dow Jones Industrial Average and the traditional min-variance portfolio allocation strategy. The proposed deep reinforcement learning approach is shown to outperform the two baselines in terms of both the Sharpe ratio and cumulative returns.", "link": "http://arxiv.org/abs/1811.07522v3"}, {"index": 691, "title": "Leveraging Financial News for Stock Trend Prediction with Attention-Based Recurrent Neural Network", "abstract": "Stock market prediction is one of the most attractive research topic since the successful prediction on the market's future movement leads to significant profit. Traditional short term stock market predictions are usually based on the analysis of historical market data, such as stock prices, moving averages or daily returns. However, financial news also contains useful information on public companies and the market. Existing methods in finance literature exploit sentiment signal features, which are limited by not considering factors such as events and the news context. We address this issue by leveraging deep neural models to extract rich semantic features from news text. In particular, a Bidirectional-LSTM are used to encode the news text and capture the context information, self attention mechanism are applied to distribute attention on most relative words, news and days. In terms of predicting directional changes in both Standard & Poor's 500 index and individual companies stock price, we show that this technique is competitive with other state of the art approaches, demonstrating the effectiveness of recent NLP technology advances for computational finance.", "link": "http://arxiv.org/abs/1811.06173v1"}, {"index": 692, "title": "How does stock market volatility react to oil shocks?", "abstract": "We study the impact of oil price shocks on the U.S. stock market volatility. We jointly analyze three different structural oil market shocks (i.e., aggregate demand, oil supply, and oil-specific demand shocks) and stock market volatility using a structural vector autoregressive model. Identification is achieved by assuming that the price of crude oil reacts to stock market volatility only with delay. This implies that innovations to the price of crude oil are not strictly exogenous, but predetermined with respect to the stock market. We show that volatility responds significantly to oil price shocks caused by unexpected changes in aggregate and oil-specific demand, whereas the impact of supply-side shocks is negligible.", "link": "http://dx.doi.org/10.1017/S1365100516000353"}, {"index": 693, "title": "Using Stock Prices as Ground Truth in Sentiment Analysis to Generate Profitable Trading Signals", "abstract": "The increasing availability of \"big\" (large volume) social media data has motivated a great deal of research in applying sentiment analysis to predict the movement of prices within financial markets. Previous work in this field investigates how the true sentiment of text (i.e. positive or negative opinions) can be used for financial predictions, based on the assumption that sentiments expressed online are representative of the true market sentiment. Here we consider the converse idea, that using the stock price as the ground-truth in the system may be a better indication of sentiment. Tweets are labelled as Buy or Sell dependent on whether the stock price discussed rose or fell over the following hour, and from this, stock-specific dictionaries are built for individual companies. A Bayesian classifier is used to generate stock predictions, which are input to an automated trading algorithm. Placing 468 trades over a 1 month period yields a return rate of 5.18%, which annualises to approximately 83% per annum. This approach performs significantly better than random chance and outperforms two baseline sentiment analysis methods tested.", "link": "http://arxiv.org/abs/1811.02886v1"}, {"index": 694, "title": "Reframing the S\\&P500 Network of Stocks along the \\nth{21} Century", "abstract": "Since the beginning of the new millennium, stock markets went through every state from long-time troughs, trade suspensions to all-time highs. The literature on asset pricing hence assumes random processes to be underlying the movement of stock returns. Observed procyclicality and time-varying correlation of stock returns tried to give the apparently random behavior some sort of structure. However, common misperceptions about the co-movement of asset prices in the years preceding the \\emph{Great Recession} and the \\emph{Global Commodity Crisis}, is said to have even fueled the crisis' economic impact. Here we show how a varying macroeconomic environment influences stocks' clustering into communities. From a sample of 296 stocks of the S\\&P 500 index, distinct periods in between 2004 and 2011 are used to develop networks of stocks. The Minimal Spanning Tree analysis of those time-varying networks of stocks demonstrates that the crises of 2007-2008 and 2010-2011 drove the market to clustered community structures in both periods, helping to restore the stock market's ceased order of the pre-crises era. However, a comparison of the emergent clusters with the \\textit{General Industry Classification Standard} conveys the impression that industry sectors do not play a major role in that order.", "link": "http://dx.doi.org/10.1016/j.physa.2019.121062"}, {"index": 695, "title": "Diversifying portfolios of U.S. stocks with crude oil and natural gas: A regime-dependent optimization with several risk measures", "abstract": "Energy markets are strategic to governments and economic development. Several commodities compete as substitutable energy sources and energy diversifiers. Such competition reduces the energy vulnerability of countries as well as portfolios' risk exposure. Vulnerability results mainly from price trends and fluctuations, following supply and demand shocks. Such energy price uncertainty attracts many market participants in the energy commodity markets. First, energy producers and consumers hedge adverse price changes with energy derivatives. Second, financial market participants use commodities and commodity derivatives to diversify their conventional portfolios. For that reason, we consider the joint dependence between the United States (U.S.) natural gas, crude oil and stock markets. We use Gatfaoui's (2015) time varying multivariate copula analysis and related variance regimes. Such approach handles structural changes in asset prices. In this light, we draw implications for portfolio optimization, when investors diversify their stock portfolios with natural gas and crude oil assets. We minimize the portfolio's variance, semi-variance and tail risk, in the presence and the absence of constraints on the portfolio's expected return and/or U.S. stock investment. The return constraint reduces the performance of the optimal portfolio. Moreover, the regime-specific portfolio optimization helps implement an enhanced active management strategy over the whole sample period. Under a return constraint, the semi-variance optimal portfolio offers the best risk-return tradeoff, whereas the tail-risk optimal portfolio offers the best tradeoff in the absence of a return constraint.", "link": "http://arxiv.org/abs/1811.02382v1"}, {"index": 696, "title": "Forecasting of Jump Arrivals in Stock Prices: New Attention-based Network Architecture using Limit Order Book Data", "abstract": "The existing literature provides evidence that limit order book data can be used to predict short-term price movements in stock markets. This paper proposes a new neural network architecture for predicting return jump arrivals in equity markets with high-frequency limit order book data. This new architecture, based on Convolutional Long Short-Term Memory with Attention, is introduced to apply time series representation learning with memory and to focus the prediction attention on the most important features to improve performance. The data set consists of order book data on five liquid U.S. stocks. The use of the attention mechanism makes it possible to analyze the importance of the inclusion limit order book data and other input variables. By using this mechanism, we provide evidence that the use of limit order book data was found to improve the performance of the proposed model in jump prediction, either clearly or marginally, depending on the underlying stock. This suggests that path-dependence in limit order book markets is a stock specific feature. Moreover, we find that the proposed approach with an attention mechanism outperforms the multi-layer perceptron network as well as the convolutional neural network and Long Short-Term memory model.", "link": "http://arxiv.org/abs/1810.10845v1"}, {"index": 697, "title": "CNNPred: CNN-based stock market prediction using several data sources", "abstract": "Feature extraction from financial data is one of the most important problems in market prediction domain for which many approaches have been suggested. Among other modern tools, convolutional neural networks (CNN) have recently been applied for automatic feature selection and market prediction. However, in experiments reported so far, less attention has been paid to the correlation among different markets as a possible source of information for extracting features. In this paper, we suggest a CNN-based framework with specially designed CNNs, that can be applied on a collection of data from a variety of sources, including different markets, in order to extract features for predicting the future of those markets. The suggested framework has been applied for predicting the next day's direction of movement for the indices of S&P 500, NASDAQ, DJI, NYSE, and RUSSELL markets based on various sets of initial features. The evaluations show a significant improvement in prediction's performance compared to the state of the art baseline algorithms.", "link": "http://arxiv.org/abs/1810.08923v1"}, {"index": 698, "title": "Enhancing Stock Movement Prediction with Adversarial Training", "abstract": "This paper contributes a new machine learning solution for stock movement prediction, which aims to predict whether the price of a stock will be up or down in the near future. The key novelty is that we propose to employ adversarial training to improve the generalization of a neural network prediction model. The rationality of adversarial training here is that the input features to stock prediction are typically based on stock price, which is essentially a stochastic variable and continuously changed with time by nature. As such, normal training with static price-based features (e.g. the close price) can easily overfit the data, being insufficient to obtain reliable models. To address this problem, we propose to add perturbations to simulate the stochasticity of price variable, and train the model to work well under small yet intentional perturbations. Extensive experiments on two real-world stock data show that our method outperforms the state-of-the-art solution with 3.11% relative improvements on average w.r.t. accuracy, validating the usefulness of adversarial training for stock prediction task.", "link": "http://arxiv.org/abs/1810.09936v2"}, {"index": 699, "title": "Temporal Relational Ranking for Stock Prediction", "abstract": "Stock prediction aims to predict the future trends of a stock in order to help investors to make good investment decisions. Traditional solutions for stock prediction are based on time-series models. With the recent success of deep neural networks in modeling sequential data, deep learning has become a promising choice for stock prediction. However, most existing deep learning solutions are not optimized towards the target of investment, i.e., selecting the best stock with the highest expected revenue. Specifically, they typically formulate stock prediction as a classification (to predict stock trend) or a regression problem (to predict stock price). More importantly, they largely treat the stocks as independent of each other. The valuable signal in the rich relations between stocks (or companies), such as two stocks are in the same sector and two companies have a supplier-customer relation, is not considered. In this work, we contribute a new deep learning solution, named Relational Stock Ranking (RSR), for stock prediction. Our RSR method advances existing solutions in two major aspects: 1) tailoring the deep learning models for stock ranking, and 2) capturing the stock relations in a time-sensitive manner. The key novelty of our work is the proposal of a new component in neural network modeling, named Temporal Graph Convolution, which jointly models the temporal evolution and relation network of stocks. To validate our method, we perform back-testing on the historical data of two stock markets, NYSE and NASDAQ. Extensive experiments demonstrate the superiority of our RSR method. It outperforms state-of-the-art stock prediction solutions achieving an average return ratio of 98% and 71% on NYSE and NASDAQ, respectively.", "link": "http://dx.doi.org/10.1145/3309547"}, {"index": 700, "title": "Tail probabilities for short-term returns on stocks", "abstract": "We consider the tail probabilities of stock returns for a general class of stochastic volatility models. In these models, the stochastic differential equation for volatility is autonomous, time-homogeneous and dependent on only a finite number of dimensional parameters. Three bounds on the high-volatility limits of the drift and diffusion coefficients of volatility ensure that volatility is mean-reverting, has long memory and is as volatile as the stock price. Dimensional analysis then provides leading-order approximations to the drift and diffusion coefficients of volatility for the high-volatility limit. Thereby, using the Kolmogorov forward equation for the transition probability of volatility, we find that the tail probability for short-term returns falls off like an inverse cubic. Our analysis then provides a possible explanation for the inverse cubic fall off that Gopikrishnan et al. (1998) report for returns over 5-120 minutes intervals. We find, moreover, that the tail probability scales like the length of the interval, over which the return is measured, to the power 3/2. There do not seem to be any empirical results in the literature with which to compare this last prediction.", "link": "http://dx.doi.org/10.13140/RG.2.2.18816.28165"}, {"index": 701, "title": "BSE: A Minimal Simulation of a Limit-Order-Book Stock Exchange", "abstract": "This paper describes the design, implementation, and successful use of the Bristol Stock Exchange (BSE), a novel minimal simulation of a centralised financial market, based on a Limit Order Book (LOB) such as is common in major stock exchanges. Construction of BSE was motivated by the fact that most of the world's major financial markets have automated, with trading activity that previously was the responsibility of human traders now being performed by high-speed autonomous automated trading systems. Research aimed at understanding the dynamics of this new style of financial market is hampered by the fact that no operational real-world exchange is ever likely to allow experimental probing of that market while it is open and running live, forcing researchers to work primarily from time-series of past trading data. Similarly, university-level education of the engineers who can create next-generation automated trading systems requires that they have hands-on learning experience in a sufficiently realistic teaching environment. BSE as described here addresses both those needs: it has been successfully used for teaching and research in a leading UK university since 2012, and the BSE program code is freely available as open-source on GitHuB.", "link": "http://arxiv.org/abs/1809.06027v1"}, {"index": 702, "title": "Visual Attention Model for Cross-sectional Stock Return Prediction and End-to-End Multimodal Market Representation Learning", "abstract": "Technical and fundamental analysis are traditional tools used to analyze individual stocks; however, the finance literature has shown that the price movement of each individual stock correlates heavily with other stocks, especially those within the same sector. In this paper we propose a general purpose market representation that incorporates fundamental and technical indicators and relationships between individual stocks. We treat the daily stock market as a \"market image\" where rows (grouped by market sector) represent individual stocks and columns represent indicators. We apply a convolutional neural network over this market image to build market features in a hierarchical way. We use a recurrent neural network, with an attention mechanism over the market feature maps, to model temporal dynamics in the market. We show that our proposed model outperforms strong baselines in both short-term and long-term stock return prediction tasks. We also show another use for our market image: to construct concise and dense market embeddings suitable for downstream prediction tasks.", "link": "http://arxiv.org/abs/1809.03684v2"}, {"index": 703, "title": "A model for stocks dynamics based on a non-Gaussian path integral", "abstract": "We introduce a model for the dynamics of stock prices based on a non quadratic path integral. The model is a generalization of Ilinski's path integral model, more precisely we choose a different action, which can be tuned to different time scales. The result is a model with a very small number of parameters that provides very good fits of some stock prices and indices fluctuations.", "link": "http://dx.doi.org/10.1016/j.physa.2018.11.044"}, {"index": 704, "title": "Enhancing Stock Market Prediction with Extended Coupled Hidden Markov Model over Multi-Sourced Data", "abstract": "Traditional stock market prediction methods commonly only utilize the historical trading data, ignoring the fact that stock market fluctuations can be impacted by various other information sources such as stock related events. Although some recent works propose event-driven prediction approaches by considering the event data, how to leverage the joint impacts of multiple data sources still remains an open research problem. In this work, we study how to explore multiple data sources to improve the performance of the stock prediction. We introduce an Extended Coupled Hidden Markov Model incorporating the news events with the historical trading data. To address the data sparsity issue of news events for each single stock, we further study the fluctuation correlations between the stocks and incorporate the correlations into the model to facilitate the prediction task. Evaluations on China A-share market data in 2016 show the superior performance of our model against previous methods.", "link": "http://arxiv.org/abs/1809.00306v1"}, {"index": 705, "title": "The financial value of knowing the distribution of stock prices in discrete market models", "abstract": "An explicit formula is derived for the value of weak information in a discrete time model that works for a wide range of utility functions including the logarithmic and power utility. We assume a complete market with a finite number of assets and a finite number of possible outcomes. Explicit calculations are performed for a binomial model with two assets. The case of trinomial models is also discussed.", "link": "http://dx.doi.org/10.2140/involve.2019.12.883"}, {"index": 706, "title": "Stock Price Correlation Coefficient Prediction with ARIMA-LSTM Hybrid Model", "abstract": "Predicting the price correlation of two assets for future time periods is important in portfolio optimization. We apply LSTM recurrent neural networks (RNN) in predicting the stock price correlation coefficient of two individual stocks. RNNs are competent in understanding temporal dependencies. The use of LSTM cells further enhances its long term predictive properties. To encompass both linearity and nonlinearity in the model, we adopt the ARIMA model as well. The ARIMA model filters linear tendencies in the data and passes on the residual value to the LSTM model. The ARIMA LSTM hybrid model is tested against other traditional predictive financial models such as the full historical model, constant correlation model, single index model and the multi group model. In our empirical study, the predictive ability of the ARIMA-LSTM model turned out superior to all other financial models by a significant scale. Our work implies that it is worth considering the ARIMA LSTM model to forecast correlation coefficient for portfolio optimization.", "link": "http://arxiv.org/abs/1808.01560v5"}, {"index": 707, "title": "Stock Chart Pattern recognition with Deep Learning", "abstract": "This study evaluates the performances of CNN and LSTM for recognizing common charts patterns in a stock historical data. It presents two common patterns, the method used to build the training set, the neural networks architectures and the accuracies obtained.", "link": "http://arxiv.org/abs/1808.00418v1"}, {"index": 708, "title": "Rebalancing Frequency Considerations for Kelly-Optimal Stock Portfolios in a Control-Theoretic Framework", "abstract": "In this paper, motivated by the celebrated work of Kelly, we consider the problem of portfolio weight selection to maximize expected logarithmic growth. Going beyond existing literature, our focal point here is the rebalancing frequency which we include as an additional parameter in our analysis. The problem is first set in a control-theoretic framework, and then, the main question we address is as follows: In the absence of transaction costs, does high-frequency trading always lead to the best performance? Related to this is our prior work on betting, also in the Kelly context, which examines the impact of making a wager and letting it ride. Our results on betting frequency can be interpreted in the context of weight selection for a two-asset portfolio consisting of one risky asset and one riskless asset. With regard to the question above, our prior results indicate that it is often the case that there are no performance benefits associated with high-frequency trading. In the present paper, we generalize the analysis to portfolios with multiple risky assets. We show that if there is an asset satisfying a new condition which we call dominance, then an optimal portfolio consists of this asset alone; i.e., the trader has \"all eggs in one basket\" and performance becomes a constant function of rebalancing frequency. Said another way, the problem of rebalancing is rendered moot. The paper also includes simulations which address practical considerations associated with real stock prices and the dominant asset condition.", "link": "http://dx.doi.org/10.1109/CDC.2018.8619189"}, {"index": 709, "title": "Strategic behaviour and indicative price diffusion in Paris Stock Exchange auctions", "abstract": "We report statistical regularities of the opening and closing auctions of French equities, focusing on the diffusive properties of the indicative auction price. Two mechanisms are at play as the auction end time nears: the typical price change magnitude decreases, favoring underdiffusion, while the rate of these events increases, potentially leading to overdiffusion. A third mechanism, caused by the strategic behavior of traders, is needed to produce nearly diffusive prices: waiting to submit buy orders until sell orders have decreased the indicative price and vice-versa.", "link": "http://arxiv.org/abs/1807.00573v1"}, {"index": 710, "title": "Mining Illegal Insider Trading of Stocks: A Proactive Approach", "abstract": "Illegal insider trading of stocks is based on releasing non-public information (e.g., new product launch, quarterly financial report, acquisition or merger plan) before the information is made public. Detecting illegal insider trading is difficult due to the complex, nonlinear, and non-stationary nature of the stock market. In this work, we present an approach that detects and predicts illegal insider trading proactively from large heterogeneous sources of structured and unstructured data using a deep-learning based approach combined with discrete signal processing on the time series data. In addition, we use a tree-based approach that visualizes events and actions to aid analysts in their understanding of large amounts of unstructured data. Using existing data, we have discovered that our approach has a good success rate in detecting illegal insider trading patterns.", "link": "http://dx.doi.org/10.1109/BigData.2018.8622303"}, {"index": 711, "title": "Long-term stock index forecasting based on text mining of regulatory disclosures", "abstract": "Share valuations are known to adjust to new information entering the market, such as regulatory disclosures. We study whether the language of such news items can improve short-term and especially long-term (24 months) forecasts of stock indices. For this purpose, this work utilizes predictive models suited to high-dimensional data and specifically compares techniques for data-driven and knowledge-driven dimensionality reduction in order to avoid overfitting. Our experiments, based on 75,927 ad hoc announcements from 1996-2016, reveal the following results: in the long run, text-based models succeed in reducing forecast errors below baseline predictions from historic lags at a statistically significant level. Our research provides implications to business applications of decision-support in financial markets, especially given the growing prevalence of index ETFs (exchange traded funds).", "link": "http://arxiv.org/abs/1806.09866v1"}, {"index": 712, "title": "Model predictive control of indoor microclimate: existing building stock comfort improvement", "abstract": "Home retrofitting provides a means to improve the basic energy and comfort characteristics of a building stock, which cannot be renewed because of prohibitive costs. We analyze how model predictive control (MPC) applied to indoor microclimate control can provide energy-efficient solutions to the problem of occupants' comfort in a variety of situations principally imposed by external weather and room occupancy. For this purpose we define an objective function for the energy consumption, and we consider two illustrative cases: one building designed and built in recent times with modern HVAC equipment, and one designed and built several decades ago with poor thermal characteristics and no dedicated ventilation system. Our model includes various physical effects such as air infiltration and indoor thermal \"inertia mass\" (inner walls, floor, ceiling, and furniture), and also accounts for the impact of human presence essentially as heat and CO$_2$ sources. The influence on the numerical results of forecast horizons and of uncertainties due to inaccuracies in the weather and room occupancy forecasts, are analyzed. As we solve non-convex optimization problems using a linear and a nonlinear optimizer, full MPC performance is compared to both linearized MPC and a standard on/off controller. The main advantage of MPC is its ability to provide satisfactory solutions for microclimate control at the least possible energy cost for both modern and old buildings. As old buildings are usually not properly ventilated, we see in light of our simulation results, that a supply ventilation system installation provides a solution for significant air quality improvement.", "link": "http://dx.doi.org/10.1016/j.enconman.2018.10.046"}, {"index": 713, "title": "Multifractal characteristics and return predictability in the Chinese stock markets", "abstract": "By adopting Multifractal detrended fluctuation (MF-DFA) analysis methods, the multifractal nature is revealed in the high-frequency data of two typical indexes, the Shanghai Stock Exchange Composite 180 Index (SH180) and the Shenzhen Stock Exchange Composite Index (SZCI). The characteristics of the corresponding multifractal spectra are defined as a measurement of market volatility. It is found that there is a statistically significant relationship between the stock index returns and the spectral characteristics, which can be applied to forecast the future market return. The in-sample and out-of-sample tests on the return predictability of multifractal characteristics indicate the spectral width $\\Delta {\\alpha}$ is a significant and positive excess return predictor. Our results shed new lights on the application of multifractal nature in asset pricing.", "link": "http://arxiv.org/abs/1806.07604v1"}, {"index": 714, "title": "Generalized framework for applying the Kelly criterion to stock markets", "abstract": "We develop a general framework for applying the Kelly criterion to stock markets. By supplying an arbitrary probability distribution modeling the future price movement of a set of stocks, the Kelly fraction for investing each stock can be calculated by inverting a matrix involving only first and second moments. The framework works for one or a portfolio of stocks and the Kelly fractions can be efficiently calculated. For a simple model of geometric Brownian motion of a single stock we show that our calculated Kelly fraction agrees with existing results. We demonstrate that the Kelly fractions can be calculated easily for other types of probabilities such as the Gaussian distribution and correlated multivariate assets.", "link": "http://dx.doi.org/10.1142/S0219024918500334"}, {"index": 715, "title": "Weak Correlations of Stocks Future Returns", "abstract": "We analyze correlations among stock returns via a series of widely adopted parameters which we refer to as explanatory variables. We subsequently exploit the results to propose a long only quantitative adaptive technique to construct a profitable portfolio of assets which exhibits minor drawdowns and higher recoveries than both an equally weighted and an efficient frontier portfolio.", "link": "http://arxiv.org/abs/1806.05160v2"}, {"index": 716, "title": "State and Network Structures of Stock Markets around the Global Financial Crisis", "abstract": "We consider the effects of the 2008 global financial crisis on the global stock market before, during, and after the crisis. We generate complex networks from a cross-correlation matrix such as the threshold network (TN) and the minimal spanning tree (MST). In the threshold network, we assign a threshold value by using the mean and standard deviation of cross-correlation coefficients. When the threshold is equal to the mean of these coefficients, we observe a giant cluster composed of three economic zones in all three periods. We find that during the crisis, the countries in the Asian zone were weakly connected and those in the American zone were tightly linked to the countries in the European zone. At a large threshold, the three economic zones were fragmented. The European countries connected tightly, but the Asian countries bound weakly. The MST constructed from the distance matrix. In the MST, France remained a hub node in all three periods. The size of the MST shrank slightly during the crisis. We observe a scaling relation between the network distance of nodes from the central hub (France) and the geometrical distance. We observe the topological change of the financial network structure during the global financial crisis. The TN and MST are complementary roles to understand the connecting structure of financial complex networks. The TN reveals to observe the clustering effects and robustness of the cluster during the financial crisis. The MST shows the central hub and connecting node among the economic zones.", "link": "http://dx.doi.org/10.1007/s10614-017-9672-x"}, {"index": 717, "title": "Asymmetric response to PMI announcements in China's stock returns", "abstract": "Considered an important macroeconomic indicator, the Purchasing Managers' Index (PMI) on Manufacturing generally assumes that PMI announcements will produce an impact on stock markets. International experience suggests that stock markets react to negative PMI news. In this research, we empirically investigate the stock market reaction towards PMI in China. The asymmetric effects of PMI announcements on the stock market are observed: no market reaction is generated towards negative PMI announcements, while a positive reaction is generally generated for positive PMI news. We further find that the positive reaction towards the positive PMI news occurs 1 day before the announcement and lasts for nearly 3 days, and the positive reaction is observed in the context of expanding economic conditions. By contrast, the negative reaction towards negative PMI news is prevalent during downward economic conditions for stocks with low market value, low institutional shareholding ratios or high price earnings. Our study implies that China's stock market favors risk to a certain extent given the vast number of individual investors in the country, and there may exist information leakage in the market.", "link": "http://arxiv.org/abs/1806.04347v1"}, {"index": 718, "title": "A Machine Learning Framework for Stock Selection", "abstract": "This paper demonstrates how to apply machine learning algorithms to distinguish good stocks from the bad stocks. To this end, we construct 244 technical and fundamental features to characterize each stock, and label stocks according to their ranking with respect to the return-to-volatility ratio. Algorithms ranging from traditional statistical learning methods to recently popular deep learning method, e.g. Logistic Regression (LR), Random Forest (RF), Deep Neural Network (DNN), and the Stacking, are trained to solve the classification task. Genetic Algorithm (GA) is also used to implement feature selection. The effectiveness of the stock selection strategy is validated in Chinese stock market in both statistical and practical aspects, showing that: 1) Stacking outperforms other models reaching an AUC score of 0.972; 2) Genetic Algorithm picks a subset of 114 features and the prediction performances of all models remain almost unchanged after the selection procedure, which suggests some features are indeed redundant; 3) LR and DNN are radical models; RF is risk-neutral model; Stacking is somewhere between DNN and RF. 4) The portfolios constructed by our models outperform market average in back tests.", "link": "http://arxiv.org/abs/1806.01743v2"}, {"index": 719, "title": "The Stock Market Has Grown Unstable Since February 2018", "abstract": "On the fifth of February, 2018, the Dow Jones Industrial Average dropped 1,175.21 points, the largest single-day fall in history in raw point terms. This followed a 666-point loss on the second, and another drop of over a thousand points occurred three days later. It is natural to ask whether these events indicate a transition to a new regime of market behavior, particularly given the dramatic fluctuations --- both gains and losses --- in the weeks since. To illuminate this matter, we can apply a model grounded in the science of complex systems, a model that demonstrated considerable success at unraveling the stock-market dynamics from the 1980s through the 2000s. By using large-scale comovement of stock prices as an early indicator of unhealthy market dynamics, this work found that abrupt drops in a certain parameter $U$ provide an early warning of single-day panics and economic crises. Decreases in $U$ indicate regimes of \"high co-movement\", a market behavior that is not the same as volatility, though market volatility can be a component of co-movement. Applying the same analysis to stock-price data from the beginning of 2016 until now, we find that the $U$ value for the period since 5 February is significantly lower than for the period before. This decrease entered the \"danger zone\" in the last week of May, 2018.", "link": "http://arxiv.org/abs/1806.00529v1"}, {"index": 720, "title": "Comparing Alternatives to Measure the Impact of DDoS Attack Announcements on Target Stock Prices", "abstract": "The attack intensity of distributed denial of service (DDoS) attacks is increasing every year. Botnets based on internet of things (IOT) devices are now being used to conduct DDoS attacks. The estimation of direct and indirect economic damages caused by these attacks is a complex problem. One of the indirect damage of a DDoS attack can be on the market value of the victim firm. In this article we analyze the impact of 45 different DDoS attack announcements on victim's stock prices. We find that previous studies have a mixed conclusion on the impact of DDoS attack announcements on the victim's stock price. Hence, in this article we evaluate this impact using three different approaches and compare the results. In the first approach, we use the assume the cumulative abnormal returns to be normally distributed and test the hypothesis that a DDoS attack announcement has no impact on the victim's stock price. In the latter two methods, we do not assume a distribution and use the empirical distribution of cumulative abnormal returns to test the hypothesis. We find that the assumption of cumulative abnormal returns being normally distributed leads to overestimation/underestimation of the impact. Finally, we analyze the impact of DDoS attack announcement on victim's stock price in each of the 45 cases and present our results.", "link": "http://dx.doi.org/10.22667/JOWUA.2017.12.31.001"}, {"index": 721, "title": "Neural networks for stock price prediction", "abstract": "Due to the extremely volatile nature of financial markets, it is commonly accepted that stock price prediction is a task full of challenge. However in order to make profits or understand the essence of equity market, numerous market participants or researchers try to forecast stock price using various statistical, econometric or even neural network models. In this work, we survey and compare the predictive power of five neural network models, namely, back propagation (BP) neural network, radial basis function (RBF) neural network, general regression neural network (GRNN), support vector machine regression (SVMR), least squares support vector machine regresssion (LS-SVMR). We apply the five models to make price prediction of three individual stocks, namely, Bank of China, Vanke A and Kweichou Moutai. Adopting mean square error and average absolute percentage error as criteria, we find BP neural network consistently and robustly outperforms the other four models.", "link": "http://arxiv.org/abs/1805.11317v1"}, {"index": 722, "title": "Dynamic Advisor-Based Ensemble (dynABE): Case study in stock trend prediction of critical metal companies", "abstract": "Stock trend prediction is a challenging task due to the market's noise, and machine learning techniques have recently been successful in coping with this challenge. In this research, we create a novel framework for stock prediction, Dynamic Advisor-Based Ensemble (dynABE). dynABE explores domain-specific areas based on the companies of interest, diversifies the feature set by creating different \"advisors\" that each handles a different area, follows an effective model ensemble procedure for each advisor, and combines the advisors together in a second-level ensemble through an online update strategy we developed. dynABE is able to adapt to price pattern changes of the market during the active trading period robustly, without needing to retrain the entire model. We test dynABE on three cobalt-related companies, and it achieves the best-case misclassification error of 31.12% and an annualized absolute return of 359.55% with zero maximum drawdown. dynABE also consistently outperforms the baseline models of support vector machine, neural network, and random forest in all case studies.", "link": "http://dx.doi.org/10.1371/journal.pone.0212487"}, {"index": 723, "title": "A Tensor-Based Sub-Mode Coordinate Algorithm for Stock Prediction", "abstract": "The investment on the stock market is prone to be affected by the Internet. For the purpose of improving the prediction accuracy, we propose a multi-task stock prediction model that not only considers the stock correlations but also supports multi-source data fusion. Our proposed model first utilizes tensor to integrate the multi-sourced data, including financial Web news, investors' sentiments extracted from the social network and some quantitative data on stocks. In this way, the intrinsic relationships among different information sources can be captured, and meanwhile, multi-sourced information can be complemented to solve the data sparsity problem. Secondly, we propose an improved sub-mode coordinate algorithm (SMC). SMC is based on the stock similarity, aiming to reduce the variance of their subspace in each dimension produced by the tensor decomposition. The algorithm is able to improve the quality of the input features, and thus improves the prediction accuracy. And the paper utilizes the Long Short-Term Memory (LSTM) neural network model to predict the stock fluctuation trends. Finally, the experiments on 78 A-share stocks in CSI 100 and thirteen popular HK stocks in the year 2015 and 2016 are conducted. The results demonstrate the improvement on the prediction accuracy and the effectiveness of the proposed model.", "link": "http://arxiv.org/abs/1805.07979v1"}, {"index": 724, "title": "Aggregating multiple types of complex data in stock market prediction: A model-independent framework", "abstract": "The increasing richness in volume, and especially types of data in the financial domain provides unprecedented opportunities to understand the stock market more comprehensively and makes the price prediction more accurate than before. However, they also bring challenges to classic statistic approaches since those models might be constrained to a certain type of data. Aiming at aggregating differently sourced information and offering type-free capability to existing models, a framework for predicting stock market of scenarios with mixed data, including scalar data, compositional data (pie-like) and functional data (curve-like), is established. The presented framework is model-independent, as it serves like an interface to multiple types of data and can be combined with various prediction models. And it is proved to be effective through numerical simulations. Regarding to price prediction, we incorporate the trading volume (scalar data), intraday return series (functional data), and investors' emotions from social media (compositional data) through the framework to competently forecast whether the market goes up or down at opening in the next day. The strong explanatory power of the framework is further demonstrated. Specifically, it is found that the intraday returns impact the following opening prices differently between bearish market and bullish market. And it is not at the beginning of the bearish market but the subsequent period in which the investors' \"fear\" comes to be indicative. The framework would help extend existing prediction models easily to scenarios with multiple types of data and shed light on a more systemic understanding of the stock market.", "link": "http://arxiv.org/abs/1805.05617v1"}, {"index": 725, "title": "Effects of a Price limit Change on Market Stability at the Intraday Horizon in the Korean Stock Market", "abstract": "This paper investigates the effects of a price limit change on the volatility of the Korean stock market's (KRX) intraday stock price process. Based on the most recent transaction data from the KRX, which experienced a change in the price limit on June 15, 2015, we examine the change in realized variance after the price limit change to investigate the overall effects of the change on the intraday market volatility. We then analyze the effects in more detail by applying the discrete Fourier transform (DFT) to the data set. We find evidence that the market becomes more volatile in the intraday horizon because of the increase in the amplitudes of the low-frequency components of the price processes after the price limit change. Therefore, liquidity providers are in a worse situation than they were prior to the change.", "link": "http://arxiv.org/abs/1805.04728v1"}, {"index": 726, "title": "Analysing The Impact Of A DDoS Attack Announcement On Victim Stock Prices", "abstract": "DDoS attacks are increasingly used by `hackers' and `hacktivists' for various purposes. A number of on-line tools are available to launch an attack of significant intensity. These attacks lead to a variety of losses at the victim's end. We analyse the impact of Distributed Denial-of-Service (DDoS) attack announcements over a period of 5 years on the stock prices of the victim firms. We propose a method for event studies that does not assume the cumulative abnormal returns to be normally distributed, instead we use the empirical distribution for testing purposes. In most cases we find no significant impact on the stock returns but in cases where a DDoS attack creates an interruption in the services provided to the customer, we find a significant negative impact.", "link": "http://dx.doi.org/10.1109/PDP.2017.82"}, {"index": 727, "title": "Quantifying macroeconomic expectations in stock markets using Google Trends", "abstract": "Among other macroeconomic indicators, the monthly release of U.S. unemployment rate figures in the Employment Situation report by the U.S. Bureau of Labour Statistics gets a lot of media attention and strongly affects the stock markets. I investigate whether a profitable investment strategy can be constructed by predicting the likely changes in U.S. unemployment before the official news release using Google query volumes for related search terms. I find that massive new data sources of human interaction with the Internet not only improves U.S. unemployment rate predictability, but can also enhance market timing of trading strategies when considered jointly with macroeconomic data. My results illustrate the potential of combining extensive behavioural data sets with economic data to anticipate investor expectations and stock market moves.", "link": "http://arxiv.org/abs/1805.00268v1"}, {"index": 728, "title": "Nonlinearity in stock networks", "abstract": "Stock networks, constructed from stock price time series, are a well-established tool for the characterization of complex behavior in stock markets. Following Mantegna's seminal paper, the linear Pearson's correlation coefficient between pairs of stocks has been the usual way to determine network edges. Recently, possible effects of nonlinearity on the graph-theoretical properties of such networks have been demonstrated when using nonlinear measures such as mutual information instead of linear correlation. In this paper, we quantitatively characterize the nonlinearity in stock time series and the effect it has on stock network properties. This is achieved by a systematic multi-step approach that allows us to quantify the nonlinearity of coupling; correct its effects wherever it is caused by simple univariate non-Gaussianity; potentially localize in space and time any remaining strong sources of this nonlinearity; and, finally, study the effect nonlinearity has on global network properties. By applying this multi-step approach to stocks included in three prominent indices (NYSE100, FTSE100 and SP500), we establish that the apparent nonlinearity that has been observed is largely due to univariate non-Gaussianity. Furthermore, strong nonstationarity in a few specific stocks may play a role. In particular, the sharp decrease in some stocks during the global financial crisis of 2008 gives rise to apparent nonlinear dependencies among stocks.", "link": "http://arxiv.org/abs/1804.10264v2"}, {"index": 729, "title": "Generative Stock Question Answering", "abstract": "We study the problem of stock related question answering (StockQA): automatically generating answers to stock related questions, just like professional stock analysts providing action recommendations to stocks upon user's requests. StockQA is quite different from previous QA tasks since (1) the answers in StockQA are natural language sentences (rather than entities or values) and due to the dynamic nature of StockQA, it is scarcely possible to get reasonable answers in an extractive way from the training data; and (2) StockQA requires properly analyzing the relationship between keywords in QA pair and the numerical features of a stock. We propose to address the problem with a memory-augmented encoder-decoder architecture, and integrate different mechanisms of number understanding and generation, which is a critical component of StockQA.   We build a large-scale dataset containing over 180K StockQA instances, based on which various technique combinations are extensively studied and compared. Experimental results show that a hybrid word-character model with separate character components for number processing, achieves the best performance. By analyzing the results, we found that 44.8% of answers generated by our best model still suffer from the generic answer problem, which can be alleviated by a straightforward hybrid retrieval-generation model.", "link": "http://arxiv.org/abs/1804.07942v2"}, {"index": 730, "title": "Cashtag piggybacking: uncovering spam and bot activity in stock microblogs on Twitter", "abstract": "Microblogs are increasingly exploited for predicting prices and traded volumes of stocks in financial markets. However, it has been demonstrated that much of the content shared in microblogging platforms is created and publicized by bots and spammers. Yet, the presence (or lack thereof) and the impact of fake stock microblogs has never systematically been investigated before. Here, we study 9M tweets related to stocks of the 5 main financial markets in the US. By comparing tweets with financial data from Google Finance, we highlight important characteristics of Twitter stock microblogs. More importantly, we uncover a malicious practice - referred to as cashtag piggybacking - perpetrated by coordinated groups of bots and likely aimed at promoting low-value stocks by exploiting the popularity of high-value ones. Among the findings of our study is that as much as 71% of the authors of suspicious financial tweets are classified as bots by a state-of-the-art spambot detection algorithm. Furthermore, 37% of them were suspended by Twitter a few months after our investigation. Our results call for the adoption of spam and bot detection techniques in all studies and applications that exploit user-generated content for predicting the stock market.", "link": "http://dx.doi.org/10.1145/3313184"}, {"index": 731, "title": "Evaluating the role of data quality when sharing information in hierarchical multi-stock assessment models, with an application to Dover Sole", "abstract": "An emerging approach to data-limited fisheries stock assessment uses hierarchical multi-stock assessment models to group stocks together, sharing information from data-rich to data-poor stocks. In this paper, we simulate data-rich and data-poor fishery and survey data scenarios for a complex of dover sole stocks. Simulated data for individual stocks were used to compare estimation performance for single-stock and hierarchical multi-stock versions of a Schaefer production model. The single-stock and best performing multi-stock models were then used in stock assessments for the real dover sole data. Multi-stock models often had lower estimation errors than single-stock models when assessment data had low statistical power. Relative errors for productivity and relative biomass parameters were lower for multi-stock assessment model configurations. In addition, multi-stock models that estimated hierarchical priors for survey catchability performed the best under data-poor scenarios. We conclude that hierarchical multi-stock assessment models are useful for data-limited stocks and could provide a more flexible alternative to data-pooling and catch only methods; however, these models are subject to non-linear side-effects of parameter shrinkage. Therefore, we recommend testing hierarchical multi-stock models in closed-loop simulations before application to real fishery management systems.", "link": "http://arxiv.org/abs/1804.03353v2"}, {"index": 732, "title": "Bayesian Extreme Value Analysis of Stock Exchange Data", "abstract": "The Solvency II Directive and Solvency Assessment and Management (the South African equivalent) give a Solvency Capital Requirement which is based on a 99.5% Value-at-Risk (VaR) calculation. This calculation involves aggregating individual risks. When considering log returns of financial instruments, especially with share prices, there are extreme losses that are observed from time to time that often do not fit whatever model is proposed for the regular trading behaviour. The problem of accurately modelling these extreme losses is addressed, which, in turn, assists with the calculation of tail probabilities such as the 99.5% VaR. The focus is on the fitting of the Generalized Pareto Distribution (GPD) beyond a threshold. We show how objective Bayes methods can improve parameter estimation and the calculation of risk measures. Lastly we consider the choice of threshold. All aspects are illustrated using share losses on the Johannesburg Stock Exchange (JSE).", "link": "http://arxiv.org/abs/1804.01807v1"}, {"index": 733, "title": "Predictive modeling of stock indices closing from web search trends", "abstract": "The study aims to explore the strength of causal relationship between stock price search interest and real stock market outcomes on worldwide equity market indices. Such a phenomenon could also be mediated by investor behavior and extent of news coverage. The stock-specific internet search trends data and corresponding index close values from different countries stock exchanges are collected and analyzed. Empirical findings show global stock price search interests correlates more with developing economies with fewer effects in south asian stock exchanges apart from strong influence in western countries. Finally this study calls for development in expert decision support systems with the synthesis of using big data sources on forecasting market outcomes", "link": "http://arxiv.org/abs/1804.01676v1"}, {"index": 734, "title": "Cluster analysis of stocks using price movements of high frequency data from National Stock Exchange", "abstract": "This paper aims to develop new techniques to describe joint behavior of stocks, beyond regression and correlation. For example, we want to identify the clusters of the stocks that move together. Our work is based on applying Kernel Principal Component Analysis(KPCA) and Functional Principal Component Analysis(FPCA) to high frequency data from NSE. Since we dealt with high frequency data with a tick size of 30 seconds, FPCA seems to be an ideal choice. FPCA is a functional variant of PCA where each sample point is considered to be a function in Hilbert space L^2. On the other hand, KPCA is an extension of PCA using kernel methods. Results obtained from FPCA and Gaussian Kernel PCA seems to be in synergy but with a lag. There were two prominent clusters that showed up in our analysis, one corresponding to the banking sector and another corresponding to the IT sector. The other smaller clusters were seen from the automobile industry and the energy sector. IT sector was seen interacting with these small clusters. The learning gained from these interactions is substantial as one can use it significantly to develop trading strategies for intraday traders.", "link": "http://arxiv.org/abs/1803.09514v1"}, {"index": 735, "title": "The Determinants of Home Bias in Stock Portfolio: An Emerging and Developed Markets Study", "abstract": "The objective of this paper is to measure the degree of home bias (HB) within holdings portfolio and to identify their determining factors. By following literature and an international capital asset pricing model, we have chosen quite a number of susceptible factors that impact HB. This model is, hence, estimated for 20 countries, with cross-section econometrics, between 2008 and 2013. Our results show that all countries have recorded a high level of HB in their holdings portfolio. After that, we test if the HB of the emerging markets and that of the developed markets react differently to the determining factors. The volatility of the exchange rate is statistically significant with emerging markets, while it is hardly remarkable for the developed countries. Co-variance, size, distance, language, legal framework and foreign organization stocks prevents American investors to invest abroad.", "link": "http://arxiv.org/abs/1804.05103v1"}, {"index": 736, "title": "The cooling-off effect of price limits in the Chinese stock markets", "abstract": "In this paper, we investigate the cooling-off effect (opposite to the magnet effect) from two aspects. Firstly, from the viewpoint of dynamics, we study the existence of the cooling-off effect by following the dynamical evolution of some financial variables over a period of time before the stock price hits its limit. Secondly, from the probability perspective, we investigate, with the logit model, the existence of the cooling-off effect through analyzing the high-frequency data of all A-share common stocks traded on the Shanghai Stock Exchange and the Shenzhen Stock Exchange from 2000 to 2011 and inspecting the trading period from the opening phase prior to the moment that the stock price hits its limits. A comparison is made of the properties between up-limit hits and down-limit hits, and the possible difference will also be compared between bullish and bearish market state by dividing the whole period into three alternating bullish periods and three bearish periods. We find that the cooling-off effect emerges for both up-limit hits and down-limit hits, and the cooling-off effect of the down-limit hits is stronger than that of the up-limit hits. The difference of the cooling-off effect between bullish period and bearish period is quite modest. Moreover, we examine the sub-optimal orders effect, and infer that the professional individual investors and institutional investors play a positive role in the cooling-off effects. All these findings indicate that the price limit trading rule exerts a positive effect on maintaining the stability of the Chinese stock markets.", "link": "http://dx.doi.org/10.1016/j.physa.2018.03.066"}, {"index": 737, "title": "A path integral based model for stocks and order dynamics", "abstract": "We introduce a model for the short-term dynamics of financial assets based on an application to finance of quantum gauge theory, developing ideas of Ilinski. We present a numerical algorithm for the computation of the probability distribution of prices and compare the results with APPLE stocks prices and the S&P500 index.", "link": "http://dx.doi.org/10.1016/j.physa.2018.07.007"}, {"index": 738, "title": "Modeling stock markets through the reconstruction of market processes", "abstract": "There are two possible ways of interpreting the seemingly stochastic nature of financial markets: the Efficient Market Hypothesis (EMH) and a set of stylized facts that drive the behavior of the markets. We show evidence for some of the stylized facts such as memory-like phenomena in price volatility in the short term, a power-law behavior and non-linear dependencies on the returns.   Given this, we construct a model of the market using Markov chains. Then, we develop an algorithm that can be generalized for any N-symbol alphabet and K-length Markov chain. Using this tool, we are able to show that it's, at least, always better than a completely random model such as a Random Walk. The code is written in MATLAB and maintained in GitHub.", "link": "http://arxiv.org/abs/1803.06653v1"}, {"index": 739, "title": "Stock Price Prediction using Principle Components", "abstract": "The literature provides strong evidence that stock prices can be predicted from past price data. Principal component analysis (PCA) is a widely used mathematical technique for dimensionality reduction and analysis of data by identifying a small number of principal components to explain the variation found in a data set. In this paper, we describe a general method for stock price prediction using covariance information, in terms of a dimension reduction operation based on principle component analysis. Projecting the noisy observation onto a principle subspace leads to a well-conditioned problem. We illustrate our method on daily stock price values for five companies in different industries. We investigate the results based on mean squared error and directional change statistic of prediction, as measures of performance, and volatility of prediction as a measure of risk.", "link": "http://arxiv.org/abs/1803.05075v1"}, {"index": 740, "title": "A Generalization of the Robust Positive Expectation Theorem for Stock Trading via Feedback Control", "abstract": "The starting point of this paper is the so-called Robust Positive Expectation (RPE) Theorem, a result which appears in literature in the context of Simultaneous Long-Short stock trading. This theorem states that using a combination of two specially-constructed linear feedback trading controllers, one long and one short, the expected value of the resulting gain-loss function is guaranteed to be robustly positive with respect to a large class of stochastic processes for the stock price. The main result of this paper is a generalization of this theorem. Whereas previous work applies to a single stock, in this paper, we consider a pair of stocks. To this end, we make two assumptions on their expected returns. The first assumption involves price correlation between the two stocks and the second involves a bounded non-zero momentum condition. With known uncertainty bounds on the parameters associated with these assumptions, our new version of the RPE Theorem provides necessary and sufficient conditions on the positive feedback parameter K of the controller under which robust positive expectation is assured. We also demonstrate that our result generalizes the one existing for the single-stock case. Finally, it is noted that our results also can be interpreted in the context of pairs trading.", "link": "http://arxiv.org/abs/1803.04591v1"}, {"index": 741, "title": "Does the time horizon of the return predictive effect of investor sentiment vary with stock characteristics? A Granger causality analysis in the frequency domain", "abstract": "Behavioral theories posit that investor sentiment exhibits predictive power for stock returns, whereas there is little study have investigated the relationship between the time horizon of the predictive effect of investor sentiment and the firm characteristics. To this end, by using a Granger causality analysis in the frequency domain proposed by Lemmens et al. (2008), this paper examine whether the time horizon of the predictive effect of investor sentiment on the U.S. returns of stocks vary with different firm characteristics (e.g., firm size (Size), book-to-market equity (B/M) rate, operating profitability (OP) and investment (Inv)). The empirical results indicate that investor sentiment has a long-term (more than 12 months) or short-term (less than 12 months) predictive effect on stock returns with different firm characteristics. Specifically, the investor sentiment has strong predictability in the stock returns for smaller Size stocks, lower B/M stocks and lower OP stocks, both in the short term and long term, but only has a short-term predictability for higher quantile ones. The investor sentiment merely has predictability for the returns of smaller Inv stocks in the short term, but has a strong short-term and long-term predictability for larger Inv stocks. These results have important implications for the investors for the planning of the short and the long run stock investment strategy.", "link": "http://arxiv.org/abs/1803.02962v1"}, {"index": 742, "title": "Efficient construction of threshold networks of stock markets", "abstract": "Although the threshold network is one of the most used tools to characterize the underlying structure of a stock market, the identification of the optimal threshold to construct a reliable stock network remains challenging. In this paper, the concept of dynamic consistence between the threshold network and the stock market is proposed. The optimal threshold is estimated by maximizing the consistence function. The application of this procedure to stocks belonging to Standard \\& Pool's 500 Index from January 2006 to December 2011 yields the threshold value 0.28. In analyzing topological characteristics of the generated network, three globally financial crises can be distinguished well from the evolutionary perspective.", "link": "http://dx.doi.org/10.1016/j.physa.2018.06.083"}, {"index": 743, "title": "Modelling stock correlations with expected returns from investors", "abstract": "Stock correlations is crucial to asset pricing, investor decision-making, and financial risk regulations. However, microscopic explanation based on agent-based modeling is still lacking. We here propose a model derived from minority game for modeling stock correlations, in which an agent's expected return for one stock is influenced by the historical return of the other stock. Each agent makes a decision based on his expected return with reference to information dissemination and the historical return of the stock. We find that the returns of the stocks are positively (negatively) correlated when agents' expected returns for one stock are positively (negatively) correlated with the historical return of the other. We provide both numerical simulations and analytical studies and give explanations to stock correlations for cases with agents having either homogeneous or heterogeneous expected returns. The result still holds when other factors such as holding decisions and external events are included which broadens the practicability of the model.", "link": "http://arxiv.org/abs/1803.02019v2"}, {"index": 744, "title": "The Dividend Discount Model with Multiple Growth Rates of Any Order for Stock Evaluation", "abstract": "In this paper we provide a general solution for the dividend discount model in order to compute the intrinsic value of a common stock that allows for multiple stage growth rates of any predetermined number of periods. A mathematical proof is provided for the suggested general solution. A numerical application is also presented. The solution introduced in this paper is expected to improve on the precision of stock valuation, which might be of fundamental importance for investors as well as financial institutions.", "link": "http://arxiv.org/abs/1802.08987v1"}, {"index": 745, "title": "Stock management (Gest\u00e3o de estoques)", "abstract": "There is a great need to stock materials for production, but storing materials comes at a cost. Lack of organization in the inventory can result in a very high cost for the final product, in addition to generating other problems in the production chain. In this work we present mathematical and statistical methods applicable to stock management. The stock analysis using ABC curves serves to identify which are the priority items, the most expensive and with the highest turnover (demand), and thus determine, through stock control models, the purchase lot size and the periodicity that minimize the total costs of storing these materials. Using the Economic Order Quantity (EOQ) model and the (Q,R) model, the inventory costs of a company were minimized. The comparison of the results provided by the models was performed.", "link": "http://dx.doi.org/10.22533/at.ed.8032226044"}, {"index": 746, "title": "Stock Market Visualization", "abstract": "We provide complete source code for a front-end GUI and its back-end counterpart for a stock market visualization tool. It is built based on the \"functional visualization\" concept we discuss, whereby functionality is not sacrificed for fancy graphics. The GUI, among other things, displays a color-coded signal (computed by the back-end code) based on how \"out-of-whack\" each stock is trading compared with its peers (\"mean-reversion\"), and the most sizable changes in the signal (\"momentum\"). The GUI also allows to efficiently filter/tier stocks by various parameters (e.g., sector, exchange, signal, liquidity, market cap) and functionally display them. The tool can be run as a web-based or local application.", "link": "http://arxiv.org/abs/1802.05264v1"}, {"index": 747, "title": "Immediate Causality Network of Stock Markets", "abstract": "A financial system contains many elements networked by their relationships. Extensive works show that topological structure of the network stores rich information on evolutionary behaviors of the system such as early warning signals of collapses and/or crises. Existing works focus mainly on the network structure within a single stock market, while a collapse/crisis occurs in a macro-scale covering several or even all markets in the world. This mismatch of scale leads to unacceptable noise to the topological structure, and lack of information stored in relationships between different markets. In this work by using the transfer entropy we reconstruct the influential network between ten typical stock markets distributed in the world. Interesting findings include, before a financial crisis the connection strength reaches a maxima, which can act as an early warning signal of financial crises; The markets in America are mono-directionally and strongly influenced by that in Europe and act as the center; Some strongly linked pairs have also close correlations. The findings are helpful in understanding the evolution and modelling the dynamical process of the global financial system.", "link": "http://dx.doi.org/10.1209/0295-5075/121/48002"}, {"index": 748, "title": "The Power of Trading Polarity: Evidence from China Stock Market Crash", "abstract": "The imbalance of buying and selling functions profoundly in the formation of market trends, however, a fine-granularity investigation of the imbalance is still missing. This paper investigates a unique transaction dataset that enables us to inspect the imbalance of buying and selling on the man-times level at high frequency, what we call 'trading polarity', for a large cross-section of stocks from Shenzhen Stock Exchange. The trading polarity measures the market sentiment toward stocks from a view of very essence of trading desire. When using the polarity to examine market crash, we find that trading polarity successfully reflects the changing of market-level behavior in terms of its flipping times, depth, and length. We further investigate the relationship between polarity and return. At market-level, trading polarity is negatively correlated with returns, while at stock-level, this correlation changes according to market conditions, which becomes a good signal of market psychology transition. Also, the significant correlation disclosed by the market polarity and market emotion implies that our presented polarity, which essentially calculated in the context of high-frequency trading data, can real-timely reflect the sentiment of the market. The trading polarity indeed provides a new way to understand and foresee the market behavior.", "link": "http://arxiv.org/abs/1802.01143v1"}, {"index": 749, "title": "On the interplay between multiscaling and stocks dependence", "abstract": "We find a nonlinear dependence between an indicator of the degree of multiscaling of log-price time series of a stock and the average correlation of the stock with respect to the other stocks traded in the same market. This result is a robust stylized fact holding for different financial markets. We investigate this result conditional on the stocks' capitalization and on the kurtosis of stocks' log-returns in order to search for possible confounding effects. We show that a linear dependence with the logarithm of the capitalization and the logarithm of kurtosis does not explain the observed stylized fact, which we interpret as being originated from a deeper relationship.", "link": "http://arxiv.org/abs/1802.01113v2"}, {"index": 750, "title": "Stock returns forecast: an examination by means of Artificial Neural Networks", "abstract": "The validity of the Efficient Market Hypothesis has been under severe scrutiny since several decades. However, the evidence against it is not conclusive. Artificial Neural Networks provide a model-free means to analize the prediction power of past returns on current returns. This chapter analizes the predictability in the intraday Brazilian stock market using a backpropagation Artificial Neural Network. We selected 20 stocks from Bovespa index, according to different market capitalization, as a proxy for stock size. We find that predictability is related to capitalization. In particular, larger stocks are less predictable than smaller ones.", "link": "http://dx.doi.org/10.1007/978-3-319-69989-9_23"}, {"index": 751, "title": "Social Network based Short-Term Stock Trading System", "abstract": "This paper proposes a novel adaptive algorithm for the automated short-term trading of financial instrument. The algorithm adopts a semantic sentiment analysis technique to inspect the Twitter posts and to use them to predict the behaviour of the stock market. Indeed, the algorithm is specifically developed to take advantage of both the sentiment and the past values of a certain financial instrument in order to choose the best investment decision. This allows the algorithm to ensure the maximization of the obtainable profits by trading on the stock market. We have conducted an investment simulation and compared the performance of our proposed with a well-known benchmark (DJTATO index) and the optimal results, in which an investor knows in advance the future price of a product. The result shows that our approach outperforms the benchmark and achieves the performance score close to the optimal result.", "link": "http://arxiv.org/abs/1801.05295v1"}, {"index": 752, "title": "Deep Learning for Forecasting Stock Returns in the Cross-Section", "abstract": "Many studies have been undertaken by using machine learning techniques, including neural networks, to predict stock returns. Recently, a method known as deep learning, which achieves high performance mainly in image recognition and speech recognition, has attracted attention in the machine learning field. This paper implements deep learning to predict one-month-ahead stock returns in the cross-section in the Japanese stock market and investigates the performance of the method. Our results show that deep neural networks generally outperform shallow neural networks, and the best networks also outperform representative machine learning models. These results indicate that deep learning shows promise as a skillful machine learning method to predict stock returns in the cross-section.", "link": "http://arxiv.org/abs/1801.01777v4"}, {"index": 753, "title": "A novel improved fuzzy support vector machine based stock price trend forecast model", "abstract": "Application of fuzzy support vector machine in stock price forecast. Support vector machine is a new type of machine learning method proposed in 1990s. It can deal with classification and regression problems very successfully. Due to the excellent learning performance of support vector machine, the technology has become a hot research topic in the field of machine learning, and it has been successfully applied in many fields. However, as a new technology, there are many limitations to support vector machines. There is a large amount of fuzzy information in the objective world. If the training of support vector machine contains noise and fuzzy information, the performance of the support vector machine will become very weak and powerless. As the complexity of many factors influence the stock price prediction, the prediction results of traditional support vector machine cannot meet people with precision, this study improved the traditional support vector machine fuzzy prediction algorithm is proposed to improve the new model precision. NASDAQ Stock Market, Standard & Poor's (S&P) Stock market are considered. Novel advanced- fuzzy support vector machine (NA-FSVM) is the proposed methodology.", "link": "http://arxiv.org/abs/1801.00681v1"}, {"index": 754, "title": "Exploiting Investors Social Network for Stock Prediction in China's Market", "abstract": "Recent works have shown that social media platforms are able to influence the trends of stock price movements. However, existing works have majorly focused on the U.S. stock market and lacked attention to certain emerging countries such as China, where retail investors dominate the market. In this regard, as retail investors are prone to be influenced by news or other social media, psychological and behavioral features extracted from social media platforms are thought to well predict stock price movements in the China's market. Recent advances in the investor social network in China enables the extraction of such features from web-scale data. In this paper, on the basis of tweets from Xueqiu, a popular Chinese Twitter-like social platform specialized for investors, we analyze features with regard to collective sentiment and perception on stock relatedness and predict stock price movements by employing nonlinear models. The features of interest prove to be effective in our experiments.", "link": "http://dx.doi.org/10.1016/j.jocs.2017.10.013"}, {"index": 755, "title": "Improving Stock Market Prediction via Heterogeneous Information Fusion", "abstract": "Traditional stock market prediction approaches commonly utilize the historical price-related data of the stocks to forecast their future trends. As the Web information grows, recently some works try to explore financial news to improve the prediction. Effective indicators, e.g., the events related to the stocks and the people's sentiments towards the market and stocks, have been proved to play important roles in the stocks' volatility, and are extracted to feed into the prediction models for improving the prediction accuracy. However, a major limitation of previous methods is that the indicators are obtained from only a single source whose reliability might be low, or from several data sources but their interactions and correlations among the multi-sourced data are largely ignored.   In this work, we extract the events from Web news and the users' sentiments from social media, and investigate their joint impacts on the stock price movements via a coupled matrix and tensor factorization framework. Specifically, a tensor is firstly constructed to fuse heterogeneous data and capture the intrinsic relations among the events and the investors' sentiments. Due to the sparsity of the tensor, two auxiliary matrices, the stock quantitative feature matrix and the stock correlation matrix, are constructed and incorporated to assist the tensor decomposition. The intuition behind is that stocks that are highly correlated with each other tend to be affected by the same event. Thus, instead of conducting each stock prediction task separately and independently, we predict multiple correlated stocks simultaneously through their commonalities, which are enabled via sharing the collaboratively factorized low rank matrices between matrices and the tensor. Evaluations on the China A-share stock data and the HK stock data in the year 2015 demonstrate the effectiveness of the proposed model.", "link": "http://dx.doi.org/10.1016/j.knosys.2017.12.025"}, {"index": 756, "title": "An Artificial Neural Network-based Stock Trading System Using Technical Analysis and Big Data Framework", "abstract": "In this paper, a neural network-based stock price prediction and trading system using technical analysis indicators is presented. The model developed first converts the financial time series data into a series of buy-sell-hold trigger signals using the most commonly preferred technical analysis indicators. Then, a Multilayer Perceptron (MLP) artificial neural network (ANN) model is trained in the learning stage on the daily stock prices between 1997 and 2007 for all of the Dow30 stocks. Apache Spark big data framework is used in the training stage. The trained model is then tested with data from 2007 to 2017. The results indicate that by choosing the most appropriate technical indicators, the neural network model can achieve comparable results against the Buy and Hold strategy in most of the cases. Furthermore, fine tuning the technical indicators and/or optimization strategy can enhance the overall trading performance.", "link": "http://dx.doi.org/10.1145/3077286.3077294"}, {"index": 757, "title": "The relationship between trading volumes, number of transactions, and stock volatility in GARCH models", "abstract": "We examine the relationship between trading volumes, number of transactions, and volatility using daily stock data of the Tokyo Stock Exchange. Following the mixture of distributions hypothesis, we use trading volumes and the number of transactions as proxy for the rate of information arrivals affecting stock volatility. The impact of trading volumes or number of transactions on volatility is measured using the generalized autoregressive conditional heteroscedasticity (GARCH) model. We find that the GARCH effects, that is, persistence of volatility, is not always removed by adding trading volumes or number of transactions, indicating that trading volumes and number of transactions do not adequately represent the rate of information arrivals.", "link": "http://dx.doi.org/10.1088/1742-6596/738/1/012097"}, {"index": 758, "title": "Sentiment Predictability for Stocks", "abstract": "In this work, we present our findings and experiments for stock-market prediction using various textual sentiment analysis tools, such as mood analysis and event extraction, as well as prediction models, such as LSTMs and specific convolutional architectures.", "link": "http://arxiv.org/abs/1712.05785v2"}, {"index": 759, "title": "Stock market as temporal network", "abstract": "Financial networks have become extremely useful in characterizing the structure of complex financial systems. Meanwhile, the time evolution property of the stock markets can be described by temporal networks. We utilize the temporal network framework to characterize the time-evolving correlation-based networks of stock markets. The market instability can be detected by the evolution of the topology structure of the financial networks. We employ the temporal centrality as a portfolio selection tool. Those portfolios, which are composed of peripheral stocks with low temporal centrality scores, have consistently better performance under different portfolio optimization schemes, suggesting that the temporal centrality measure can be used as new portfolio optimization and risk management tools. Our results reveal the importance of the temporal attributes of the stock markets, which should be taken serious consideration in real life applications.", "link": "http://dx.doi.org/10.1016/j.physa.2018.05.039"}, {"index": 760, "title": "Listening to Chaotic Whispers: A Deep Learning Framework for News-oriented Stock Trend Prediction", "abstract": "Stock trend prediction plays a critical role in seeking maximized profit from stock investment. However, precise trend prediction is very difficult since the highly volatile and non-stationary nature of stock market. Exploding information on Internet together with advancing development of natural language processing and text mining techniques have enable investors to unveil market trends and volatility from online content. Unfortunately, the quality, trustworthiness and comprehensiveness of online content related to stock market varies drastically, and a large portion consists of the low-quality news, comments, or even rumors. To address this challenge, we imitate the learning process of human beings facing such chaotic online news, driven by three principles: sequential content dependency, diverse influence, and effective and efficient learning. In this paper, to capture the first two principles, we designed a Hybrid Attention Networks to predict the stock trend based on the sequence of recent related news. Moreover, we apply the self-paced learning mechanism to imitate the third principle. Extensive experiments on real-world stock market data demonstrate the effectiveness of our approach.", "link": "http://arxiv.org/abs/1712.02136v3"}, {"index": 761, "title": "Distributions of Historic Market Data - Stock Returns", "abstract": "We show that the moments of the distribution of historic stock returns are in excellent agreement with the Heston model and not with the multiplicative model, which predicts power-law tails of volatility and stock returns. We also show that the mean realized variance of returns is a linear function of the number of days over which the returns are calculated. The slope is determined by the mean value of the variance (squared volatility) in the mean-reverting stochastic volatility models, such as Heston and multiplicative, independent of stochasticity. The distribution function of stock returns, which rescales with the increase of the number of days of return, is obtained from the steady-state variance distribution function using the product distribution with the normal distribution.", "link": "http://dx.doi.org/10.1140/epjb/e2019-90218-8"}, {"index": 762, "title": "Impact of Cross-Listing Chinese Stock Returns. A and N Shares Rate of Return Comparison", "abstract": "The paper examines the Chinese market reaction to the ADR issue by comparing returns and their stochastic variances of the Chinese firms cross-listed in the U.S. stock market. First, It was implemented capital asset pricing model (CAPM) to determine expected returns A and N shares. The CAPM provided with a methodology to quantify risk and translate that risk into estimates of expected return on equity. Overall findings document that N shares of Chinese entities listed on U.S. market were greatly affected by economic turmoil during the period of World Financial Crises 2007-2008 than the A shares listed on the local market. After in order to test the hypothesis of beneficial cross-listing, it was implemented an event study method and the returns was modeled following GARCH process, which assumes homoscedasticity in residual returns. The results indicate a significant negative abnormal market return on an ADR listing date. The return volatilities after the listing date are compared to those before the listing. Four out of ten companies experienced increased volatility of local return after the cross-listing. Keywords: cross-listing, ADR, rate of return, volatility, CAPM, GARCH model, N shares, A shares", "link": "http://dx.doi.org/10.13140/RG.2.2.12115.68642"}, {"index": 763, "title": "Time Series Prediction : Predicting Stock Price", "abstract": "Time series forecasting is widely used in a multitude of domains. In this paper, we present four models to predict the stock price using the SPX index as input time series data. The martingale and ordinary linear models require the strongest assumption in stationarity which we use as baseline models. The generalized linear model requires lesser assumptions but is unable to outperform the martingale. In empirical testing, the RNN model performs the best comparing to other two models, because it will update the input through LSTM instantaneously, but also does not beat the martingale. In addition, we introduce an online to batch algorithm and discrepancy measure to inform readers the newest research in time series predicting method, which doesn't require any stationarity or non mixing assumptions in time series data. Finally, to apply these forecasting to practice, we introduce basic trading strategies that can create Win win and Zero sum situations.", "link": "http://arxiv.org/abs/1710.05751v2"}, {"index": 764, "title": "Inference of forex and stock-index financial networks based on the normalised mutual information rate", "abstract": "In this paper we study data from financial markets using an information-theory tool that we call the normalised Mutual Information Rate and show how to use it to infer the underlying network structure of interrelations in foreign currency exchange rates and stock indices of 14 countries world-wide and the European Union. We first present the mathematical method and discuss about its computational aspects, and then apply it to artificial data from chaotic dynamics and to correlated random variates. Next, we apply the method to infer the network structure of the financial data. Particularly, we study and reveal the interrelations among the various foreign currency exchange rates and stock indices in two separate networks for which we also perform an analysis to identify their structural properties. Our results show that both are small-world networks sharing similar properties but also having distinct differences in terms of assortativity. Finally, the consistent relationships depicted among the 15 economies are further supported by a discussion from the economics view point.", "link": "http://dx.doi.org/10.1371/journal.pone.0192160"}, {"index": 765, "title": "On Drawdown-Modulated Feedback Control in Stock Trading", "abstract": "Control of drawdown, that is, the control of the drops in wealth over time from peaks to subsequent lows, is of great concern from a risk management perspective. With this motivation in mind, the focal point of this paper is to address the drawdown issue in a stock trading context. Although our analysis can be carried out without reference to control theory, to make the work accessible to this community, we use the language of feedback systems. The takeoff point for the results to follow, which we call the Drawdown Modulation Lemma, characterizes any investment which guarantees that the percentage drawdown is no greater than a prespecified level with probability one. With the aid of this lemma, we introduce a new scheme which we call the drawdown-modulated feedback control. To illustrate the power of the theory, we consider a drawdown-constrained version of the well-known Kelly Optimization Problem which involves maximizing the expected logarithmic growth of the trader's account value. As the drawdown parameter dmax in our new formulation tends to one, we recover existing results as a special case. This new theory leads to an optimal investment strategy whose application is illustrated via an example with historical stock-price data.", "link": "http://dx.doi.org/10.1016/j.ifacol.2017.08.167"}, {"index": 766, "title": "Valuation of Employee Stock Options (ESOs) by means of Mean-Variance Hedging", "abstract": "We consider the problem of ESO valuation in continuous time. In particular, we consider models that assume that an appropriate random time serves as a proxy for anything that causes the ESO's holder to exercise the option early, namely, reflects the ESO holder's job termination risk as well as early exercise behaviour. In this context, we study the problem of ESO valuation by means of mean-variance hedging. Our analysis is based on dynamic programming and uses PDE techniques. We also express the ESO's value that we derive as the expected discounted payoff that the ESO yields with respect to an equivalent martingale measure, which does not coincide with the minimal martingale measure or the variance-optimal measure. Furthermore, we present a numerical study that illustrates aspects or our theoretical results.", "link": "http://arxiv.org/abs/1710.00897v1"}, {"index": 767, "title": "Executive stock option exercise with full and partial information on a drift change point", "abstract": "We analyse the optimal exercise of an executive stock option (ESO) written on a stock whose drift parameter falls to a lower value at a change point, an exponentially distributed random time independent of the Brownian motion driving the stock. Two agents, who do not trade the stock, have differing information on the change point, and seek to optimally exercise the option by maximising its discounted payoff under the physical measure. The first agent has full information, and observes the change point. The second agent has partial information and filters the change point from price observations. This scenario is designed to mimic the positions of two employees of varying seniority, a fully informed executive and a partially informed less senior employee, each of whom receives an ESO. The partial information scenario yields a model under the observation filtration $\\widehat{\\mathbb{F}}$ in which the stock drift becomes a diffusion driven by the innovations process, an $\\widehat{\\mathbb{F}}$-Brownian motion also driving the stock under $\\widehat{\\mathbb{F}}$, and the partial information optimal stopping value function has two spatial dimensions. We rigorously characterise the free boundary PDEs for both agents, establish shape and regularity properties of the associated optimal exercise boundaries, and prove the smooth pasting property in both information scenarios, exploiting some stochastic flow ideas to do so in the partial information case. We develop finite difference algorithms to numerically solve both agents' exercise and valuation problems and illustrate that the additional information of the fully informed agent can result in exercise patterns which exploit the information on the change point, lending credence to empirical studies which suggest that privileged information of bad news is a factor leading to early exercise of ESOs prior to poor stock price performance.", "link": "http://arxiv.org/abs/1709.10141v4"}, {"index": 768, "title": "Facebook drives behavior of passive households in stock markets", "abstract": "Recent studies using data on social media and stock markets have mainly focused on predicting stock returns. Instead of predicting stock price movements, we examine the relation between Facebook data and investors' decision making in stock markets with a unique data on investors' transactions on Nokia. We find that the decisions to buy versus sell are associated with Facebook data especially for passive households and also for nonprofit organizations. At the same time, it seems that more sophisticated investors---financial and insurance institutions---are behaving independently from Facebook activities.", "link": "http://dx.doi.org/10.1016/j.frl.2018.03.020"}, {"index": 769, "title": "Stock-out Prediction in Multi-echelon Networks", "abstract": "In multi-echelon inventory systems the performance of a given node is affected by events that occur at many other nodes and in many other time periods. For example, a supply disruption upstream will have an effect on downstream, customer-facing nodes several periods later as the disruption \"cascades\" through the system. There is very little research on stock-out prediction in single-echelon systems and (to the best of our knowledge) none on multi-echelon systems. However, in real the world, it is clear that there is significant interest in techniques for this sort of stock-out prediction. Therefore, our research aims to fill this gap by using deep neural networks (DNN) to predict stock-outs in multi-echelon supply chains.", "link": "http://arxiv.org/abs/1709.06922v2"}, {"index": 770, "title": "Universal L\u00e9vy's stable law of stock market and its characterization", "abstract": "Price fluctuations in financial markets can be characterized by L\\'evy's stable distribution, which is supported by the generalized central limit system. When the stable parameters were estimated from four different stock markets in long term, they similarly indicated an unique value. On the other hand, when analyzed in short term, parameters and the stock prices fluctuated with correlation, which shows that the stock markets are instable.", "link": "http://arxiv.org/abs/1709.06279v2"}, {"index": 771, "title": "Deep Stock Representation Learning: From Candlestick Charts to Investment Decisions", "abstract": "We propose a novel investment decision strategy (IDS) based on deep learning. The performance of many IDSs is affected by stock similarity. Most existing stock similarity measurements have the problems: (a) The linear nature of many measurements cannot capture nonlinear stock dynamics; (b) The estimation of many similarity metrics (e.g. covariance) needs very long period historic data (e.g. 3K days) which cannot represent current market effectively; (c) They cannot capture translation-invariance. To solve these problems, we apply Convolutional AutoEncoder to learn a stock representation, based on which we propose a novel portfolio construction strategy by: (i) using the deeply learned representation and modularity optimisation to cluster stocks and identify diverse sectors, (ii) picking stocks within each cluster according to their Sharpe ratio (Sharpe 1994). Overall this strategy provides low-risk high-return portfolios. We use the Financial Times Stock Exchange 100 Index (FTSE 100) data for evaluation. Results show our portfolio outperforms FTSE 100 index and many well known funds in terms of total return in 2000 trading days.", "link": "http://arxiv.org/abs/1709.03803v3"}, {"index": 772, "title": "Opening the Black Box of Financial AI with CLEAR-Trade: A CLass-Enhanced Attentive Response Approach for Explaining and Visualizing Deep Learning-Driven Stock Market Prediction", "abstract": "Deep learning has been shown to outperform traditional machine learning algorithms across a wide range of problem domains. However, current deep learning algorithms have been criticized as uninterpretable \"black-boxes\" which cannot explain their decision making processes. This is a major shortcoming that prevents the widespread application of deep learning to domains with regulatory processes such as finance. As such, industries such as finance have to rely on traditional models like decision trees that are much more interpretable but less effective than deep learning for complex problems. In this paper, we propose CLEAR-Trade, a novel financial AI visualization framework for deep learning-driven stock market prediction that mitigates the interpretability issue of deep learning methods. In particular, CLEAR-Trade provides a effective way to visualize and explain decisions made by deep stock market prediction models. We show the efficacy of CLEAR-Trade in enhancing the interpretability of stock market prediction by conducting experiments based on S&P 500 stock index prediction. The results demonstrate that CLEAR-Trade can provide significant insight into the decision-making process of deep learning-driven financial models, particularly for regulatory processes, thus improving their potential uptake in the financial industry.", "link": "http://arxiv.org/abs/1709.01574v1"}, {"index": 773, "title": "Time-Varying Extreme Value Dependence with Application to Leading European Stock Markets", "abstract": "Extremal dependence between international stock markets is of particular interest in today's global financial landscape. However, previous studies have shown this dependence is not necessarily stationary over time. We concern ourselves with modeling extreme value dependence when that dependence is changing over time, or other suitable covariate. Working within a framework of asymptotic dependence, we introduce a regression model for the angular density of a bivariate extreme value distribution that allows us to assess how extremal dependence evolves over a covariate. We apply the proposed model to assess the dynamics governing extremal dependence of some leading European stock markets over the last three decades, and find evidence of an increase in extremal dependence over recent years.", "link": "http://arxiv.org/abs/1709.01198v1"}, {"index": 774, "title": "Stock Trading via Feedback Control: Stochastic Model Predictive or Genetic?", "abstract": "We seek a discussion about the most suitable feedback control structure for stock trading under the consideration of proportional transaction costs. Suitability refers to robustness and performance capability. Both are tested by considering different one-step ahead prediction qualities, including the ideal case, correct prediction of the direction of change in daily stock prices and the worst-case. Feedback control structures are partitioned into two general classes: stochastic model predictive control (SMPC) and genetic. For the former class three controllers are discussed, whereby it is distinguished between two Markowitz- and one dynamic hedging-inspired SMPC formulation. For the latter class five trading algorithms are disucssed, whereby it is distinguished between two different moving average (MA) based, two trading range (TR) based, and one strategy based on historical optimal (HistOpt) trajectories. This paper also gives a preliminary discussion about how modified dynamic hedging-inspired SMPC formulations may serve as alternatives to Markowitz portfolio optimization. The combinations of all of the eight controllers with five different one-step ahead prediction methods are backtested for daily trading of the 30 components of the German stock market index DAX for the time period between November 27, 2015 and November 25, 2016.", "link": "http://arxiv.org/abs/1708.08857v2"}, {"index": 775, "title": "A General Class of Multifractional Processes and Stock Price Informativeness", "abstract": "We introduce a general class of stochastic processes driven by a multifractional Brownian motion (mBm) and study the estimation problems of their pointwise H\\\"older exponents (PHE) based on a new localized generalized quadratic variation approach (LGQV). By comparing our suggested approach with the other two existing benchmark estimation approaches (classic GQV and oscillation approach) through a simulation study, we show that our estimator has better performance in the case where the observed process is some unknown bivariate function of time and mBm. Such multifractional processes, whose PHEs are time-varying, can be used to model stock prices under various market conditions, that are both time-dependent and region-dependent. As an application to finance, an empirical study on modeling cross-listed stocks provides new evidence that the equity path's roughness varies via time and the stock price informativeness properties from global stock markets.", "link": "http://dx.doi.org/10.1016/j.chaos.2018.08.004"}, {"index": 776, "title": "Modeling soil organic carbon with Quantile Regression: Dissecting predictors' effects on carbon stocks", "abstract": "Soil Organic Carbon (SOC) estimation is crucial to manage both natural and anthropic ecosystems and has recently been put under the magnifying glass after the Paris agreement 2016 due to its relationship with greenhouse gas. Statistical applications have dominated the SOC stock mapping at regional scale so far. However, the community has hardly ever attempted to implement Quantile Regression (QR) to spatially predict the SOC distribution. In this contribution, we test QR to estimate SOC stock (0-30 $cm$ depth) in the agricultural areas of a highly variable semi-arid region (Sicily, Italy, around 25,000 $km2$) by using topographic and remotely sensed predictors. We also compare the results with those from available SOC stock measurement. The QR models produced robust performances and allowed to recognize dominant effects among the predictors with respect to the considered quantile. This information, currently lacking, suggests that QR can discern predictor influences on SOC stock at specific sub-domains of each predictors. In this work, the predictive map generated at the median shows lower errors than those of the Joint Research Centre and International Soil Reference, and Information Centre benchmarks. The results suggest the use of QR as a comprehensive and effective method to map SOC using legacy data in agro-ecosystems. The R code scripted in this study for QR is included.", "link": "http://arxiv.org/abs/1708.03859v1"}, {"index": 777, "title": "Dynamic Conditional Correlation between Electricity and Stock markets during the Financial Crisis in Greece", "abstract": "Liberalization of electricity markets has increasingly created the need for understanding the volatility and correlation structure between electricity and financial markets. This work reveals the existence of structural changes in correlation patterns among these two markets and links the changes to both fundamentals and regulatory conditions prevailing in the markets, as well as the current European financial crisis. We apply a Dynamic Conditional Correlation (DCC) GARCH model to a set of market s fundamental variables and Greece s financial market and microeconomic indexes to study their interaction. Emphasis is given on the period of severe financial crisis of the Country to understand contagion and volatility spillover between these two markets.", "link": "http://arxiv.org/abs/1708.07063v1"}, {"index": 778, "title": "Decoding Stock Market with Quant Alphas", "abstract": "We give an explicit algorithm and source code for extracting expected returns for stocks from expected returns for alphas. Our algorithm altogether bypasses combining alphas with weights into \"alpha combos\". Simply put, we have developed a new method for trading alphas which does not involve combining them. This yields substantial cost savings as alpha combos cost hedge funds around 3% of the P&L, while alphas themselves cost around 10%. Also, the extra layer of alpha combos, which our new method avoids, adds noise and suboptimality. We also arrive at our algorithm independently by explicitly constructing alpha risk models based on position data.", "link": "http://arxiv.org/abs/1708.02984v1"}, {"index": 779, "title": "Machine learning in sentiment reconstruction of the simulated stock market", "abstract": "In this paper we continue the study of the simulated stock market framework defined by the driving sentiment processes. We focus on the market environment driven by the buy/sell trading sentiment process of the Markov chain type. We apply the methodology of the Hidden Markov Models and the Recurrent Neural Networks to reconstruct the transition probabilities matrix of the Markov sentiment process and recover the underlying sentiment states from the observed stock price behavior.", "link": "http://dx.doi.org/10.1016/j.physa.2017.11.093"}, {"index": 780, "title": "Stock-flow consistent macroeconomic model with nonuniform distributional constraint", "abstract": "We report on results concerning a partially aggregated Stock Flow Consistent (SFC) macroeconomic model in the stationary state where the sectors of banks and firms are aggregated, the sector of households is dis-aggregated, and the probability density function (pdf) of the wealth of households is exogenous, constrained by econometric data. It is shown that the equality part of the constraint can be reduced to a single constant-sum equation, which relates this problem to the study of continuous mass transport problems, and to the sum of iid random variables. Existing results can thus be applied, and provide marginal probabilities, and the location of the critical point before condensation occurs. Various numerical experiments are performed using Monte Carlo sampling of the hit-and-run type, using wealth and income data for France.", "link": "http://arxiv.org/abs/1708.00645v1"}, {"index": 781, "title": "An Evolutionary Stochastic-Local-Search Framework for One-Dimensional Cutting-Stock Problems", "abstract": "We introduce an evolutionary stochastic-local-search (SLS) algorithm for addressing a generalized version of the so-called 1/V/D/R cutting-stock problem. Cutting-stock problems are encountered often in industrial environments and the ability to address them efficiently usually results in large economic benefits. Traditionally linear-programming-based techniques have been utilized to address such problems, however their flexibility might be limited when nonlinear constraints and objective functions are introduced. To this end, this paper proposes an evolutionary SLS algorithm for addressing one-dimensional cutting-stock problems. The contribution lies in the introduction of a flexible structural framework of the optimization that may accommodate a large family of diversification strategies including a novel parallel pattern appropriate for SLS algorithms (not necessarily restricted to cutting-stock problems). We finally demonstrate through experiments in a real-world manufacturing problem the benefit in cost reduction of the considered diversification strategies.", "link": "http://arxiv.org/abs/1707.08776v1"}, {"index": 782, "title": "Stock Prediction: a method based on extraction of news features and recurrent neural networks", "abstract": "This paper proposed a method for stock prediction. In terms of feature extraction, we extract the features of stock-related news besides stock prices. We first select some seed words based on experience which are the symbols of good news and bad news. Then we propose an optimization method and calculate the positive polar of all words. After that, we construct the features of news based on the positive polar of their words. In consideration of sequential stock prices and continuous news effects, we propose a recurrent neural network model to help predict stock prices. Compared to SVM classifier with price features, we find our proposed method has an over 5% improvement on stock prediction accuracy in experiments.", "link": "http://arxiv.org/abs/1707.07585v1"}, {"index": 783, "title": "Correlations and Flow of Information between The New York Times and Stock Markets", "abstract": "We use Random Matrix Theory (RMT) and information theory to analyze the correlations and flow of information between 64,939 news from The New York Times and 40 world financial indices during 10 months along the period 2015-2016. The set of news was quantified and transformed into daily polarity time series using tools from sentiment analysis. Results from RMT shows that a common factor lead the world indices and news, and even share the same dynamics. Furthermore, the global correlation structure has found preserved when adding white noise, which indicate that correlations are not due to sample size effects. Likewise, we found a lot of information flowing from news to world indices for specific delay, being of practical interest for trading purpose. Our results suggest a deep relationship between news and world indices, and show a situation where news drive world market movements, giving a new evidence to support behavioral finance as the current economic paradigm.", "link": "http://dx.doi.org/10.1016/j.physa.2018.02.154"}, {"index": 784, "title": "Wax and wane of the cross-sectional momentum and contrarian effects: Evidence from the Chinese stock markets", "abstract": "This paper investigates the time-varying risk-premium relation of the Chinese stock markets within the framework of cross-sectional momentum and contrarian effects by adopting the Capital Asset Pricing Model and the French-Fama three factor model. The evolving arbitrage opportunities are also studied by quantifying the performance of time-varying cross-sectional momentum and contrarian effects in the Chinese stock markets. The relation between the contrarian profitability and market condition factors that could characterize the investment context is also investigated. The results reveal that the risk-premium relation varies over time, and the arbitrage opportunities based on the contrarian portfolios wax and wane over time. The performance of contrarian portfolios are highly dependent on several market conditions. The periods with upward trend of market state, higher market volatility and liquidity, lower macroeconomics uncertainty are related to higher contrarian profitability. These findings are consistent with the Adaptive Markets Hypothesis and have practical implications for market participants.", "link": "http://dx.doi.org/10.1016/j.physa.2017.05.078"}, {"index": 785, "title": "Plunges in the Bombay stock exchange: Characteristics and indicators", "abstract": "We study the various sectors of the Bombay Stock Exchange (BSE) for a period of eight years from January 2006 to March 2014. Using the data of the daily returns of a period of eight years we investigate the financial cross correlation co-efficients among the sectors of BSE and Price by Earning (PE) ratio of BSE Sensex. We show that the behavior of these quantities during normal periods and during crisis is very different. We show that the PE ratio shows a particular distinctive trend in the approach to a crash of the financial market and can therefore be used as an indicator of an impending catastrophe. We propose that a model of analysis of crashes in a financial market can be built using two parameters: (i) the PE ratio and (ii) the largest eigenvalue of the cross correlation matrix.", "link": "http://dx.doi.org/10.1142/S0217979217501600"}, {"index": 786, "title": "Linking Twitter Events With Stock Market Jitters", "abstract": "Predicting investors reactions to financial and political news is important for the early detection of stock market jitters. Evidence from several recent studies suggests that online social media could improve prediction of stock market movements. However, utilizing such information to predict strong stock market fluctuations has not been explored so far. In this work, we propose a novel event detection method on Twitter, tailored to detect financial and political events that influence a specific stock market. The proposed approach applies a bursty topic detection method on a stream of tweets related to finance or politics followed by a classification process which filters-out events that do not influence the examined stock market. We train our classifier to recognise real events by using solely information about stock market volatility, without the need of manual labeling. We model Twitter events as feature vectors that encompass a rich variety of information, such as the geographical distribution of tweets, their polarity, information about their authors as well as information about bursty words associated with the event. We show that utilizing only information about tweets polarity, like most previous studies, results in wasting important information. We apply the proposed method on high-frequency intra-day data from the Greek and Spanish stock market and we show that our financial event detector successfully predicts most of the stock market jitters.", "link": "http://arxiv.org/abs/1709.06519v1"}, {"index": 787, "title": "Incorporating Black-Litterman Views in Portfolio Construction when Stock Returns are a Mixture of Normals", "abstract": "In this paper, we consider the basic problem of portfolio construction in financial engineering, and analyze how market-based and analytical approaches can be combined to obtain efficient portfolios. As a first step in our analysis, we model the asset returns as a random variable distributed according to a mixture of normal random variables. We then discuss how to construct portfolios that minimize the Conditional Value-at-Risk (CVaR) under this probabilistic model via a convex program. We also construct a second-order cone representable approximation of the CVaR under the mixture model, and demonstrate its theoretical and empirical accuracy. Furthermore, we incorporate the market equilibrium information into this procedure through the well-known Black-Litterman approach via an inverse optimization framework by utilizing the proposed approximation. Our computational experiments on a real dataset show that this approach with an emphasis on the market equilibrium typically yields less risky portfolios than a purely market-based portfolio while producing similar returns on average.", "link": "http://dx.doi.org/10.1016/j.omega.2018.11.017"}, {"index": 788, "title": "Stock Trading Using PE ratio: A Dynamic Bayesian Network Modeling on Behavioral Finance and Fundamental Investment", "abstract": "On a daily investment decision in a security market, the price earnings (PE) ratio is one of the most widely applied methods being used as a firm valuation tool by investment experts. Unfortunately, recent academic developments in financial econometrics and machine learning rarely look at this tool. In practice, fundamental PE ratios are often estimated only by subjective expert opinions. The purpose of this research is to formalize a process of fundamental PE estimation by employing advanced dynamic Bayesian network (DBN) methodology. The estimated PE ratio from our model can be used either as a information support for an expert to make investment decisions, or as an automatic trading system illustrated in experiments. Forward-backward inference and EM parameter estimation algorithms are derived with respect to the proposed DBN structure. Unlike existing works in literatures, the economic interpretation of our DBN model is well-justified by behavioral finance evidences of volatility. A simple but practical trading strategy is invented based on the result of Bayesian inference. Extensive experiments show that our trading strategy equipped with the inferenced PE ratios consistently outperforms standard investment benchmarks.", "link": "http://arxiv.org/abs/1706.02985v1"}, {"index": 789, "title": "Predicting stock market movements using network science: An information theoretic approach", "abstract": "A stock market is considered as one of the highly complex systems, which consists of many components whose prices move up and down without having a clear pattern. The complex nature of a stock market challenges us on making a reliable prediction of its future movements. In this paper, we aim at building a new method to forecast the future movements of Standard & Poor's 500 Index (S&P 500) by constructing time-series complex networks of S&P 500 underlying companies by connecting them with links whose weights are given by the mutual information of 60-minute price movements of the pairs of the companies with the consecutive 5,340 minutes price records. We showed that the changes in the strength distributions of the networks provide an important information on the network's future movements. We built several metrics using the strength distributions and network measurements such as centrality, and we combined the best two predictors by performing a linear combination. We found that the combined predictor and the changes in S&P 500 show a quadratic relationship, and it allows us to predict the amplitude of the one step future change in S&P 500. The result showed significant fluctuations in S&P 500 Index when the combined predictor was high. In terms of making the actual index predictions, we built ARIMA models. We found that adding the network measurements into the ARIMA models improves the model accuracy. These findings are useful for financial market policy makers as an indicator based on which they can interfere with the markets before the markets make a drastic change, and for quantitative investors to improve their forecasting models.", "link": "http://dx.doi.org/10.1007/s41109-017-0055-y"}, {"index": 790, "title": "Herding boosts too-connected-to-fail risk in stock market of China", "abstract": "The crowd panic and its contagion play non-negligible roles at the time of the stock crash, especially for China where inexperienced investors dominate the market. However, existing models rarely consider investors in networking stocks and accordingly miss the exact knowledge of how panic contagion leads to abrupt crash. In this paper, by networking stocks of sharing common mutual funds, a new methodology of investigating the market crash is presented. It is surprisingly revealed that the herding, which origins in the mimic of seeking for high diversity across investment strategies to lower individual risk, will produce too-connected-to-fail stocks and reluctantly boosts the systemic risk of the entire market. Though too-connected stocks might be relatively stable during the crisis, they are so influential that a small downward fluctuation will cascade to trigger severe drops of massive successor stocks, implying that their falls might be unexpectedly amplified by the collective panic and result in the market crash. Our findings suggest that the whole picture of portfolio strategy has to be carefully supervised to reshape the stock network.", "link": "http://dx.doi.org/10.1016/j.physa.2018.04.020"}, {"index": 791, "title": "Stock Volatility Prediction Using Recurrent Neural Networks with Sentiment Analysis", "abstract": "In this paper, we propose a model to analyze sentiment of online stock forum and use the information to predict the stock volatility in the Chinese market. We have labeled the sentiment of the online financial posts and make the dataset public available for research. By generating a sentimental dictionary based on financial terms, we develop a model to compute the sentimental score of each online post related to a particular stock. Such sentimental information is represented by two sentiment indicators, which are fused to market data for stock volatility prediction by using the Recurrent Neural Networks (RNNs). Empirical study shows that, comparing to using RNN only, the model performs significantly better with sentimental indicators.", "link": "http://arxiv.org/abs/1705.02447v1"}, {"index": 792, "title": "Tales of Emotion and Stock in China: Volatility, Causality and Prediction", "abstract": "How the online social media, like Twitter or its variant Weibo, interacts with the stock market and whether it can be a convincing proxy to predict the stock market have been debated for years, especially for China. As the traditional theory in behavioral finance states, the individual emotions can influence decision-makings of investors, it is reasonable to further explore these controversial topics systematically from the perspective of online emotions, which are richly carried by massive tweets in social media. Through thorough studies on over 10 million stock-relevant tweets and 3 million investors from Weibo, it is revealed that inexperienced investors with high emotional volatility are more sensible to the market fluctuations than the experienced or institutional ones, and their dominant occupation also indicates that the Chinese market might be more emotional as compared to its western counterparts. Then both correlation analysis and causality test demonstrate that five attributes of the stock market in China can be competently predicted by various online emotions, like disgust, joy, sadness and fear. Specifically, the presented prediction model significantly outperforms the baseline model, including the one taking purely financial time series as input features, on predicting five attributes of the stock market under the $K$-means discretization. We also employ this prediction model in the scenario of realistic online application and its performance is further testified.", "link": "http://arxiv.org/abs/1705.00294v1"}, {"index": 793, "title": "Dynamical Analysis of Stock Market Instability by Cross-correlation Matrix", "abstract": "We study stock market instability by using cross-correlations constructed from the return time series of 366 stocks traded on the Tokyo Stock Exchange from January 5, 1998 to December 30, 2013. To investigate the dynamical evolution of the cross-correlations, cross-correlation matrices are calculated with a rolling window of 400 days. To quantify the volatile market stages where the potential risk is high, we apply the principal components analysis and measure the cumulative risk fraction (CRF), which is the system variance associated with the first few principal components. From the CRF, we detected three volatile market stages corresponding to the bankruptcy of Lehman Brothers, the 2011 Tohoku Region Pacific Coast Earthquake, and the FRB QE3 reduction observation in the study period. We further apply the random matrix theory for the risk analysis and find that the first eigenvector is more equally de-localized when the market is volatile.", "link": "http://arxiv.org/abs/1704.08612v1"}, {"index": 794, "title": "Linear and nonlinear correlations in order aggressiveness of Chinese stocks", "abstract": "The diagonal effect of orders is well documented in different markets, which states that orders are more likely to be followed by orders of the same aggressiveness and implies the presence of short-term correlations in order flows. Based on the order flow data of 43 Chinese stocks, we investigate if there are long-range correlations in the time series of order aggressiveness. The detrending moving average analysis shows that there are crossovers in the scaling behaviors of overall fluctuations and order aggressiveness exhibits linear long-term correlations. We design an objective procedure to determine the two Hurst indexes delimited by the crossover scale. We find no correlations in the short term and strong correlations in the long term for all stocks except for an outlier stock. The long-term correlation is found to depend on several firm specific characteristics. We also find that there are nonlinear long-term correlations in the order aggressiveness when we perform the multifractal detrending moving average analysis.", "link": "http://dx.doi.org/10.1142/S0218348X17500414"}, {"index": 795, "title": "The q-dependent detrended cross-correlation analysis of stock market", "abstract": "The properties of q-dependent cross-correlation matrices of stock market have been analyzed by using the random matrix theory and complex network. The correlation structures of the fluctuations at different magnitudes have unique properties. The cross-correlations among small fluctuations are much stronger than those among large fluctuations. The large and small fluctuations are dominated by different groups of stocks. We use complex network representation to study these q-dependent matrices and discover some new identities. By utilizing those q-dependent correlation-based networks, we are able to construct some portfolio by those most independent stocks which consistently perform the best. The optimal multifractal order for portfolio optimization is approximately $q=2$. These results have deepened our understanding about the collective behaviors of the complex financial system.", "link": "http://dx.doi.org/10.1088/1742-5468/aa9db0"}, {"index": 796, "title": "Application of a Shallow Neural Network to Short-Term Stock Trading", "abstract": "Machine learning is increasingly prevalent in stock market trading. Though neural networks have seen success in computer vision and natural language processing, they have not been as useful in stock market trading. To demonstrate the applicability of a neural network in stock trading, we made a single-layer neural network that recommends buying or selling shares of a stock by comparing the highest high of 10 consecutive days with that of the next 10 days, a process repeated for the stock's year-long historical data. A chi-squared analysis found that the neural network can accurately and appropriately decide whether to buy or sell shares for a given stock, showing that a neural network can make simple decisions about the stock market.", "link": "http://arxiv.org/abs/1703.10458v1"}, {"index": 797, "title": "Analysis of Realized Volatility for Nikkei Stock Average on the Tokyo Stock Exchange", "abstract": "We calculate realized volatility of the Nikkei Stock Average (Nikkei225) Index on the Tokyo Stock Exchange and investigate the return dynamics. To avoid the bias on the realized volatility from the non-trading hours issue we calculate realized volatility separately in the two trading sessions, i.e. morning and afternoon, of the Tokyo Stock Exchange and find that the microstructure noise decreases the realized volatility at small sampling frequency. Using realized volatility as a proxy of the integrated volatility we standardize returns in the morning and afternoon sessions and investigate the normality of the standardized returns by calculating variance, kurtosis and 6th moment. We find that variance, kurtosis and 6th moment are consistent with those of the standard normal distribution, which indicates that the return dynamics of the Nikkei Stock Average are well described by a Gaussian random process with time-varying volatility.", "link": "http://dx.doi.org/10.1088/1742-6596/710/1/012010"}, {"index": 798, "title": "Emergence of world-stock-market network", "abstract": "In the age of globalization, it is natural that the stock market of each country is not independent form the other markets. In this case, collective behavior could be emerged form their dependency together. This article studies the collective behavior of a set of forty influential markets in the world economy with the aim of exploring a global financial structure that could be called world-stock-market network. Towards this end, we analyze the cross-correlation matrix of the indices of these forty markets using Random Matrix Theory (RMT). We find the degree of collective behavior among the markets and the share of each market in their structural formation. This finding together with the results obtained from the same calculation on four stock markets reinforce the idea of a world financial market. Finally, we draw the dendrogram of the cross-correlation matrix to make communities in this abstract global market visible. The dendrogram, drawn by at least thirty percent of correlation, shows that the world financial market comprises three communities each of which includes stock markets with geographical proximity.", "link": "http://arxiv.org/abs/1703.08781v1"}, {"index": 799, "title": "Lot sizing problem integrated with cutting stock problem in a paper industry: a multiobjective approach", "abstract": "In this work, we use a multiobjective approach to address the lot sizing problem integrated with the cutting stock problem in a paper industry. We analyze the trade-offs and correlations which exist among the costs and their decision variables. Considering some of our computational results, if we decrease the production costs, then we increase the waste of material of the cutting process and vice versa. Thereby we show the importance of the multiobjective approach in allowing multiple answers to the decision maker, using Pareto optimal solutions set. Several tests were performed to check the quality of our approach.", "link": "http://arxiv.org/abs/1703.03024v2"}, {"index": 800, "title": "Time series momentum and contrarian effects in the Chinese stock market", "abstract": "This paper concentrates on the time series momentum or contrarian effects in the Chinese stock market. We evaluate the performance of the time series momentum strategy applied to major stock indices in mainland China and explore the relation between the performance of time series momentum strategies and some firm-specific characteristics. Our findings indicate that there is a time series momentum effect in the short run and a contrarian effect in the long run in the Chinese stock market. The performances of the time series momentum and contrarian strategies are highly dependent on the look-back and holding periods and firm-specific characteristics.", "link": "http://dx.doi.org/10.1016/j.physa.2017.04.139"}, {"index": 801, "title": "Market Depth and Risk Return Analysis of Dhaka Stock Exchange: An Empirical Test of Market Efficiency", "abstract": "It is customary that when security prices fully reflect all available information, the markets for those securities are said to be efficient. And if markets are inefficient, investors can use available information ignored by the market to earn abnormally high returns on their investments. In this context this paper tries to find evidence supporting the reality of weak-form efficiency of the Dhaka Stock Exchange (DSE) by examining the issues of market risk-return relationship and market depth or liquidity for DSE. The study uses a data set of daily market index and returns for the period of 1994 to 2005 and weekly market capital turnover in proportion of total market capital for the period of 1994 to 2005. The paper also looks about the market risk (systemic risk) and return where it is found that market rate of return of DSE is very low or sometimes negative. Eventually Capital Asset Pricing Model (CAPM), which envisages the relationship between risk and the expected rate of return on a risky security, is found unrelated in DSE market. As proper risk-return relationships of the market is seems to be deficient in DSE and the market is not liquid, interest of the available investors are bring into being very insignificant. All these issues are very noteworthy to the security analysts, investors and security exchange regulatory bodies in their policy making decisions to progress the market condition.", "link": "http://arxiv.org/abs/1702.01354v1"}, {"index": 802, "title": "Assessing of a portion of the Pacific Thunnus albacares stock: Ahi in the Main Hawaiian Islands", "abstract": "Regional tuna fishery management organizations cannot provide specific advice to local fishery managers in small island jurisdictions. The State of Hawaii maintains time series of yellowfin tuna catches dating back to 1949, but these data have never been formally applied to evaluating the effects of the yellowfin fishery in the Main Hawaiian Islands on the local stock. I develop a new approach utilizing these data that links the local stock dynamics to the dynamics of the larger Pacific stock. This approach uses a state-space logistic production model linked to the larger Pacific stock using an index of abundance. The conclusion is that such a model is feasible, that the local stock is not overfished and that local fisheries are fishing at acceptable levels.", "link": "http://arxiv.org/abs/1702.01217v1"}, {"index": 803, "title": "Day of the Week Effect in biotechnology stocks: An Application of the GARCH processes", "abstract": "This study examines the presence of the day-of-the-week effect on daily returns of biotechnology stocks over a 16-year period from January 2002 to December 2015. Using daily returns from the NASDAQ Biotechnology Index (NBI), we find that the stock returns were the lowest on Mondays, and compared to the Mondays the stock returns were significantly higher on Wednesdays, Thursdays, and Fridays. Moreover, the results from using the asymmetric GARCH processes reveal that momentum and small-firm effect were positively associated with the market risk-adjusted returns of the biotechnology stocks during this period. The findings of our study suggest that active portfolio managers need to consider the day of the week, momentum, and small-firm effect when making trading decisions for biotechnology stocks.", "link": "http://arxiv.org/abs/1701.07175v1"}, {"index": 804, "title": "Trading strategies for stock pairs regarding to the cross-impact cost", "abstract": "We extend the framework of trading strategies of Gatheral [2010] from single stocks to a pair of stocks. Our trading strategy with the executions of two round-trip trades can be described by the trading rates of the paired stocks and the ratio of their trading periods. By minimizing the potential cost arising from cross-impacts, i.e., the price change of one stock due to the trades of another stock, we can find out an optimal strategy for executing a sequence of trades from different stocks. We further apply the model of the strategy to a specific case, where we quantify the cross-impacts of traded volumes and of time lag with empirical data for the computation of costs. We thus picture the influence of cross-impacts on the trading strategy.", "link": "http://arxiv.org/abs/1701.03098v3"}, {"index": 805, "title": "Property Safety Stock Policy for Correlated Commodities Based on Probability Inequality", "abstract": "Deriving the optimal safety stock quantity with which to meet customer satisfaction is one of the most important topics in stock management. However, it is difficult to control the stock management of correlated marketable merchandise when using an inventory control method that was developed under the assumption that the demands are not correlated. For this, we propose a deterministic approach that uses a probability inequality to derive a reasonable safety stock for the case in which we know the correlation between various commodities. Moreover, over a given lead time, the relation between the appropriate safety stock and the allowable stockout rate is analytically derived, and the potential of our proposed procedure is validated by numerical experiments.", "link": "http://arxiv.org/abs/1701.02245v1"}, {"index": 806, "title": "Optimal liquidation in a Level-I limit order book for large tick stocks", "abstract": "We propose a framework to study the optimal liquidation strategy in a limit order book for large-tick stocks, with spread equal to one tick. All order book events (market orders, limit orders and cancellations) occur according to independent Poisson processes, with parameters depending on price move directions. Our goal is to maximise the expected terminal wealth of an agent who needs to liquidate her positions within a fixed time horizon. Assuming that the agent trades (through sell limit order or/and sell market order) only when the price moves, we model her liquidation procedure as a semi-Markov decision process, and compute the semi-Markov kernel using Laplace method in the language of queueing theory. The optimal liquidation policy is then solved by dynamic programming, and illustrated numerically.", "link": "http://arxiv.org/abs/1701.01327v3"}, {"index": 807, "title": "The Price of Political Uncertainty: Evidence from the 2016 U.S. Presidential Election and the U.S. Stock Markets", "abstract": "There is bountiful evidence that political uncertainty stemming from presidential elections or doubt about the direction of future policy make financial markets significantly volatile, especially in proximity to close elections or elections that may prompt radical policy changes. Although several studies have examined the association between presidential elections and stock returns, very little attention has been given to the impacts of elections and election induced uncertainty on stock markets. This paper explores, at sectoral level, the uncertain information hypothesis (UIH) as a means of explaining the reaction of markets to the arrival of unanticipated information. This hypothesis postulates that political uncertainty is greater prior to the elections (relative to pre-election period) but is resolved once the outcome of the elections is determined (relative to post-election period). To this end, we adopt an event-study methodology that examines abnormal return behavior around the election date. We show that collapsing stock returns around the election result is reversed by positive abnormal return on the next day, except some cases where we note negative responses following the vote count. Although Trump's win plunges US into uncertain future, positive reactions of abnormal return are found. Therefore, our results do not support the UIH hypothesis. Besides, the effect of political uncertainty is sector-specific. While some sectors emerged winners (healthcare, oil and gas, real estate, defense, financials and consumer goods and services), others took the opposite route (technology and utilities). The winning industries are generally those that will benefit from the new administration's focus on rebuilding infrastructure, renegotiating trade agreements, reforming tax policy and labour laws, increasing defense funding, easing restrictions on energy production, and rolling back Obamacare.", "link": "http://arxiv.org/abs/1612.06200v2"}, {"index": 808, "title": "Evaluating the Performance of ANN Prediction System at Shanghai Stock Market in the Period 21-Sep-2016 to 11-Oct-2016", "abstract": "This research evaluates the performance of an Artificial Neural Network based prediction system that was employed on the Shanghai Stock Exchange for the period 21-Sep-2016 to 11-Oct-2016. It is a follow-up to a previous paper in which the prices were predicted and published before September 21. Stock market price prediction remains an important quest for investors and researchers. This research used an Artificial Intelligence system, being an Artificial Neural Network that is feedforward multi-layer perceptron with error backpropagation for prediction, unlike other methods such as technical, fundamental or time series analysis. While these alternative methods tend to guide on trends and not the exact likely prices, neural networks on the other hand have the ability to predict the real value prices, as was done on this research. Nonetheless, determination of suitable network parameters remains a challenge in neural network design, with this research settling on a configuration of 5:21:21:1 with 80% training data or 4-year of training data as a good enough model for stock prediction, as already determined in a previous research by the author. The comparative results indicate that neural network can predict typical stock market prices with mean absolute percentage errors that are as low as 1.95% over the ten prediction instances that was studied in this research.", "link": "http://arxiv.org/abs/1612.02666v1"}, {"index": 809, "title": "The low-mass population in the young cluster Stock 8: Stellar properties and Initial Mass Function", "abstract": "The evolution of HII regions/supershells can trigger a new generation of stars/clusters at their peripheries, with environmental conditions that may affect the initial mass function, disk evolution and star formation efficiency. In this paper we study the stellar content and star formation processes in the young cluster Stock 8, which itself is thought to be formed during the expansion of a supershell. We present deep optical photometry along with JHK and 3.6, 4.5 {\\mu}m photometry from UKIDSS and Spitzer-IRAC. We use multi-color criteria to identify the candidate young stellar objects in the region. Using evolutionary models, we obtain a median log(age) of ~6.5 (~3.0 Myr) with an observed age spread of ~0.25 dex for the cluster. Monte Carlo simulations of the population of Stock 8, based on estimates for the photometric uncertainty, differential reddening, binarity, and variability, indicate that these uncertainties introduce an age spread of ~0.15 dex. The intrinsic age spread in the cluster is ~0.2 dex. The fraction of young stellar objects surrounded by disk is ~35%. The K-band luminosity function of Stock 8 is similar to that of the Trapezium cluster. The IMF of Stock 8 has a Salpeter- like slope at >0.5 Msun and the IMF flattens and peaks at ~0.4 Msun, below which declines into the substellar regime. Although Stock 8 is surrounded by several massive stars, there seems to be no severe environmental effect in the form of IMF due to the proximity of massive stars around the cluster.", "link": "http://dx.doi.org/10.3847/1538-4357/836/1/98"}, {"index": 810, "title": "Quantifying immediate price impact of trades based on the $k$-shell decomposition of stock trading networks", "abstract": "Traders in a stock market exchange stock shares and form a stock trading network. Trades at different positions of the stock trading network may contain different information. We construct stock trading networks based on the limit order book data and classify traders into $k$ classes using the $k$-shell decomposition method. We investigate the influences of trading behaviors on the price impact by comparing a closed national market (A-shares) with an international market (B-shares), individuals and institutions, partially filled and filled trades, buyer-initiated and seller-initiated trades, and trades at different positions of a trading network. Institutional traders professionally use some trading strategies to reduce the price impact and individuals at the same positions in the trading network have a higher price impact than institutions. We also find that trades in the core have higher price impacts than those in the peripheral shell.", "link": "http://dx.doi.org/10.1209/0295-5075/116/28006"}, {"index": 811, "title": "Immediate price impact of a stock and its warrant: Power-law or logarithmic model?", "abstract": "Based on the order flow data of a stock and its warrant, the immediate price impacts of market orders are estimated by two competitive models, the power-law model (PL model) and the logarithmic model (LG model). We find that the PL model is overwhelmingly superior to the LG model, regarding the robustness of the estimated parameters and the accuracy of out-of-sample forecasting. We also find that the price impacts of ask and bid orders are consistent with each other for filled trades, since significant positive correlations are observed between the model parameters of both types of orders. Our findings may provide valuable insights for optimal trade execution.", "link": "http://dx.doi.org/10.1142/S0217979217500485"}, {"index": 812, "title": "Time-varying return predictability in the Chinese stock market", "abstract": "China's stock market is the largest emerging market all over the world. It is widely accepted that the Chinese stock market is far from efficiency and it possesses possible linear and nonlinear dependence. We study the predictability of returns in the Chinese stock market by employing the wild bootstrap automatic variance ratio test and the generalized spectral test. We find that the return predictability vary over time and significant return predictability is observed around market turmoils. Our findings are consistent with the Adaptive Markets Hypothesis and have practical implications for market participants.", "link": "http://dx.doi.org/10.1142/S2424942417400023"}, {"index": 813, "title": "Emerging interdependence between stock values during financial crashes", "abstract": "To identify emerging interdependencies between traded stocks we investigate the behavior of the stocks of FTSE 100 companies in the period 2000-2015, by looking at daily stock values. Exploiting the power of information theoretical measures to extract direct influences between multiple time series, we compute the information flow across stock values to identify several different regimes. While small information flows is detected in most of the period, a dramatically different situation occurs in the proximity of global financial crises, where stock values exhibit strong and substantial interdependence for a prolonged period. This behavior is consistent with what one would generally expect from a complex system near criticality in physical systems, showing the long lasting effects of crashes on stock markets.", "link": "http://dx.doi.org/10.1371/journal.pone.0176764"}, {"index": 814, "title": "Global carbon stocks and potential emissions due to mangrove deforestation from 2000 to 2012", "abstract": "Mangrove forests store high densities of organic carbon compared to other forested ecosystems. High carbon storage coupled with high rates of deforestation means that mangroves contribute substantially to carbon emissions. Thus, mangroves are candidates for inclusion in Intended Nationally Determined Contributions (INDCs) to the UNFCC Payments for Ecosystem Services (PES) program. This study quantifies two datasets required for INDCs and PES reporting. These are annual mangrove carbon stocks from 2000 to 2012 at the global, national, and sub-national levels and global carbon emissions resulting from deforestation. Mangroves stored 4.19 Pg of carbon in 2012, with Indonesia, Brazil, Malaysia, and Papua New Guinea accounting for greater than 50% of this stock. 2.96 Pg of the global carbon stock is contained within the soil and 1.23 Pg in the living biomass. Two percent of global mangrove carbon was lost between 2000 and 2012, equivalent to a maximum potential of 316,996,250 t of CO2 emissions.", "link": "http://dx.doi.org/10.1038/s41558-018-0090-4"}, {"index": 815, "title": "Sentiment Analysis of Twitter Data for Predicting Stock Market Movements", "abstract": "Predicting stock market movements is a well-known problem of interest. Now-a-days social media is perfectly representing the public sentiment and opinion about current events. Especially, twitter has attracted a lot of attention from researchers for studying the public sentiments. Stock market prediction on the basis of public sentiments expressed on twitter has been an intriguing field of research. Previous studies have concluded that the aggregate public mood collected from twitter may well be correlated with Dow Jones Industrial Average Index (DJIA). The thesis of this work is to observe how well the changes in stock prices of a company, the rises and falls, are correlated with the public opinions being expressed in tweets about that company. Understanding author's opinion from a piece of text is the objective of sentiment analysis. The present paper have employed two different textual representations, Word2vec and N-gram, for analyzing the public sentiments in tweets. In this paper, we have applied sentiment analysis and supervised machine learning principles to the tweets extracted from twitter and analyze the correlation between stock market movements of a company and sentiments in tweets. In an elaborate way, positive news and tweets in social media about a company would definitely encourage people to invest in the stocks of that company and as a result the stock price of that company would increase. At the end of the paper, it is shown that a strong correlation exists between the rise and falls in stock prices with the public sentiments in tweets.", "link": "http://arxiv.org/abs/1610.09225v1"}, {"index": 816, "title": "Two approaches to modeling the interaction of small and medium price-taking traders with a stock exchange by mathematical programming techniques", "abstract": "The paper presents two new approaches to modeling the interaction of small and medium pricetaking traders with a stock exchange. In the framework of these approaches, the traders can form and manage their portfolios of financial instruments traded on a stock exchange with the use of linear, integer, and mixed programming techniques. Unlike previous authors publications on the subject, besides standard securities, the present publication considers derivative financial instruments such as futures and options contracts.", "link": "http://arxiv.org/abs/1610.05703v1"}, {"index": 817, "title": "The Cross-section of Expected Returns on Penny Stocks: Are Low-hanging Fruits Not-so Sweet?", "abstract": "In this paper, we study the determinants of expected returns on the listed penny stocks from two perspectives. Traditionally financial economics literature has been devoted to study the macro and micro determinants of expected returns on stocks (Subrahmanyam, 2010). Very few research has been carried out on penny stocks (Liu, Rhee, & Zhang, 2011; Nofsinger & Verma, 2014). Our study is an effort to contribute more empirical evidence on penny stocks in the emerging market context. We see the return dynamics of penny stocks from corporate governance perspective. Issues such as shareholding patters are considered to be of much significance when it comes to understand the price movements. Using cross-sectional data on 167 penny stocks listed in the National Stock Exchange of India, we show that (i) Returns of portfolio of lower market-cap penny stocks are significantly different(higher) than that of higher market-cap penny stocks. (ii)Returns of portfolio lower P/E stocks are significantly different (higher) than that of higher P/E stocks. Similarly, returns of portfolio of lower P/B stocks are significantly different (higher) than that of higher P/B stocks, and returns of portfolio of lower priced penny stocks are significantly different(higher) than that of higher priced penny stocks. (iii) Trading volume differences due to alphabetism are insignificant. (iv)Differences in returns of portfolios based on beta and shareholding patterns are insignificant.", "link": "http://arxiv.org/abs/1610.01338v1"}, {"index": 818, "title": "Taylor's Law of temporal fluctuation scaling in stock illiquidity", "abstract": "Taylor's law of temporal fluctuation scaling, variance $\\sim$ $a($mean$)^b$, is ubiquitous in natural and social sciences. We report for the first time convincing evidence of a solid temporal fluctuation scaling law in stock illiquidity by investigating the mean-variance relationship of the high-frequency illiquidity of almost all stocks traded on the Shanghai Stock Exchange (SHSE) and the Shenzhen Stock Exchange (SZSE) during the period from 1999 to 2011. Taylor's law holds for A-share markets (SZSE Main Board, SZSE Small & Mediate Enterprise Board, SZSE Second Board, and SHSE Main Board) and B-share markets (SZSE B-share and SHSE B-share). We find that the scaling exponent $b$ is greater than 2 for the A-share markets and less than 2 for the B-share markets. We further unveil that Taylor's law holds for stocks in 17 industry categories, in 28 industrial sectors and in 31 provinces and direct-controlled municipalities with the majority of scaling exponents $b\\in(2,3)$. We also investigate the $\\Delta{t}$-min illiquidity and find that the scaling exponent $b(\\Delta{t})$ increases logarithmically for small $\\Delta{t}$ values and decreases fast to a stable level.", "link": "http://dx.doi.org/10.1142/S0219477516500292"}, {"index": 819, "title": "Modelling Stock-market Investors as Reinforcement Learning Agents [Correction]", "abstract": "Decision making in uncertain and risky environments is a prominent area of research. Standard economic theories fail to fully explain human behaviour, while a potentially promising alternative may lie in the direction of Reinforcement Learning (RL) theory. We analyse data for 46 players extracted from a financial market online game and test whether Reinforcement Learning (Q-Learning) could capture these players behaviour using a risk measure based on financial modeling. Moreover we test an earlier hypothesis that players are \"na\\\"ive\" (short-sighted). Our results indicate that a simple Reinforcement Learning model which considers only the selling component of the task captures the decision-making process for a subset of players but this is not sufficient to draw any conclusion on the population. We also find that there is not a significant improvement of fitting of the players when using a full RL model against a myopic version, where only immediate reward is valued by the players. This indicates that players, if using a Reinforcement Learning approach, do so na\\\"ively", "link": "http://dx.doi.org/10.1109/EAIS.2015.7368789"}, {"index": 820, "title": "Choosing the observational likelihood in state-space stock assessment models", "abstract": "Data used in stock assessment models result from combinations of biological, ecological, fishery, and sampling processes. Since different types of errors propagate through these processes it can be difficult to identify a particular family of distributions for modelling errors on observations a priori. By implementing several observational likelihoods, modelling both numbers- and proportions-at-age, in an age based state-space stock assessment model, we compare the model fit for each choice of likelihood along with the implications for spawning stock biomass and average fishing mortality. We propose using AIC intervals based on fitting the full observational model for comparing different observational likelihoods. Using data from four stocks, we show that the model fit is improved by modelling the correlation of observations within years. However, the best choice of observational likelihood differs for different stocks, and the choice is important for the short-term conclusions drawn from the assessment model; in particular, the choice can influence total allowable catch advise based on reference points.", "link": "http://dx.doi.org/10.1139/cjfas-2015-0532"}, {"index": 821, "title": "Predicting Future Shanghai Stock Market Price using ANN in the Period 21-Sep-2016 to 11-Oct-2016", "abstract": "Predicting the prices of stocks at any stock market remains a quest for many investors and researchers. Those who trade at the stock market tend to use technical, fundamental or time series analysis in their predictions. These methods usually guide on trends and not the exact likely prices. It is for this reason that Artificial Intelligence systems, such as Artificial Neural Network, that is feedforward multi-layer perceptron with error backpropagation, can be used for such predictions. A difficulty in neural network application is the determination of suitable network parameters. A previous research by the author already determined the network parameters as 5:21:21:1 with 80% training data or 4-year of training data as a good enough model for stock prediction. This model has been put to the test in predicting selected Shanghai Stock Exchange stocks in the future period of 21-Sep-2016 to 11-Oct-2016, about one week after the publication of these predictions. The research aims at confirming that simple neural network systems can be quite powerful in typical stock market predictions.", "link": "http://arxiv.org/abs/1609.05394v1"}, {"index": 822, "title": "Microscopic Understanding of Cross-Responses between Stocks: a Two-Component Price Impact Model", "abstract": "We construct a price impact model between stocks in a correlated market. For the price change of a given stock induced by the short-run liquidity of this stock itself and of the information about other stocks, we introduce a self- and a cross-impact function of the time lag. We model the average cross-response functions for individual stocks employing the impact functions of the time lag, the impact functions of traded volumes and the trade-sign correlators. To quantify the self- and cross-impacts, we propose a construction to fix the parameters in the impact functions. These parameters are further corroborated by a diffusion function that measures the correlated motion of prices from different stocks. This construction is mainly ad hoc and alternative ones are not excluded. It turns out that both the sign cross- and self-correlators are connected with the cross-responses. The self- and cross-impact functions are indispensable to compensate amplification effects which are due to the sign correlators integrated over time. We further quantify and interpret the price impacts of time lag in terms of temporary and permanent components. To support our model, we also analyze empirical data, in particular the memory properties of the sign self- and average cross-correlators. The relation between the average cross-responses and the traded volumes which are smaller than their average is of power-law form.", "link": "http://dx.doi.org/10.1142/S2382626618500090"}, {"index": 823, "title": "Covariance of random stock prices in the Stochastic Dividend Discount Model", "abstract": "Dividend discount models have been developed in a deterministic setting. Some authors (Hurley and Johnson, 1994 and 1998; Yao, 1997) have introduced randomness in terms of stochastic growth rates, delivering closed-form expressions for the expected value of stock prices. This paper extends such previous results by determining a formula for the covariance between random stock prices when the dividends' rates of growth are correlated. The formula is eventually applied to real market data.", "link": "http://arxiv.org/abs/1609.03029v2"}, {"index": 824, "title": "Dissecting cross-impact on stock markets: An empirical analysis", "abstract": "The vast majority of market impact studies assess each product individually, and the interactions between the different order flows are disregarded. This strong approximation may lead to an underestimation of trading costs and possible contagion effects. Transactions in fact mediate a significant part of the correlation between different instruments. In turn, liquidity shares the sectorial structure of market correlations, which can be encoded as a set of eigenvalues and eigenvectors. We introduce a multivariate linear propagator model that successfully describes such a structure, and accounts for a significant fraction of the covariance of stock returns. We dissect the various dynamical mechanisms that contribute to the joint dynamics of assets. We also define two simplified models with substantially less parameters in order to reduce overfitting, and show that they have superior out-of-sample performance.", "link": "http://dx.doi.org/10.1088/1742-5468/aa53f7"}, {"index": 825, "title": "Quantile Dependence between Stock Markets and its Application in Volatility Forecasting", "abstract": "This paper examines quantile dependence between international stock markets and evaluates its use for improving volatility forecasting. First, we analyze quantile dependence and directional predictability between the US stock market and stock markets in the UK, Germany, France and Japan. We use the cross-quantilogram, which is a correlation statistic of quantile hit processes. The detailed dependence between stock markets depends on specific quantile ranges and this dependence is generally asymmetric; the negative spillover effect is stronger than the positive spillover effect and there exists strong directional predictability from the US market to the UK, Germany, France and Japan markets. Second, we consider a simple quantile-augmented volatility model that accommodates the quantile dependence and directional predictability between the US market and these other markets. The quantile-augmented volatility model provides superior in-sample and out-of-sample volatility forecasts.", "link": "http://arxiv.org/abs/1608.07193v1"}, {"index": 826, "title": "Nonstationary Spatial Prediction of Soil Organic Carbon: Implications for Stock Assessment Decision Making", "abstract": "The Rapid Carbon Assessment (RaCA) project was conducted by the US Department of Agriculture's National Resources Conservation Service between 2010-2012 in order to provide contemporaneous measurements of soil organic carbon (SOC) across the US. Despite the broad extent of the RaCA data collection effort, direct observations of SOC are not available at the high spatial resolution needed for studying carbon storage in soil and its implications for important problems in climate science and agriculture. As a result, there is a need for predicting SOC at spatial locations not included as part of the RaCA project. In this paper, we compare spatial prediction of SOC using a subset of the RaCA data for a variety of statistical methods. We investigate the performance of methods with off-the-shelf software available (both stationary and nonstationary) as well as a novel nonstationary approach based on partitioning relevant spatially-varying covariate processes. Our new method addresses open questions regarding (1) how to partition the spatial domain for segmentation-based nonstationary methods, (2) incorporating partially observed covariates into a spatial model, and (3) accounting for uncertainty in the partitioning. In applying the various statistical methods we find that there are minimal differences in out-of-sample criteria for this particular data set, however, there are major differences in maps of uncertainty in SOC predictions. We argue that the spatially-varying measures of prediction uncertainty produced by our new approach are valuable to decision makers, as they can be used to better benchmark mechanistic models, identify target areas for soil restoration projects, and inform carbon sequestration projects.", "link": "http://arxiv.org/abs/1608.05655v5"}, {"index": 827, "title": "Time-scale effects on the gain-loss asymmetry in stock indices", "abstract": "The gain-loss asymmetry, observed in the inverse statistics of stock indices is present for logarithmic return levels that are over $2\\%$, and it is the result of the non-Pearson type auto-correlations in the index. These non-Pearson type correlations can be viewed also as functionally dependent daily volatilities, extending for a finite time interval. A generalized time-window shuffling method is used to show the existence of such auto-correlations. Their characteristic time-scale proves to be smaller (less than $25$ trading days) than what was previously believed. It is also found that this characteristic time-scale has decreased with the appearance of program trading in the stock market transactions. Connections with the leverage effect are also established.", "link": "http://dx.doi.org/10.1103/PhysRevE.94.022311"}, {"index": 828, "title": "Dynamic structure of stock communities: A comparative study between stock returns and turnover rates", "abstract": "The detection of community structure in stock market is of theoretical and practical significance for the study of financial dynamics and portfolio risk estimation. We here study the community structures in Chinese stock markets from the aspects of both price returns and turnover rates, by using a combination of the PMFG and infomap methods based on a distance matrix. We find that a few of the largest communities are composed of certain specific industry or conceptional sectors and the correlation inside a sector is generally larger than the correlation between different sectors. In comparison with returns, the community structure for turnover rates is more complex and the sector effect is relatively weaker. The financial dynamics is further studied by analyzing the community structures over five sub-periods. Sectors like banks, real estate, health care and New Shanghai take turns to compose a few of the largest communities for both returns and turnover rates in different sub-periods. Several specific sectors appear in the communities with different rank orders for the two time series even in the same sub-period. A comparison between the evolution of prices and turnover rates of stocks from these sectors is conducted to better understand their differences. We find that stock prices only had large changes around some important events while turnover rates surged after each of these events relevant to specific sectors, which may offer a possible explanation for the complexity of stock communities for turnover rates.", "link": "http://dx.doi.org/10.1140/epjb/e2017-70625-7"}, {"index": 829, "title": "Sectoral co-movements in the Indian stock market: A mesoscopic network analysis", "abstract": "In this article we review several techniques to extract information from stock market data. We discuss recurrence analysis of time series, decomposition of aggregate correlation matrices to study co-movements in financial data, stock level partial correlations with market indices, multidimensional scaling and minimum spanning tree. We apply these techniques to daily return time series from the Indian stock market. The analysis allows us to construct networks based on correlation matrices of individual stocks in one hand and on the other, we discuss dynamics of market indices. Thus both micro level and macro level dynamics can be analyzed using such tools. We use the multi-dimensional scaling methods to visualize the sectoral structure of the stock market, and analyze the comovements among the sectoral stocks. Finally, we construct a mesoscopic network based on sectoral indices. Minimum spanning tree technique is seen to be extremely useful in order to separate technologically related sectors and the mapping corresponds to actual production relationship to a reasonable extent.", "link": "http://arxiv.org/abs/1607.05514v1"}, {"index": 830, "title": "Stock Market Market Crash of 2008: an empirical study of the deviation of share prices from company fundamentals", "abstract": "The aim of this study is to investigate quantitatively whether share prices deviated from company fundamentals in the stock market crash of 2008. For this purpose, we use a large database containing the balance sheets and share prices of 7,796 worldwide companies for the period 2004 through 2013. We develop a panel regression model using three financial indicators--dividends per share, cash flow per share, and book value per share--as explanatory variables for share price. We then estimate individual company fundamentals for each year by removing the time fixed effects from the two-way fixed effects model, which we identified as the best of the panel regression models. One merit of our model is that we are able to extract unobservable factors of company fundamentals by using the individual fixed effects.   Based on these results, we analyze the market anomaly quantitatively using the divergence rate--the rate of the deviation of share price from a company's fundamentals. We find that share prices on average were overvalued in the period from 2005 to 2007, and were undervalued significantly in 2008, when the global financial crisis occurred. Share prices were equivalent to the fundamentals on average in the subsequent period. Our empirical results clearly demonstrate that the worldwide stock market fluctuated excessively in the time period before and just after the global financial crisis of 2008.", "link": "http://dx.doi.org/10.1080/13504851.2018.1486004"}, {"index": 831, "title": "Stock trend prediction using news sentiment analysis", "abstract": "Efficient Market Hypothesis is the popular theory about stock prediction. With its failure much research has been carried in the area of prediction of stocks. This project is about taking non quantifiable data such as financial news articles about a company and predicting its future stock trend with news sentiment classification. Assuming that news articles have impact on stock market, this is an attempt to study relationship between news and stock trend. To show this, we created three different classification models which depict polarity of news articles being positive or negative. Observations show that RF and SVM perform well in all types of testing. Na\\\"ive Bayes gives good result but not compared to the other two. Experiments are conducted to evaluate various aspects of the proposed model and encouraging results are obtained in all of the experiments. The accuracy of the prediction model is more than 80% and in comparison with news random labeling with 50% of accuracy; the model has increased the accuracy by 30%.", "link": "http://arxiv.org/abs/1607.01958v1"}, {"index": 832, "title": "Taking stock of SLSN and LGRB host galaxy comparison using a complete sample of LGRBs", "abstract": "Long gamma-ray bursts (LGRBs) and superluminous supernovae (SLSNe) are both explosive transients with very massive progenitor stars. Clues about the nature of the progenitors can be found by investigating environments in which such transients occur. While studies of LGRB host galaxies have a long history, dedicated observational campaigns have only recently resulted in a high enough number of photometrically and spectroscopically observed SLSN hosts to allow statistically significant analysis of their properties. In this paper we make a comparison of the host galaxies of hydrogen-poor (H-poor) SLSNe and the Swift/BAT6 sample of LGRBs. In contrast to previous studies we use a complete sample of LGRBs and we address a special attention to the comparison methodology and the selection of SLSN sample whose data have been compiled from the available literature. At intermediate redshifts (0.3 < z < 0.7) the two classes of transients select galaxies whose properties (stellar mass, luminosity, star-formation rate, specific star-formation rate and metallicity) do not differ on average significantly. Moreover, the host galaxies of both classes of objects follow the fundamental metallicity relation and the fundamental plane of metallicity. In contrast to previous studies we show that at intermediate redshifts the emission line equivalent widths of the two populations are essentially the same and that the previous claims regarding the higher fraction of SLSN hosts among the extreme emission line galaxies with respect to LGRBs are mostly due to a larger fraction of strong-line emitters among SLSN hosts at z < 0.3, where samples of LGRB hosts are small and poorly defined.", "link": "http://dx.doi.org/10.1051/0004-6361/201628603"}, {"index": 833, "title": "Stock Market Insider Trading in Continuous Time with Imperfect Dynamic Information", "abstract": "This paper studies the equilibrium pricing of asset shares in the presence of dynamic private information. The market consists of a risk-neutral informed agent who observes the firm value, noise traders, and competitive market makers who set share prices using the total order flow as a noisy signal of the insider's information. I provide a characterization of all optimal strategies, and prove existence of both Markovian and non Markovian equilibria by deriving closed form solutions for the optimal order process of the informed trader and the optimal pricing rule of the market maker. The consideration of non Markovian equilibrium is relevant since the market maker might decide to re-weight past information after receiving a new signal. Also, I show that a) there is a unique Markovian equilibrium price process which allows the insider to trade undetected, and that b) the presence of an insider increases the market informational efficiency, in particular for times close to dividend payment.", "link": "http://arxiv.org/abs/1607.00035v1"}, {"index": 834, "title": "Minimum cost polygon overlay with rectangular shape stock panels", "abstract": "Minimum Cost Polygon Overlay (MCPO) is a unique two-dimensional optimization problem that involves the task of covering a polygon shaped area with a series of rectangular shaped panels. This has a number of applications in the construction industry. This work examines the MCPO problem in order to construct a model that captures essential parameters of the problem to be solved automatically using numerical optimization algorithms. Three algorithms have been implemented of the actual optimization task: the greedy search, the Monte Carlo (MC) method, and the Genetic Algorithm (GA). Results are presented to show the relative effectiveness of the algorithms. This is followed by critical analysis of various findings of this research.", "link": "http://dx.doi.org/10.1080/15578770802494516"}, {"index": 835, "title": "The study of Thai stock market across the 2008 financial crisis", "abstract": "The cohomology theory for financial market can allow us to deform Kolmogorov space of time series data over time period with the explicit definition of eight market states in grand unified theory. The anti-de Sitter space induced from a coupling behavior field among traders in case of a financial market crash acts like gravitational field in financial market spacetime. Under this hybrid mathematical superstructure, we redefine a behavior matrix by using Pauli matrix and modified Wilson loop for time series data. We use it to detect the 2008 financial market crash by using a degree of cohomology group of sphere over tensor field in correlation matrix over all possible dominated stocks underlying Thai SET50 Index Futures. The empirical analysis of financial tensor network was performed with the help of empirical mode decomposition and intrinsic time scale decomposition of correlation matrix and the calculation of closeness centrality of planar graph.", "link": "http://dx.doi.org/10.1016/j.physa.2016.06.078"}, {"index": 836, "title": "One-dimensional Cutting Stock Problem with Divisible Items", "abstract": "This paper considers the one-dimensional cutting stock problem with divisible items, which is a new problem in the cutting stock literature. The problem exists in steel industries. In the new problem, each item can be divided into smaller pieces, then they can be recombined again by welding. The objective is to minimize both the trim loss and the number of the welds. We present a mathematical model and a dynamic programming based heuristic for the problem. Furthermore, a software, which is based on the proposed heuristic algorithm, is developed to use in MKA company, and its performance is analyzed by solving real-life problems in the steel industry. The computational experiments show the efficiency of the proposed algorithm.", "link": "http://arxiv.org/abs/1606.01419v1"}, {"index": 837, "title": "Discrete Wavelet Transform-Based Prediction of Stock Index: A Study on National Stock Exchange Fifty Index", "abstract": "Financial Times Series such as stock price and exchange rates are, often, non-linear and non-stationary. Use of decomposition models has been found to improve the accuracy of predictive models. The paper proposes a hybrid approach integrating the advantages of both decomposition model (namely, Maximal Overlap Discrete Wavelet Transform (MODWT)) and machine learning models (ANN and SVR) to predict the National Stock Exchange Fifty Index. In first phase, the data is decomposed into a smaller number of subseries using MODWT. In next phase, each subseries is predicted using machine learning models (i.e., ANN and SVR). The predicted subseries are aggregated to obtain the final forecasts. In final stage, the effectiveness of the proposed approach is evaluated using error measures and statistical test. The proposed methods (MODWT-ANN and MODWT-SVR) are compared with ANN and SVR models and, it was observed that the return on investment obtained based on trading rules using predicted values of MODWT-SVR model was higher than that of Buy-and-hold strategy.", "link": "http://arxiv.org/abs/1605.07278v1"}, {"index": 838, "title": "The impact of the financial crisis on the long-range memory of European corporate bond and stock markets", "abstract": "This paper investigates the presence of long memory in corporate bond and stock indices of six European Union countries from July 1998 to February 2015. We compute the Hurst exponent by means of the DFA method and using a sliding window in order to measure long range dependence. We detect that Hurst exponents behave differently in the stock and bond markets, being smoother in the stock indices than in the bond indices. We verify that the level of informational efficiency is time-varying. Moreover we find an asymmetric impact of the 2008 financial crisis in the fixed income and the stock markets, affecting the former but not the latter. Similar results are obtained using the R/S method.", "link": "http://dx.doi.org/10.1007/s10663-016-9340-8"}, {"index": 839, "title": "Signal Regression Models for Location, Scale and Shape with an Application to Stock Returns", "abstract": "We discuss scalar-on-function regression models where all parameters of the assumed response distribution can be modeled depending on covariates. We thus combine signal regression models with generalized additive models for location, scale and shape (GAMLSS). We compare two fundamentally different methods for estimation, a gradient boosting and a penalized likelihood based approach, and address practically important points like identifiability and model choice. Estimation by a component-wise gradient boosting algorithm allows for high dimensional data settings and variable selection. Estimation by a penalized likelihood based approach has the advantage of directly provided statistical inference. The motivating application is a time series of stock returns where it is of interest to model both the expectation and the variance depending on lagged response values and functional liquidity curves.", "link": "http://arxiv.org/abs/1605.04281v1"}, {"index": 840, "title": "Predicting the direction of stock market prices using random forest", "abstract": "Predicting trends in stock market prices has been an area of interest for researchers for many years due to its complex and dynamic nature. Intrinsic volatility in stock market across the globe makes the task of prediction challenging. Forecasting and diffusion modeling, although effective can't be the panacea to the diverse range of problems encountered in prediction, short-term or otherwise. Market risk, strongly correlated with forecasting errors, needs to be minimized to ensure minimal risk in investment. The authors propose to minimize forecasting error by treating the forecasting problem as a classification problem, a popular suite of algorithms in Machine learning. In this paper, we propose a novel way to minimize the risk of investment in stock market by predicting the returns of a stock using a class of powerful machine learning algorithms known as ensemble learning. Some of the technical indicators such as Relative Strength Index (RSI), stochastic oscillator etc are used as inputs to train our model. The learning model used is an ensemble of multiple decision trees. The algorithm is shown to outperform existing algo- rithms found in the literature. Out of Bag (OOB) error estimates have been found to be encouraging. Key Words: Random Forest Classifier, stock price forecasting, Exponential smoothing, feature extraction, OOB error and convergence.", "link": "http://arxiv.org/abs/1605.00003v1"}, {"index": 841, "title": "Can Online Emotions Predict the Stock Market in China?", "abstract": "Whether the online social media, like Twitter or its variant Weibo, can be a convincing proxy to predict the stock market has been debated for years, especially for China. However, as the traditional theory in behavioral finance states, the individual emotions can influence decision-making of investors, so it is reasonable to further explore this controversial topic from the perspective of online emotions, which is richly carried by massive tweets in social media. Surprisingly, through thorough study on over 10 million stock-relevant tweets from Weibo, both correlation analysis and causality test show that five attributes of the stock market in China can be competently predicted by various online emotions, like disgust, joy, sadness and fear. Specifically, the presented model significantly outperforms the baseline solutions on predicting five attributes of the stock market under the $K$-means discretization. We also employ this model in the scenario of realistic online application and its performance is further testified.", "link": "http://arxiv.org/abs/1604.07529v2"}, {"index": 842, "title": "Using Clustering Method to Understand Indian Stock Market Volatility", "abstract": "In this paper we use Clustering Method to understand whether stock market volatility can be predicted at all, and if so, when it can be predicted. The exercise has been performed for the Indian stock market on daily data for two years. For our analysis we map number of clusters against number of variables. We then test for efficiency of clustering. Our contention is that, given a fixed number of variables, one of them being historic volatility of NIFTY returns, if increase in the number of clusters improves clustering efficiency, then volatility cannot be predicted. Volatility then becomes random as, for a given time period, it gets classified in various clusters. On the other hand, if efficiency falls with increase in the number of clusters, then volatility can be predicted as there is some homogeneity in the data. If we fix the number of clusters and then increase the number of variables, this should have some impact on clustering efficiency. Indeed if we can hit upon, in a sense, an optimum number of variables, then if the number of clusters is reasonably small, we can use these variables to predict volatility. The variables that we consider for our study are volatility of NIFTY returns, volatility of gold returns, India VIX, CBOE VIX, volatility of crude oil returns, volatility of DJIA returns, volatility of DAX returns, volatility of Hang Seng returns and volatility of Nikkei returns. We use three clustering algorithms namely Kernel K-Means, Self Organizing Maps and Mixture of Gaussian models and two internal clustering validity measures, Silhouette Index and Dunn Index, to assess the quality of generated clusters.", "link": "http://dx.doi.org/10.5120/cae2015651793"}, {"index": 843, "title": "Forecasting Volatility in Indian Stock Market using Artificial Neural Network with Multiple Inputs and Outputs", "abstract": "Volatility in stock markets has been extensively studied in the applied finance literature. In this paper, Artificial Neural Network models based on various back propagation algorithms have been constructed to predict volatility in the Indian stock market through volatility of NIFTY returns and volatility of gold returns. This model considers India VIX, CBOE VIX, volatility of crude oil returns (CRUDESDR), volatility of DJIA returns (DJIASDR), volatility of DAX returns (DAXSDR), volatility of Hang Seng returns (HANGSDR) and volatility of Nikkei returns (NIKKEISDR) as predictor variables. Three sets of experiments have been performed over three time periods to judge the effectiveness of the approach.", "link": "http://dx.doi.org/10.5120/21245-4034"}, {"index": 844, "title": "A Framework for Predictive Analysis of Stock Market Indices : A Study of the Indian Auto Sector", "abstract": "Analysis and prediction of stock market time series data has attracted considerable interest from the research community over the last decade. Rapid development and evolution of sophisticated algorithms for statistical analysis of time series data, and availability of high-performance hardware has made it possible to process and analyze high volume stock market time series data effectively, in real-time. Among many other important characteristics and behavior of such data, forecasting is an area which has witnessed considerable focus. In this work, we have used time series of the index values of the Auto sector in India during January 2010 to December 2015 for a deeper understanding of the behavior of its three constituent components, e.g., the trend, the seasonal component, and the random component. Based on this structural analysis, we have also designed five approaches for forecasting and also computed their accuracy in prediction using suitably chosen training and test data sets. Extensive results are presented to demonstrate the effectiveness of our proposed decomposition approaches of time series and the efficiency of our forecasting techniques, even in presence of a random component and a sharply changing trend component in the time-series.", "link": "http://arxiv.org/abs/1604.04044v1"}, {"index": 845, "title": "Investigation Into The Effectiveness Of Long Short Term Memory Networks For Stock Price Prediction", "abstract": "The effectiveness of long short term memory networks trained by backpropagation through time for stock price prediction is explored in this paper. A range of different architecture LSTM networks are constructed trained and tested.", "link": "http://arxiv.org/abs/1603.07893v3"}, {"index": 846, "title": "The geometric phase of stock trading", "abstract": "Geometric phases describe how in a continuous-time dynamical system the displacement of a variable (called phase variable) can be related to other variables (shape variables) undergoing a cyclic motion, according to an area rule. The aim of this paper is to show that geometric phases can exist also for discrete-time systems, and even when the cycles in shape space have zero area. A context in which this principle can be applied is stock trading. A zero-area cycle in shape space represents the type of trading operations normally carried out by high-frequency traders (entering and exiting a position on a fast time-scale), while the phase variable represents the cash balance of a trader. Under the assumption that trading impacts stock prices, even zero-area cyclic trading operations can induce geometric phases, i.e., profits or losses, without affecting the stock quote.", "link": "http://dx.doi.org/10.1371/journal.pone.0161538"}, {"index": 847, "title": "Stock Selection as a Problem in Phylogenetics -- Evidence from the ASX", "abstract": "We report the results of fifteen sets of portfolio selection simulations using stocks in the ASX200 index for the period May 2000 to December 2013. We investigated five portfolio selection methods, randomly and from within industrial groups, and three based on neighbor-Net phylogenetic networks. We report that using random, industrial groups, or neighbor-Net phylogenetic networks alone rarely produced statistically significant reduction in risk, though in four out of the five cases in which it did so, the portfolios selected using the phylogenetic networks had the lowest risk. However, we report that when using the neighbor-Net phylogenetic networks in combination with industry group selection that substantial reductions in portfolio return spread were achieved.", "link": "http://arxiv.org/abs/1603.02354v1"}, {"index": 848, "title": "Cross-response in correlated financial markets: individual stocks", "abstract": "Previous studies of the stock price response to trades focused on the dynamics of single stocks, i.e. they addressed the self-response. We empirically investigate the price response of one stock to the trades of other stocks in a correlated market, i.e. the cross-responses. How large is the impact of one stock on others and vice versa? -- This impact of trades on the price change across stocks appears to be transient instead of permanent as we discuss from the viewpoint of market efficiency. Furthermore, we compare the self-responses on different scales and the self- and cross-responses on the same scale. We also find that the cross-correlation of the trade signs turns out to be a short-memory process.", "link": "http://dx.doi.org/10.1140/epjb/e2016-60818-y"}, {"index": 849, "title": "Stock prices, inflation and inflation uncertainty in the U.S.: Testing the long-run relationship considering Dow Jones sector indexes", "abstract": "We test for the long-run relationship between stock prices, inflation and its uncertainty for different U.S. sector stock indexes, over the period 2002M7 to 2015M10. For this purpose we use a cointegration analysis with one structural break to capture the crisis effect, and we assess the inflation uncertainty based on a time-varying unobserved component model. In line with recent empirical studies we discover that in the long-run, the inflation and its uncertainty negatively impact the stock prices, opposed to the well-known Fisher effect. In addition we show that for several sector stock indexes the negative effect of inflation and its uncertainty vanishes after the crisis setup. However, in the short-run the results provide evidence in the favor of a negative impact of uncertainty, while the inflation has no significant influence on stock prices, except for the consumption indexes. The consideration of business cycle effects confirms our findings, which proves that the results are robust, both for the long-and the short-run relationships.", "link": "http://arxiv.org/abs/1603.01231v1"}, {"index": 850, "title": "Equity forecast: Predicting long term stock price movement using machine learning", "abstract": "Long term investment is one of the major investment strategies. However, calculating intrinsic value of some company and evaluating shares for long term investment is not easy, since analyst have to care about a large number of financial indicators and evaluate them in a right manner. So far, little help in predicting the direction of the company value over the longer period of time has been provided from the machines. In this paper we present a machine learning aided approach to evaluate the equity's future price over the long time. Our method is able to correctly predict whether some company's value will be 10% higher or not over the period of one year in 76.5% of cases.", "link": "http://dx.doi.org/10.1453/jel.v3i2.750"}, {"index": 851, "title": "Protecting suppliers' private information: the case of stock levels and the impact of correlated items", "abstract": "A marketplace is defined where the private data of suppliers (e.g., prosumers) are protected, so that neither their identity nor their level of stock is made known to end customers, while they can sell their products at a reduced price. A broker acts as an intermediary, which takes care of providing the items missing to meet the customers' demand and allows end customers to take advantages of reduced prices through the subscription of option contracts. Formulas are provided for the option price under three different probability models for the availability of items. Option pricing allows the broker to partially transfer its risk on end customers.", "link": "http://arxiv.org/abs/1603.00182v1"}, {"index": 852, "title": "Contagion in the world's stock exchanges seen as a set of coupled oscillators", "abstract": "We study how the phenomenon of contagion can take place in the network of the world's stock exchanges due to the behavioral trait \"blindeness to small changes\". On large scale individual, the delay in the collective response may significantly change the dynamics of the overall system. We explicitely insert a term describing the behavioral phenomenon in a system of equations that describe the build and release of stress across the worldwide stock markets. In the mathematical formulation of the model, each stock exchange acts as an integrate-and-fire oscillator. Calibration on market data validate the model.   One advantage of the integrate-and-fire dynamics is that it enables for a direct identification of cause and effect of price movements, without the need for statistical tests such as for example Granger causality tests often used in the identification of causes of contagion. Our methodology can thereby identify the most relevant nodes with respect to onset of contagion in the network of stock exchanges, as well as identify potential periods of high vulnerability of the network. The model is characterized by a separation of time scales created by a slow build up of stresses, for example due to (say monthly/yearly) macroeconomic factors, and then a fast (say hourly/daily) release of stresses through \"price-quakes\" of price movements across the worlds network of stock exchanges.", "link": "http://arxiv.org/abs/1602.07452v1"}, {"index": 853, "title": "Modeling Stock Price Dynamics with Fuzzy Opinion Networks", "abstract": "We propose a mathematical model for the word-of-mouth communications among stock investors through social networks and explore how the changes of the investors' social networks influence the stock price dynamics and vice versa. An investor is modeled as a Gaussian fuzzy set (a fuzzy opinion) with the center and standard deviation as inputs and the fuzzy set itself as output. Investors are connected in the following fashion: the center input of an investor is taken as the average of the neighbors' outputs, where two investors are neighbors if their fuzzy opinions are close enough to each other, and the standard deviation (uncertainty) input is taken with local, global or external reference schemes to model different scenarios of how investors define uncertainties. The centers and standard deviations of the fuzzy opinions are the expected prices and their uncertainties, respectively, that are used as inputs to the price dynamic equation. We prove that with the local reference scheme the investors converge to different groups in finite time, while with the global or external reference schemes all investors converge to a consensus within finite time and the consensus may change with time in the external reference case. We show how to model trend followers, contrarians and manipulators within this mathematical framework and prove that the biggest enemy of a manipulator is the other manipulators. We perform Monte Carlo simulations to show how the model parameters influence the price dynamics, and we apply a modified version of the model to the daily closing prices of fifteen top banking and real estate stocks in Hong Kong for the recent two years from Dec. 5, 2013 to Dec. 4, 2015 and discover that a sharp increase of the combined uncertainty is a reliable signal to predict the reversal of the current price trend.", "link": "http://arxiv.org/abs/1602.06213v1"}, {"index": 854, "title": "A study of co-movements between oil price, stock index and exchange rate under a cross-bicorrelation perspective: the case of Mexico", "abstract": "In this chapter we studied the nonlinear co-movements between the Mexican Crude Oil price, the Mexican Stock Market Index and the USD/MXN Exchange Rate, for the sample period from 1994 to date. We used a battery of nonlinear tests, cf. (Patterson & Ashley, 2000) and one multivariate test, in order to determine the dynamic co-movement exerted from the oil prices to the stock and exchange rate markets. Such co-movement and time windows are exposed using the Brooks & Hinich (1999) cross- bicorrelation statistical test. The effects of oil spills on other markets have been studied from different angles and on several financial assets. In this study, we focus our attention on the detection, not only of the correlations amongst markets but on the epochs in which such nonlinear dependence might occur. This is important in order to understand better, how the markets that drive the economy interact with each other. We hope to contribute to the literature with such findings, filling a gap in the emerging markets context, in particular, for the Mexican case.", "link": "http://arxiv.org/abs/1602.03271v1"}, {"index": 855, "title": "Stock loans with liquidation", "abstract": "We derive a \"semi-analytic\" solution for a stock loan in which the lender forces liquidation when the loan-to-collateral ratio drops beneath a certain threshold. We use this to study the sensitivity of the contract to model parameters.", "link": "http://arxiv.org/abs/1602.00619v2"}, {"index": 856, "title": "Expert Opinions and Logarithmic Utility Maximization for Multivariate Stock Returns with Gaussian Drift", "abstract": "This paper investigates optimal trading strategies in a financial market with multidimensional stock returns where the drift is an unobservable multivariate Ornstein-Uhlenbeck process. Information about the drift is obtained by observing stock returns and expert opinions. The latter provide unbiased estimates on the current state of the drift at discrete points in time.   The optimal trading strategy of investors maximizing expected logarithmic utility of terminal wealth depends on the filter which is the conditional expectation of the drift given the available information. We state filtering equations to describe its dynamics for different information settings. Between expert opinions this is the Kalman filter. The conditional covariance matrices of the filter follow ordinary differential equations of Riccati type. We rely on basic theory about matrix Riccati equations to investigate their properties. Firstly, we consider the asymptotic behaviour of the covariance matrices for an increasing number of expert opinions on a finite time horizon. Secondly, we state conditions for the convergence of the covariance matrices on an infinite time horizon with regularly arriving expert opinions.   Finally, we derive the optimal trading strategy of an investor. The optimal expected logarithmic utility of terminal wealth, the value function, is a functional of the conditional covariance matrices. Hence, our analysis of the covariance matrices allows us to deduce properties of the value function.", "link": "http://dx.doi.org/10.1142/S0219024917500224"}, {"index": 857, "title": "Sufficiency on the Stock Market", "abstract": "It is well-known that there are a number of relations between theoretical finance theory and information theory. Some of these relations are exact and some are approximate. In this paper we will explore some of these relations and determine under which conditions the relations are exact. It turns out that portfolio theory always leads to Bregman divergences. The Bregman divergence is only proportional to information divergence in situations that are essentially equal to the type of gambling studied by Kelly. This can be related an abstract sufficiency condition.", "link": "http://arxiv.org/abs/1601.07593v1"}, {"index": 858, "title": "The Excess Returns of \"Quality\" Stocks: A Behavioral Anomaly", "abstract": "This note investigates the causes of the quality anomaly, which is one of the strongest and most scalable anomalies in equity markets. We explore two potential explanations. The \"risk view\", whereby investing in high quality firms is somehow riskier, so that the higher returns of a quality portfolio are a compensation for risk exposure. This view is consistent with the Efficient Market Hypothesis. The other view is the \"behavioral view\", which states that some investors persistently underestimate the true value of high quality firms. We find no evidence in favor of the \"risk view\": The returns from investing in quality firms are abnormally high on a risk-adjusted basis, and are not prone to crashes. We provide novel evidence in favor of the \"behavioral view\": In their forecasts of future prices, and while being overall overoptimistic, analysts systematically underestimate the future return of high quality firms, compared to low quality firms.", "link": "http://arxiv.org/abs/1601.04478v1"}, {"index": 859, "title": "A comparison among some Hurst exponent approaches to predict nascent bubbles in $500$ company stocks", "abstract": "In this paper, three approaches to calculate the self-similarity exponent of a time series are compared in order to determine which one performs best to identify the transition from random efficient market behavior (EM) to herding behavior (HB) and hence, to find out the beginning of a market bubble. In particular, classical Detrended Fluctuation Analysis (DFA), Generalized Hurst Exponent (GHE) and GM2 (one of Geometric Method-based algorithms) were applied for self-similarity exponent calculation purposes. Traditionally, researchers have been focused on identifying the beginning of a crash. Instead of this, we are pretty interested in identifying the beginning of the transition process from EM to a market bubble onset, what we consider could be more interesting. The relevance of self-similarity index in such a context lies on the fact that it becomes a suitable indicator which allows to identify the raising of HB in financial markets. Overall, we could state that the greater the self-similarity exponent in financial series, the more likely the transition process to HB could start. This fact is illustrated through actual S\\&P500 stocks.", "link": "http://dx.doi.org/10.1142/S0218348X17500062"}, {"index": 860, "title": "Decomposition of Time Series Data of Stock Markets and its Implications for Prediction: An Application for the Indian Auto Sector", "abstract": "With the rapid development and evolution of sophisticated algorithms for statistical analysis of time series data, the research community has started spending considerable effort in technical analysis of such data. Forecasting is also an area which has witnessed a paradigm shift in its approach. In this work, we have used the time series of the index values of the Auto sector in India during January 2010 to December 2015 for a deeper understanding of the behavior of its three constituent components, e.g., the Trend, the Seasonal component, and the Random component. Based on this structural analysis, we have also designed three approaches for forecasting and also computed their accuracy in prediction using suitably chosen training and test data sets. The results clearly demonstrate the accuracy of our decomposition results and efficiency of our forecasting techniques, even in presence of a dominant Random component in the time series.", "link": "http://dx.doi.org/10.13140/RG.2.1.3232.0241"}, {"index": 861, "title": "Geography and distance effect on financial dynamics in the Chinese stock market", "abstract": "Geography effect is investigated for the Chinese stock market including the Shanghai and Shenzhen stock markets, based on the daily data of individual stocks. The Shanghai city and the Guangdong province can be identified in the stock geographical sector. By investigating a geographical correlation on a geographical parameter, the stock location is found to have an impact on the financial dynamics, except for the financial crisis time of the Shenzhen market. Stock distance effect is further studied, with a crossover behavior observed for the stock distance distribution. The probability of the short distance is much greater than that of the long distance. The average stock correlation is found to weakly decay with the stock distance for the Shanghai stock market, but stays nearly stable for different stock distance for the Shenzhen stock market.", "link": "http://dx.doi.org/10.1016/j.physa.2016.03.058"}, {"index": 862, "title": "Volume of the steady-state space of financial flows in a monetary stock-flow-consistent model", "abstract": "We show that a steady-state stock-flow consistent macro-economic model can be represented as a Constraint Satisfaction Problem (CSP).The set of solutions is a polytope, which volume depends on the constraintsapplied and reveals the potential fragility of the economic circuit,with no need to study the dynamics. Several methods to compute the volume are compared, inspired by operations research methods and theanalysis of metabolic networks, both exact and approximate.We also introduce a random transaction matrix, and study the particularcase of linear flows with respect to money stocks.", "link": "http://dx.doi.org/10.1016/j.physa.2017.01.050"}, {"index": 863, "title": "How much diversification potential is there in a single market? Evidence from the Australian Stock Exchange", "abstract": "We present four methods of assessing the diversification potential within a stock market, two of these are based on principal component analysis. They were applied to the Australian stock exchange for the years 2000 to 2014 and all show a consistent picture. The potential for diversification declined almost monotonically in the three years prior to the 2008 financial crisis. On one of the measures the diversification potential declined even further in the 2011 European debt crisis and the American credit downgrade.", "link": "http://arxiv.org/abs/1512.06486v1"}, {"index": 864, "title": "Deep Learning Stock Volatility with Google Domestic Trends", "abstract": "We have applied a Long Short-Term Memory neural network to model S&P 500 volatility, incorporating Google domestic trends as indicators of the public mood and macroeconomic factors. In a held-out test set, our Long Short-Term Memory model gives a mean absolute percentage error of 24.2%, outperforming linear Ridge/Lasso and autoregressive GARCH benchmarks by at least 31%. This evaluation is based on an optimal observation and normalization scheme which maximizes the mutual information between domestic trends and daily volatility in the training set. Our preliminary investigation shows strong promise for better predicting stock behavior via deep learning and neural network models.", "link": "http://arxiv.org/abs/1512.04916v3"}, {"index": 865, "title": "Identifying Highly Correlated Stocks Using the Last Few Principal Components", "abstract": "We show that the last few components in principal component analysis of the correlation matrix of a group of stocks may contain useful financial information by identifying highly correlated pairs or larger groups of stocks. The results of this type of analysis can easily be included in the information an investor uses to manage their portfolio.", "link": "http://arxiv.org/abs/1512.03537v1"}, {"index": 866, "title": "The Alternating Stock Size Problem and the Gasoline Puzzle", "abstract": "Given a set S of integers whose sum is zero, consider the problem of finding a permutation of these integers such that: (i) all prefix sums of the ordering are nonnegative, and (ii) the maximum value of a prefix sum is minimized. Kellerer et al. referred to this problem as the \"Stock Size Problem\" and showed that it can be approximated to within 3/2. They also showed that an approximation ratio of 2 can be achieved via several simple algorithms.   We consider a related problem, which we call the \"Alternating Stock Size Problem\", where the number of positive and negative integers in the input set S are equal. The problem is the same as above, but we are additionally required to alternate the positive and negative numbers in the output ordering. This problem also has several simple 2-approximations. We show that it can be approximated to within 1.79.   Then we show that this problem is closely related to an optimization version of the gasoline puzzle due to Lov\\'asz, in which we want to minimize the size of the gas tank necessary to go around the track. We present a 2-approximation for this problem, using a natural linear programming relaxation whose feasible solutions are doubly stochastic matrices. Our novel rounding algorithm is based on a transformation that yields another doubly stochastic matrix with special properties, from which we can extract a suitable permutation.", "link": "http://arxiv.org/abs/1511.09259v5"}, {"index": 867, "title": "How do the naive Bayes classifier and the Support Vector Machine compare in their ability to forecast the Stock Exchange of Thailand?", "abstract": "This essay investigates the question of how the naive Bayes classifier and the support vector machine compare in their ability to forecast the Stock Exchange of Thailand. The theory behind the SVM and the naive Bayes classifier is explored. The algorithms are trained using data from the month of January 2010, extracted from the MarketWatch.com website. Input features are selected based on previous studies of the SET100 Index. The Weka 3 software is used to create models from the labeled training data. Mean squared error and proportion of correctly classified instances, and a number of other error measurements are the used to compare the two algorithms. This essay shows that these two algorithms are currently not advanced enough to accurately model the stock exchange. Nevertheless, the naive Bayes is better than the support vector machine at predicting the Stock Exchange of Thailand.", "link": "http://arxiv.org/abs/1511.08987v1"}, {"index": 868, "title": "Risk-return relationship: An empirical study of different statistical methods for estimating the Capital Asset Pricing Models (CAPM) and the Fama-French model for large cap stocks", "abstract": "The Capital Asset Pricing Model (CAPM) is one of the original models in explaining risk-return relationship in the financial market. However, when applying the CAPM into reality, it demonstrates a lot of shortcomings. While improving the performance of the model, many studies, on one hand, have attempted to apply different statistical methods to estimate the model, on the other hand, have added more predictors to the model. First, the thesis focuses on reviewing the CAPM and comparing popular statistical methods used to estimate it, and then, the thesis compares predictive power of the CAPM and the Fama-French model, which is an important extension of the CAPM. Through an empirical study on the data set of large cap stocks, we have demonstrated that there is no statistical method that would recover the expected relationship between systematic risk (represented by beta) and return from the CAPM, and that the Fama-French model does not have a better predictive performance than the CAPM on individual stocks. Therefore, the thesis provides more evidence to support the incorrectness of the CAPM and the limitation of the Fama-French model in explaining risk-return relationship.", "link": "http://arxiv.org/abs/1511.07101v1"}, {"index": 869, "title": "Patterns of trading profiles at the Nordic Stock Exchange. A correlation-based approach", "abstract": "We investigate the trading behavior of Finnish individual investors trading the stocks selected to compute the OMXH25 index in 2003 by tracking the individual daily investment decisions. We verify that the set of investors is a highly heterogeneous system under many aspects. We introduce a correlation based method that is able to detect a hierarchical structure of the trading profiles of heterogeneous individual investors. We verify that the detected hierarchical structure is highly overlapping with the cluster structure obtained with the approach of statistically validated networks when an appropriate threshold of the hierarchical trees is used. We also show that the combination of the correlation based method and of the statistically validated method provides a way to expand the information about the clusters of investors with similar trading profiles in a robust and reliable way.", "link": "http://dx.doi.org/10.1016/j.chaos.2016.02.027"}, {"index": 870, "title": "\"Speculative Influence Network\" during financial bubbles: application to Chinese Stock Markets", "abstract": "We introduce the Speculative Influence Network (SIN) to decipher the causal relationships between sectors (and/or firms) during financial bubbles. The SIN is constructed in two steps. First, we develop a Hidden Markov Model (HMM) of regime-switching between a normal market phase represented by a geometric Brownian motion (GBM) and a bubble regime represented by the stochastic super-exponential Sornette-Andersen (2002) bubble model. The calibration of the HMM provides the probability at each time for a given security to be in the bubble regime. Conditional on two assets being qualified in the bubble regime, we then use the transfer entropy to quantify the influence of the returns of one asset $i$ onto another asset $j$, from which we introduce the adjacency matrix of the SIN among securities. We apply our technology to the Chinese stock market during the period 2005-2008, during which a normal phase was followed by a spectacular bubble ending in a massive correction. We introduce the Net Speculative Influence Intensity (NSII) variable as the difference between the transfer entropies from $i$ to $j$ and from $j$ to $i$, which is used in a series of rank ordered regressions to predict the maximum loss (\\%{MaxLoss}) endured during the crash. The sectors that influenced other sectors the most are found to have the largest losses. There is a clear prediction skill obtained by using the transfer entropy involving industrial sectors to explain the \\%{MaxLoss} of financial institutions but not vice versa. We also show that the bubble state variable calibrated on the Chinese market data corresponds well to the regimes when the market exhibits a strong price acceleration followed by clear change of price regimes. Our results suggest that SIN may contribute significant skill to the development of general linkage-based systemic risks measures and early warning metrics.", "link": "http://arxiv.org/abs/1510.08162v1"}, {"index": 871, "title": "An empirical analysis of the relationships between crude oil, gold and stock markets", "abstract": "This paper analyzes the direction of the causality between crude oil, gold and stock markets for the largest economy in the world with respect to such markets, the US. To do so, we apply non-linear Granger causality tests. We find a nonlinear causal relationship among the three markets considered, with the causality going in all directions, when the full sample and different subsamples are considered. However, we find a unidirectional nonlinear causal relationship between the crude oil and gold market (with the causality only going from oil price changes to gold price changes) when the subsample runs from the first date of any year between the mid-1990s and 2001 to last available data (February 5, 2015). The latter result may explain the lack of consensus existing in the literature about the direction of the causal link between the crude oil and gold markets.", "link": "http://arxiv.org/abs/1510.07599v2"}, {"index": 872, "title": "Detrended cross-correlations between returns, volatility, trading activity, and volume traded for the stock market companies", "abstract": "We consider a few quantities that characterize trading on a stock market in a fixed time interval: logarithmic returns, volatility, trading activity (i.e., the number of transactions), and volume traded. We search for the power-law cross-correlations among these quantities aggregated over different time units from 1 min to 10 min. Our study is based on empirical data from the American stock market consisting of tick-by-tick recordings of 31 stocks listed in Dow Jones Industrial Average during the years 2008-2011. Since all the considered quantities except the returns show strong daily patterns related to the variable trading activity in different parts of a day, which are the best evident in the autocorrelation function, we remove these patterns by detrending before we proceed further with our study. We apply the multifractal detrended cross-correlation analysis with sign preserving (MFCCA) and show that the strongest power-law cross-correlations exist between trading activity and volume traded, while the weakest ones exist (or even do not exist) between the returns and the remaining quantities. We also show that the strongest cross-correlations are carried by those parts of the signals that are characterized by large and medium variance. Our observation that the most convincing power-law cross-correlations occur between trading activity and volume traded reveals the existence of strong fractal-like coupling between these quantities.", "link": "http://dx.doi.org/10.1209/0295-5075/112/48001"}, {"index": 873, "title": "On the Efficient Market Hypothesis of Stock Market Indexes: The Role of Non-synchronous Trading and Portfolio Effects", "abstract": "In this article, the long-term behavior of the stock market index of the New York Stock Exchange is studied, for the period 1950 to 2013. Specifically, the CRSP Value-Weighted and CRSP Equal-Weighted index are analyzed in terms of market efficiency, using the standard ratio variance test, considering over 1600 one week rolling windows. For the equally weighted index, the null hypothesis of random walk is rejected in the whole period, while for the weighted market value index, the null hypothesis start to be accepted from the 1990s. In order to explain this difference, we raised the hypothesis that this behavior can be explained by the joint action of portfolios and non-synchronous trading effects. To check the feasibility of the above assumption, we performed a simulation of both effects, on two- and six-asset portfolios. The results showed that it is possible to explain the empirical difference between the two index, almost entirely by the joint effects of portfolio and non-synchronous trading.", "link": "http://arxiv.org/abs/1510.03926v1"}, {"index": 874, "title": "Is the Indian Stock Market efficient - A comprehensive study of Bombay Stock Exchange Indices", "abstract": "How an investor invests in the market is largely influenced by the market efficiency because if a market is efficient, it is extremely difficult to make excessive returns because in an efficient market there will be no undervalued securities i.e. securities whose value is less than its assumed intrinsic value, which offer returns that are higher than the deserved expected returns, given their risk. However, there is a possibility of making excessive returns if the market is not efficient. This article analyses the five popular stock indices of BSE. This would not only test the efficiency of the Indian Stock Market but also test the random walk nature of the stock market. The study undertaken in this paper has provided strong evidence in favor of the inefficient form of the Indian Stock Market. The series of stock indices in the Indian Stock Market are found to be biased random time series and the random walk model can't be applied in the Indian Stock Market. This study confirms that there is a drift in market efficiency and investors can capitalize on this by correctly choosing the securities that are undervalued.", "link": "http://arxiv.org/abs/1510.03704v1"}, {"index": 875, "title": "The effect of stock market indexing on corporate tax avoidance", "abstract": "Membership in the Russell 1000 and 2000 Indices is based on a ranking of market capitalization in May. Each index is separately value weighted such that firms just inside the Russell 2000 are comparable in size to firms just outside (i.e. at the bottom of the Russell 1000) but have much higher index weights. These features allow for the the annual reconstitution of these indices to be used as part of a regression discontinuity design to identify the effect of stock market indexing. Using this design, I investigate whether stock market indexing affects corporate tax avoidance. I find no evidence that firms just inside the Russell 2000 have significantly different effective tax rates than firms just outside.", "link": "http://arxiv.org/abs/1509.00136v1"}, {"index": 876, "title": "Early warning of large volatilities based on recurrence interval analysis in Chinese stock markets", "abstract": "Being able to forcast extreme volatility is a central issue in financial risk management. We present a large volatility predicting method based on the distribution of recurrence intervals between volatilities exceeding a certain threshold $Q$ for a fixed expected recurrence time $\\tau_Q$. We find that the recurrence intervals are well approximated by the $q$-exponential distribution for all stocks and all $\\tau_Q$ values. Thus a analytical formula for determining the hazard probability $W(\\Delta t |t)$ that a volatility above $Q$ will occur within a short interval $\\Delta t$ if the last volatility exceeding $Q$ happened $t$ periods ago can be directly derived from the $q$-exponential distribution, which is found to be in good agreement with the empirical hazard probability from real stock data. Using these results, we adopt a decision-making algorithm for triggering the alarm of the occurrence of the next volatility above $Q$ based on the hazard probability. Using a \"receiver operator characteristic\" (ROC) analysis, we find that this predicting method efficiently forecasts the occurrance of large volatility events in real stock data. Our analysis may help us better understand reoccurring large volatilities and more accurately quantify financial risks in stock markets.", "link": "http://dx.doi.org/10.1080/14697688.2016.1175656"}, {"index": 877, "title": "Law on the Market? Abnormal Stock Returns and Supreme Court Decision-Making", "abstract": "What happens when the Supreme Court of the United States decides a case impacting one or more publicly-traded firms? While many have observed anecdotal evidence linking decisions or oral arguments to abnormal stock returns, few have rigorously or systematically investigated the behavior of equities around Supreme Court actions. In this research, we present the first comprehensive, longitudinal study on the topic, spanning over 15 years and hundreds of cases and firms. Using both intra- and interday data around decisions and oral arguments, we evaluate the frequency and magnitude of statistically-significant abnormal return events after Supreme Court action. On a per-term basis, we find 5.3 cases and 7.8 stocks that exhibit abnormal returns after decision. In total, across the cases we examined, we find 79 out of the 211 cases (37%) exhibit an average abnormal return of 4.4% over a two-session window with an average $|t|$-statistic of 2.9. Finally, we observe that abnormal returns following Supreme Court decisions materialize over the span of hours and days, not minutes, yielding strong implications for market efficiency in this context. While we cannot causally separate substantive legal impact from mere revision of beliefs, we do find strong evidence that there is indeed a \"law on the market\" effect as measured by the frequency of abnormal return events, and that these abnormal returns are not immediately incorporated into prices.", "link": "http://arxiv.org/abs/1508.05751v2"}, {"index": 878, "title": "Forecasting stock market returns over multiple time horizons", "abstract": "In this paper we seek to demonstrate the predictability of stock market returns and explain the nature of this return predictability. To this end, we introduce investors with different investment horizons into the news-driven, analytic, agent-based market model developed in Gusev et al. (2015). This heterogeneous framework enables us to capture dynamics at multiple timescales, expanding the model's applications and improving precision. We study the heterogeneous model theoretically and empirically to highlight essential mechanisms underlying certain market behaviors, such as transitions between bull- and bear markets and the self-similar behavior of price changes. Most importantly, we apply this model to show that the stock market is nearly efficient on intraday timescales, adjusting quickly to incoming news, but becomes inefficient on longer timescales, where news may have a long-lasting nonlinear impact on dynamics, attributable to a feedback mechanism acting over these horizons. Then, using the model, we design algorithmic strategies that utilize news flow, quantified and measured, as the only input to trade on market return forecasts over multiple horizons, from days to months. The backtested results suggest that the return is predictable to the extent that successful trading strategies can be constructed to harness this predictability.", "link": "http://arxiv.org/abs/1508.04332v2"}, {"index": 879, "title": "How to predict the consequences of a tick value change? Evidence from the Tokyo Stock Exchange pilot program", "abstract": "The tick value is a crucial component of market design and is often considered the most suitable tool to mitigate the effects of high frequency trading. The goal of this paper is to demonstrate that the approach introduced in Dayri and Rosenbaum (2015) allows for an ex ante assessment of the consequences of a tick value change on the microstructure of an asset. To that purpose, we analyze the pilot program on tick value modifications started in 2014 by the Tokyo Stock Exchange in light of this methodology. We focus on forecasting the future cost of market and limit orders after a tick value change and show that our predictions are very accurate. Furthermore, for each asset involved in the pilot program, we are able to define (ex ante) an optimal tick value. This enables us to classify the stocks according to the relevance of their tick value, before and after its modification.", "link": "http://arxiv.org/abs/1507.07052v1"}, {"index": 880, "title": "Novel and topical business news and their impact on stock market activities", "abstract": "We propose an indicator to measure the degree to which a particular news article is novel, as well as an indicator to measure the degree to which a particular news item attracts attention from investors. The novelty measure is obtained by comparing the extent to which a particular news article is similar to earlier news articles, and an article is regarded as novel if there was no similar article before it. On the other hand, we say a news item receives a lot of attention and thus is highly topical if it is simultaneously reported by many news agencies and read by many investors who receive news from those agencies. The topicality measure for a news item is obtained by counting the number of news articles whose content is similar to an original news article but which are delivered by other news agencies. To check the performance of the indicators, we empirically examine how these indicators are correlated with intraday financial market indicators such as the number of transactions and price volatility. Specifically, we use a dataset consisting of over 90 million business news articles reported in English and a dataset consisting of minute-by-minute stock prices on the New York Stock Exchange and the NASDAQ Stock Market from 2003 to 2014, and show that stock prices and transaction volumes exhibited a significant response to a news article when it is novel and topical.", "link": "http://arxiv.org/abs/1507.06477v1"}, {"index": 881, "title": "Analysis of cyclical behavior in time series of stock market returns", "abstract": "In this paper we have analyzed scaling properties and cyclical behavior of the three types of stock market indexes (SMI) time series: data belonging to stock markets of developed economies, emerging economies, and of the underdeveloped or transitional economies. We have used two techniques of data analysis to obtain and verify our findings: the wavelet spectral analysis to study SMI returns data, and the Hurst exponent formalism to study local behavior around market cycles and trends. We have found cyclical behavior in all SMI data sets that we have analyzed. Moreover, the positions and the boundaries of cyclical intervals that we have found seam to be common for all markets in our dataset. We list and illustrate the presence of nine such periods in our SMI data. We also report on the possibilities to differentiate between the level of growth of the analyzed markets by way of statistical analysis of the properties of wavelet spectra that characterize particular peak behaviors. Our results show that measures like the relative WT energy content and the relative WT amplitude for the peaks in the small scales region could be used for partial differentiation between market economies. Finally, we propose a way to quantify the level of development of a stock market based on the Hurst scaling exponent approach. From the local scaling exponents calculated for our nine peak regions we have defined what we named the Development Index, which proved, at least in the case of our dataset, to be suitable to rank the SMI series that we have analyzed in three distinct groups.", "link": "http://dx.doi.org/10.1016/j.cnsns.2017.05.009"}, {"index": 882, "title": "Quantum Gates and Quantum Circuits of Stock Portfolio", "abstract": "In quantum computation, series of quantum gates have to be arranged in a predefined sequence that led to a quantum circuit in order to solve a particular problem. What if the sequence of quantum gates is known but both the problem to be solved and the outcome of the so defined quantum circuit remain in the shadow? This is the situation of the stock market. The price time series of a portfolio of stocks are organized in braids that effectively simulate quantum gates in the hypothesis of Ising anyons quantum computational model. Following the prescriptions of Ising anyons model, 1-qubit quantum gates are constructed for portfolio composed of four stocks. Adding two additional stocks at the initial portfolio result in 2-qubits quantum gates and circuits. Hadamard gate, Pauli gates or controlled-Z gate are some of the elementary quantum gates that are identified in the stock market structure. Addition of other pairs of stocks, that eventually represent a market index, like Dow Jones industrial Average, it results in a sequence of n-qubits quantum gates that form a quantum code. Deciphering this mysterious quantum code of the stock market is an issue for future investigations.", "link": "http://arxiv.org/abs/1507.02310v2"}, {"index": 883, "title": "Impact of non-stationarity on estimating and modeling empirical copulas of daily stock returns", "abstract": "All too often measuring statistical dependencies between financial time series is reduced to a linear correlation coefficient. However this may not capture all facets of reality. We study empirical dependencies of daily stock returns by their pairwise copulas. Here we investigate particularly to which extent the non-stationarity of financial time series affects both the estimation and the modeling of empirical copulas. We estimate empirical copulas from the non-stationary, original return time series and stationary, locally normalized ones. Thereby we are able to explore the empirical dependence structure on two different scales: a global and a local one. Additionally the asymmetry of the empirical copulas is emphasized as a fundamental characteristic. We compare our empirical findings with a single Gaussian copula, with a correlation-weighted average of Gaussian copulas, with the K-copula directly addressing the non-stationarity of dependencies as a model parameter, and with the skewed Student's t-copula. The K-copula covers the empirical dependence structure on the local scale most adequately, whereas the skewed Student's t-copula best captures the asymmetry of the empirical copula on the global scale.", "link": "http://dx.doi.org/10.21314/JOR.2016.342"}, {"index": 884, "title": "Leverage Financial News to Predict Stock Price Movements Using Word Embeddings and Deep Neural Networks", "abstract": "Financial news contains useful information on public companies and the market. In this paper we apply the popular word embedding methods and deep neural networks to leverage financial news to predict stock price movements in the market. Experimental results have shown that our proposed methods are simple but very effective, which can significantly improve the stock prediction accuracy on a standard financial database over the baseline system using only the historical price information.", "link": "http://arxiv.org/abs/1506.07220v1"}, {"index": 885, "title": "A Novel Method for Stock Forecasting based on Fuzzy Time Series Combined with the Longest Common/Repeated Sub-sequence", "abstract": "Stock price forecasting is an important issue for investors since extreme accuracy in forecasting can bring about high profits. Fuzzy Time Series (FTS) and Longest Common/Repeated Sub-sequence (LCS/LRS) are two important issues for forecasting prices. However, to the best of our knowledge, there are no significant studies using LCS/LRS to predict stock prices. It is impossible that prices stay exactly the same as historic prices. Therefore, this paper proposes a state-of-the-art method which combines FTS and LCS/LRS to predict stock prices. This method is based on the principle that history will repeat itself. It uses different interval lengths in FTS to fuzzify the prices, and LCS/LRS to look for the same pattern in the historical prices to predict future stock prices. In the experiment, we examine various intervals of fuzzy time sets in order to achieve high prediction accuracy. The proposed method outperforms traditional methods in terms of prediction accuracy and, furthermore, it is easy to implement.", "link": "http://arxiv.org/abs/1506.06366v1"}, {"index": 886, "title": "The Effects of Twitter Sentiment on Stock Price Returns", "abstract": "Social media are increasingly reflecting and influencing behavior of other complex systems. In this paper we investigate the relations between a well-know micro-blogging platform Twitter and financial markets. In particular, we consider, in a period of 15 months, the Twitter volume and sentiment about the 30 stock companies that form the Dow Jones Industrial Average (DJIA) index. We find a relatively low Pearson correlation and Granger causality between the corresponding time series over the entire time period. However, we find a significant dependence between the Twitter sentiment and abnormal returns during the peaks of Twitter volume. This is valid not only for the expected Twitter volume peaks (e.g., quarterly announcements), but also for peaks corresponding to less obvious events. We formalize the procedure by adapting the well-known \"event study\" from economics and finance to the analysis of Twitter data. The procedure allows to automatically identify events as Twitter volume peaks, to compute the prevailing sentiment (positive or negative) expressed in tweets at these peaks, and finally to apply the \"event study\" methodology to relate them to stock returns. We show that sentiment polarity of Twitter peaks implies the direction of cumulative abnormal returns. The amount of cumulative abnormal returns is relatively low (about 1-2%), but the dependence is statistically significant for several days after the events.", "link": "http://dx.doi.org/10.1371/journal.pone.0138441"}, {"index": 887, "title": "Evolutionary Model of Stock Markets", "abstract": "The paper presents an evolutionary economic model for the price evolution of stocks. Treating a stock market as a self-organized system governed by a fast purchase process and slow variations of demand and supply the model suggests that the short term price distribution has the form a logistic (Laplace) distribution. The long term return can be described by Laplace-Gaussian mixture distributions. The long term mean price evolution is governed by a Walrus equation, which can be transformed into a replicator equation. This allows quantifying the evolutionary price competition between stocks. The theory suggests that stock prices scaled by the price over all stocks can be used to investigate long-term trends in a Fisher-Pry plot. The price competition that follows from the model is illustrated by examining the empirical long-term price trends of two stocks.", "link": "http://dx.doi.org/10.1016/j.physa.2014.08.037"}, {"index": 888, "title": "Phase Transitions, Renormalization and Yang-Lee Zeros in Stock Markets", "abstract": "The present paper analyses the formal parallelism existing between the laws of thermodynamics and some economic principles. Based on previous works, we shall show how the existence in Economics of principles analogous to those in thermodynamics involves the occurrence of economic events that remind of well-known phenomenological thermodynamic paradigms (i.e., the magnetocaloric effect and population inversion). We shall also show how the phase transition and renormalization theory provides a natural framework to understand and predict trend changes in stock markets. Finally, current negotiation strategies in financial markets are briefly reviewed.", "link": "http://arxiv.org/abs/1505.00471v1"}, {"index": 889, "title": "Profitability of contrarian strategies in the Chinese stock market", "abstract": "This paper reexamines the profitability of loser, winner and contrarian portfolios in the Chinese stock market using monthly data of all stocks traded on the Shanghai Stock Exchange and Shenzhen Stock Exchange covering the period from January 1997 to December 2012. We find evidence of short-term and long-term contrarian profitability in the whole sample period when the estimation and holding horizons are 1 month or longer than 12 months and the annualized returns of contrarian portfolios increases with the estimation and holding horizons. We perform subperiod analysis and find that the long-term contrarian effect is significant in both bullish and bearish states while the short-term contrarian effect disappears in bullish states. We compare the performance of contrarian portfolios based on different grouping manners in the estimation period and unveil that decile grouping outperforms quintile grouping and tertile grouping, which is more evident and robust in the long run. Generally, loser portfolios and winner portfolios have positive returns and loser portfolios perform much better than winner portfolios. Both loser and winner portfolios in bullish states perform better than those in the whole sample period. In contrast, loser and winner portfolios have smaller returns in bearish states in which loser portfolio returns are significant only in the long term and winner portfolio returns become insignificant. These results are robust to the one-month skipping between the estimation and holding periods and for the two stock exchanges. Our findings show that the Chinese stock market is not efficient in the weak form. These findings also have obvious practical implications for financial practitioners.", "link": "http://dx.doi.org/10.1371/journal.pone.0137892"}, {"index": 890, "title": "ESO Valuation with Job Termination Risk and Jumps in Stock Price", "abstract": "Employee stock options (ESOs) are American-style call options that can be terminated early due to employment shock. This paper studies an ESO valuation framework that accounts for job termination risk and jumps in the company stock price. Under general L\\'evy stock price dynamics, we show that a higher job termination risk induces the ESO holder to voluntarily accelerate exercise, which in turn reduces the cost to the company. The holder's optimal exercise boundary and ESO cost are determined by solving an inhomogeneous partial integro-differential variational inequality (PIDVI). We apply Fourier transform to simplify the variational inequality and develop accurate numerical methods. Furthermore, when the stock price follows a geometric Brownian motion, we provide closed-form formulas for both the vested and unvested perpetual ESOs. Our model is also applied to evaluate the probabilities of understating ESO expenses and contract termination.", "link": "http://arxiv.org/abs/1504.08073v1"}, {"index": 891, "title": "Transitions in the Stock Markets of the US, UK, and Germany", "abstract": "In an analysis of the US, the UK, and the German stock market we find a change in the behavior based on the stock's beta values. Before 2006 risky trades were concentrated on stocks in the IT and technology sector. Afterwards risky trading takes place for stocks from the financial sector. We show that an agent-based model can reproduce these changes. We further show that the initial impulse for the transition might stem from the increase of high frequency trading at that time.", "link": "http://dx.doi.org/10.1080/14697688.2016.1183812"}, {"index": 892, "title": "A Study of Correlations in the Stock Market", "abstract": "We study the various sectors of the Bombay Stock Exchange(BSE) for a period of 8 years from April 2006 - March 2014. Using the data of daily returns of a period of eight years we make a direct model free analysis of the pattern of the sectorial indices movement and the correlations among them. Our analysis shows significant auto correlation among the individual sectors and also strong cross-correlation among sectors. We also find that auto correlations in some of the sectors persist in time. This is a very significant result and has not been reported so far in Indian context These findings will be very useful in model building for prediction of price movement of equities, derivatives and portfolio management. We show that the Random Walk Hypothesis is not applicable in modeling the Indian market and Mean-Variance-Skewness-Kurtosis based portfolio optimization might be required. We also find that almost all sectors are highly correlated during large fluctuation periods and have only moderate correlation during normal periods.", "link": "http://dx.doi.org/10.1016/j.physa.2015.03.061"}, {"index": 893, "title": "Estimating the Algorithmic Complexity of Stock Markets", "abstract": "Randomness and regularities in Finance are usually treated in probabilistic terms. In this paper, we develop a completely different approach in using a non-probabilistic framework based on the algorithmic information theory initially developed by Kolmogorov (1965). We present some elements of this theory and show why it is particularly relevant to Finance, and potentially to other sub-fields of Economics as well. We develop a generic method to estimate the Kolmogorov complexity of numeric series. This approach is based on an iterative \"regularity erasing procedure\" implemented to use lossless compression algorithms on financial data. Examples are provided with both simulated and real-world financial time series. The contributions of this article are twofold. The first one is methodological : we show that some structural regularities, invisible with classical statistical tests, can be detected by this algorithmic method. The second one consists in illustrations on the daily Dow-Jones Index suggesting that beyond several well-known regularities, hidden structure may in this index remain to be identified.", "link": "http://arxiv.org/abs/1504.04296v1"}, {"index": 894, "title": "Profitability of simple technical trading rules of Chinese stock exchange indexes", "abstract": "Although technical trading rules have been widely used by practitioners in financial markets, their profitability still remains controversial. We here investigate the profitability of moving average (MA) and trading range break (TRB) rules by using the Shanghai Stock Exchange Composite Index (SHCI) from May 21, 1992 through December 31, 2013 and Shenzhen Stock Exchange Composite Index (SZCI) from April 3, 1991 through December 31, 2013. The $t$-test is adopted to check whether the mean returns which are conditioned on the trading signals are significantly different from unconditioned returns and whether the mean returns conditioned on the buy signals are significantly different from the mean returns conditioned on the sell signals. We find that TRB rules outperform MA rules and short-term variable moving average (VMA) rules outperform long-term VMA rules. By applying White's Reality Check test and accounting for the data snooping effects, we find that the best trading rule outperforms the buy-and-hold strategy when transaction costs are not taken into consideration. Once transaction costs are included, trading profits will be eliminated completely. Our analysis suggests that simple trading rules like MA and TRB cannot beat the standard buy-and-hold strategy for the Chinese stock exchange indexes.", "link": "http://dx.doi.org/10.1016/j.physa.2015.07.032"}, {"index": 895, "title": "Splitting hybrid Make-To-Order and Make-To-Stock demand profiles", "abstract": "In this paper a demand time series is analysed to support Make-To-Stock (MTS) and Make-To-Order (MTO) production decisions. Using a purely MTS production strategy based on the given demand can lead to unnecessarily high inventory levels thus it is necessary to identify likely MTO episodes.   This research proposes a novel outlier detection algorithm based on special density measures. We divide the time series' histogram into three clusters. One with frequent-low volume covers MTS items whilst a second accounts for high volumes which is dedicated to MTO items. The third cluster resides between the previous two with its elements being assigned to either the MTO or MTS class. The algorithm can be applied to a variety of time series such as stationary and non-stationary ones.   We use empirical data from manufacturing to study the extent of inventory savings. The percentage of MTO items is reflected in the inventory savings which were shown to be an average of 18.1%.", "link": "http://arxiv.org/abs/1504.03594v1"}, {"index": 896, "title": "U.S. stock market interaction network as learned by the Boltzmann Machine", "abstract": "We study historical dynamics of joint equilibrium distribution of stock returns in the U.S. stock market using the Boltzmann distribution model being parametrized by external fields and pairwise couplings. Within Boltzmann learning framework for statistical inference, we analyze historical behavior of the parameters inferred using exact and approximate learning algorithms. Since the model and inference methods require use of binary variables, effect of this mapping of continuous returns to the discrete domain is studied. The presented analysis shows that binarization preserves market correlation structure. Properties of distributions of external fields and couplings as well as industry sector clustering structure are studied for different historical dates and moving window sizes. We found that a heavy positive tail in the distribution of couplings is responsible for the sparse market clustering structure. We also show that discrepancies between the model parameters might be used as a precursor of financial instabilities.", "link": "http://dx.doi.org/10.1140/epjb/e2015-60282-3"}, {"index": 897, "title": "A study of co-movements between USA and Latin American stock markets: a cross-bicorrelations perspective", "abstract": "In this paper we use the Brooks and Hinich cross-bicorrelation test in order to uncover nonlinear dependence periods between USA Standard and Poor 500 (SP500), used as benchmark, and six Latin American stock markets indexes: Mexico (BMV), Brazil (BOVESPA), Chile (IPSA), Colombia (COLCAP), Peru (IGBVL) and Argentina (MERVAL). We have found windows of nonlinear dependence and co-movement between the SP500 and the Latin American stock markets, some of which coincide with periods of crisis, giving way to a possible contagion or interdependence interpretation.", "link": "http://arxiv.org/abs/1503.06926v1"}, {"index": 898, "title": "Canonical Sectors and Evolution of Firms in the US Stock Markets", "abstract": "A classification of companies into sectors of the economy is important for macroeconomic analysis and for investments into the sector-specific financial indices and exchange traded funds (ETFs). Major industrial classification systems and financial indices have historically been based on expert opinion and developed manually. Here we show how unsupervised machine learning can provide a more objective and comprehensive broad-level sector decomposition of stocks. An emergent low-dimensional structure in the space of historical stock price returns automatically identifies \"canonical sectors\" in the market, and assigns every stock a participation weight into these sectors. Furthermore, by analyzing data from different periods, we show how these weights for listed firms have evolved over time.", "link": "http://arxiv.org/abs/1503.06205v5"}, {"index": 899, "title": "Pricing of Warrants with Stock Price Dependent Threshold Conditions", "abstract": "Warrants with stock price dependent threshold conditions give the right to buy specially issued stocks, if the performance of the stock price satisfies some requirements. Existence of these derivatives changes the price process of the underlying. We show that in the presence of such warrants one cannot assume that the stock market is arbitrage free and that the stock is tradeable at every time moment with the same price for buying and selling. This means that the usual methods for deriving fair prices for such warrants cannot be used. We start from a simple model for the firm's value process and discuss some ways to specify a related model for the stock price process in the presence of warrants with threshold conditions. We also discuss how indifference pricing approach can be used for pricing such warrants.", "link": "http://arxiv.org/abs/1503.05139v1"}, {"index": 900, "title": "Profitable forecast of prices of stock options on real market data via the solution of an ill-posed problem for the Black-Scholes equation", "abstract": "A new mathematical model for the Black-Scholes equation is proposed to forecast option prices. This model includes new interval for the price of the underlying stock as well as new initial and boundary conditions. Conventional notions of maturity time and strike prices are not used. The Black-Scholes equation is solved as a parabolic equation with the reversed time, which is an ill-posed problem. Thus, a regularization method is used to solve it. This idea is verified on real market data for twenty liquid options. A trading strategy is proposed. This strategy indicates that our method is profitable on at least those twenty options. We conjecture that our method might lead to significant profits of those financial institutions which trade large amounts of options. We caution, however, that detailed further studies are necessary to verify this conjecture.", "link": "http://arxiv.org/abs/1503.03567v1"}, {"index": 901, "title": "Statistical Properties and Pre-hit Dynamics of Price Limit Hits in the Chinese Stock Markets", "abstract": "Price limit trading rules are adopted in some stock markets (especially emerging markets) trying to cool off traders' short-term trading mania on individual stocks and increase market efficiency. Under such a microstructure, stocks may hit their up-limits and down-limits from time to time. However, the behaviors of price limit hits are not well studied partially due to the fact that main stock markets such as the US markets and most European markets do not set price limits. Here, we perform detailed analyses of the high-frequency data of all A-share common stocks traded on the Shanghai Stock Exchange and the Shenzhen Stock Exchange from 2000 to 2011 to investigate the statistical properties of price limit hits and the dynamical evolution of several important financial variables before stock price hits its limits. We compare the properties of up-limit hits and down-limit hits. We also divide the whole period into three bullish periods and three bearish periods to unveil possible differences during bullish and bearish market states. To uncover the impacts of stock capitalization on price limit hits, we partition all stocks into six portfolios according to their capitalizations on different trading days. We find that the price limit trading rule has a cooling-off effect (object to the magnet effect), indicating that the rule takes effect in the Chinese stock markets. We find that price continuation is much more likely to occur than price reversal on the next trading day after a limit-hitting day, especially for down-limit hits, which has potential practical values for market practitioners.", "link": "http://dx.doi.org/10.1371/journal.pone.0120312"}, {"index": 902, "title": "Influence network in Chinese stock market", "abstract": "In a stock market, the price fluctuations are interactive, that is, one listed company can influence others. In this paper, we seek to study the influence relationships among listed companies by constructing a directed network on the basis of Chinese stock market. This influence network shows distinct topological properties, particularly, a few large companies that can lead the tendency of stock market are recognized. Furthermore, by analyzing the subnetworks of listed companies distributed in several significant economic sectors, it is found that the influence relationships are totally different from one economic sector to another, of which three types of connectivity as well as hub-like listed companies are identified. In addition, the rankings of listed companies obtained from the centrality metrics of influence network are compared with that according to the assets, which gives inspiration to uncover and understand the importance of listed companies in the stock market. These empirical results are meaningful in providing these topological properties of Chinese stock market and economic sectors as well as revealing the interactively influence relationships among listed companies.", "link": "http://dx.doi.org/10.1088/1742-5468/2015/03/P03017"}, {"index": 903, "title": "State and group dynamics of world stock market by principal component analysis", "abstract": "We study the dynamic interactions and structural changes in global financial indices in the years 1998-2012. We apply a principal component analysis (PCA) to cross-correlation coefficients of the stock indices. We calculate the correlations between principal components (PCs) and each asset, known as PC coefficients. A change in market state is identified as a change in the first PC coefficients. Some indices do not show significant change of PCs in market state during crises. The indices exposed to the invested capitals in the stock markets are at the minimum level of risk. Using the first two PC coefficients, we identify indices that are similar and more strongly correlated than the others. We observe that the European indices form a robust group over the observation period. The dynamics of the individual indices within the group increase in similarity with time, and the dynamics of indices are more similar during the crises. Furthermore, the group formation of indices changes position in two-dimensional spaces due to crises. Finally, after a financial crisis, the difference of PCs between the European and American indices narrows.", "link": "http://dx.doi.org/10.1016/j.physa.2015.12.144"}, {"index": 904, "title": "Assessment of 48 Stock markets using adaptive multifractal approach", "abstract": "Stock market comovements are examined using cointegration, Granger causality tests and nonlinear approaches in context of mutual information and correlations. Underlying data sets are affected by non-stationarities and trends, we also apply AMF-DFA and AMF-DXA. We find only 170 pair of Stock markets cointegrated, and according to the Granger causality and mutual information, we realize that the strongest relations lies between emerging markets, and between emerging and frontier markets. According to scaling exponent given by AMF-DFA, $h(q=2)>1$, we find that all underlying data sets belong to non-stationary process. According to EMH, only 8 markets are classified in uncorrelated processes at $2\\sigma$ confidence interval. 6 Stock markets belong to anti-correlated class and dominant part of markets has memory in corresponding daily index prices during January 1995 to February 2014. New-Zealand with $H=0.457\\pm0.004$ and Jordan with $H=0.602\\pm 0.006$ are far from EMH. The nature of cross-correlation exponents based on AMF-DXA is almost multifractal for all pair of Stock markets. The empirical relation, $H_{xy}\\le [H_{xx}+H_{yy}]/2$, is confirmed. Mentioned relation for $q>0$ is also satisfied while for $q<0$ there is a deviation from this relation confirming behavior of markets for small fluctuations is affected by contribution of major pair. For larger fluctuations, the cross-correlation contains information from both local and global conditions. Width of singularity spectrum for auto-correlation and cross-correlation are $\\Delta \\alpha_{xx}\\in [0.304,0.905]$ and $\\Delta \\alpha_{xy}\\in [0.246,1.178]$, respectively. The wide range of singularity spectrum for cross-correlation confirms that the bilateral relation between Stock markets is more complex. The value of $\\sigma_{DCCA}$ indicates that all pairs of stock market studied in this time interval belong to cross-correlated processes.", "link": "http://dx.doi.org/10.1016/j.physa.2017.05.046"}, {"index": 905, "title": "Cutting Stock with Binary Patterns: Arc-flow Formulation with Graph Compression", "abstract": "The cutting stock problem with binary patterns (0-1 CSP) is a variant of CSP that usually appears as a relaxation of 2D and 3D packing problems. We present an exact method, based on an arc-flow formulation with side constraints, for solving 0-1 CSP by simply representing all the patterns in a very compact graph.   Gilmore-Gomory's column generation approach is usually used to compute strong lower bounds for 0-1 CSP. We report a computational comparison between the arc-flow approach and the Gilmore-Gomory's approach.", "link": "http://arxiv.org/abs/1502.02899v1"}, {"index": 906, "title": "Evaluation of modelling approaches for predicting the spatial distribution of soil organic carbon stocks at the national scale", "abstract": "Soil organic carbon (SOC) plays a major role in the global carbon budget. It can act as a source or a sink of atmospheric carbon, thereby possibly influencing the course of climate change. Improving the tools that model the spatial distributions of SOC stocks at national scales is a priority, both for monitoring changes in SOC and as an input for global carbon cycles studies. In this paper, we compare and evaluate two recent and promising modelling approaches. First, we considered several increasingly complex boosted regression trees (BRT), a convenient and efficient multiple regression model from the statistical learning field. Further, we considered a robust geostatistical approach coupled to the BRT models. Testing the different approaches was performed on the dataset from the French Soil Monitoring Network, with a consistent cross-validation procedure. We showed that when a limited number of predictors were included in the BRT model, the standalone BRT predictions were significantly improved by robust geostatistical modelling of the residuals. However, when data for several SOC drivers were included, the standalone BRT model predictions were not significantly improved by geostatistical modelling. Therefore, in this latter situation, the BRT predictions might be considered adequate without the need for geostatistical modelling, provided that i) care is exercised in model fitting and validating, and ii) the dataset does not allow for modelling of local spatial autocorrelations, as is the case for many national systematic sampling schemes.", "link": "http://dx.doi.org/10.1016/j.geoderma.2014.01.005"}, {"index": 907, "title": "Functional response additive model estimation with online virtual stock markets", "abstract": "While functional regression models have received increasing attention recently, most existing approaches assume both a linear relationship and a scalar response variable. We suggest a new method, \"Functional Response Additive Model Estimation\" (FRAME), which extends the usual linear regression model to situations involving both functional predictors, $X_j(t)$, scalar predictors, $Z_k$, and functional responses, $Y(s)$. Our approach uses a penalized least squares optimization criterion to automatically perform variable selection in situations involving multiple functional and scalar predictors. In addition, our method uses an efficient coordinate descent algorithm to fit general nonlinear additive relationships between the predictors and response. We develop our model for novel forecasting challenges in the entertainment industry. In particular, we set out to model the decay rate of demand for Hollywood movies using the predictive power of online virtual stock markets (VSMs). VSMs are online communities that, in a market-like fashion, gather the crowds' prediction about demand for a particular product. Our fully functional model captures the pattern of pre-release VSM trading prices and provides superior predictive accuracy of a movie's post-release demand in comparison to traditional methods. In addition, we propose graphical tools which give a glimpse into the causal relationship between market behavior and box office revenue patterns, and hence provide valuable insight to movie decision makers.", "link": "http://dx.doi.org/10.1214/14-AOAS781"}, {"index": 908, "title": "Adaptive Filter Design for Stock Market Prediction Using a Correlation-based Criterion", "abstract": "This paper presents a novel adaptive-filter approach for predicting assets on the stock markets. Concepts are introduced here, which allow understanding this method and computing of the corresponding forecast. This approach is applied, as an example, through the prediction over the actual valuation of the PETR3 shares (Petrobras ON) traded in the Brazilian Stock Market. The first-rate choices of the window length and the number of filter coefficient are evaluated. This is done by observing the correlation between the predictor signal and the actual course performed by the market in terms of both the window prevision length and filter coefficient values. It is shown that such adaptive predictors furnish, on the average, very substantial profit on the invested amount.", "link": "http://arxiv.org/abs/1501.07504v1"}, {"index": 909, "title": "Effects of Marine Protected Areas on Overfished Fishing Stocks with Multiple Stable States", "abstract": "Marine protected areas (MPAs) have attracted much attention as a tool for sustainable fisheries management, restoring depleted fisheries stocks and maintaining ecosystems. However, even with total exclusion of fishing effort, depleted stocks sometimes show little or no recovery over a long time period. Here, using a mathematical model, we show that multiple stable states may hold the key to understanding the tendency for fisheries stocks to recover because of MPAs. We find that MPAs can have either a positive effect or almost no effect on the recovery of depleted fishing stocks, depending on the fish migration patterns and the fishing policies. MPAs also reinforce ecological resilience, particularly for migratory species. In contrast to previous reports, our results show that MPAs have small or sometimes negative effects on the recovery of sedentary species. Unsuitable MPA planning might result in low effectiveness or even deterioration of the existing condition.", "link": "http://dx.doi.org/10.1016/j.jtbi.2013.09.027"}, {"index": 910, "title": "Information in stock prices and some consequences: A model-free approach", "abstract": "The price of a stock will rarely follow the assumed model and a curious investor or a Regulatory Authority may wish to obtain a probability model the prices support. A risk neutral probability ${\\cal P}^*$ for the stock's price at time $T$ is determined in closed form from the prices before $T$ without assuming a price model. The findings indicate that ${\\cal P}^*$ may be a mixture. Under mild conditions on the prices the necessary and sufficient condition to obtain ${\\cal P}^*$ is the coincidence at $T$ of the stock price ranges assumed by the stock's trader and buyer. This result clarifies the relation between market's informational efficiency and the arbitrage-free option pricing methodology. It also shows that in an incomplete market there are risk neutral probabilities not supported by each stock and their use can be limited. ${\\cal P}^*$-price $C$ for the stock's European call option expiring at $T$ is obtained. Among other results it is shown for \"calm\" prices, like the log-normal, that i) $C$ is the Black-Scholes-Merton price thus confirming its validity for various stock prices, ii) the buyer's price carries an exponentially increasing volatility premium and its difference with $C$ provides a measure of the market risk premium.", "link": "http://arxiv.org/abs/1501.07473v2"}, {"index": 911, "title": "Optimal Selling Time of a Stock under Capital Gains Taxes", "abstract": "We investigate the impact of capital gains taxes on optimal investment decisions in a quite simple model. Namely, we consider a risk neutral investor who owns one risky stock from which she assumes that it has a lower expected return than the riskless bank account and determine the optimal stopping time at which she sells the stock to invest the proceeds in the bank account up to the maturity date. In the case of linear taxes and a positive riskless interest rate, the problem is nontrivial because at the selling time the investor has to realize book profits which triggers tax payments. We derive a boundary that is continuous and increasing in time and decreasing in the volatility of the stock such that the investor sells the stock at the first time its price is smaller or equal to this boundary.", "link": "http://arxiv.org/abs/1501.00026v1"}, {"index": 912, "title": "Large-scale empirical study on pairs trading for all possible pairs of stocks listed on the first section of the Tokyo Stock Exchange", "abstract": "We carry out a large-scale empirical data analysis to examine the efficiency of the so-called pairs trading. On the basis of relevant three thresholds, namely, starting, profit-taking, and stop-loss for the `first-passage process' of the spread (gap) between two highly-correlated stocks, we construct an effective strategy to make a trade via `active' stock-pairs automatically. The algorithm is applied to $1,784$ stocks listed on the first section of the Tokyo Stock Exchange leading up to totally $1,590,436$ pairs. We are numerically confirmed that the asset management by means of the pairs trading works effectively at least for the past three years (2010-2012) data sets in the sense that the profit rate becomes positive (totally positive arbitrage) in most cases of the possible combinations of thresholds corresponding to `absorbing boundaries' in the literature of first-passage processes.", "link": "http://arxiv.org/abs/1412.7269v2"}, {"index": 913, "title": "ANN Model to Predict Stock Prices at Stock Exchange Markets", "abstract": "Stock exchanges are considered major players in financial sectors of many countries. Most Stockbrokers, who execute stock trade, use technical, fundamental or time series analysis in trying to predict stock prices, so as to advise clients. However, these strategies do not usually guarantee good returns because they guide on trends and not the most likely price. It is therefore necessary to explore improved methods of prediction.   The research proposes the use of Artificial Neural Network that is feedforward multi-layer perceptron with error backpropagation and develops a model of configuration 5:21:21:1 with 80% training data in 130,000 cycles. The research develops a prototype and tests it on 2008-2012 data from stock markets e.g. Nairobi Securities Exchange and New York Stock Exchange, where prediction results show MAPE of between 0.71% and 2.77%. Validation done with Encog and Neuroph realized comparable results. The model is thus capable of prediction on typical stock markets.", "link": "http://arxiv.org/abs/1502.06434v1"}, {"index": 914, "title": "Financial Time Series: Stylized Facts for the Mexican Stock Exchange Index Compared to Developed Markets", "abstract": "We present some stylized facts exhibited by the time series of returns of the Mexican Stock Exchange Index (IPC) and compare them to a sample of both developed (USA, UK and Japan) and emerging markets (Brazil and India). The period of study is 1997-2011. The stylized facts are related mostly to the probability distribution func- tion and the autocorrelation function (e.g. fat tails, non-normality, volatility cluster- ing, among others). We find that positive skewness for returns in Mexico and Brazil, but not in the rest, suggest investment opportunities. Evidence of nonlinearity is also documented.", "link": "http://arxiv.org/abs/1412.3126v1"}, {"index": 915, "title": "Ecuador's mangrove forest carbon stocks: A spatiotemporal analysis of living carbon holdings and their depletion since the advent of commercial aquaculture", "abstract": "In this paper we estimate the living carbon lost from Ecuador's mangrove forests since the advent of export-focused shrimp aquaculture. We use remote sensing techniques to delineate the extent of mangroves and aquaculture at approximately decadal periods since the arrival of aquaculture in each Ecuadorian estuary. We then spatiotemporally calculate the carbon values of the mangrove forests and estimate the amount of carbon lost due to direct displacement by aquaculture. Additionally, we calculate the new carbon stocks generated due to mangrove reforestation or afforestation. This research introduces time and land use / land cover change (LUCC) into the tropical forest carbon literature and examines forest carbon loss at a higher spatiotemporal resolution than in many earlier analyses. We find that 80%, or 7,014,517 t of the living carbon lost in Ecuadorian mangrove forests can be attributed to direct displacement of mangrove forests by shrimp aquaculture. We also find that Intergovernmental Panel on Climate Change (IPCC) compliant carbon grids within Ecuador's estuaries overestimate living carbon levels in estuaries where substantial LUCC has occurred. By approaching the mangrove forest carbon loss question from a LUCC perspective, these findings allow for tropical nations and other intervention agents to prioritize and target a limited set of land transitions that likely drive the majority of carbon losses. This singular cause of transition has implications for programs that attempt to offset or limit future forest carbon losses and place value on forest carbon or other forest good and services.", "link": "http://dx.doi.org/10.1371/journal.pone.0118880"}, {"index": 916, "title": "Maximum sustainable yield from interacting fish stocks in an uncertain world: two policy choices and underlying trade-offs", "abstract": "The case of fisheries management illustrates how the inherent structural instability of ecosystems can have deep-running policy implications. We contrast ten types of management plans to achieve maximum sustainable yields (MSY) from multiple stocks and compare their effectiveness based on a management strategy evaluation (MSE) that uses complex food webs in its operating model. Plans that target specific stock sizes ($B_{\\text{MSY}}$) consistently led to higher yields than plans targeting specific fishing pressures ($F_{\\text{MSY}}$). A new self-optimising control rule, introduced here for its robustness to structural instability, led to intermediate yields. Most plans outperformed single-species management plans with pressure targets set without considering multispecies interactions. However, more refined plans to \"maximise the yield from each stock separately\", in the sense of a Nash equilibrium, produced total yields comparable to plans aiming to maximise total harvested biomass, and were more robust to structural instability. Our analyses highlight trade-offs between yields, amenability to negotiations, pressures on biodiversity, and continuity with current approaches in the European context. Based on these results, we recommend directions for developments of EU fisheries policy.", "link": "http://dx.doi.org/10.1093/icesjms/fsw113"}, {"index": 917, "title": "Trend and Fractality Assessment of Mexico's Stock Exchange", "abstract": "The total value of domestic market capitalization of the Mexican Stock Exchange was calculated at 520 billion of dollars by the end of November 2013. To manage this system and make optimum capital investments, its dynamics needs to be predicted. However, randomness within the stock indexes makes forecasting a difficult task. To address this issue, in this work, trends and fractality were studied using GNU-R over the opening and closing prices indexes over the past 23 years. Returns, Kernel density estimation, autocorrelation function and R/S analysis and the Hurst exponent were used in this research. As a result, it was found that the Kernel estimation density and the autocorrelation function shown the presence of long-range memory effects. In a first approximation, the returns of closing prices seems to behave according to a Markovian random walk with a length of step size given by an alpha-stable random process. For extreme values, returns decay asymptotically as a power law with a characteristic exponent approximately equal to 2.5.", "link": "http://arxiv.org/abs/1411.3399v1"}, {"index": 918, "title": "When does the stock market listen to economic news? New evidence from copulas and news wires", "abstract": "We study association between macroeconomic news and stock market returns using the statistical theory of copulas, and a new comprehensive measure of news based on the indexing of news wires. We find the impact of economic news on equity returns to be nonlinear and asymmetric. In particular, controlling for economic conditions and surprises associated with releases of economic data, we find that the market reacts strongly and negatively to the most unfavourable macroeconomic news, but appears to largely discount the good news. This relationship persists throughout the different stages of the business cycle.", "link": "http://arxiv.org/abs/1410.8427v1"}, {"index": 919, "title": "Stock fluctuations are correlated and amplified across networks of interlocking directorates", "abstract": "Traded corporations are required by law to have a majority of outside directors on their board. This requirement allows the existence of directors who sit on the board of two or more corporations at the same time, generating what is commonly known as interlocking directorates. While research has shown that networks of interlocking directorates facilitate the transmission of information between corporations, little is known about the extent to which such interlocking networks can explain the fluctuations of stock price returns. Yet, this is a special concern since the risk of amplifying stock fluctuations is latent. To answer this question, here we analyze the board composition, traders' perception, and stock performance of more than 1500 US traded corporations from 2007-2011. First, we find that the fewer degrees of separation between two corporations in the interlocking network, the stronger the temporal correlation between their stock price returns. Second, we find that the centrality of traded corporations in the interlocking network correlates with the frequency at which financial traders talk about such corporations, and this frequency is in turn proportional to the corresponding traded volume. Third, we show that the centrality of corporations was negatively associated with their stock performance in 2008, the year of the big financial crash. These results suggest that the strategic decisions made by interlocking directorates are strongly followed by stock analysts and have the potential to correlate and amplify the movement of stock prices during financial crashes. These results may have relevant implications for scholars, investors, and regulators.", "link": "http://dx.doi.org/10.1140/epjds/s13688-014-0030-0"}, {"index": 920, "title": "Scaling analysis of time series of daily prices from stock markets of transitional economies in the Western Balkans", "abstract": "In this paper we have analyzed scaling properties of time series of stock market indices (SMIs) of developing economies of Western Balkans, and have compared the results we have obtained with the results from more developed economies. We have used three different techniques of data analysis to obtain and verify our findings: Detrended Fluctuation Analysis (DFA) method, Detrended Moving Average (DMA) method, and Wavelet Transformation (WT) analysis. We have found scaling behavior in all SMI data sets that we have analyzed. The scaling of our SMI series changes from long-range correlated to slightly anti-correlated behavior with the change in growth or maturity of the economy the stock market is embedded in. We also report the presence of effects of potential periodic-like influences on the SMI data that we have analyzed. One such influence is visible in all our SMI series, and appears at a period $T_{p}\\approx 90$ days. We propose that the existence of various periodic-like influences on SMI data may partially explain the observed difference in types of correlated behavior of corresponding scaling functions.", "link": "http://dx.doi.org/10.1140/epjb/e2014-50655-5"}, {"index": 921, "title": "Visualising stock flow consistent models as directed acyclic graphs", "abstract": "We show how every stock-flow consistent model of the macroeconomy can be represented as a directed acyclic graph. The advantages of representing the model in this way include graphical clarity, causal inference, and model specification. We provide many examples implemented with a new software package.", "link": "http://arxiv.org/abs/1409.4541v1"}, {"index": 922, "title": "A spring-block analogy for the dynamics of stock indexes", "abstract": "A spring-block chain placed on a running conveyor belt is considered for modeling stylized facts observed in the dynamics of stock indexes. Individual stocks are modeled by the blocks, while the stock-stock correlations are introduced via simple elastic forces acting in the springs. The dragging effect of the moving belt corresponds to the expected economic growth. The spring-block system produces collective behavior and avalanche like phenomena, similar to the ones observed in stock markets. An artificial index is defined for the spring-block chain, and its dynamics is compared with the one measured for the Dow Jones Industrial Average. For certain parameter regions the model reproduces qualitatively well the dynamics of the logarithmic index, the logarithmic returns, the distribution of the logarithmic returns, the avalanche-size distribution and the distribution of the investment horizons. A noticeable success of the model is that it is able to account for the gain-loss asymmetry observed in the inverse statistics. Our approach has mainly a pedagogical value, bridging between a complex socio-economic phenomena and a basic (mechanical) model in physics.", "link": "http://dx.doi.org/10.1016/j.physa.2015.01.079"}, {"index": 923, "title": "Intra-day variability of the stock market activity versus stationarity of the financial time series", "abstract": "We describe the impact of the intra-day activity pattern on the autocorrelation function estimator. We obtain an exact formula relating estimators of the autocorrelation functions of non-stationary process to its stationary counterpart. Hence, we proved that the day seasonality of inter-transaction times extends the memory of as well the process itself as its absolute value. That is, both processes relaxation to zero is longer.", "link": "http://dx.doi.org/10.1016/j.physa.2015.03.033"}, {"index": 924, "title": "A two-stage architecture for stock price forecasting by combining SOM and fuzzy-SVM", "abstract": "This paper proposed a model to predict the stock price based on combining Self-Organizing Map (SOM) and fuzzy-Support Vector Machines (f-SVM). Extraction of fuzzy rules from raw data based on the combining of statistical machine learning models is base of this proposed approach. In the proposed model, SOM is used as a clustering algorithm to partition the whole input space into the several disjoint regions. For each partition, a set of fuzzy rules is extracted based on a f-SVM combining model. Then fuzzy rules sets are used to predict the test data using fuzzy inference algorithms. The performance of the proposed approach is compared with other models using four data sets", "link": "http://arxiv.org/abs/1408.5241v1"}, {"index": 925, "title": "Maximum Entropy Production Principle for Stock Returns", "abstract": "In our previous studies we have investigated the structural complexity of time series describing stock returns on New York's and Warsaw's stock exchanges, by employing two estimators of Shannon's entropy rate based on Lempel-Ziv and Context Tree Weighting algorithms, which were originally used for data compression. Such structural complexity of the time series describing logarithmic stock returns can be used as a measure of the inherent (model-free) predictability of the underlying price formation processes, testing the Efficient-Market Hypothesis in practice. We have also correlated the estimated predictability with the profitability of standard trading algorithms, and found that these do not use the structure inherent in the stock returns to any significant degree. To find a way to use the structural complexity of the stock returns for the purpose of predictions we propose the Maximum Entropy Production Principle as applied to stock returns, and test it on the two mentioned markets, inquiring into whether it is possible to enhance prediction of stock returns based on the structural complexity of these and the mentioned principle.", "link": "http://arxiv.org/abs/1408.3728v1"}, {"index": 926, "title": "Granger Causality Stock Market Networks: Temporal Proximity and Preferential Attachment", "abstract": "The structure of return spillovers is examined by constructing Granger causality networks using daily closing prices of 20 developed markets from 2nd January 2006 to 31st December 2013. The data is properly aligned to take into account non-synchronous trading effects. The study of the resulting networks of over 94 sub-samples revealed three significant findings. First, after the recent financial crisis the impact of the US stock market has declined. Second, spatial probit models confirmed the role of the temporal proximity between market closing times for return spillovers, i.e. the time distance between national stock markets matters. Third, preferential attachment between stock markets exists, i.e. spillover from market j to market i is more likely if A) market j influences other markets other than i, or when B) market i is influenced by other markets other than j.", "link": "http://dx.doi.org/10.1016/j.physa.2015.02.017"}, {"index": 927, "title": "Dynamics in two networks based on stocks of the US stock market", "abstract": "We follow the main stocks belonging to the New York Stock Exchange and to Nasdaq from 2003 to 2012, through years of normality and of crisis, and study the dynamics of networks built on two measures expressing relations between those stocks: correlation, which is symmetric and measures how similar two stocks behave, and Transfer Entropy, which is non-symmetric and measures the influence of the time series of one stock onto another in terms of the information that the time series of one stock transmits to the time series of another stock. The two measures are used in the creation of two networks that evolve in time, revealing how the relations between stocks and industrial sectors changed in times of crisis. The two networks are also used in conjunction with a dynamic model of the spreading of volatility in order to detect which are the stocks that are most likely to spread crises, according to the model. This information may be used in the building of policies aiming to reduce the effect of financial crises.", "link": "http://arxiv.org/abs/1408.1728v2"}, {"index": 928, "title": "Comparing series of rankings with ties by using complex networks: An analysis of the spanish stock market (IBEX-35 index)", "abstract": "In this paper we extend the concept of Competitivity Graph to compare series of rankings with ties ({\\em partial rankings}). We extend the usual method used to compute Kendall's coefficient for two partial rankings to the concept of evolutive Kendall's coefficient for a series of partial rankings. The theoretical framework consists of a four-layer multiplex network. Regarding the treatment of ties, our approach allows to define a tie between two values when they are close {\\em enough}, depending on a threshold. We show an application using data from the Spanish Stock Market; we analyse the series of rankings defined by $25$ companies that have contributed to the IBEX-35 return and volatility values over the period 2003 to 2013.", "link": "http://arxiv.org/abs/1407.3180v1"}, {"index": 929, "title": "Stock Market Prediction from WSJ: Text Mining via Sparse Matrix Factorization", "abstract": "We revisit the problem of predicting directional movements of stock prices based on news articles: here our algorithm uses daily articles from The Wall Street Journal to predict the closing stock prices on the same day. We propose a unified latent space model to characterize the \"co-movements\" between stock prices and news articles. Unlike many existing approaches, our new model is able to simultaneously leverage the correlations: (a) among stock prices, (b) among news articles, and (c) between stock prices and news articles. Thus, our model is able to make daily predictions on more than 500 stocks (most of which are not even mentioned in any news article) while having low complexity. We carry out extensive backtesting on trading strategies based on our algorithm. The result shows that our model has substantially better accuracy rate (55.7%) compared to many widely used algorithms. The return (56%) and Sharpe ratio due to a trading strategy based on our model are also much higher than baseline indices.", "link": "http://arxiv.org/abs/1406.7330v1"}, {"index": 930, "title": "A probable pre-main sequence chemically peculiar star in the open cluster Stock 16", "abstract": "We used the Ultraviolet and Visual Echelle Spectrograph of the ESO-Very Large Telescope to obtain a high resolution and high signal-to-noise ratio spectrum of Stock 16-12, an early-type star which previous Delta-a photometric observations suggest being a chemically peculiar (CP) star. We used spectral synthesis to perform a detailed abundance analysis obtaining an effective temperature of 8400 +/- 400 K, a surface gravity of 4.1 +/- 0.4, a microturbulence velocity of 3.4 +0.7/-0.3 km/s, and a projected rotational velocity of 68 +/- 4 km/s. We provide photometric and spectroscopic evidence showing the star is most likely a member of the young Stock 16 open cluster (age 3-8 Myr). The probable cluster membership, the star's position in the Hertzsprung-Russell diagram, and the found infrared excess strongly suggest the star is still in the pre-main-sequence (PMS) phase. We used PMS evolutionary tracks to determine the stellar mass, which ranges between 1.95 and 2.3 Msun, depending upon the adopted spectroscopic or photometric data results. Similarly, we obtained a stellar age ranging between 4 and 6 Myr, in agreement with that of the cluster. Because the star's chemical abundance pattern resembles well that known of main sequence CP metallic line (Am) stars, the object sets important constraints to the diffusion theory. Additional spectroscopic and spectropolarimetric data allowed us to conclude that the object is probably a single non-magnetic star.", "link": "http://dx.doi.org/10.1093/mnras/stu1130"}, {"index": 931, "title": "Decoding Stock Market Behavior with the Topological Quantum Computer", "abstract": "A surprising image of the stock market arises if the price time series of all Dow Jones Industrial Average stock components are represented in one chart at once. The chart evolves into a braid representation of the stock market by taking into account only the crossing of stocks and fixing a convention defining overcrossings and undercrossings. The braid of stocks prices has a remarkable connection with the topological quantum computer. Using pairs of quasi-particles, called non-abelian anyons, having their trajectories braided in time, topological quantum computer can effectively simulate the stock market behavior encoded in the braiding of stocks. In a typically topological quantum computation process the trajectories of non-abelian anyons are manipulated according to the braiding of stocks and the outcome reflects the probability of the future state of stock market. The probability depends only on the Jones polynomial of the knot formed by plat closing the quantum computation. The Jones polynomial of the knotted stock market acts, making a parallel with the common financial literature, in a topological quantum computation as a counterpart of a classical technical indicator in trading the stock market. The type of knot stock market formed is an indicator of its future tendencies.", "link": "http://arxiv.org/abs/1406.3531v1"}, {"index": 932, "title": "Supervised classification-based stock prediction and portfolio optimization", "abstract": "As the number of publicly traded companies as well as the amount of their financial data grows rapidly, it is highly desired to have tracking, analysis, and eventually stock selections automated. There have been few works focusing on estimating the stock prices of individual companies. However, many of those have worked with very small number of financial parameters. In this work, we apply machine learning techniques to address automated stock picking, while using a larger number of financial parameters for individual companies than the previous studies. Our approaches are based on the supervision of prediction parameters using company fundamentals, time-series properties, and correlation information between different stocks. We examine a variety of supervised learning techniques and found that using stock fundamentals is a useful approach for the classification problem, when combined with the high dimensional data handling capabilities of support vector machine. The portfolio our system suggests by predicting the behavior of stocks results in a 3% larger growth on average than the overall market within a 3-month time period, as the out-of-sample test suggests.", "link": "http://arxiv.org/abs/1406.0824v1"}, {"index": 933, "title": "Does the \"uptick rule\" stabilize the stock market? Insights from Adaptive Rational Equilibrium Dynamics", "abstract": "This paper investigates the effects of the \"uptick rule\" (a short selling regulation formally known as rule 10a-1) by means of a simple stock market model, based on the ARED (adaptive rational equilibrium dynamics) modeling framework, where heterogeneous and adaptive beliefs on the future prices of a risky asset were first shown to be responsible for endogenous price fluctuations.   The dynamics of stock prices generated by the model, with and without the uptick-rule restriction, are analyzed by pairing the classical fundamental prediction with beliefs based on both linear and nonlinear technical analyses. The comparison shows a reduction of downward price movements of undervalued shares when the short selling restriction is imposed. This gives evidence that the uptick rule meets its intended objective. However, the effects of the short selling regulation fade when the intensity of choice to switch trading strategies is high. The analysis suggests possible side effects of the regulation on price dynamics.", "link": "http://arxiv.org/abs/1405.7747v1"}, {"index": 934, "title": "Minimal proper non-IRUP instances of the one-dimensional Cutting Stock Problem", "abstract": "We consider the well-known one dimensional cutting stock problem (1CSP). Based on the pattern structure of the classical ILP formulation of Gilmore and Gomory, we can decompose the infinite set of 1CSP instances, with a fixed demand n, into a finite number of equivalence classes. We show up a strong relation to weighted simple games. Studying the integer round-up property we computationally show that all 1CSP instances with $n\\le 9$ are proper IRUP, while we give examples of a proper non-IRUP instances with $n=10$. A gap larger than 1 occurs for $n=11$. The worst known gap is raised from 1.003 to 1.0625. The used algorithmic approaches are based on exhaustive enumeration and integer linear programming. Additionally we give some theoretical bounds showing that all 1CSP instances with some specific parameters have the proper IRUP.", "link": "http://dx.doi.org/10.1016/j.dam.2015.02.020"}, {"index": 935, "title": "Application of Multilayer Feedforward Neural Networks in Predicting Tree Height and Forest Stock Volume of Chinese Fir", "abstract": "Wood increment is critical information in forestry management. Previous studies used mathematics models to describe complex growing pattern of forest stand, in order to determine the dynamic status of growing forest stand in multiple conditions. In our research, we aimed at studying non-linear relationships to establish precise and robust Artificial Neural Networks (ANN) models to predict the precise values of tree height and forest stock volume based on data of Chinese fir. Results show that Multilayer Feedforward Neural Networks with 4 nodes (MLFN-4) can predict the tree height with the lowest RMS error (1.77); Multilayer Feedforward Neural Networks with 7 nodes (MLFN-7) can predict the forest stock volume with the lowest RMS error (4.95). The training and testing process have proved that our models are precise and robust.", "link": "http://arxiv.org/abs/1405.5206v1"}, {"index": 936, "title": "Quantum spatial-periodic harmonic model for daily price-limited stock markets", "abstract": "We investigate the behavior of stocks in daily price-limited stock markets by purposing a quantum spatial-periodic harmonic model. The stock price is presumed to oscillate and damp in a quantum spatial-periodic harmonic oscillator potential well. Complicated non-linear relations including inter-band positive correlation and intra-band negative correlation between the volatility and the trading volume of stocks are derived by considering the energy band structure of the model. The validity of price limitation is then examined and abnormal phenomena of a price-limited stock market (Shanghai Stock Exchange) of China are studied by applying our quantum model.", "link": "http://dx.doi.org/10.1016/j.physa.2015.06.041"}, {"index": 937, "title": "Quantum Brownian motion model for the stock market", "abstract": "It is believed by the majority today that the efficient market hypothesis is imperfect because of market irrationality. Using the physical concepts and mathematical structures of quantum mechanics, we construct an econophysics framework for the stock market, based on which we analogously map massive numbers of single stocks into a reservoir consisting of many quantum harmonic oscillators and their stock index into a typical quantum open system--a quantum Brownian particle. In particular, the irrationality of stock transactions is quantitatively considered as the Planck constant within Heisenberg's uncertainty relationship of quantum mechanics in an analogous manner. We analyze real stock data of Shanghai Stock Exchange of China and investigate fat-tail phenomena and non-Markovian behaviors of the stock index with the assistance of the quantum Brownian motion model, thereby interpreting and studying the limitations of the classical Brownian motion model for the efficient market hypothesis from a new perspective of quantum open system dynamics.", "link": "http://dx.doi.org/10.1016/j.physa.2016.02.026"}, {"index": 938, "title": "Gaussian-Chain Filters for Heavy-Tailed Noise with Application to Detecting Big Buyers and Big Sellers in Stock Market", "abstract": "We propose a new heavy-tailed distribution --- Gaussian-Chain (GC) distribution, which is inspirited by the hierarchical structures prevailing in social organizations. We determine the mean, variance and kurtosis of the Gaussian-Chain distribution to show its heavy-tailed property, and compute the tail distribution table to give specific numbers showing how heavy is the heavy-tails. To filter out the heavy-tailed noise, we construct two filters --- 2nd and 3rd-order GC filters --- based on the maximum likelihood principle. Simulation results show that the GC filters perform much better than the benchmark least-squares algorithm when the noise is heavy-tail distributed. Using the GC filters, we propose a trading strategy, named Ride-the-Mood, to follow the mood of the market by detecting the actions of the big buyers and the big sellers in the market based on the noisy, heavy-tailed price data. Application of the Ride-the-Mood strategy to five blue-chip Hong Kong stocks over the recent two-year period from April 2, 2012 to March 31, 2014 shows that their returns are higher than the returns of the benchmark Buy-and-Hold strategy and the Hang Seng Index Fund.", "link": "http://arxiv.org/abs/1405.2220v1"}, {"index": 939, "title": "Stylized facts of price gaps in limit order books: Evidence from Chinese stocks", "abstract": "Price gap, defined as the logarithmic price difference between the first two occupied price levels on the same side of a limit order book (LOB), is a key determinant of market depth, which is one of the dimensions of liquidity. However, the properties of price gaps have not been thoroughly studied due to the less availability of ultrahigh frequency data. In the paper, we rebuild the LOB dynamics based on the order flow data of 26 A-share stocks traded on the Shenzhen Stock Exchange in 2003. Three key empirical statistical properties of price gaps are investigated. We find that the distribution of price gaps has a power-law tail for all stocks with an average tail exponent close to 3.2. Applying modern statistical methods, we confirm that the gap time series are long-range correlated and possess multifractal nature. These three features vary from stock to stock and are not universal. Furthermore, we also unveil buy-sell asymmetry phenomena in the properties of price gaps on the buy and sell sides of the LOBs for individual stocks. These findings deepen our understanding of the dynamics of liquidity of common stocks and can be used to calibrate agent-based computational financial models.", "link": "http://dx.doi.org/10.1016/j.chaos.2015.10.031"}, {"index": 940, "title": "Predictable markets? A news-driven model of the stock market", "abstract": "We attempt to explain stock market dynamics in terms of the interaction among three variables: market price, investor opinion and information flow. We propose a framework for such interaction and apply it to build a model of stock market dynamics which we study both empirically and theoretically. We demonstrate that this model replicates observed market behavior on all relevant timescales (from days to years) reasonably well. Using the model, we obtain and discuss a number of results that pose implications for current market theory and offer potential practical applications.", "link": "http://arxiv.org/abs/1404.7364v2"}, {"index": 941, "title": "Braided and Knotted Stocks in the Stock Market: Anticipating the flash crashes", "abstract": "A simple and elegant arrangement of stock components of a portfolio (market index-DJIA) in a recent paper [1], has led to the construction of crossing of stocks diagram. The crossing stocks method revealed hidden remarkable algebraic and geometrical aspects of stock market. The present paper continues to uncover new mathematical structures residing from crossings of stocks diagram by introducing topological properties stock market is endowed with. The crossings of stocks are categorized as overcrossings and undercrossings and interpreted as generators of braid that stocks form in the process of prices quotations in the market. Topological structure of the stock market is even richer if the closure of stocks braid is considered, such that it forms a knot. To distinguish the kind of knot that stock market forms, Alexander-Conway polynomial and the Jones polynomials are calculated for some knotted stocks. These invariants of knots are important for the future practical applications topological stock market might have. Such application may account of the relation between Jones polynomial and phase transition statistical models to provide a clear way to anticipate the transition of financial markets to the phase that leads to crisis. The resemblance between braided stocks and logic gates of topological quantum computers could quantum encode the stock market behavior.", "link": "http://arxiv.org/abs/1404.6637v2"}, {"index": 942, "title": "Stochastic Evolution of Stock Market Volume-Price Distributions", "abstract": "Using available data from the New York stock market (NYSM) we test four different bi-parametric models to fit the correspondent volume-price distributions at each $10$-minute lag: the Gamma distribution, the inverse Gamma distribution, the Weibull distribution and the log-normal distribution. The volume-price data, which measures market capitalization, appears to follow a specific statistical pattern, other than the evolution of prices measured in similar studies. We find that the inverse Gamma model gives a superior fit to the volume-price evolution than the other models. We then focus on the inverse Gamma distribution as a model for the NYSM data and analyze the evolution of the pair of distribution parameters as a stochastic process. Assuming that the evolution of these parameters is governed by coupled Langevin equations, we derive the corresponding drift and diffusion coefficients, which then provide insight for understanding the mechanisms underlying the evolution of the stock market.", "link": "http://arxiv.org/abs/1404.1730v2"}, {"index": 943, "title": "Ensemble Committees for Stock Return Classification and Prediction", "abstract": "This paper considers a portfolio trading strategy formulated by algorithms in the field of machine learning. The profitability of the strategy is measured by the algorithm's capability to consistently and accurately identify stock indices with positive or negative returns, and to generate a preferred portfolio allocation on the basis of a learned model. Stocks are characterized by time series data sets consisting of technical variables that reflect market conditions in a previous time interval, which are utilized produce binary classification decisions in subsequent intervals. The learned model is constructed as a committee of random forest classifiers, a non-linear support vector machine classifier, a relevance vector machine classifier, and a constituent ensemble of k-nearest neighbors classifiers. The Global Industry Classification Standard (GICS) is used to explore the ensemble model's efficacy within the context of various fields of investment including Energy, Materials, Financials, and Information Technology. Data from 2006 to 2012, inclusive, are considered, which are chosen for providing a range of market circumstances for evaluating the model. The model is observed to achieve an accuracy of approximately 70% when predicting stock price returns three months in advance.", "link": "http://arxiv.org/abs/1404.1492v1"}, {"index": 944, "title": "An agent-based computational model for China's stock market and stock index futures market", "abstract": "This study presents an agent-based computational cross-market model for Chinese equity market structure, which includes both stocks and CSI 300 index futures. In this model, we design several stocks and one index futures to simulate this structure. This model allows heterogeneous investors to make investment decisions with restrictions including wealth, market trading mechanism, and risk management. Investors' demands and order submissions are endogenously determined. Our model successfully reproduces several key features of the Chinese financial markets including spot-futures basis distribution, bid-ask spread distribution, volatility clustering and long memory in absolute returns. Our model can be applied in cross-market risk control, market mechanism design and arbitrage strategies analysis.", "link": "http://dx.doi.org/10.1155/2014/563912"}, {"index": 945, "title": "Computational experiments successfully predict the emergence of autocorrelations in ultra-high-frequency stock returns", "abstract": "Social and economic systems are complex adaptive systems, in which heterogenous agents interact and evolve in a self-organized manner, and macroscopic laws emerge from microscopic properties. To understand the behaviors of complex systems, computational experiments based on physical and mathematical models provide a useful tools. Here, we perform computational experiments using a phenomenological order-driven model called the modified Mike-Farmer (MMF) to predict the impacts of order flows on the autocorrelations in ultra-high-frequency returns, quantified by Hurst index $H_r$. Three possible determinants embedded in the MMF model are investigated, including the Hurst index $H_s$ of order directions, the Hurst index $H_x$ and the power-law tail index $\\alpha_x$ of the relative prices of placed orders. The computational experiments predict that $H_r$ is negatively correlated with $\\alpha_x$ and $H_x$ and positively correlated with $H_s$. In addition, the values of $\\alpha_x$ and $H_x$ have negligible impacts on $H_r$, whereas $H_s$ exhibits a dominating impact on $H_r$. The predictions of the MMF model on the dependence of $H_r$ upon $H_s$ and $H_x$ are verified by the empirical results obtained from the order flow data of 43 Chinese stocks.", "link": "http://dx.doi.org/10.1007/s10614-016-9612-1"}, {"index": 946, "title": "Asymptotic analysis of stock price densities and implied volatilities in mixed stochastic models", "abstract": "In this paper, we obtain sharp asymptotic formulas with error estimates for the Mellin convolution of functions, and use these formulas to characterize the asymptotic behavior of marginal distribution densities of stock price processes in mixed stochastic models. Special examples of mixed models are jump-diffusion models and stochastic volatility models with jumps. We apply our general results to the Heston model with double exponential jumps, and make a detailed analysis of the asymptotic behavior of the stock price density, the call option pricing function, and the implied volatility in this model. We also obtain similar results for the Heston model with jumps distributed according to the NIG law.", "link": "http://arxiv.org/abs/1403.5302v1"}, {"index": 947, "title": "Collective behaviours in the stock market -- A maximum entropy approach", "abstract": "Scale invariance, collective behaviours and structural reorganization are crucial for portfolio management (portfolio composition, hedging, alternative definition of risk, etc.). This lack of any characteristic scale and such elaborated behaviours find their origin in the theory of complex systems. There are several mechanisms which generate scale invariance but maximum entropy models are able to explain both scale invariance and collective behaviours. The study of the structure and collective modes of financial markets attracts more and more attention. It has been shown that some agent based models are able to reproduce some stylized facts. Despite their partial success, there is still the problem of rules design. In this work, we used a statistical inverse approach to model the structure and co-movements in financial markets. Inverse models restrict the number of assumptions. We found that a pairwise maximum entropy model is consistent with the data and is able to describe the complex structure of financial systems. We considered the existence of a critical state which is linked to how the market processes information, how it responds to exogenous inputs and how its structure changes. The considered data sets did not reveal a persistent critical state but rather oscillations between order and disorder. In this framework, we also showed that the collective modes are mostly dominated by pairwise co-movements and that univariate models are not good candidates to model crashes. The analysis also suggests a genuine adaptive process since both the maximum variance of the log-likelihood and the accuracy of the predictive scheme vary through time. This approach may provide some clue to crash precursors and may provide highlights on how a shock spreads in a financial network and if it will lead to a crash. The natural continuation of the present work could be the study of such a mechanism.", "link": "http://arxiv.org/abs/1403.5179v2"}, {"index": 948, "title": "Photoelectric search for peculiar stars in open clusters. XV. Feinstein 1, NGC 2168, NGC 2323, NGC 2437, NGC 2547, NGC 4103, NGC 6025, NGC 6633, Stock 2, and Trumpler 2", "abstract": "The chemically peculiar (CP) stars of the upper main sequence are mainly characterized by strong overabundances of heavy elements. Two subgroups (CP2 and CP4) have strong local magnetic fields which make them interesting targets for astrophysical studies. This star group, in general, is often used for the analysis of stellar formation and evolution in the context of diffusion as well as meridional circulation. In continuation of a long term study of CP stars (initiated in the 1980ies), we present new results based on photoelectric measurements for ten open clusters that are, with one exception, younger than 235Myr. Observations in star clusters are favourable because they represent samples of stars of constant age and homogeneous chemical composition. The very efficient tool of Delta a photometry was applied. It samples the flux depression at 5200A typically for CP stars. In addition, it is able to trace emission line Be/Ae and lambda Bootis stars. Virtually all CP2 and CP4 stars can be detected via this tool. For all targets in the cluster areas, we performed a kinematic membership analysis. We obtained new photoelectric Delta a photometry of 304 stars from which 207 objects have a membership probability higher than 50%. Our search for chemically peculiar objects results in fifteen detections. The stars have masses between 1.7 M(Sun) and 7.7 M(Sun) and are between the zero- and terminal-age-main-sequence. We discuss the published spectral classifications in the light of our Delta a photometry and identify several misclassified CP stars. We are also able to establish and support the nature of known bona fide CP candidates. The new and confirmed CP stars are interesting targets for spectroscopic follow-up observations to put constraints on the formation and evolution of CP stars.", "link": "http://dx.doi.org/10.1051/0004-6361/201423521"}, {"index": 949, "title": "Empirical properties of inter-cancellation durations in the Chinese stock market", "abstract": "Order cancellation process plays a crucial role in the dynamics of price formation in order-driven stock markets and is important in the construction and validation of computational finance models. Based on the order flow data of 18 liquid stocks traded on the Shenzhen Stock Exchange in 2003, we investigate the empirical statistical properties of inter-cancellation durations in units of events defined as the waiting times between two consecutive cancellations. The inter-cancellation durations for both buy and sell orders of all the stocks favor a $q$-exponential distribution when the maximum likelihood estimation method is adopted; In contrast, both cancelled buy orders of 6 stocks and cancelled sell orders of 3 stocks prefer Weibull distribution when the nonlinear least-square estimation is used. Applying detrended fluctuation analysis (DFA), centered detrending moving average (CDMA) and multifractal detrended fluctuation analysis (MF-DFA) methods, we unveil that the inter-cancellation duration time series process long memory and multifractal nature for both buy and sell cancellations of all the stocks. Our findings show that order cancellation processes exhibit long-range correlated bursty behaviors and are thus not Poissonian.", "link": "http://dx.doi.org/10.3389/fphy.2014.00016"}, {"index": 950, "title": "Time Series Analysis on Stock Market for Text Mining Correlation of Economy News", "abstract": "This paper proposes an information retrieval method for the economy news. The effect of economy news, are researched in the word level and stock market values are considered as the ground proof. The correlation between stock market prices and economy news is an already addressed problem for most of the countries. The most well-known approach is applying the text mining approaches to the news and some time series analysis techniques over stock market closing values in order to apply classification or clustering algorithms over the features extracted. This study goes further and tries to ask the question what are the available time series analysis techniques for the stock market closing values and which one is the most suitable? In this study, the news and their dates are collected into a database and text mining is applied over the news, the text mining part has been kept simple with only term frequency-inverse document frequency method. For the time series analysis part, we have studied 10 different methods such as random walk, moving average, acceleration, Bollinger band, price rate of change, periodic average, difference, momentum or relative strength index and their variation. In this study we have also explained these techniques in a comparative way and we have applied the methods over Turkish Stock Market closing values for more than a 2 year period. On the other hand, we have applied the term frequency-inverse document frequency method on the economy news of one of the high-circulating newspapers in Turkey.", "link": "http://arxiv.org/abs/1403.2002v1"}, {"index": 951, "title": "A Machine Learning Model for Stock Market Prediction", "abstract": "Stock market prediction is the act of trying to determine the future value of a company stock or other financial instrument traded on a financial exchange.", "link": "http://arxiv.org/abs/1402.7351v1"}, {"index": 952, "title": "LSSVM-ABC Algorithm for Stock Price prediction", "abstract": "In this paper, Artificial Bee Colony (ABC) algorithm which inspired from the behavior of honey bees swarm is presented. ABC is a stochastic population-based evolutionary algorithm for problem solving. ABC algorithm, which is considered one of the most recently swarm intelligent techniques, is proposed to optimize least square support vector machine (LSSVM) to predict the daily stock prices. The proposed model is based on the study of stocks historical data, technical indicators and optimizing LSSVM with ABC algorithm. ABC selects best free parameters combination for LSSVM to avoid over-fitting and local minima problems and improve prediction accuracy. LSSVM optimized by Particle swarm optimization (PSO) algorithm, LSSVM, and ANN techniques are used for comparison with proposed model. Proposed model tested with twenty datasets representing different sectors in S&P 500 stock market. Results presented in this paper show that the proposed model has fast convergence speed, and it also achieves better accuracy than compared techniques in most cases.", "link": "http://arxiv.org/abs/1402.6366v1"}, {"index": 953, "title": "Stock portfolio structure of individual investors infers future trading behavior", "abstract": "Although the understanding of and motivation behind individual trading behavior is an important puzzle in finance, little is known about the connection between an investor's portfolio structure and her trading behavior in practice. In this paper, we investigate the relation between what stocks investors hold, and what stocks they buy, and show that investors with similar portfolio structures to a great extent trade in a similar way. With data from the central register of shareholdings in Sweden, we model the market in a similarity network, by considering investors as nodes, connected with links representing portfolio similarity. From the network, we find groups of investors that not only identify different investment strategies, but also represent groups of individual investors trading in a similar way. These findings suggest that the stock portfolios of investors hold meaningful information, which could be used to earn a better understanding of stock market dynamics.", "link": "http://dx.doi.org/10.1371/journal.pone.0103006"}, {"index": 954, "title": "Correlation and Network Topologies in Global and Local Stock Indices", "abstract": "This study examined how the correlation and network structure of 30 global indices and 145 local Korean indices belonging to the KOSPI 200 have changed during the 13-year period, 2000-2012. The correlations among the indices were calculated. The results showed that although the average correlations of the global indices increased with time, the local indices showed a decreasing trend except for drastic changes during crises. The average correlation of the local indices exceeded the global indices during the crises from 2000-2002, implying a strong correlation structure among the local indices during this period due to the detrimental effect of the dot-com bubble. The threshold networks (TN) were constructed in the observation time window by assigning a threshold value and determining the network topologies. A significant change in the network topologies was observed due to the financial crises in both markets. The Jaccard similarities were also determined using the common links of TNs. The TNs of the financial network were not consistent with the evolution of the time, and the successive TNs of the global indices were more similar than those of the successive local indices. Finally, the Jaccard similarities identified the change in the market state due to a crisis in both markets.", "link": "http://dx.doi.org/10.1016/j.physleta.2014.07.009"}, {"index": 955, "title": "Crossing Stocks and the Positive Grassmannian I: The Geometry behind Stock Market", "abstract": "It seems to be very unlikely that all relevant information in the stock market could be fully encoded in a geometrical shape. Still,the present paper will reveal the geometry behind the stock market transactions. The prices of market index (DJIA) stock components are arranged in ascending order from the smallest one in the left to the highest in the right. In such arrangement, as stock prices changes due to daily market quotations, it could be noticed that the price of a certain stock get over /under the price of a neighbor stock. These stocks are crossing. Arranged this way, the diagram of successive stock crossings is nothing else than a permutation diagram. From this point on the financial and combinatorial concepts are netted together to build a bridge connecting the stock market to a beautiful geometrical object that will be called stock market polytope. The stock market polytope is associated with the remarkable structure of positive Grassmannian . This procedure makes all the relevant information about the stock market encoded in the geometrical shape of the stock market polytope more readable.", "link": "http://arxiv.org/abs/1402.1281v2"}, {"index": 956, "title": "Cross-correlation asymmetries and causal relationships between stock and market risk", "abstract": "We study historical correlations and lead-lag relationships between individual stock risk (volatility of daily stock returns) and market risk (volatility of daily returns of a market-representative portfolio) in the US stock market. We consider the cross-correlation functions averaged over all stocks, using 71 stock prices from the Standard \\& Poor's 500 index for 1994--2013. We focus on the behavior of the cross-correlations at the times of financial crises with significant jumps of market volatility. The observed historical dynamics showed that the dependence between the risks was almost linear during the US stock market downturn of 2002 and after the US housing bubble in 2007, remaining on that level until 2013. Moreover, the averaged cross-correlation function often had an asymmetric shape with respect to zero lag in the periods of high correlation. We develop the analysis by the application of the linear response formalism to study underlying causal relations. The calculated response functions suggest the presence of characteristic regimes near financial crashes, when the volatility of an individual stock follows the market volatility and vice versa.", "link": "http://dx.doi.org/10.1371/journal.pone.0105874"}, {"index": 957, "title": "Multiple-output support vector regression with a firefly algorithm for interval-valued stock price index forecasting", "abstract": "Highly accurate interval forecasting of a stock price index is fundamental to successfully making a profit when making investment decisions, by providing a range of values rather than a point estimate. In this study, we investigate the possibility of forecasting an interval-valued stock price index series over short and long horizons using multi-output support vector regression (MSVR). Furthermore, this study proposes a firefly algorithm (FA)-based approach, built on the established MSVR, for determining the parameters of MSVR (abbreviated as FA-MSVR). Three globally traded broad market indices are used to compare the performance of the proposed FA-MSVR method with selected counterparts. The quantitative and comprehensive assessments are performed on the basis of statistical criteria, economic criteria, and computational cost. In terms of statistical criteria, we compare the out-of-sample forecasting using goodness-of-forecast measures and testing approaches. In terms of economic criteria, we assess the relative forecast performance with a simple trading strategy. The results obtained in this study indicate that the proposed FA-MSVR method is a promising alternative for forecasting interval-valued financial time series.", "link": "http://dx.doi.org/10.1016/j.knosys.2013.10.012"}, {"index": 958, "title": "Dynamical Models of Stock Prices Based on Technical Trading Rules Part III: Application to Hong Kong Stocks", "abstract": "In Part III of this study, we apply the price dynamical model with big buyers and big sellers developed in Part I of this paper to the daily closing prices of the top 20 banking and real estate stocks listed in the Hong Kong Stock Exchange. The basic idea is to estimate the strength parameters of the big buyers and the big sellers in the model and make buy/sell decisions based on these parameter estimates. We propose two trading strategies: (i) Follow-the-Big-Buyer which buys when big buyer begins to appear and there is no sign of big sellers, holds the stock as long as the big buyer is still there, and sells the stock once the big buyer disappears; and (ii) Ride-the-Mood which buys as soon as the big buyer strength begins to surpass the big seller strength, and sells the stock once the opposite happens. Based on the testing over 245 two-year intervals uniformly distributed across the seven years from 03-July-2007 to 02-July-2014 which includes a variety of scenarios, the net profits would increase 67% or 120% on average if an investor switched from the benchmark Buy-and-Hold strategy to the Follow-the-Big-Buyer or Ride-the-Mood strategies during this period, respectively.", "link": "http://dx.doi.org/10.1109/TFUZZ.2014.2374193"}, {"index": 959, "title": "Dynamical Models of Stock Prices Based on Technical Trading Rules Part II: Analysis of the Models", "abstract": "In Part II of this paper, we concentrate our analysis on the price dynamical model with the moving average rules developed in Part I of this paper. By decomposing the excessive demand function, we reveal that it is the interplay between trend-following and contrarian actions that generates the price chaos, and give parameter ranges for the price series to change from divergence to chaos and to oscillation. We prove that the price dynamical model has an infinite number of equilibrium points but all these equilibrium points are unstable. We demonstrate the short-term predictability of the return volatility and derive the detailed formula of the Lyapunov exponent as function of the model parameters. We show that although the price is chaotic, the volatility converges to some constant very quickly at the rate of the Lyapunov exponent. We extract the formula relating the converged volatility to the model parameters based on Monte-Carlo simulations. We explore the circumstances under which the returns show independency and illustrate in details how the independency index changes with the model parameters. Finally, we plot the strange attractor and return distribution of the chaotic price model to illustrate the complex structure and fat-tailed distribution of the returns.", "link": "http://dx.doi.org/10.1109/TFUZZ.2014.2346244"}, {"index": 960, "title": "Dynamical Models of Stock Prices Based on Technical Trading Rules Part I: The Models", "abstract": "In this paper we use fuzzy systems theory to convert the technical trading rules commonly used by stock practitioners into excess demand functions which are then used to drive the price dynamics. The technical trading rules are recorded in natural languages where fuzzy words and vague expressions abound. In Part I of this paper, we will show the details of how to transform the technical trading heuristics into nonlinear dynamic equations. First, we define fuzzy sets to represent the fuzzy terms in the technical trading rules; second, we translate each technical trading heuristic into a group of fuzzy IF-THEN rules; third, we combine the fuzzy IF-THEN rules in a group into a fuzzy system; and finally, the linear combination of these fuzzy systems is used as the excess demand function in the price dynamic equation. We transform a wide variety of technical trading rules into fuzzy systems, including moving average rules, support and resistance rules, trend line rules, big buyer, big seller and manipulator rules, band and stop rules, and volume and relative strength rules. Simulation results show that the price dynamics driven by these technical trading rules are complex and chaotic, and some common phenomena in real stock prices such as jumps, trending and self-fulfilling appear naturally.", "link": "http://dx.doi.org/10.1109/TFUZZ.2014.2327994"}, {"index": 961, "title": "ss3sim: An R package for fisheries stock assessment simulation with Stock Synthesis", "abstract": "Simulation testing is an important approach to evaluating fishery stock assessment methods. In the last decade, the fisheries stock assessment modeling framework Stock Synthesis (SS3) has become widely used around the world. However, there lacks a generalized and scriptable framework for SS3 simulation testing. Here, we introduce ss3sim, an R package that facilitates reproducible, flexible, and rapid end-to-end simulation testing with SS3. ss3sim requires an existing SS3 model configuration along with plain-text control files describing alternative population dynamics, fishery properties, sampling scenarios, and assessment approaches. ss3sim then generates an underlying 'truth' from a specified operating model, samples from that truth, modifies and runs an estimation model, and synthesizes the results. The simulations can be run in parallel, reducing runtime, and the source code is free to be modified under an open-source MIT license. ss3sim is designed to explore structural differences between the underlying truth and assumptions of an estimation model, or between multiple estimation model configurations. For example, ss3sim can be used to answer questions about model misspecification, retrospective patterns, and the relative importance of different types of fisheries data. We demonstrate the software with an example, discuss how ss3sim complements other simulation software, and outline specific research questions that ss3sim could address.", "link": "http://dx.doi.org/10.1371/journal.pone.0092725"}, {"index": 962, "title": "Coupled mode theory of stock price formation", "abstract": "We develop a theory of bid and ask price dynamics where the two prices form due to interaction of buy and sell orders. In this model the two prices are represented by eigenvalues of a 2x2 price operator corresponding to \"bid\" and \"ask\" eigenstates. Matrix elements of price operator fluctuate in time which results in phase jitter for eigenstates. We show that the theory reflects very important characteristics of bid and ask dynamics and order density in the order book. Calibration examples are provided for stocks at various time scales. Lastly, this model allows to quantify and measure risk associated with spread and its fluctuations.", "link": "http://arxiv.org/abs/1312.4622v1"}, {"index": 963, "title": "Nucleation, condensation and lambda-transition on a real-life stock market", "abstract": "We fill a void in merging empirical and phenomenological characterisation of the dynamical phase transitions in complex systems by identifying three of them on real-life financial markets. We extract and interpret the empirical, numerical, and semi-analytical evidences for the existence of these phase transitions, by considering the Frankfurt Stock Exchange (FSE), as a typical example of a financial market of a medium size. Using the canonical object for the graph theory, i.e. the Minimal Spanning Tree (MST) network, we observe: (i) The initial phase transition from the equilibrium to non-equilibrium MST network in its nucleation phase, occurring at some critical time. Coalescence of edges on the FSE's transient leader is observed within the nucleation and is approximately characterized by the Lifsthiz-Slyozov growth exponent; (ii) The nucleation accelerates and transforms to the condensation process, in the second phase transition, forming a logarithmically diverging lambda-peak of short-range order parameters at the subsequent critical time - an analogon of such a transition in superfluidity; (iii) In the third phase transition, the peak logarithmically decreases over three quarters of the year, resulting in a few loosely connected sub-graphs. This peak is reminiscent of a non-equilibrium superstar-like superhub or a `dragon king' effect, abruptly accelerating the evolution of the leader company. All these phase transitions are caused by the few richest vertices, which drift towards the leader and provide the most of the edges increasing the leader's degree. Thus, we capture an amazing phenomenon, likely of a more universal character, where a peripheral vertex becomes the one which is over dominating the complex network during an exceptionally long period of time.", "link": "http://arxiv.org/abs/1311.5753v3"}, {"index": 964, "title": "Stock Market Trend Analysis Using Hidden Markov Models", "abstract": "Price movements of stock market are not totally random. In fact, what drives the financial market and what pattern financial time series follows have long been the interest that attracts economists, mathematicians and most recently computer scientists [17]. This paper gives an idea about the trend analysis of stock market behaviour using Hidden Markov Model (HMM). The trend once followed over a particular period will sure repeat in future. The one day difference in close value of stocks for a certain period is found and its corresponding steady state probability distribution values are determined. The pattern of the stock market behaviour is then decided based on these probability values for a particular time. The goal is to figure out the hidden state sequence given the observation sequence so that the trend can be analyzed using the steady state probability distribution( ) values. Six optimal hidden state sequences are generated and compared. The one day difference in close value when considered is found to give the best optimum state sequence.", "link": "http://arxiv.org/abs/1311.4771v1"}, {"index": 965, "title": "Impact of information cost and switching of trading strategies in an artificial stock market", "abstract": "This paper studies the switching of trading strategies and its effect on the market volatility in a continuous double auction market. We describe the behavior when some uninformed agents, who we call switchers, decide whether or not to pay for information before they trade. By paying for the information they behave as informed traders. First we verify that our model is able to reproduce some of the stylized facts in real financial markets. Next we consider the relationship between switching and the market volatility under different structures of investors. We find that there exists a positive relationship between the market volatility and the percentage of switchers. We therefore conclude that the switchers are a destabilizing factor in the market. However, for a given fixed percentage of switchers, the proportion of switchers that decide to buy information at a given moment of time is negatively related to the current market volatility. In other words, if more agents pay for information to know the fundamental value at some time, the market volatility will be lower. This is because the market price is closer to the fundamental value due to information diffusion between switchers.", "link": "http://dx.doi.org/10.1016/j.physa.2014.04.004"}, {"index": 966, "title": "Structural Changes on Warsaw's Stock Exchange: the end of Financial Crisis", "abstract": "In this paper we analyse the structure of Warsaw's stock market using complex systems methodology together with network science and information theory. We find minimal spanning trees for log returns on Warsaw's stock exchange for yearly times series between 2000 and 2013. For each stock in those trees we calculate its Markov centrality measure to estimate its importance in the network. We also estimate entropy rate for each of those time series using Lempel-Ziv algorithm based estimator to study the predictability of those price changes. The division of the studied stocks into 26 sectors allows us to study the changing structure of the Warsaw's stock market and conclude that the financial crisis sensu stricto has ended on Warsaw's stock market in 2012-13. We also comment on the history and the outlook of the Warsaw's market based on the log returns, their average, variability, entropy and the centrality of a stock in the dependency network.", "link": "http://arxiv.org/abs/1311.4230v1"}, {"index": 967, "title": "Multiagent's model of stock market with p-adic description of prices", "abstract": "A new multiagent model of the stock market is formulated that contains four states in which the agents may be located. Next, the model is reformulated in the language of the functional integral containing fluctuations of prices and quantities of cash flows. It is shown that in the functional integral of that type description of the prices is given not by the real numbers as is made in many papers but the p-adic numbers. It is shown in the following simple examples extracted from the proposed theory that the p-adic description of prices gives good description of fractal behavior of the trends. The formula is given for the p-adic mapping of prices. Using this formula we obtain the main p-adic patterns which are the same as the patterns of Elliott wave theory, this fact allows us to give a rigorous mathematical proof of this theory. Our model is the only model that gives a strict point like description of the fractal behavior of prices. The developed approach opens the possibility to give the formulation of p-adic technical analysis of the stock market.", "link": "http://arxiv.org/abs/1310.8431v1"}, {"index": 968, "title": "Stock returns versus trading volume: is the correspondence more general?", "abstract": "This paper presents a quantitative analysis of the relationship between the stock market returns and corresponding trading volumes using high- frequency data from the Polish stock market. First, for stocks that were traded for suffciently long period of time, we study the return and volume distributions and identify their consistency with the power-law functions. We find that, for majority of stocks, the scaling exponents of both distri- butions are systematically related by about a factor of 2 with the ones for the returns being larger. Second, we study the empirical price impact of trades of a given volume and find that this impact can be well described by a square-root dependence: r(V) V^(1/2). We conclude that the prop- erties of data from the Polish market resemble those reported in literature concerning certain mature markets.", "link": "http://dx.doi.org/10.5506/APhysPolB.44.2035"}, {"index": 969, "title": "Frequency Effects on Predictability of Stock Returns", "abstract": "We propose that predictability is a prerequisite for profitability on financial markets. We look at ways to measure predictability of price changes using information theoretic approach and employ them on all historical data available for NYSE 100 stocks. This allows us to determine whether frequency of sampling price changes affects the predictability of those. We also relations between price changes predictability and the deviation of the price formation processes from iid as well as the stock's sector. We also briefly comment on the complicated relationship between predictability of price changes and the profitability of algorithmic trading.", "link": "http://arxiv.org/abs/1310.5540v2"}, {"index": 970, "title": "Agent-Based Stock Market Model with Endogenous Agents' Impact", "abstract": "The three-state agent-based 2D model of financial markets as proposed by Giulia Iori has been extended by introducing increasing trust in the correctly predicting agents, a more realistic consultation procedure as well as a formal validation mechanism. This paper shows that such a model correctly reproduces the three fundamental stylised facts: fat-tail log returns, power-law volatility autocorrelation decay in time and volatility clustering.", "link": "http://arxiv.org/abs/1310.0762v2"}, {"index": 971, "title": "Variability Survey in the Open Cluster Stock 14 and the Surrounding Fields", "abstract": "We present the results of a photometric variability survey in the young open cluster Stock 14 and the surrounding fields. In total, we detected 103 variable stars of which 88 are new discoveries. We confirm short-period, low-amplitude light variations in two eclipsing members of the cluster, HD 101838 and HD 101794. In addition, we find two new beta Cephei stars of which one, HD 101993, is also a member. The sample of pulsating cluster members is supplemented by one multimode slowly pulsating B-type star and several single-mode candidates of this type. The other pulsating stars in our sample are mostly field stars. In particular, we found fourteen delta Scuti stars including one gamma Dor/delta Sct hybrid pulsator. From our UBV photometry we derived new parameters of Stock 14: the mean reddening E(B-V) = 0.21 +/- 0.02 mag, the true distance modulus, 11.90 +/- 0.05 mag, and the age, 20 +/- 10 Myr. Finally, we use the new photometry to analyze changes of the 6.322-d orbital period of the bright eclipsing binary and the member of the cluster, V346 Cen. In addition to the known apsidal motion, we find that another effect, possibly light-time effect in a hierarchical system of a very long orbital period, affects these changes. The updated value of the period of apsidal motion for this system amounts to 306 +/- 4 yr. The open cluster Stock 14 was found to be a fairly good candidate for successful ensemble asteroseismology.", "link": "http://arxiv.org/abs/1309.7371v1"}, {"index": 972, "title": "Stock price direction prediction by directly using prices data: an empirical study on the KOSPI and HSI", "abstract": "The prediction of a stock market direction may serve as an early recommendation system for short-term investors and as an early financial distress warning system for long-term shareholders. Many stock prediction studies focus on using macroeconomic indicators, such as CPI and GDP, to train the prediction model. However, daily data of the macroeconomic indicators are almost impossible to obtain. Thus, those methods are difficult to be employed in practice. In this paper, we propose a method that directly uses prices data to predict market index direction and stock price direction. An extensive empirical study of the proposed method is presented on the Korean Composite Stock Price Index (KOSPI) and Hang Seng Index (HSI), as well as the individual constituents included in the indices. The experimental results show notably high hit ratios in predicting the movements of the individual constituents in the KOSPI and HIS.", "link": "http://dx.doi.org/10.1504/IJBIDM.2014.065091"}, {"index": 973, "title": "The Relationship Between Stock Market Parameters and Interbank Lending Market: an Empirical Evidence", "abstract": "The article presents calculations that prove practical importance of the earlier derived theoretical relationship between the interest rate on the interbank credit market, volume of investment and the quantity of securities tradable on the stock exchange.", "link": "http://arxiv.org/abs/1309.5703v1"}, {"index": 974, "title": "A nested factor model for non-linear dependences in stock returns", "abstract": "The aim of our work is to propose a natural framework to account for all the empirically known properties of the multivariate distribution of stock returns. We define and study a \"nested factor model\", where the linear factors part is standard, but where the log-volatility of the linear factors and of the residuals are themselves endowed with a factor structure and residuals. We propose a calibration procedure to estimate these log-vol factors and the residuals. We find that whereas the number of relevant linear factors is relatively large (10 or more), only two or three log-vol factors emerge in our analysis of the data. In fact, a minimal model where only one log-vol factor is considered is already very satisfactory, as it accurately reproduces the properties of bivariate copulas, in particular the dependence of the medial-point on the linear correlation coefficient, as reported in Chicheportiche and Bouchaud (2012). We have tested the ability of the model to predict Out-of-Sample the risk of non-linear portfolios, and found that it performs significantly better than other schemes.", "link": "http://dx.doi.org/10.1080/14697688.2014.994668"}, {"index": 975, "title": "Forecasting Stock Time-Series using Data Approximation and Pattern Sequence Similarity", "abstract": "Time series analysis is the process of building a model using statistical techniques to represent characteristics of time series data. Processing and forecasting huge time series data is a challenging task. This paper presents Approximation and Prediction of Stock Time-series data (APST), which is a two step approach to predict the direction of change of stock price indices. First, performs data approximation by using the technique called Multilevel Segment Mean (MSM). In second phase, prediction is performed for the approximated data using Euclidian distance and Nearest-Neighbour technique. The computational cost of data approximation is O(n ni) and computational cost of prediction task is O(m |NN|). Thus, the accuracy and the time required for prediction in the proposed method is comparatively efficient than the existing Label Based Forecasting (LBF) method [1].", "link": "http://arxiv.org/abs/1309.2517v1"}, {"index": 976, "title": "Modeling of Stock Returns and Trading Volume", "abstract": "In this study, we investigate the statistical properties of the returns and the trading volume. We show a typical example of power-law distributions of the return and of the trading volume. Next, we propose an interacting agent model of stock markets inspired from statistical mechanics [24] to explore the empirical findings. We show that as the interaction among the interacting traders strengthens both the returns and the trading volume present power-law behavior.", "link": "http://arxiv.org/abs/1309.2416v1"}, {"index": 977, "title": "Statistical inference of co-movements of stocks during a financial crisis", "abstract": "In order to figure out and to forecast the emergence phenomena of social systems, we propose several probabilistic models for the analysis of financial markets, especially around a crisis. We first attempt to visualize the collective behaviour of markets during a financial crisis through cross-correlations between typical Japanese daily stocks by making use of multi- dimensional scaling. We find that all the two-dimensional points (stocks) shrink into a single small region when a economic crisis takes place. By using the properties of cross-correlations in financial markets especially during a crisis, we next propose a theoretical framework to predict several time-series simultaneously. Our model system is basically described by a variant of the multi-layered Ising model with random fields as non-stationary time series. Hyper-parameters appearing in the probabilistic model are estimated by means of minimizing the 'cumulative error' in the past market history. The justification and validity of our approaches are numerically examined for several empirical data sets.", "link": "http://dx.doi.org/10.1088/1742-6596/473/1/012008"}, {"index": 978, "title": "Short-term Market Reaction after Trading Halts in Chinese Stock Market", "abstract": "In this paper, we study the dynamics of absolute return, trading volume and bid-ask spread after the trading halts using high-frequency data from the Shanghai Stock Exchange. We deal with all three types of trading halts, namely intraday halts, one-day halts and inter-day halts, of 203 stocks in Shanghai Stock Exchange from August 2009 to August 2011. We find that absolute return, trading volume, and in case of bid-ask spread around intraday halts share the same pattern with a sharp peak and a power law relaxation after that. While for different types of trading halts, the peaks' height and the relaxation exponents are different. From the perspective of halt reasons or halt duration, the relaxation exponents of absolute return after inter-day halts are larger than that after intraday halts and one-day halts, which implies that inter-day halts are most effective. From the perspective of price trends, the relaxation exponents of excess absolute return and excess volume for positive events are larger than that for negative events in case of intraday halts and one-day halts, implying that positive events are more effective than negative events for intraday halts and one-day halts. In contrast, negative events are more effective than positive events for inter-day halts.", "link": "http://dx.doi.org/10.1016/j.physa.2014.01.044"}, {"index": 979, "title": "Contagion among Central and Eastern European stock markets during the financial crisis", "abstract": "This paper contributes to the literature on international stock market comovements and contagion. The novelty of our approach lies in application of wavelet tools to high-frequency financial market data, which allows us to understand the relationship between stock markets in a time-frequency domain. While major part of economic time series analysis is done in time or frequency domain separately, wavelet analysis combines these two fundamental approaches. Wavelet techniques uncover interesting dynamics of correlations between the Central and Eastern European (CEE) stock markets and the German DAX at various investment horizons. The results indicate that connection of the CEE markets to the leading market of the region is significantly lower at higher frequencies in comparison to the lower frequencies. Contrary to previous literature, we document significantly lower contagion between the CEE markets and the German DAX after the large 2008 stock market crash.", "link": "http://arxiv.org/abs/1309.0491v2"}, {"index": 980, "title": "Can we still benefit from international diversification? The case of the Czech and German stock markets", "abstract": "One of the findings of the recent literature is that the 2008 financial crisis caused reduction in international diversification benefits. To fully understand the possible potential from diversification, we build an empirical model which combines generalised autoregressive score copula functions with high frequency data, and allows us to capture and forecast the conditional time-varying joint distribution of stock returns. Using this novel methodology and fresh data covering five years after the crisis, we compute the conditional diversification benefits to answer the question, whether it is still interesting for an international investor to diversify. As diversification tools, we consider the Czech PX and the German DAX broad stock indices, and we find that the diversification benefits strongly vary over the 2008--2013 crisis years.", "link": "http://arxiv.org/abs/1308.6120v2"}, {"index": 981, "title": "Analyzing Herd Behavior in Global Stock Markets: An Intercontinental Comparison", "abstract": "Herd behavior is an important economic phenomenon, especially in the context of the recent financial crises. In this paper, herd behavior in global stock markets is investigated with a focus on intercontinental comparison. Since most existing herd behavior indices do not provide a comparative method, we propose a new herd behavior index and demonstrate its desirable properties through simple theoretical models. As for empirical analysis, we use global stock market data from Morgan Stanley Capital International to study herd behavior especially during periods of financial crises in detail.", "link": "http://arxiv.org/abs/1308.3966v1"}, {"index": 982, "title": "Fractality of profit landscapes and validation of time series models for stock prices", "abstract": "We apply a simple trading strategy for various time series of real and artificial stock prices to understand the origin of fractality observed in the resulting profit landscapes. The strategy contains only two parameters $p$ and $q$, and the sell (buy) decision is made when the log return is larger (smaller) than $p$ ($-q$). We discretize the unit square $(p, q) \\in [0, 1] \\times [0, 1]$ into the $N \\times N$ square grid and the profit $\\Pi (p, q)$ is calculated at the center of each cell. We confirm the previous finding that local maxima in profit landscapes are scattered in a fractal-like fashion: The number M of local maxima follows the power-law form $M \\sim N^{a}$, but the scaling exponent $a$ is found to differ for different time series. From comparisons of real and artificial stock prices, we find that the fat-tailed return distribution is closely related to the exponent $a \\approx 1.6$ observed for real stock markets. We suggest that the fractality of profit landscape characterized by $a \\approx 1.6$ can be a useful measure to validate time series model for stock prices.", "link": "http://dx.doi.org/10.1140/epjb/e2013-31116-3"}, {"index": 983, "title": "Asymmetric connectedness of stocks: How does bad and good volatility spill over the U.S. stock market?", "abstract": "Asymmetries in volatility spillovers are highly relevant to risk valuation and portfolio diversification strategies in financial markets. Yet, the large literature studying information transmission mechanisms ignores the fact that bad and good volatility may spill over at different magnitudes. This paper fills this gap with two contributions. One, we suggest how to quantify asymmetries in volatility spillovers due to bad and good volatility. Two, using high frequency data covering most liquid U.S. stocks in seven sectors, we provide ample evidence of the asymmetric connectedness of stocks. We universally reject the hypothesis of symmetric connectedness at the disaggregate level but in contrast, we document the symmetric transmission of information in an aggregated portfolio. We show that bad and good volatility is transmitted at different magnitudes in different sectors, and the asymmetries sizably change over time. While negative spillovers are often of substantial magnitudes, they do not strictly dominate positive spillovers. We find that the overall intra-market connectedness of U.S. stocks increased substantially with the increased uncertainty of stock market participants during the financial crisis.", "link": "http://arxiv.org/abs/1308.1221v2"}, {"index": 984, "title": "Dynamic evolution of cross-correlations in the Chinese stock market", "abstract": "We study the dynamic evolution of cross-correlations in the Chinese stock market mainly based on the random matrix theory (RMT). The correlation matrices constructed from the return series of 367 A-share stocks traded on the Shanghai Stock Exchange from January 4, 1999 to December 30, 2011 are calculated over a moving window with a size of 400 days. The evolutions of the statistical properties of the correlation coefficients, eigenvalues, and eigenvectors of the correlation matrices are carefully analyzed. We find that the stock correlations are significantly increased in the periods of two market crashes in 2001 and 2008, during which only five eigenvalues significantly deviate from the random correlation matrix, and the systemic risk is higher in these volatile periods than calm periods. By investigating the significant contributors of the deviating eigenvectors in different moving windows, we observe a dynamic evolution behavior in business sectors such as IT, electronics, and real estate, which lead the rise (drop) before (after) the crashes.", "link": "http://dx.doi.org/10.1371/journal.pone.0097711"}, {"index": 985, "title": "Unveiling correlations between financial variables and topological metrics of trading networks: Evidence from a stock and its warrant", "abstract": "Traders adopt different trading strategies to maximize their returns in financial markets. These trading strategies not only results in specific topological structures in trading networks, which connect the traders with the pairwise buy-sell relationships, but also have potential impacts on market dynamics. Here, we present a detailed analysis on how the market behaviors are correlated with the structures of traders in trading networks based on audit trail data for the Baosteel stock and its warrant at the transaction level from 22 August 2005 to 23 August 2006. In our investigation, we divide each trade day into 48 time windows with a length of five minutes, construct a trading network within each window, and obtain a time series of over 1,100 trading networks. We find that there are strongly simultaneous correlations between the topological metrics (including network centralization, assortative index, and average path length) of trading networks that characterize the patterns of order execution and the financial variables (including return, volatility, intertrade duration, and trading volume) for the stock and its warrant. Our analysis may shed new lights on how the microscopic interactions between elements within complex system affect the system's performance.", "link": "http://dx.doi.org/10.1016/j.physa.2014.10.039"}, {"index": 986, "title": "Gold, Oil, and Stocks", "abstract": "We employ a wavelet approach and conduct a time-frequency analysis of dynamic correlations between pairs of key traded assets (gold, oil, and stocks) covering the period from 1987 to 2012. The analysis is performed on both intra-day and daily data. We show that heterogeneity in correlations across a number of investment horizons between pairs of assets is a dominant feature during times of economic downturn and financial turbulence for all three pairs of the assets under research. Heterogeneity prevails in correlations between gold and stocks. After the 2008 crisis, correlations among all three assets increase and become homogenous: the timing differs for the three pairs but coincides with the structural breaks that are identified in specific correlation dynamics. A strong implication emerges: during the period under research, and from a different-investment-horizons perspective, all three assets could be used in a well-diversified portfolio only during relatively short periods.", "link": "http://arxiv.org/abs/1308.0210v2"}, {"index": 987, "title": "Quantum Tunneling of Stock Price in Range Bound Market Conditions", "abstract": "Applications of Quantum Tunneling effect have long gone beyond the traditional physical meaning. Initially created by Gamow to explain {\\alpha}-decay of nuclear particles, along the time, quantum tunneling found fertile domain of research in chemistry and recently in biology, where the new discipline of Quantum Biology emerges. The present paper extends the applicability of quantum tunneling to financial markets. In a recent paper [1] a time-independent equation for pricing the options having the underlying stock in a range bound markets is found. The equation is identical with a time-independent Schrodinger equation but incorporates elements of finance. The financial time-independent equation for option pricing is solved to explain a particular explosive violent movement of stock price in range bound markets. The aforementioned particular stock price movement is assimilated with a quantum tunneling effect. The probability of stock price to quantum tunneling out of the bounded region, known as transmission coefficient, is deduced. Quantum aspects of tunneling effect in financial markets are discussed. Recent evidences of price quantum tunneling in stock market are also shown.", "link": "http://arxiv.org/abs/1307.6727v1"}, {"index": 988, "title": "Are benefits from oil - stocks diversification gone? New evidence from a dynamic copula and high frequency data", "abstract": "Oil is perceived as a good diversification tool for stock markets. To fully understand this potential, we propose a new empirical methodology that combines generalized autoregressive score copula functions with high frequency data and allows us to capture and forecast the conditional time-varying joint distribution of the oil -- stocks pair accurately. Our realized GARCH with time-varying copula yields statistically better forecasts of the dependence and quantiles of the distribution relative to competing models. Employing a recently proposed conditional diversification benefits measure that considers higher-order moments and nonlinear dependence from tail events, we document decreasing benefits from diversification over the past ten years. The diversification benefits implied by our empirical model are, moreover, strongly varied over time. These findings have important implications for asset allocation, as the benefits of including oil in stock portfolios may not be as large as perceived.", "link": "http://arxiv.org/abs/1307.5981v2"}, {"index": 989, "title": "Modeling record-breaking stock prices", "abstract": "We study the statistics of record-breaking events in daily stock prices of 366 stocks from the Standard and Poors 500 stock index. Both the record events in the daily stock prices themselves and the records in the daily returns are discussed. In both cases we try to describe the record statistics of the stock data with simple theoretical models. The daily returns are compared to i.i.d. RV's and the stock prices are modeled using a biased random walk, for which the record statistics are known. These models agree partly with the behavior of the stock data, but we also identify several interesting deviations. Most importantly, the number of records in the stocks appears to be systematically decreased in comparison with the random walk model. Considering the autoregressive AR(1) process, we can predict the record statistics of the daily stock prices more accurately. We also compare the stock data with simulations of the record statistics of the more complicated GARCH(1,1) model, which, in combination with the AR(1) model, gives the best agreement with the observational data. To better understand our findings, we discuss the survival and first-passage times of stock prices on certain intervals and analyze the correlations between the individual record events. After recapitulating some recent results for the record statistics of ensembles of N stocks, we also present some new observations for the weekly distributions of record events.", "link": "http://dx.doi.org/10.1016/j.physa.2013.11.001"}, {"index": 990, "title": "Discovering Stock Price Prediction Rules of Bombay Stock Exchange Using Rough Fuzzy Multi Layer Perception Networks", "abstract": "In India financial markets have existed for many years. A functionally accented, diverse, efficient and flexible financial system is vital to the national objective of creating a market driven, productive and competitive economy. Today markets of varying maturity exist in equity, debt, commodities and foreign exchange. In this work we attempt to generate prediction rules scheme for stock price movement at Bombay Stock Exchange using an important Soft Computing paradigm viz., Rough Fuzzy Multi Layer Perception. The use of Computational Intelligence Systems such as Neural Networks, Fuzzy Sets, Genetic Algorithms, etc. for Stock Market Predictions has been widely established. The process is to extract knowledge in the form of rules from daily stock movements. These rules can then be used to guide investors. To increase the efficiency of the prediction process, Rough Sets is used to discretize the data. The methodology uses a Genetic Algorithm to obtain a structured network suitable for both classification and rule extraction. The modular concept, based on divide and conquer strategy, provides accelerated training and a compact network suitable for generating a minimum number of rules with high certainty values. The concept of variable mutation operator is introduced for preserving the localized structure of the constituting Knowledge Based sub-networks, while they are integrated and evolved. Rough Set Dependency Rules are generated directly from the real valued attribute table containing Fuzzy membership values. The paradigm is thus used to develop a rule extraction algorithm. The extracted rules are compared with some of the related rule extraction techniques on the basis of some quantitative performance indices. The proposed methodology extracts rules which are less in number, are accurate, have high certainty factor and have low confusion with less computation time.", "link": "http://arxiv.org/abs/1307.1895v1"}, {"index": 991, "title": "Wisdom of Crowds Algorithm for Stock Market Predictions", "abstract": "In this paper we present a mathematical model for collaborative filtering implementation in stock market predictions. In popular literature collaborative filtering, also known as Wisdom of Crowds, assumes that group has a greater knowledge than the individual while each individual can improve group's performance by its specific information input. There are commercially available tools for collaborative stock market predictions and patent protected web-based software solutions. Mathematics that lies behind those algorithms is not disclosed in the literature, so the presented model and algorithmic implementation are the main contributions of this work.", "link": "http://arxiv.org/abs/1306.5098v1"}, {"index": 992, "title": "Phase Transition in the S&P Stock Market", "abstract": "We analyze the stock prices of the S&P market from 1987 until 2012 with the covariance matrix of the firm returns determined in time windows of several years. The eigenvector belonging to the leading eigenvalue (market) exhibits in its long term time dependence a phase transition with an order parameter which can be interpreted within an agent-based model. From 1995 to 2005 the market is in an ordered state and after 2005 in a disordered state.", "link": "http://dx.doi.org/10.1007/s11403-015-0160-x"}, {"index": 993, "title": "Market-wide price co-movement around crashes in the Tokyo Stock Exchange", "abstract": "As described in this paper, we study market-wide price co-movements around crashes by analyzing a dataset of high-frequency stock returns of the constituent issues of Nikkei 225 Index listed on the Tokyo Stock Exchange for the three years during 2007--2009. Results of day-to-day principal component analysis of the time series sampled at the 1 min time interval during the continuous auction of the daytime reveal the long range up to a couple of months significant auto-correlation of the maximum eigenvalue of the correlation matrix, which express the intensity of market-wide co-movement of stock prices. It also strongly correlates with the open-to-close intraday return and daily return of Nikkei 225 Index. We also study the market mode, which is the first principal component corresponding to the maximum eigenvalue, in the framework of Multi-fractal random walk model. The parameter of the model estimated in a sliding time window, which describes the covariance of the logarithm of the stochastic volatility, grows before almost all large intraday price declines of less than -5%. This phenomenon signifies the upwelling of the market-wide collective behavior before the crash, which might reflect a herding of market participants.", "link": "http://arxiv.org/abs/1306.2188v1"}, {"index": 994, "title": "Tweets Miner for Stock Market Analysis", "abstract": "In this paper, we present a software package for the data mining of Twitter microblogs for the purpose of using them for the stock market analysis. The package is written in R langauge using apropriate R packages. The model of tweets has been considered. We have also compared stock market charts with frequent sets of keywords in Twitter microblogs messages.", "link": "http://arxiv.org/abs/1305.7014v1"}, {"index": 995, "title": "On a Heath-Jarrow-Morton approach for stock options", "abstract": "This paper aims at transferring the philosophy behind Heath-Jarrow-Morton to the modelling of call options with all strikes and maturities. Contrary to the approach by Carmona and Nadtochiy (2009) and related to the recent contribution Carmona and Nadtochiy (2012) by the same authors, the key parametrisation of our approach involves time-inhomogeneous L\\'evy processes instead of local volatility models. We provide necessary and sufficient conditions for absence of arbitrage. Moreover we discuss the construction of arbitrage-free models. Specifically, we prove their existence and uniqueness given basic building blocks.", "link": "http://arxiv.org/abs/1305.5621v2"}, {"index": 996, "title": "Approximately pi proofs that the stock market can approximate pi", "abstract": "We give three derivations of Polya's approximation for the expected range of a simple random walk in one dimension. This result allows for an estimation of the volatility of a financial instrument from the difference between the high and low prices, or, equivalently, for an estimation of pi from the ratio of the volatility to the difference between high and low prices.", "link": "http://arxiv.org/abs/1305.4408v1"}, {"index": 997, "title": "A Model for Stock Returns and Volatility", "abstract": "We prove that Student's t-distribution provides one of the better fits to returns of S&P component stocks and the generalized inverse gamma distribution best fits VIX and VXO volatility data. We further argue that a more accurate measure of the volatility may be possible based on the fact that stock returns can be understood as the product distribution of the volatility and normal distributions. We find Brown noise in VIX and VXO time series and explain the mean and the variance of the relaxation times on approach to the steady-state distribution.", "link": "http://dx.doi.org/10.1016/j.physa.2013.11.032"}, {"index": 998, "title": "A Fokker-Planck description for the queue dynamics of large tick stocks", "abstract": "Motivated by empirical data, we develop a statistical description of the queue dynamics for large tick assets based on a two-dimensional Fokker-Planck (diffusion) equation, that explicitly includes state dependence, i.e. the fact that the drift and diffusion depends on the volume present on both sides of the spread. \"Jump\" events, corresponding to sudden changes of the best limit price, must also be included as birth-death terms in the Fokker-Planck equation. All quantities involved in the equation can be calibrated using high-frequency data on best quotes. One of our central finding is the the dynamical process is approximately scale invariant, i.e., the only relevant variable is the ratio of the current volume in the queue to its average value. While the latter shows intraday seasonalities and strong variability across stocks and time periods, the dynamics of the rescaled volumes is universal. In terms of rescaled volumes, we found that the drift has a complex two-dimensional structure, which is a sum of a gradient contribution and a rotational contribution, both stable across stocks and time. This drift term is entirely responsible for the dynamical correlations between the ask queue and the bid queue.", "link": "http://dx.doi.org/10.1103/PhysRevE.88.032809"}, {"index": 999, "title": "Analysis of Realized Volatility in Two Trading Sessions of the Japanese Stock Market", "abstract": "We analyze realized volatilities constructed using high-frequency stock data on the Tokyo Stock Exchange. In order to avoid non-trading hours issue in volatility calculations we define two realized volatilities calculated separately in the two trading sessions of the Tokyo Stock Exchange, i.e. morning and afternoon sessions. After calculating the realized volatilities at various sampling frequencies we evaluate the bias from the microstructure noise as a function of sampling frequency. Taking into account of the bias to realized volatility we examine returns standardized by realized volatilities and confirm that price returns on the Tokyo Stock Exchange are described approximately by Gaussian time series with time-varying volatility, i.e. consistent with a mixture of distributions hypothesis.", "link": "http://dx.doi.org/10.1143/PTPS.194.43"}, {"index": 1000, "title": "Firm's Information Environment and Stock Liquidity : Evidence from Tunisian Context,", "abstract": "This paper analyzes the relationship between public disclosure, private information and stock liquidity in Tunisian context using a sample of 41 listed firms in the Tunis Stock Exchange in 2007. First, we find no evidence that there is a relation between public and private information. Second, Tunisian investors do not trust the information disclosed in both annual reports and web sites, consequently it has no effects on stock liquidity, in contrast with private information.", "link": "http://arxiv.org/abs/1304.4852v1"}]